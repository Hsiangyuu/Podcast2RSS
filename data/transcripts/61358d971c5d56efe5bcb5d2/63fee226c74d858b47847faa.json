{
  "pid": "61358d971c5d56efe5bcb5d2",
  "eid": "63fee226c74d858b47847faa",
  "title": "103.AGI远不止ChatGPT，跟顶尖学者聊大模型演变",
  "task_id": "kvjony7myoxynlx3",
  "transcription": [
    {
      "time": "00:00:05",
      "text": "Hello, 欢迎来到乱翻书，我是潘乱。这是一档关注商业科技和互联网的对话节目。ChatGPT犹如一枚核弹，在全球范围内掀起了AI狂潮。但ChatGPT其实是一个语言类的对话模型，它的成功来源于背后的大规模语言模型，在这些年取得了突猛进的进步。本期我们讨论和关注的问题焦点就是大模型，聊一聊ChatGPT的神通和局限，从大模型到通用人工智能，以及大模型的应用以及未来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:39",
      "text": "本场的嘉宾是兰州科技的创始人和CEO周明。现任中国计算机学会副理事长，创新工场首席科学家，曾经担任过国际计算语言学会的主席，微软亚洲研究院的副院长。另外一位嘉宾是清华大学计算机科学与技术系的长聘副教授，聆心智能的创始人黄明烈。他还曾经获得过中国人工智能学会吴文俊人工智能科技进步奖一等奖第一完成人。这两位嘉宾既是自然语言处理方向的学界大牛，同时也都是正在做大模型技术方向的创业者。本场讨论由极客公园fund PK策划，我跟张鹏老师共同主持。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:22",
      "text": "我们今天组织了五位在GPT，就在AI领域里面本身做长期的研究，同时在GPT这件事上有比较深入的思考，甚至已经开始做创新的实践的这样的创业者。因为今天是founder park这个社区里边，其实是有非常多的创业者的那我们也专门找出这几个五位专家，专家型的创业者来。真正的目标就是把ChatGPT这事儿我们聊得通透一点。因为这个热闹应该已经热闹的差不多了，对吧？就看热闹已经看的差不多了，咱得看点门道。我们今天的上半场是要聊通这个ChatGPT背后到底的技术的革命革新是什么。同时我们下半场会聊一聊ChatGPT，你觉得它很棒很热闹，咱们能拿它干嘛呢？在哪些领域里开始可以运用这个创新的技术往前去做创新的业务了，那下半场就会比较务实周明和民烈都跟大家打个招呼，稍微做做一下自我介绍。来，周明老师先来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:23",
      "text": "好，大家好，我是兰州科技的周明。然后我们公司在训练大模型，用大模型来支持各行各业，也从小模型开始，中模型、大模型，各种size的模型我们都在做，然后也是各种垂直领域的模型也在做，也希望跟大家多交流。",
      "speaker": "发言人3"
    },
    {
      "time": "00:02:43",
      "text": "好，明烈你也介绍一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:48",
      "text": "好的，大家好，我是来自清华大学的黄明烈，然后我们有一家创业公司叫林星智能。我们在做的是超拟人的AI大模型。主要是想在这样的一个大模型里边，把一些拟人化的特征和这个功能性结合在一起。未来我们是想去创建AGI时代的AGI companion，我们叫AGI的伙伴，然后去赋能各行各业。",
      "speaker": "发言人4"
    },
    {
      "time": "00:03:16",
      "text": "OK就是我觉得大家都在聊ChatGPT，但是好像很多人的关心都是在这个chat，就是在聊天这个事情是不是？它其实只是一个API，我们把这个事情给跑偏了。然后如果我们看这个D的话，它这种生成式它是不是只是大模型中的一种？其实是我好奇，比如说chat跟GPT是一个什么样的关系？然后现在除了GPT之外还有什么样的模型？就是大模型这些年都经历过什么样的一个演变历程？这里面的主要玩家都有谁？不可能只有OpenAI一家。我其实想先Q一下周明老师，两位都来回答一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:00",
      "text": "这个问题。好，我试着回答一下，其实大模型这件事不是今天ChatGPT冒出来还有这个大模型的事儿，而且ChatGPT也不代表所有的大模型。2017年那个transformer出来的时候，谷歌的传输M出来的时候，然后2018就是bird了。然后后面有GPT1、GPT2，然后GPT3就是GPT系列的。你还有T5系列的，咱们国内还有一些Albert，还有别的系列的那大概三种系列。第一个就是bird系列，就是encode only。然后第二个系列就是GPT，代表的就是decoder only。第三个就是那个T5，代表的就是encoder，又有decoder。然后这三大流派都是往各自的方向发展的，而且发展的也都不错。",
      "speaker": "发言人3"
    },
    {
      "time": "00:04:48",
      "text": "比如说我们做文本生成的话，当年我们用GPT two做的话，还不如那个T5做的结果好。T5就是输入输出，就encode decoder。我们做比如说做bird的话，你做比如说信息抽取，那birt的那个style的模型可能要比GPT的style的模型还会好。所以根据你的客户的需求，来决定用什么样的模型比较好，这是在过去的做法。",
      "speaker": "发言人3"
    },
    {
      "time": "00:05:17",
      "text": "现在来讲，这个ChatGPT1出来，首先它第一个字叫chat，第二叫GPT。他首先他把那个GPT3和InstructGPT在这个基础上他又做了更好的改善。所以你可以认为它是Better GPT3或者Better GPT3.5。他有chat能力，它通过chat来体现用户跟系统的一个交流，而且它更加流畅。然后从P2的角度，因为所有的人都可以通过chat来试，所以会取得很大的影响力。现在大家都觉得ChatGPT就是一切了。你要这么说，你可以说他有很多的能力，包括文本的理解，生成，对话的能力大幅度提升。",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:03",
      "text": "但是回到那个用户自己的业务流程流程里面，如果你不需要chat这个功能，你只是比如说简单的说你只需要sentiment analysis，这个我们通常称之为单轮的信息抽取问题或者分类问题。那你也许不需要ChatGPT，那它很重。那你用一个10亿的模型也许就跟ChatGPT就175B的模型在这个任务上也许就类似。可是你要说我要走AGI，因为我刚才所说的那个birt也好，GPT也好，就是原始的T5也好，都不是AGI。那ChatGPT有点要走出AGI的这个意思了，就是说暴露万象的任务它都能够体现出来。有的水平很高，有的水平不是那么高，没有专业的模型或者小一点的模型更好。但是他从用户的感觉来看，他是有点包罗万象的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:56",
      "text": "所以我总结一下我的解释，就是这个大模型是多元化多样化的这是第一第二就是如果你需要简单的任务，也不需要用这种复杂的大模型。如果你需要AGI，那么现在AGI ChatGPT是一个新的里程碑。好，我就先说这些。",
      "speaker": "发言人3"
    },
    {
      "time": "00:07:17",
      "text": "黄老师。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:19",
      "text": "好的，其实这刚才周老师讲的很全了。其实从任务来讲，现在大模型可以用在它有两类，一类是用用来做语义理解的，然后另外一类用来做生成的语义理解。就比如说birt这种，还有各种birt的变种。然后生成就是包括GPT是最典型的一类框架了。刚才从周老师也提到，如果从模型所以刚才讲的是从任务的角度分，一个是理解和一个是生产。然后他们有分别有不同的大模型或者是中小模型的代表哈那那生成就是我们知道因为生成更复杂一点，然后它要处理的数据规模量也更大一点，所以它通常来讲生成模型都是比较大的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:08:03",
      "text": "然后从从这个模型的结构来讲的话，它有这种只有encode了，所以就比较类似bird，也有encode，decode就类似。But然后T5这种模型是有一些它的编码器和解码器，它的结构是相对独立开的，像GPT这种就是编码和解码结构是完全一样的，叫decode only的这样一个结构。对它基本上是在技术上发展的就是这样的一个体系。在每个体系下它都有一些发展的路径。",
      "speaker": "发言人4"
    },
    {
      "time": "00:08:35",
      "text": "然后从开源的这个系统来讲，包括OPT，bloom、PPT这种模型，其实都是蛮多的，也有一些diversity。但是背后的基本的框架和逻辑都差不太多。只是说训练的数据是不是训练的充分，是不是用的很成功，为什么为什么今天的这个OpenAI在所有的大模型里边脱颖而出呢？这其实是跟它的发展的理念和路线是不一样的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:09:06",
      "text": "就是OpenAI的GPT从GPT two之后它就没开源了，它就变成了一个闭源的东西。然后在这个里边它又扶持了养活了美国的一个大众的一个生态公司，有很多的真实的IAPI的调用。然后这种调用的数据在它的迭代过程里边发挥了至关重要的作用。同时它又在数据团队去把这个数据对齐到人类的这个指令和人类的价值观上面来。所以我觉得这是为什么它在众多的模型里边脱颖而出的一个非常至关重要的一点。",
      "speaker": "发言人4"
    },
    {
      "time": "00:09:39",
      "text": "你看其他的开源模型，因为大家说实话训练了一个版本已经放在那了，可能公司会在自己的场景里面再去继续的优化和迭代，但是后续的版本是看不到的。所以其实我们也可以看到一个现象，就是说现在的这种OpenAI的这种API的调用的性能，其实都要远远好过开源模型能够做到的能力。也是因为背后的不断的调优和优化的这样的一个过程。",
      "speaker": "发言人4"
    },
    {
      "time": "00:10:06",
      "text": "我想追问一下，因为刚才两位专家我知道已经在特别希望能够用科普的方式让所有人去理解了。但我相信直播间里的可能90%的人还是没能太完全理解这些词儿。对，因为这些词儿你看我们里边涉及到transformer对吧？我们涉及到包括像bird GPT，然后我们涉及到大语言模型就是LLM等等。经常我们会看到这些词儿，但这些词儿我们怎么造句，把它摆起来，怎么描述这把这个词儿放在对应的位置，大家都能理解上下文。虽然我们不懂那个技术，但我们知道是怎么层关系了。要不中庸老师先来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:46",
      "text": "对我先说一下，你有几个关键的概念。第一个就是self supervised learning，中文叫自监督学习。有的人也会说成是无监督学习，反正我们就不使劲抠这个词儿，他是。什么意思呢？就不需要对训练语料做任何标注，就可以训练这个大模型。它的道理其实是非常简单的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:08",
      "text": "再科普一下，比如说我们前面的词出现了，我们预测下一个词。比如我想吃饭的概率，是不是我想吃杯子的概率？他俩相比的话，是不是吃饭的概率大于吃杯子的概率呢？那就是说你把语料找来之后，你就预测下一个词的正确性，对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:30",
      "text": "前N个词预测下一词正确性，那你搞个神经网络预测，那你肯定预测不准，那他有标准答案，然后你一算，那他预测不准，然后你调一下神经网络，下次希望他预测的更准一些。这个就是GPT的style，就是从左到右按顺序来做下一个词。那你要是word这个style就更容易理解了，它就是把某些词盖住，让周围的词预测当前这个词。那肯定假设我们搞一个神经网络，就是不要预测被盖住这些词，那预测错了的话也是一个信号来调整这个神经网络，当然你也可以把句子打乱，持续打乱，反正你看你能不能恢复回来。这种模型就是bot style模型，这是第一个。",
      "speaker": "发言人3"
    },
    {
      "time": "00:12:16",
      "text": "应该大家就了解怎么来做大规模语料，然后用这个大规模语料来训一个GPT的模型和board模型。其实科普来讲就这么简单。然后要不请黄老师接着再讲讲其他的科普，比如说transformer和其他的概念。",
      "speaker": "发言人3"
    },
    {
      "time": "00:12:36",
      "text": "对，就是transformer。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:37",
      "text": "对我刚才说。",
      "speaker": "发言人4"
    },
    {
      "time": "00:12:38",
      "text": "的PPT我觉得分的很清楚。周周老师刚才那个讲的很非常的准确，对吧？就是非常的科普了，也就是让大家理解了bird和GPT它两个不同。但是大家可能transformer、LLM、大语言模型什么，包括AGI和原来的这个非AGI等等词，可能很多人没概念。咱们怎么把这个剧造起来让大家能理解。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:01",
      "text": "要黄老师接着讲。",
      "speaker": "发言人3"
    },
    {
      "time": "00:13:03",
      "text": "黄老师那那我就直接造句。因为城市是一个底层的模型结构，对吧？我们可以这样造句，就基于transform这样一个神经架构，我们衍生出来了用于语言理解的bert之类的模型，以及语言生成的GPT之类的模型。所有的这些模型都可以统1到1个大规模语言模型的这样的一个范畴。",
      "speaker": "发言人4"
    },
    {
      "time": "00:13:30",
      "text": "因为现在的last scale的language model已经变成了说我们在整个在源处理里边的一个标准的一个工具。但实际上我们会出现一新的我生成和统一，就是理解和生成是可以完全统一的。就像刚才朱明老师介绍的，就是我们预训练任务？填空或者做扰动，其实都可以统一到同样的一个语言建模的一个范式下。所以也就是为什么LLM可以说是对T和GPT加了所有模型的一个统称。",
      "speaker": "发言人4"
    },
    {
      "time": "00:14:04",
      "text": "所以我在追问一个问题，是说他能够这么惊艳的这个能力的体现，和之前的这个对话的语言，对画的机器人，就是我们知道的chatbot相比，再到ChatGPT，因为我们刚才把GPT大概捋清楚，那到ChatGPT又比原来的那种chat board对话机器人就体现出如此进化的能力。这个核心靠。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:27",
      "text": "的是什么呢？好，我就试着解释一下，请黄老师纠正我或补充。就是ChatGPT跟我们以前做的，比如chat box，我们我们以前在微软做的小兵相比的话，它有几方面的能力的提升，而且是大幅度的提升。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:44",
      "text": "第一个就是用户的复杂query的理解。你可以前面说一个上下文，然后你再提个问题，这个理解的能力远远高于历史上所有的菜报的能力。大家可能都试过，比如说我有个朋友啊什么爱吃川菜，他喜欢到微软周围的饭店找一个，然后你给他推荐一个什么什么地儿，他真的把这件事都理解出来，然后给你推荐一个川菜的东西。要是以前的话，他就不知道你要问的是啥。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:16",
      "text": "以前的大家都知道做chat bard的话，有一种方式叫FAQ based，就是retail al based的chatbot。是我搞一大堆输入和输出。你来了个新的用户的输入，我去找一个最相近的。找到了之后我把它对应的答案给抽取出来，然后稍微改吧改吧，就输出出来了。这有一个问题，就是说你这个QA pair，q2 pair你收集的不全。因为这个所谓AGI的话，用户随便都可以说任何问题。那你不可能把所有的用户的问题都提前做好，答案摆在那儿。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:51",
      "text": "还有一个就是你匹配的时候，他是在语义层次匹配。我们过去做的话，按关键词匹配加点权重的话，有些问题也匹配不上，所以存在recall不足的问题。当然后来又发展了基于生成的一些chatbot，但是基于生成就无非就是又回到GPT。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:12",
      "text": "GPT two three的话，它远远低于ChatGPT的能力。刚才说了第一个就是复杂query理解的能力。第二就是多轮对话的建模能力，他可以很长轮，你N轮之后他还记得你前几轮问的问题。那么他有些重要信息会加在当前轮的回复之中，让你感到他是理解你上下文了。第三就是他在生成答案的时候，它是有层次的。生成答案就是有前因后果，有依据，然后有总结。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:46",
      "text": "这个过去的话我们做chatbot的话，只是一个简单的回复就行了。没有想到这个ChatGPT他回答的真溜，他把所有的地方，包括政治正确的地方都想到，然后最后一定有个summary让你看到，就是非常清晰。这一块我个人认为就比原来的菜爆了，不知道高多少个档次。那他背后那他到底怎么做的？就是ChatGPT的背后的核心的原理使然。",
      "speaker": "发言人3"
    },
    {
      "time": "00:17:16",
      "text": "您这有什么补充吗？王老师。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:19",
      "text": "好的，那那我也说一下我的理解。刚才张老师提到，其实这一代技术跟上一代技术还是一个本质的区别。上一代技术最主要的技术用的是基于检索，就是我有一个大的语料库，然后用户来了之后，从这个库里检索一些相似的一些query，然后把它们所对应的内容再返回。所以这是上一代包括可能也用了一些基于RN的生成的架构。但是因为RN的容量，各方面数据规模上不去，所以它的性能是比较局限的。所以上一代的技术基本上可以总结为基于检索语料库为主。所以它在相关性，各方面自然度，然后这方面都做的都比较差。",
      "speaker": "发言人4"
    },
    {
      "time": "00:18:01",
      "text": "这一代技术像是纯粹是基于大规模语言模型去纯生成的一种做法。那这种生成的做法，它是建立在语言模型的一个强大的一个能力之上的。就包括首先它有一个语言模型的一个基本的能力，它会在进一步在这个对话的数据场景下做一些优化。就比如说ChatGPT实际上是基于InstructGPT，然后进一步在对话的这个场景下，进行了刚才朱老师讲的，比如说上下文的更好的理解，复杂的这种问题的理解，以及在对话场景的一些数据的一些优化。所以它其实体现的是两大技术之间的这样的一个差异。",
      "speaker": "发言人4"
    },
    {
      "time": "00:18:41",
      "text": "当然这里边背后的一个大的一个成功，还是因为transformer这个架构，它能够去做到很大的容量以及很大的数据上，能够用上这种并行算力的这样的一个能力上去。所以我觉得也就是今天看到的很大的一个不同。你包括其实今新的ChatGPT可能只是一个影子。还有其实历史上还有像google的mina然后包括2022年他们发的number的这也是一个纯对话系统。它只是定位的是偏闲聊一点，但他的能力也是非常惊人的，其实完全达到类人的这样的一个水准。包括国内的play to，包括我们做的OPD这样的模型，都是基于这种新的这种大的一个生成式的这种底座来做的这样的一个对话的一个系统。所以其实并不是只有ChatGPT，可能大家只了解chat。实际上过去我们也有非常多非常成功的，就是21年22年这两年之间有非常多的无论是中文还是英文都非常不错的这种生成式的这种对话的这种系统出来。",
      "speaker": "发言人4"
    },
    {
      "time": "00:19:44",
      "text": "黄老师你们做的是感觉有些是偏向于情感的，就是零星是吗？但感觉ChatGPT有点类似于就是我其实想到两个机器人的形象，一个是那个钢铁侠里面的那个贾维斯，其实就感觉有点像这个ChatGPT。他是我的助手，就是高级的助手，可以帮我解决任何问题。另外一个就是一个人工智能电影和里面的那个玛塔莎对吧？他可以真的成为人的恋人。我好奇这两种AI它有什么不一样吗？我觉得非常好的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:16",
      "text": "那个ChatGPT它的定义就是一个通用任务助理，所以它是完全的是一设定是一个机器属性。你比如说你在他的回复里面经常会看，不能说他我只是个语言模型，我只是个AI我不能帮你回答一些情感或者什么什么决策之类的问题，对吧？所以它的设定是非常清晰的，就是一个机器。但实际上像贺这里边一些AI，实际上是说我们希望能够去满足人的一个情感，一个社交的一个需求。所以这是定位上是有明显的不一样的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:20:47",
      "text": "但是其实我我们未来我们认为AGI时代的这种对话智能体，应该是会统一这个功能性和这种情感性的。就是说拟人的特征。我们叫一个是功能性，一个是拟人的特征。所以也就是我刚才讲的AGI companion的概念是什么呢？就是我既要能够有能够完成处理机器功能性的一方面，同时也需要有情感社交需求的这一方面。那类人的这部分，把这两个统一在一起，我觉得才是代表整个AGI的这样的一个方向。",
      "speaker": "发言人4"
    },
    {
      "time": "00:21:19",
      "text": "但其实现在今天的OKI已经在开始在考虑这个事儿了。因为前段时间他们那个CEO就说我们希望通过特定的一些customize，然后去实现这种有personal的这种对话的这种行为。所以他们其实已经在考虑。",
      "speaker": "发言人4"
    },
    {
      "time": "00:21:33",
      "text": "但我看评论区刘江老师说从大模型角度看，这两种AI技术上其实没啥不一样，只是产品决策跟选型的问题，AGI就是啥都能干。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:43",
      "text": "我觉得不是，他还是有挺多不一样的。因为对情感和对社会连接的处理其实会挺不一样的。比如说像我们在做情感对话的时候，我们会借鉴一些心理学的一些东西，心理学的一些理论，一些话术？能够更好的去做情感的支持，多倾听，然后去做这个安抚。所以这里边是不太一样的东西。任务的话相对来讲就是说要更客观一点，然后情感的东西更主观一点。其实也情感方面也会面临更多，比如说伦理，就AI治理这方面的一些潜在的一些问题。",
      "speaker": "发言人4"
    },
    {
      "time": "00:22:18",
      "text": "OK如果我们聊回这个chat GP，我想问一下周明老师，为什么现在好像尽管大家都说要做这个方向，但是公开的对于ChatGPT的复现做的都不够好？这个事情它到底难在什么地方呢？就是就不够大吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:36",
      "text": "对他谢谢主持人问题，我们也在考虑这个类似的问题。首先那个OpenAI憋了个大招，他是从GPT3就没有开源，他是放了API。然后以上GPT就是GPT3.5更没有开源，然后恰好就是过去疫情这两年，我觉得它是GPT3的话是2020年，那到现在为止就是两年过去了，他中间都没有开源，所以这时候大家对它的理解本身就是小。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:06",
      "text": "然后他中间只冒出了一个叫infront GPT的一篇文章，那个写的还算详细，但是大概有百分之二三十的这是不可能在里面写的。有两种可能，一个是他当时也不知道什么东西work不work，他所以他写的你看他写的还是挺实在的。第二就是说他后面work的东西，他可能就不一定非得写了，还有一些你也知道有些trick的话，从科学上来讲没什么可说的，就是工程上做了很多傻活。比如说我标了更多的数据，我更多的任务，我做了很多的强化学习的那种人工的标注。那你说这些东西你要写文章的话也很难写，比如说我标注增加了十倍就能写出文章来？他也写不出这样文章。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:54",
      "text": "然后第二就是刚才说的，就是人工标注这块大幅度的增加。第二个就是他的语料训练语料的话，我们现在能拿到come cloud这些东西，那他这个语料可能是远远超过com crowd，他自己不说45T还是多少，然后他有些语料可能是不分享出来的那你也拿不到的那这是语料方面第三大的算力。大家都说这个open eye背后依靠微软，然后有巨大的算力，它可以来回试错。这个不行，他就改一改参数，然后又换一个trip，最后总能试出一个比较好的一个trick的组合，然后效果不好不错，他就是再放出来。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:37",
      "text": "而这些东西比较可怕在哪儿呢？这些功夫，这都是纯功夫。比如标注数据，标多少类问题，每一个问问题标多少个答案，这个没人能把握的好，他能把握好在哪儿？他GPT3放出去之后就有API就有很多人用他API做事情了，他就知道宽睿分布，他就知道哪些做的好，哪些做的不好。他以此为导向，他就可以有意识的有针对性的去标更多的数据。这个别人都不知道的要标哪类数据，要标多少数据。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:13",
      "text": "第二，他那个强化学习，他自己文章上说只标了多少几万，但我猜他肯定标的更多，他不一定说出来。然后他把强化学习那个强化rewarding那个score，他做的应该是非常好。机器出的结果他能断出谁更好，来做一个输出的选择。这一块你不去做的话，你咋知道你的rewarding那个函数做的好？",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:41",
      "text": "对，一般人也只能去试了，试来试去可能试到一个你认为不错的，但也不一定有ChatGPT那么强。所以我是觉得它背后无论是raw data还是标注data，以及标注data的分布和力度。再加上这种大规模的算力，再加上很多trick的组合磨练它得到目前的ChatGPT。而这个东西就是跟你讲了的话，你也得花这么大的功夫。所以这正是目前很多公司要复制，包括美国的公司，包括谷歌，不是那么轻易的达到目前的状态我就先说这些。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:22",
      "text": "听下来是一个非常具有规模效应的一个事情。就比如说把推荐引擎印在抖音的里面，他疯狂的往里面倒流量，然后有更多人发ugc然后他自然就可以比其他后来所有人做的更好。类似于这种概念吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:36",
      "text": "是的，他有一个飞轮效应。大家都知道他以前GPT3的时候就有一定的飞轮效应了，只不过他没有to c它是to b但是他应该有一定的飞轮效应。他可以跟某些厂商说，我可以看你的query，或者你可以告诉我你这个满意度程度等等。然后我知道你这厂商做什么，它内部产生小飞轮效应，而如今它放出来之后，这个to c的话一下子上亿用户用起来，这可是大飞轮效应。那一天产生那么多块，一天上千万用户发各种各样的query，他都知道大家关心什么，哪些做的好，哪些做的差，他就再及时的补充。这样的话他一迭代一飞轮起来的话，也许我们可能会做到他11月底12月初那个拆的GPT的水平。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:26",
      "text": "可是人家在迭代，那你就是一直在后头追你，没有飞轮效应的话，大概永远追不上你，除非有别的办法，但是不排除我们有别的办法是出来，我们也在想，比如说我们走更多的to b的模型，或者说我们有中文的一些特色，加入中国自己的新的数据。那ChatGPT都没有。那有可能我们的初始模型和chinese，ChatGPT for chinese可能一开始比他好点，那它的飞轮效应我们能稍微的克服那么一点点，看看有没有可能再追上一点，大概是这样的一个感觉。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:05",
      "text": "我也想把这个问题再延伸一下。因为刚才我觉得钟鸣老师把这个ChatGPT他为什么在今天追起来很难这个事儿，其实描述的非常清楚了。但是我刚才关注到一点，就是两位其实都谈到了AGI，就是通用人工智能。因为在ChatGPT刚出来之后，我记得就是最近在科技圈里都很热的两个人，一个王小川，一个李志飞，两位都看起来都是要投身其中的。然后我记得在那个之前曾经组织过一个线上的企业家交流。对在那场里面这两位是确实是率先跳出来说，这是看到了AGI的曙光。而在之前他们认为AGI是个遥远的东西，对吧？就是他我们要长期努力，而是个北极星。但现在你发现你已经看到这个光了，这是他们俩是确实在我认识人里最先提出来的。而今天两位我看都谈到了A就为什么我们会说ChatGPT是在AGI这个路线上，就通用人工智能上是有里程碑意义的，让大家会这么有感觉。我们怎么理解这件事要不民烈你能不能先给我们讲一讲？因为刚才你也谈到了这个事儿，站在AGI视角去看他。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:16",
      "text": "首先咱们得澄清一下，AGI有不同的定义，然后每个人的理解不一样，然后也有叫什么强人工智能的，但是这个词其实本质上并没有一个严谨的定义。所以我们今天讨论的A加，我们不妨把它redefine一下。就是说其实就是一个接近于类人的这样的一个水平的一个AI能力。",
      "speaker": "发言人4"
    },
    {
      "time": "00:29:36",
      "text": "所以在过去至少我现在这边从对话包括语言生成这个角度来看的话，2020年到2022年这个期间确实发生了巨大的进展。这个进展就是得益于transformer这种神经架构的这样的一个成功，因为它能够去首先模型的容量能够做到很大。就好比说我们能够做到人的大脑那么多的神经元，甚至10倍于更多的这样的神经元。另外就是它能够很好的运用上我们的数据，以及我们的并行的计算的这个框架，就GPU这种算力。所以可以看到就是说从2021年到，我记得印象特别清楚。就是2021年的我记得是三月份和4月份，就是谷歌发了一个mini，紧接着大概差不多一个月之后，facebook就发了一个叫blender的兑换系统。然后他们的当时的对话能力都挺惊人的，然后从拉姆达2022年，其实他的那个对话能力就更惊人了，基本上你可以认为是完全累人的这样一个水平。这样的一个能力其实在过去我们真的是不太敢想象的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:30:41",
      "text": "因为我们我们做对话做了这么久，我们觉得说之前的都做的很傻，就是费了好多力气，然后就是怎么着做做不上去，对吧？比如说最早我们基于RNN的那个框架。因为2015年google发了一篇最早的UNINN sequence的这个架构去做对话的那个论文，没有发表，但是引用数还挺。所以就是我们在RN时代，其实感觉不太能够去想象说我们今天能够做到这样的一个规模。和这样的一个能力。所以我觉得去讨论说类人的这样的一个交互能力，或者类人的这样的一个智能的水平是可以去讨论的。所以这是我的一个看法。",
      "speaker": "发言人4"
    },
    {
      "time": "00:31:21",
      "text": "为什么语言跟智能之间会有这么强烈的这个关系？就是我我理解AGI里边可能也有一部分大家关注的叫能够多任务的处理，对吧？就他不是个专用的能力，他是一个综合性的能力？然后你问他啥，他好像都能处理，让他写小说也行，让他写这个程序也可以。然后这件事儿好像又跟语言有很强的关系，我们怎么理解这件事？周斌老师可不可以帮我们解读？",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:47",
      "text": "对我觉得大家说认知智能。其实认知智能无非就是原理解，然后问题求解，什么辅助决策、什么预测、规划，这些就是认知智能这个语言在这里起到了最重要的作用。你第一语言理解，人家来了问题你得理解了，你才能回答问题。第二你回答的时候，你得用语言来组织。所以包括你在思考的时候有个推理链，也是用语言来体现的。所以我觉得NRP就约等于认知智能，约等于我们过去做NRP的人胆子也比较小，就是说NRP叫natural language processing of自然语言处理。",
      "speaker": "发言人3"
    },
    {
      "time": "00:32:31",
      "text": "就没几乎没有人敢说AGI的任何事儿。就是说你给我一句话，给我一篇文章，我告诉你这里主谓宾丁壮武是谁，然后讲的什么事儿，然后这里头有有哪些人物时间，他的一个大概的摘要是什么？这个就是我们所谓的语言的处理，还不敢都不敢说是理解，没人敢说理解。但这个语言处理就有工业界很多应用了这件这是好事也是坏事。好事就是说我们把目标收到一个可操作的范围，而且在工业界就有一些落地的机会。坏事就是说贫穷限制了我们的想象。就是我们做的东西就整天忙着这些东西，什么分个词，什么做一个情感分类，做个句法语义分析，最多做个简单对话什么这些东西。但是我最近观察ChatGPT，他们的雄心真的是令人敬佩，这也是我认为我们应该学习的地方。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:32",
      "text": "他就在很早的时间提出AGI，就是语言理解还没搞明白，语言处理也没搞那么厉害。刚大模型刚出来，你看那个谁，这个就算，他就是提出AGI了，他跟微软讲，我就要做的AGI你要不要投，对吧？那其实就是一张白纸，但是他想的非常长远。他认为我如果把互联网中的所有的数据抓下来，我如果把常见的任务都做了一定的标注，做多任务学习。那么我建一个模型，这模型叫GPT系列。然后我就对语言有充分的理解和生成能力了。我再加一个chat的能力，让老百姓能够感受到，我就是某种意义上体现出一个AGI的能力。所以现在也不敢说ChatGPT就是AGI的能力，但是让人感觉到他往AGI方向大幅度大跨步的去迈进了，然后也给大家带来了无穷多的一些期待。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:37",
      "text": "其实现在AGI可以大胆的去提出来了。AGI这个件事我自己认为它是一个逼近的过程，就是他不可能一步到位就到了AGI，那跟人的智能完全一样，不是这样的，他先解决一些简单的问题，再解决你觉得一般机器做不了，但人做的还能做，但大家从来不期待机器能做的好的问题。比如说写个作文，现在他向他所展示的，然后他再多做一点问题，比如算个小学数学的问题。那你觉得这种模型它又不是计算机，它能算小学数学题。然后你再一点点加他，最后把常见的任务，要么通过数据驱动方法加入到大模型的训练中使它自然体现了某种意义上的这这方面的能力。",
      "speaker": "发言人3"
    },
    {
      "time": "00:35:29",
      "text": "要么就刚才你也说了另一件非常重要的事，它有自然语言转code的能力，就是他自然语言可以转寇的能力。这个能力加上去之后，意味着现有的所有的扣的都可以为它所调用。这样一来的话，AGI真的是越来越逼近了，所以我个人认为这是他非常聪明的地方，就是数据驱动。但是又把扣的这些引擎和功能巧妙的能够纳入到里面。虽然他现在的这个自然源转扣的转的有时候错，有时候你不能马上执行。但是他假以时日的话，你可以认为只要人类已经编好了任何code都可以通过自然语言来指挥它，来实现人的某些智能。所以这两个数据智能加上这种透的智能加起来的话，我个人认为就真的是一点点的逼近AGI。我们应该勇敢的去拥抱AGI这件事。",
      "speaker": "发言人3"
    },
    {
      "time": "00:36:33",
      "text": "OK就是听下来，这其实已经算是通用人工智能AGI1个里程碑。就是我们看到真正的第一个里程碑，我们可以这么理解吗？或者说它其实就类似于iphone那个时刻，或比如说PC上网景浏览器的那个时刻。当然我们也看到像李志辉，他可能会觉得更多的会像那个智能云的OS，我不知道譬如说周明老师和黄老师你们怎么看？然后我们在上一场我之前聊的时候，比如说刘江老师其实认为这玩意儿以后可能就会像是苹果和安卓，其实就是AI时代的这个操作系统，或者说以后也会变成是中国和美国双系统这种。就是对于大模型这个事情，当然这是类比，我不知道像你们会怎么来看这件事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:18",
      "text": "我就简单说两句，请黄老师再补充几句。首先这件事意义重大，就是他把自然语言理解你不是说全解决了，他至少解决了我的理解，解决了70%成的功力。这个七成的功力解决体现在哪儿呢？我刚才说复杂篇理解，上下文建模，多轮对话建模，然后内容生成的时候有条有理体现这个思维链。第二他我刚才也说code和自然语言的交流，就产生无限多的想象空间，就是把物理世界和数字世界联络在一起了。大家都知道就是苹果也好，微软也好，都受益于新一代的用户界面的产生。当时你像苹果那个GUI一起，后来微软的windows一起，两个公司全都腾黑了。那你现在有一件事，假设你natural user natural language user interface能够做的非常的自如的话，那所有的device都会受益。而且它是变成自然人际交流，这是它的意义，比ChatGPT的意义可能还大。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:31",
      "text": "第二件事我就说那个code和自然源的交流。这件事儿就物理世界的跟数字世界的联动有更多的想象空间，已经远超自然源本身了。第三的话，用一套机制解决了自然语的理解、生成、翻译、转换等各项任务，在一个界面下统一完成这件事带来的无数的一些想象空间和未来的商业化的机会。我就说这些。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:03",
      "text": "那明烈也补充一下，你怎么看？",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:07",
      "text": "我觉得肯定是AGI的一个划时代的，或者是里程碑底下的一个事件，这是毫无疑问的。然后我觉得他相当于是第一次让所有的人用一种特别低门槛的方式展示了这个AI语言AI的能力。因为你看对话作为一种每个人他都是没有任何门槛就能去用起来的东西。因为对话是这个形式是最自然的对吧？所以我觉得他们也找到了一个特别好的一个全民科普的这样一个方式。然后把所有的复杂的任务都装在这样的一个模型里面，让大家都能够去用，能够快速的体量。我觉得这是一个特别棒的一个事情。",
      "speaker": "发言人4"
    },
    {
      "time": "00:39:50",
      "text": "所以未来我觉得未来我们能做成啥样，或者继续往前走会是怎样呢？我觉得很多情况下也不太能够预测。就比如说我们大家都在说GPT four到底是什么样的一个版本对吧？是不是有多模态，是不是有grounding，然后是不是说只是尺寸很大，能力更强还是什么？我非常赞同之前朱老师也提到一点，就是说我们可能不要老是因为一个跟随的思路。其实我们可能要再往前想一点，就想到说大家人家还没想到的事情，就比如说他们我估计他们内部再花很多的时间精力去解决这个事错误，就是一本正经的胡说八道这件事，对吧？他们可能已经有了比较不错的解决方案。如果我们今天的跟随者如果不提前去想这件事的话，那么永远落在别人的后面。",
      "speaker": "发言人4"
    },
    {
      "time": "00:40:40",
      "text": "我觉得这是我们去思考的一个点。另外一个点，其实这些事情对我们今天的学术研究，还有工业实践都带来很大的挑战。其实我们过去做了很多事情，可能就不再特别有价值，特别有意义。那当下我们就应该怎么去做我们的学术研究，怎么去做我们的商业应用，其实都是很值得我们去思考的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:41:03",
      "text": "我其实刚才听到看我们在这个直播间里也有人问。因为刚才我们说了一个说GPT的这个模型，它比原来的bert什么这方面它为什么会有优势？我们说了一个在两侧，原来是两端有问题，然后发现他就把一端解决完了，也能解决那个问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:23",
      "text": "准确的讲可能因为两位老师到时候可以补充，我要说的不对的话，以前是理解你也要搞，对吧？然后生成你也要搞。但现在说白了它就是核心以生成为核心，发现把生成做好了。因为它有rewarding的机制，它反过来也得把理解能够训练好。所以。他就变成了一个更明确目标的大模型，加上transformer提供了这样的一个能支撑大模型训练的很好的架构。所以他就在这个方向上形成了一些跟原来不一样的技术速度的突破。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:54",
      "text": "我当时曾经有过一个特别，就完全不用学术名词的解读，类你的解读我说出来以后，两位老师给一个修正，这样我觉得我们直播间里很多人就可以带走这段话。就是说以前的AI我们说的AI是刚上幼儿园就开始训练拧螺丝，他是全世界能把螺丝领的最好的这样的一个力量，但他这辈子只能领螺丝这样。但是今天我们说这个GPT他的这个思路是我们先让他上大学，先让他饱览整个世界上所有的知识，让他学会人类的语言，在人类的所有的知识的体系里面去给他弄到18岁。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:35",
      "text": "把他的这个认知的图谱和能力变成从一个大学生的水平出来。再通过定向的prom的训练，让他在更多的可能性上，比如说他既可以做客服，也可以做营销，也可以去写小说，也可以怎么着。就是因为他他已经是大学毕业了，他整体的素质到这儿了。在这上面我们再给他定向演示他怎么做是对的，他就能够变成一个做什么都很厉害。所以他这两件事儿是带来了在AI之前的AI和今天我们说的AGI带来了巨大的差别。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:08",
      "text": "就是你看这里我们基本没有什么用什么这个学术词，但我们把它类比为一个是少儿幼儿幼儿园就训练拧螺丝。一个是上完大学再让他进社会去做对应的工作去实习。实习完了变成你发现一个大学毕业的人可以干很多的事儿了，未必就是他那个专业。我不知道这个比喻是否恰当，或者有什么容易被误导了，要请两位专家来给定性一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:30",
      "text": "对我觉得这个张鹏讲的挺好的，其实就是形象的，就是这个意思就是我们因为比如说open I或者GPT这种东西，等于他把全世界所有的数据看了一遍。看完了之后他可能不求甚解，所以就是建模的水平到底有多高。不同的人，不同的公司有不同的建模水平。他目前这个知识萃取的能力就比较强。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:58",
      "text": "他看完了之后，他就能搞一个类似于大脑的，某种意义上类似大脑的神经网络。输入一个东西就能变成一个输出的东西。这个东西八九不离十，还靠就说明他的脑筋被这个大规模的数据翻听过了。他见的东西也多。他也是万金油，什么都能少一点，但是有的东西也是胡说八道，但是他表现的是有思维能力的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:44:27",
      "text": "好，这样的一个万金油的一个人，让他在做具体任务的时候，不能指望他能做的多好。因为他就是像您说的，他就是什么都会的，但什么都有可能不是那么精，这时候怎么办呢？他再拿这个任务有关的数据或领域有关的数据，带标的带标注的。就是用户输入这样的东西，你一定要输出这样的东西，这就要带标注的。好，拿那样的数据再在这个万金油的这个模型上再翻听在微调。微调来微调去，他就等于说我高中毕业的时候水平不懂计算机。但是我进了清华学计算机，学了四年我一直在微调，我就对计算机就非常有了解了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:45:10",
      "text": "但是其他的人学物理，那就是微调物理去了。你可以很难想象说像ChatGPT什么方面都达到了专家水平。第一不需要那样的话，训练代价和成本太大。第二也闹不到那么多专家的数据。最重要的是他的惰性，这人天生聪明，让他再学什么东西就快，这样能保证就可以。我补充你那大。",
      "speaker": "发言人3"
    },
    {
      "time": "00:45:37",
      "text": "模型下面，它会往什么样的方向去发展呢？是继续在这个参数上面去搞军备竞赛，还是说在数据里面去做更多的功夫，还是去我看他们都说要去解决那种事实可靠性的问题。然后比如说谷歌，他说那个没有全发布的一个原因之一，就是说在一些政治正确上的问题，他不能够完全保证说他做出不伤害用户的那些言论。我是好奇就是像这个大模型往下面是会往什么样的方向去发展，然他大概是一个什么样的逻辑？",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:17",
      "text": "黄老师要不你先说。",
      "speaker": "发言人3"
    },
    {
      "time": "00:46:20",
      "text": "好，我我我觉得这个问题比较难回答，朝哪个方向发展？我我我猜测是可能是应该是首先还是要把事实正确这件事要做的做到至少得做到80分，现在应该还差的比较远，就是对于一些事实类的问题比较胡说八道，我觉得这是一个比较fundamental的问题。那另外一个问题，就是我觉得有一些数学的精确计算现在也做的很不好。虽然他们现在修的很快，但是我觉得从理论上来讲，就是打补丁的方法可能需要有一些更跟符号，跟这种精确推理结合的一些更好的一些做法。当然这个东西不见得是说要在现在的大模型的整体的框架下去做。",
      "speaker": "发言人4"
    },
    {
      "time": "00:47:07",
      "text": "但是我们看到的问题就是这样的。第一个是说事实错误能不能很好的解决，对吧？第二就是说这种精确计算能不能很好的解决。第三个还有一个就是说从多模态的角度，就是说我现在我们还是多单模代码，那未来真实世界里面肯定是多模态的。所以而且多模态有很多应用的场景，那他可能一定会把这个模态的信息结合进来，就是说什么时候用，然后怎么用，然后用到什么样的程度，我觉得这是另外一个问题，但是他肯定大的方向肯定是这样，然后size会不会越来越大，一定程度会越来越大。但如果把多模态放进那肯定需要更大。",
      "speaker": "发言人4"
    },
    {
      "time": "00:47:48",
      "text": "但是我自己的观点不是说越大越好，还是说要跟你的问题和场景匹配。如果是通讯问题的话，它是是需要有一定的大的程度。但如果在领域和行业结合的，然后也不太需要那么大。还是给你的问题的复杂度，然后整个场景的数据量，任务的复杂度都是紧密关联的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:48:11",
      "text": "周老师有什么补充吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:13",
      "text": "我补充一下，我觉得黄老师讲的非常好了，我就不重复他他的一些观点了。我就从别的角度再补充一下。第一个是从所谓科学或者算法来讲，就是ChatGPT未来还能往哪儿发展。这个无非是大家能够看到，至少他文章是这么写的，insert GPT这么写的，无非那几个是叫什么label data，就super White。Learning它越来越强化，还有一个强化，学习它强化还有没有可能有其他的方面的新的算法的出现？我觉得肯定还是应该去探讨的。但是你让我说，可能我也说不出来。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:50",
      "text": "这一块应该有探索的空间的。包括神经网络transformer这个架构有没有可能再改进一下，或者说从结构优化上再进一步的优化。一个迹象就是昨天像昨天的meta搞的那个l lama，他自己就号称模型比那个GPT小很多，然后能力还强很多。假设他的是观点是正确的，那么实际上就是在模型训练和架构上也许又有新的发现了。这个也是可能未来应该发展的一个一件事。",
      "speaker": "发言人3"
    },
    {
      "time": "00:49:25",
      "text": "第二就是工程上要快速建立飞轮效应，而且快速的对log分析。因为log的话太多了，咱们说起来容易说搞飞轮效应，然后把log分析一下，然后把那个做的不好的东西再找人label一些data再会做的更好。但背后这个log分析本身，这就是一项又是另一个人工智能的问题了。就是每天这么多log来几十亿G或者是更多了。你把log自动分类做好，然后能够去有意识的做active learning，做重点标注。然后把标注的结果还要快速的learning到原来的模型里来体现效果。整个这个过程要自动化程度高要快。目前来讲，即使是ChatGPT，我觉得它也是有一定的困难的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:18",
      "text": "第三的话我是觉得就是从那种叫deploy层面，就是部署层面，因为这个模型太大，每一个query大概是三个美分左右，那实际上对任何一个公司都是巨大的一个要承受的一个成本，即使微软背后支持它也是一个巨大的成本。那他有没有可能把模型比如轻量化一些，或者说用的机器小一些，来解决这个效率问题，我认为这块也是ChatGPT应该考虑的问题。第四的话，我觉得就是落地问题，因为ChatGPT更像一个通用人工智能，但做具体任务都不太灵。比如说你让他做金融中的量化分析，你让他写个研报，写的是四十二非，你要是仔细看基本没法用，但是他写的好像还挺有条理。实际上就是在落地这一块，其实ChatGPT还有很大的空间要走，当然我们国内的创业者也有一些新的机会，这几个方面如果能够他很好的规划出来的话，可以期待他未来的ChatGPT的能力会更强。",
      "speaker": "发言人3"
    },
    {
      "time": "00:51:30",
      "text": "如果让我总结一下，就是刚才我们这个第一趴其实说了一些比较关键的东西。第一，到底我们怎么理解这个ChatGPT它带来的变革？首先我们看到就是说它能够把大学生造出来这件事儿实际上是一个根本性的东西。跟原来上来就是变成铜工拧螺丝，之前的AI说的什么人脸识别什么的就是不一样。在这一点的技术变化是非常值得关注的。而且刚才黄老师说到了，就是ADI的，一定要看到了ADI的到来。这个件事儿包括周老师也说要敢于提出意见，就是他的出现其实带来了ADI这件事儿可以登堂入室，大家在这方面开始更。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:09",
      "text": "努力的创新，甚至超越GPT这唯一的唯一一个单一方式的创新，这是非常重要的一个应该留给我们的东西，对吧？就是这里边未来是需要给他送研究生，还是让他赶紧进产业里去做实习呢？他既然是一个AGI的模式，但今天其实赢得了我们的关注是吧？这个大学生很酷，说话言谈举止很不错。但是你确实不信任他，进入到你的公司去干活，你不能把事儿交给他，因为他还嫩。所以接下来是让他生还是到产业里，我觉得是要值得探讨的，可能都有机会。同时周明老师我们刚才聊到了一点，就是昨天这个meta就facebook把这个拉玛开源了，这个东西会带来什么变化，这个也是我们只看到了开源，我们并不知道这个会带来什么变化，能不能帮我们推演一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:58",
      "text": "对，谢谢。这个问题facebook也是不甘寂寞，因为那个OpenAI包括微软他们俩是一伙的，然后谷歌是一伙的那facebook老3，就算还有未来老四可能AWS，那就咱们说的是世界上这个飞速杨乐坤同学他也是不服气的？大家看到他发了很多的那个话，发发了很多的退，然后让人感觉有点酸溜溜的。但实际上他以他的功力，咱们就是稍微八卦一下。以他的功力说非要做出一个ChatGPT，他下了决心做，我觉得是有可能的。第一个里程碑就是昨天他放了一个lama，这个lama的话是我的印象是600亿参数，但是他已经超至至少他的文章这么写的超过了GPT3。GPT3是175B1751，所以比它是它的2分之1的样子，它的能力又超越了，就是给人一种启示，就是模型size也不是完全的唯一的一个尺度，可能模型做的训的好，还有很多功夫可以下来，这是第一个。",
      "speaker": "发言人3"
    },
    {
      "time": "00:54:16",
      "text": "所以我们去研究了一下这个拉玛，拉玛的话它其实语料上没有太多，引入新的语料，比如说come on cross以英文为主的，然后C4的语料，还有一些book的语料等等等等，他很少有中文的语料。所以很多咱们国内的创业者说，我把拉玛当底座，然后continue出个中文。我个人认为至少现在目前不明朗，因为他对中文的支持是比较弱的。第二个就是他把模型开源，好像训练code并未开源，所以你要改一些东西，至少目前还改不了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:54:57",
      "text": "但是你应该关注，就是这件事应该关注。因为那个ChatGPT它实际上是构成了某种意义上的垄断，你也不知道他怎么做的，他也不开源。我们是实际上非常欢迎这个国际上的大公司挑战ChatGPT，并且走开源路线。这样的话受贿所有的人就所有的人都受贿。你继续做的，你去中文模型的逝去日文模型的，你做应用的，你都可以拿它当底座做，拿上你自己的专用数据做continue寸，然后就可以走到一些新的应用场景里。包括我们的大学教授应该也欢迎这种事情。",
      "speaker": "发言人3"
    },
    {
      "time": "00:55:38",
      "text": "ChatGPT出来之后，好多人就是说找我了，大学老师，还有NRP的领域的大学老师和同学就跟我说，说我们的工作基本没有了，我们价格没有了。因为你看他啥玩意儿都做了，他又不开源，我们想买上了做点小算法，然后再搞点新东西，发一篇SR文章都没有可能了。我们搞一些小数据，发个SR文章，人家说ChatGPT比你这都做的好，你还发什么劲呢？所以这个对大家来讲，实际上是有一点点的恐慌的。所以如果开源路线走的不错的话，我认为对整个学术界、工业界都非常有好处。也希望这几个大公司，包括meta还有像AWS能够起到好的带头作用。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:25",
      "text": "我先介绍一下，我们刚连进来的是起源世界的联合创始人CTO龙海涛，欢迎海涛。海涛跟大家打个招呼，自我介绍一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:36",
      "text": "三位老师好。然后直播间的朋友大家好，我是全世界的联合创始人CTO。我们公司的话是17年八月份就成立了，当时也是国内可能最早以AGI为定位的这样的一个公司。我们在17年到20年的话，主要是在做这个决策大模型。就基于这种游戏环境里面去把这个感知、认知、决策一体。然后在游戏环境里面去做这种复杂环境的这种动态决策问题。然后当时也是研发了星际争霸的AI然后这块的话也是在一个挑战赛上去达到一个职业水平的留言。然后在21年到现在的话，我们就是继续在做这个语言大模型这块，基本是在百亿参数的这样的一个大模型。这块我们主要是用在这种游戏，数字人，虚拟世界这里面的一些应用场景，这个大概是我们公司的一个情况。",
      "speaker": "发言人5"
    },
    {
      "time": "00:57:37",
      "text": "OK我接着问，刚才周明老师聊到了开源可能对于整个行业，整个世界的影响。如果我们把只是看中国，比如说像对于现在来说，因为我们知道很多人就是很多公司这真的感觉到又回到1415年，就是百花齐放，就是万众创业，万大众创万众创新。那个时候了，有很多人也想做这个相关的方向。但是我们好奇的问题是，就比如说现在中国做大模型，就比如说做这种生成式的AI来说，它的算力算法数据在国内这一块可能哪个方向上它更容易被卡脖子。然后现在中国大模型发展的话，它面临的核心挑战都会有哪些？就是之前之前好像周老师也聊过，可能那个简中网络的内容质量好像也不一定是一个特别严重的问问题。对那那问题可能来自于什么地方？这么多人都有涌过来，然后都认为这是一个堪比互联网和移动互联网的一个机会。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:45",
      "text": "对我觉得谢谢您。这个问题其实不同的人站在不同的角色应该有不同的思考。首先国与国之间的思考，中国和美国尤其中国世界第二大经济体，中美关系这么个糟糕，所有人工智能核心技术就跟当年的芯片操作系统一样。中国一定要有自己的，你不管我们落后还是领先，我们一定要有自己的这肯定是这是既定的国策。大家可能最近看中央领导人的一些讲话，包括科技部的一些部长的讲话，其实都是强调中国的这种自由创新，那其实主要是讲这个ChatGPT的能力，一定要建立中国自己的覆盖全球的ChatGPT的能力。当然start with中文，这是国与国那一个国家之内那做类似ChatGPT，还有不同的观点。",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:44",
      "text": "有的公司是做大模型的那他就应该把这个大模型底座做好，甚至超越ChatGPT。我个人认为就是未来肯定有巨大的空间是能够超越ChatGPT，大家也别太迷信他，我个人认为他就是吹响了下一代人工智能的号角，但绝不是终点，启迪大家去奋力前行，总有新的机会，有各种变种出现，甚至走出中国特色的这种下一代人工智能之路，这是所谓做大模型的公司。这样的公司一般是大公司，或者就是以大模型为己任的这种初创公司。包括我们在内，就是我们的情怀就是说我们要做一个世界上最好的中文的大模型。你可以笑话我们，你这个团队小，机器少。但是我们的情怀就是我们一天天吭哧吭哧的往前做，我们想尽各种办法克服机器算力问题、数据问题、落地问题。我们快速迭代有可能走出自己的特色。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:50",
      "text": "还有一类公司，它是做应用的那就没有必要去嚷嚷我要做什么ChatGPT，你就老老实实回到自己的业务上，你需要什么用什么。我刚才说了，如果你的业务只是简单的信息抽取，你就用bot这种T5或者GPT two，或者我们国内的很多模型，加上我们兰州的一些模型，就能做的非常之好了，跟ChatGPT1样的水平或者更高的水平。你如果只做单轮信息抽取的话，那其实这个答案已经在那儿。不需要去凑热闹去搞一个什么ChatGPT，然后粉饰太平，装点门面。不根本就不需要你该干啥就应该干什么。当然你要了解最新的技术进展。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:39",
      "text": "还有一类是做研究的，他不是做大模型的，他就是想研究其中的关键算法，这主要是学校和研究所。这样的话我个人认为，要么他跟大公司合作，人家给他底座用，要么他就找开源的东西用来试验他的某些算法。比如说举个例子，ChatGPT一本正经胡说八道，他搞一种算法说有效的抑制了一本正经胡说八道，可以发表论文甚至写专利。这里机会还是蛮多的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:09",
      "text": "还有其他的情感问题，就是有AIAI的伦理问题，还有比如说推理链的问题。他现在说有个推理链，但是可能有些场合做的不是太理想，那你又改进了。还有更重要的就是所谓的可解释性问题，你给人家一个答案，你要给充分的解释，信服令人信服。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:32",
      "text": "可能还有什么，你有自己的数据，自己的知识或者常识来融合到这种ChatGPT这样的大模型，不需要改模型，但是你可以动态把你的数据和业务链嵌入到大模型之中。现在不有这样的创业公司吗？这些我认为都是可以去考虑的一些几个方向。所以总而言之一句话，千万别一窝蜂都去做ChatGPT。这基本上99%的公司都是死路一条，也没有多大的意义。一定要针对自己的实际情况，然后审时度势，走出自己的一条路来。",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:13",
      "text": "海涛海涛你作为一看你这是。也在投身其中，也做了很多年了。你觉得在这一波ChatGPT打开的新浪潮，你们是怎么思考的？你们觉得你们要做的事儿是什么事儿？",
      "speaker": "发言人2"
    },
    {
      "time": "01:03:27",
      "text": "刚才就是回应一下，就是说中美这个差距的问题，因为我们确实做的比较早，确实在这五年的话感触还是很深的。如果要做AGI的或者是TGP这种前沿的科技研究的话，就推动这种科技发展，我觉得还是有两点是比较重要的。一个是资本的密度，一个是人才的密度。其实在我们过去几年的话，如果说中国一个公司要做一下的创新的话，其实在这个资本环境下还是比较难的。你可以看到的话其实最早拿了10亿美金，后来又拿了20亿美金，到最近的话又拿了100亿美金。其实很多的资本的话，它其实是一个因为看见才相信。可能在国外的话，它是一个因为相信才看见。对所以这块，当然这块现在大家都看到了x GPT的这种巨大的一个效应，所以资本这块的问题可能不会太大。",
      "speaker": "发言人5"
    },
    {
      "time": "01:04:23",
      "text": "第二个问题就是这个人才密度。人才的密度这块的话可能是更加的一个制约就中国这种底层的这种技术大模型的发展的一个要素。其实有人估算，就是说在全球范围内，如果在这种拿这种创业的资源下，能够有效率的去玩转这个高效的训练千亿参数模型。像这种人的话可能不超过200个，中国的话可能本土的话人应该是会更少。这块我觉得是一个很大的一个差距。而我们在21年的时候就开始招这种我们做白参数的这种大模型训练的人才会发现市场上是非常的少，几乎是没有说有有做过这个大模型训练的相关人才。这块我觉得是我们中国需要分析之类的。",
      "speaker": "发言人5"
    },
    {
      "time": "01:05:16",
      "text": "那至于我们公司的一个定位的话，我们确实是这定位在这种垂类的应用场景下面去做这种AI技术的这种小型化。然后把它能够应用在各行各业里面，这也是我们的一个定位。所以我们会在一些这种锤炼的大模型去做一些自研，或者是结合行业数据，然后形成这种数据飞轮，然后应用到像这种游戏，数字这种一些应用场景里面去。这个是我们公司目前的一个经营。",
      "speaker": "发言人5"
    },
    {
      "time": "01:05:46",
      "text": "蛮务实的。对，跟周老师刚才说，在今天虽然一波热潮下，但是大家该干啥这件事儿得想清楚，我觉得是完全在一个体系下。我觉得其实真正的创业者，大家其实都真的是能够看清楚这个ChatGPT，它既是一个你要去复现起来并不容易。但是同时你也看到也并不一定你奉献了，他就是你一定作为中间赢家，他可能还要结合自己的对应的领域，因为一会儿我们下半场还会有另外两位创业者加入进来。我们一会儿下半场的时候，会有更多在这方面的实际。用这一波AI变革，我们往前看，有什么商业的这种创新的空间会体现出来，这个我们下半场也会聊到更多。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:33",
      "text": "但刚才我看也有人在直播间提了个问题，说为什么ChatGPT能够在中文的理解和响应上也做的这么好？不是说他们在里边学的这个东西是相对很少的，占的可能连1%都不不到的。这个中文的材料他们是怎么做到的这块儿我也想听周明老师给解读一下。刚才我的直播间里有人在问这个问题。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:57",
      "text": "好，谢谢主持人的问题。这问题很有意义，首先语言有相通性，就是包括code语言跟英语以及中文、日文、法文，他们语言在语义层面是有相通性的。比如推理层面，语义理解方面。所以这个ChatGPT实际上大量的code语言，大量的英文，然后中文的即使这个量不是那么大，他已经借劲儿了，这是第一件事儿。",
      "speaker": "发言人3"
    },
    {
      "time": "01:07:27",
      "text": "第二，ChatGPT里面包括微软里面有很多中国人，我也认识其中的很多人，他们对中文非常了解，包括对咱们网信办在干什么都非常的了解。所以他会做出符合中国习惯的用户习惯的一些产品出来。所以大家也不要奇怪，你看包括他的回复都好像挺符合中文的特点的这是两个。第三的话，其实它的中文数据虽然相对英文少，可能他也有世界上最大的中文数据集可能啊。第四的话，我个人认为就是由于有了这个多语言模型和翻译的能力，他也会考虑把其他语言的一些数据转换成中文。这个多少我不能猜测，我觉得这是有可能做到的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:08:23",
      "text": "对我我其实在这里边大家也看到了一点，ChatGPT因为给大家带来很多的震撼。但刚才咱们也说了，他准确的形容就是这是一个看起来很让人惊艳的大学生。但是如果我作为公司的老板，就是你觉得这个人过来也是要经历实习复杂的培训，然后再验证。反正我现在不敢把主流业务交给，因为他很多时候还在一本正经胡说八道，对吧？而且他很多的数据，比如他给我的东西，可能是我要不验证真的是出错了。所以我们如果看一看他今天的这个就是这个这种的GPT的路线上，它的上能力上限我们有没有？可我们会看到一些能力上限吗？还是说就是不断的扩大这个模型，不断的暴力，不断把这个大的算力搁进去，它是无上限。可能延展这一块儿我觉得也听听，海涛不知道你们怎么看，因为你们也一直应该会关注，你可以先说着，然后再让这个周老师再补充。",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:23",
      "text": "对，我们确实是比较信奉这个大力出这条路子的。就是说底层的话是大算力大数据大模型，然后在网上的话就是基于这种深度学习，加强化学习去训练。",
      "speaker": "发言人5"
    },
    {
      "time": "01:09:36",
      "text": "就是你是暴力美，你在信奉者是吧？",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:39",
      "text": "对，确实我们在做，不管是之前做橘色大模型还是现在语言大模型，确实是可以看到它的智能是从量变到质变的一个过程，就涌现出来很多的一些智能的表现。现在我觉得它的上线肯定还远远没有被挖掘出来。因为一个像这种一个方法论下面的话，其实它是跟三方三个因素有关系。第一个是训练的一个时间，第二个就是这个模型的这个容量参数，第三个就是数据吧？他只要这三块的话，都可以往往上去推的话，他的这个能力还是可以再继续往上涨。包括现在像GPT，它目前就是code和这个多国语言的这样语料在里面。那下一代GP4肯定是有这种像图像、视频，对吧？这更多的这样的一些数据喂进去，这个数据量其实更大。这样的话其实它的智能会造成这种指数级的一个增长。因为据我们了解，就是GP4是会比现在这个GPT3.5和ChatGPT要好一倍的效果，这个是比较肯定的，就是他们内部人去去做出来这样的一个结论。所以来自。",
      "speaker": "发言人5"
    },
    {
      "time": "01:10:47",
      "text": "OpenAI内部的已经泄露出来的这样的一个类似于结论的东西了吗？",
      "speaker": "发言人2"
    },
    {
      "time": "01:10:53",
      "text": "对对对，就是要好一倍，所以这个东西现在目前还没有放出来。因为他昨天那个OKR其实也发了一个通用人工智能的一个宣言，里面就是可以看到它是其实是有意的在放缓。把这个比较更强的模型放出来，是让普通大众能有一个接受的一个过程。并且通过放一个比较差一点的模型出来以后的话，可以根据这样的一些用户的反馈来去及时的修正它的这样的一些部署，实施的这样的一个方法。所以可以期待一下，就是下一代这个大的模型应该是会有更强的一个水平了。那当然会GP56的话，它的发展速度应该是还是会是一个指数级的一个增长，这是我们比较相信的一个点。",
      "speaker": "发言人5"
    },
    {
      "time": "01:11:41",
      "text": "对。OK评论区有两个问题，我问一下钟鸣老师，用中文或者外文写提示词，它的处理会依据用户使用的语言来组织信息吗？还是会忽略用不使用的具体语言，而是使用统一的表达方式。因为现在这个GPT也能够给我们的感受是一本正经胡说八道。尽管中文的语料在里面占比非常少。",
      "speaker": "发言人1"
    },
    {
      "time": "01:12:04",
      "text": "这个就是用不同语言写prompt。这个写prompt的话，它激活这个ChatGPT的某些能力。那他有没有说单独区分说激活中文的能力或激活英文的能力，我个人是持怀疑态度的。我觉得就是把所有语言都当成一种语言，就是你输入啥，你输中文、英文、法文、德文，它ChatGPT都认为它是一种语言，他就是人类的某某某一种语言，他去走同样的机制来做的那当然你输入中文倾向于输出中文，那可能它内部有这样的机制。因为你在训练的时候是Q因为中文的Q和中文的r response是成对儿出现的，所以它也肯定是优先选出中文的这个关键词表。因为它有一个vocabulary，他要算所有语言的token加在一起是形成一个大的cabal，然后他要算下一个词出现的概率是多大，那肯定是中文前面是中文，后面出现中文的概率肯定是更大。所以我猜是不需要单独处理的。但是从工程角度要不要去单独处理呢？就是比如说有的语言弱，他给翻译成某种语言，然后用那种语言出结果，然后再翻回来，这个就不得而知了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:13:24",
      "text": "OK就是从原理上不区分。另外一个问题就是ChatGPT数据，它如果按照刚才海涛老师讲的那个，就是他循循着暴力美学这条路往前走，大力出奇迹。它的数据会越来越多，它会不会因为桑争而导致容杂，然后让它越来越不精确。就因为我们媒体老师写稿，其实不一定是信息掌握的越多越好，过了某个值之后就其实不知道怎么写了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:13:49",
      "text": "对我觉得暴力美学有几个角度。一个数据的暴力美学，就数据越来越多，还有神经网络的size parameter，就是这个参数量越来越多。当然这背后得用更大的算力来支撑，数据大家都知道到一定程度都差不多了，互联网就那么多数据在产生的数据，大概都是ChatGPT产生的数据。就是新的数据不一定增长那么快了，当然每时每刻都有增长，所以数据不停的在增加，这个趋势会议减缓。",
      "speaker": "发言人3"
    },
    {
      "time": "01:14:23",
      "text": "第二就是垂直领域的数据会逐渐增强，就是我们用ChatGPT或者类似的模型做垂直领域。有些垂直领域的数据是在网上查不到的，比如金融，人家这个数据不拿出来，那垂直领域的数据会在垂直领域的引擎上体现更好的作用。同样的数据大小下，他的这个神经网络的参数量可以再通过暴力美学，比如说再增加十倍百倍千倍，这个是完全可以做到的，只要你有这样的算力就去做。",
      "speaker": "发言人3"
    },
    {
      "time": "01:14:57",
      "text": "现在来讲它那个有限能力，刚才海涛也说有限能力就是这个泛化能力。随着神经网络的层数增加，也参数量加大的话，会体现更强的能力。像ChatGPT比GPT3的能力要更强。",
      "speaker": "发言人3"
    },
    {
      "time": "01:15:12",
      "text": "那是不是一直强下去？这个我不敢说，我觉得可能到一定程度会平缓。但不知道哪个地方是个基点，就是说再往下就不怎么涨了，涨那么一点点，但不值是吧？你加了十倍就涨了0.1的水平，那可能就不值。但是这个点到底在哪？我个人认为是没有人知道，只能发展到那个时候你才能有感觉。",
      "speaker": "发言人3"
    },
    {
      "time": "01:15:37",
      "text": "还有就是有没有可能这也是学术界关心的，说暴力出奇迹，我也服了，我知道是有可能暴力出奇迹，但是我在算法上能不能进行优化，使它对这个模型的size和训练的GPU的数量能够减少呢？就依赖减少？那意思就省点钱，省点事儿，这块我认为应该有很大的空间可以去做的，不是说我们就一直傻乎乎乎的线性增长这个GPU，线性增长或者是线性增长十倍、20倍、100倍增长那个参数量。也许到一定的程度下我们什么都不涨，但是我算法增长了他的能力也有可能有提升的可能，这个包括现在当然还要继续验证。有很多公司提出就用很小的GPU也能是一个很大的一个模型，也有多么强的能力等等，这个要进一步的验证。但是这个方向我觉得是引起大家关注的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:16:41",
      "text": "如果这个问题抛给海涛老师，就譬如说我们问通向IGA路径这个问题，就是因因为我我们现在感受到的其实大家都是被OpenAI给震住了。然后其实就是你模型越大数据越多，好像你就越牛逼一样。然后这如果是这样的话，就是在我们前面的叙述框架里面，其实就类似于推荐算法在抖音跟tiktok里面应用。后面的话就没有那么大的规模效应，想要追它就非常难。但是同时我们刚才也聊到，比如说facebook他发了一个更简单的，就是是用了更少数据量的模型，甚至在某一些的指标上还获得了一个更优。我是好奇是什么样的路径，然后这里面他是否还会，这已经是我们知道的通往那条路的最优解的全部吗？是否还有其他不同的路径，包括在通往这过程里的方向里面。就比如说像刚才黄明烈老师他聊的，他是否存在比如说就是有主观跟客观，然后有这种感性和理智的不同方向的这种差别呢？",
      "speaker": "发言人1"
    },
    {
      "time": "01:17:44",
      "text": "对，就是从这个方向来讲的话，刚才讲其实有部分。第一部分就是那刚才讲的就是那个一个结构，就是有一个很好的一个网络结构，这块这个是非常重要的。包括你可以看到从历史上就是从这个卷积网络到SDM叫做transformer的发明。就是一个好的结构。它是可以带来一个非常大的一个质的一个提升的那我相信form之后应该还会有类似的这种重量级的这种结构出来。这样的话可以大大提升我们的整个AGI的质的一个飞跃。",
      "speaker": "发言人5"
    },
    {
      "time": "01:18:17",
      "text": "这里面我比较期待能够出现一种可以进行这种推理，这种的神经网络结构能够出来。这样的话可能会对整个的像这个大模型的一些刚才说的事实性错误等等这样的一些东西的话，他可能会从根本上去解决这个问题。因为包括像我看内部的话，其实也是把AI推理这件事情当做是AJI最后的一个堡垒。现目前当然大模型可以表现出来一些浅层次的推理，但像这种深度的推理其实还是比较欠缺的那这块我觉得是比较期待这块能够有一个比较好的突破。但当然也是也是信奉它是一个连接主义，还是神经网络这样的一个范式上面去增长，去发明出来这样的一个结构。",
      "speaker": "发言人5"
    },
    {
      "time": "01:19:02",
      "text": "第二块就是数据，数据的话其实那个大是一方面，但是质量其实更重要吧？像meta最近发的那些数据来看，其实一些质量包括清洗好更好的一些数据出来以后，这个对大模型的表现是非常关键的。包括我们很多的一些模型，它其实是undertrained。之前的话我们像这种百亿模型，可能用个几百B的这种token就可以去训练。那它你可以看到meter发出来的话，它是用了一T的图像去训练的。然后它的数据叠加以后的话，它表现是会更好的。其实在网上的话，其实是在这种学习方法上能够有更好的一个就像刚才朱教授说的这样的话，有一些更好的一些发明，能够让这个算法的效率和他鲁棒性更强。就像我们当时做那个星际争霸这个比赛的时候，我们在这个里面做这个角色大模型，其实它是用了三三步骤。",
      "speaker": "发言人5"
    },
    {
      "time": "01:19:58",
      "text": "第一步是通过这个模仿学，就像这种TTP，它是用互联网的数据去做这种这种自监督学习对吧？这个可以达到一个人类的一个普通水平。在网上的话发现就是说结合强化学习，其实它是可以从一个普通水平然后到一个专家水平。这个是在不管是在之前打游戏阿法狗或者是pop star，包括现在这个ChatGPT，用RHF去增强更好的一个智能水平的，都可以发现就是用强化学习再去，如果你能够把这个强化学习用进去，那他一定是可以往上去优化的。然后从一个普通水平变成一个专家水平。",
      "speaker": "发言人5"
    },
    {
      "time": "01:20:39",
      "text": "那我们还比较期待，可能有一些更好的像这种演化算法出来。他不光是能够通过人的这种反馈去做，然后他是不是可以自己自我进化。当时我们打信息的时候，其实是建了一个像这种智能体联赛的这样的一个机制。这样的话可以把所有的智能体放在里面去他去训练。然后这样的话他见过各种各样的专利，所以他的鲁邦性会非常高。他就不是说只会打某一种战术，打某一种战术的话很容易被人的去探索到你的弱点，对吧？那可能这个就是不是一个很鲁棒的一个人。这块同样在这种语言大模型里面，是不是也会有同样的这种算法方法出来。这个我也是比较期待的，就是会不会有这种就算这样的话，如果说他找到一个AI可以自己对抗，然后自我进化的这样一个算法的话，那他有可能会把一些这种鲁邦性、可靠性，包括更高级的这种智能能够进化出来。",
      "speaker": "发言人5"
    },
    {
      "time": "01:21:38",
      "text": "今天既然做这种通用的大模型，其实看起来我们要追赶的这个历程是蛮长的，投入也不会低，对吧？当然我们也可以去努力讲有什么创新的方法，但总之是一个挑战很大的事儿。是不是现在我们就直接做这个垂直的领域的大模型，然后直接就通向把它变得更有用，在这某个能力上做强化，这个是不是就是更适合的方式呢？是不是我们就不在这个通用大模型较劲了呢？就是我用我从之前的一个感觉，我不知道对不对。好像说如果我们不在这个通用大模型上有这样的基础能力，我直接往一个垂直领域又变成一个提前训练米罗斯，你到最终是容易被一个通用模型直接干翻的，我不知道这个逻辑是不是这样。因为这件事决定了今天的中国的创业者们，在大漠这个GPT的之后的时代，就是他们到底应该怎么选择的这个问题。这个可能要听到周老师更专业的对这事儿的判断。",
      "speaker": "发言人2"
    },
    {
      "time": "01:22:35",
      "text": "好，谢谢。这个问题其实引起很多人的思考，就是你到底走什么？我先说站在国家的角度，国家的角度一定要做一个非常有水平的一个AGI。你可以不叫ChatGPT，你叫任何XYZ都行，它就是体现A键能力的语言大模型。这个基本上就是国内的大厂，或者说专门做AGI大模型的一些创业团队来做。全中国超不过我觉得超不过十家单位。我们也是勉励前行，也是在这里头继续做大模型的研究。",
      "speaker": "发言人3"
    },
    {
      "time": "01:23:14",
      "text": "第二个就是说你是做垂直领域的厂家，你希望得到一个这种大模型的基座，然后你对垂直领域进行翻译。如果你是这样的一个考虑的话，你最好跟以上这些公司进行合作，试图拿到他们的基座模型。然后在你的领域上继续加上新的数据。就这样的话形成一个生态链，就是基座有基座的模型的单位做。更多的是在把基座用在垂直领域，垂直任务上去做。",
      "speaker": "发言人3"
    },
    {
      "time": "01:23:51",
      "text": "所以说站在不同的人的角度是要做不同的决策的。第一种决策就是你真有实力，真有情怀，你还是应该去努力去做AGI的大模型，否则的话这个时不我待，人生能有几回博，你应该去做的。第二，你没有那么大的能力，也没有那么大的情怀，我就是想把我垂直领域快速做起来。我要见效，我要算成本的问题。那你就老老实实找一个底座大模型，然后在人家的基础上翻译就可以了。所以千万不要走一个极端说第一个就是说我非得做大模型，就把人和钱都耗耗进去。第二我非不做大模型，我明明有这个能力，有这个情况，我非不去做，我就赶紧走了一个垂直领域挣点小钱活下来。",
      "speaker": "发言人3"
    },
    {
      "time": "01:24:41",
      "text": "你就会发现长期以往的话，你会陷于一个局部最优。你再往前看的话，你就会被其他的公司或美国卡脖子。所以这个要审时度势，不同的公司有不同的策略的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:24:59",
      "text": "感谢周明老师说的非常的清晰，谢谢周明老师今天的参与，后续有机会还是要多请你来。今天周明老师也带着我们这儿非常明确的表达，他是有情怀有能力要参与到艺术大模型建立的top 10之一，大家牢牢记住这一点，给周东老师要鼓掌的。我觉得赶在今天做这件事。",
      "speaker": "发言人2"
    },
    {
      "time": "01:25:20",
      "text": "就是这个能力真的不容易。",
      "speaker": "发言人3"
    },
    {
      "time": "01:25:23",
      "text": "好，谢谢老师。",
      "speaker": "发言人2"
    },
    {
      "time": "01:25:25",
      "text": "好了OK今天就先聊到这边，大家可以订阅、点赞、评论、分享。如果还有什么想听我说的，欢迎在评论区互动留言，我们下期见。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "本次讨论深入分析了ChatGPT及其大型语言模型对商业科技和互联网领域的变革性影响，探讨了AI领域的长远发展，特别是通用人工智能（AGI）的可能实现路径。讨论强调了中国在数据、算法和算力方面的挑战与机遇，以及如何推动国内AI技术发展。此外，对话还涵盖了模型发展中的算法创新、模型规模与数据量增长、神经网络结构演进、学习方法的进步，以及AGI发展方向，突出了在面对大模型竞争时，创业者和企业应根据自身实力和目标，选择合适的AI研发路径。整体而言，本次讨论强调了创新、数据质量和学习方法在推动AI技术进步中的关键作用，并鼓励审慎评估自身情况，做出明智决策。",
    "qa_pairs": [
      {
        "question": "ChatGPT是否代表了所有大模型，以及目前有哪些主要的大模型系列？大模型的主要任务类型有哪些？",
        "answer": "ChatGPT并不代表所有大模型，大模型的发展有多元化的趋势。主要有三个系列：bird系列（只包含编码器）、GPT系列（decoder only）和T5系列（同时包含编码器和解码器）。其中，GPT系列和T5系列都有不同的变种，用于不同的应用场景。大模型主要应用于两类任务，一类是语义理解，另一类是生成语义理解，例如birt模型和GPT模型等。生成模型通常规模较大，因为其处理的数据规模更大。",
        "time": "00:04:00"
      },
      {
        "question": "大模型背后的训练理念和逻辑是什么？",
        "answer": "以OpenAI的GPT为例，从GPT 2之后它成为闭源并形成了一个社区生态，通过IAPI调用的数据不断迭代优化，并确保模型与人类指令和价值观对齐，这使得OpenAI在众多模型中脱颖而出。",
        "time": "00:09:06"
      },
      {
        "question": "如何理解自监督学习（self-supervised learning）和transformer模型？",
        "answer": "自监督学习是指在训练过程中无需对训练语料进行人工标注，模型通过预测下一个词的正确性来调整自身参数。而transformer模型是基于这种自监督学习原理，利用大规模语料训练出的底层模型结构，衍生出了诸如BERT和GPT等用于不同目的的语言模型。",
        "time": "00:13:03"
      },
      {
        "question": "ChatGPT相比于之前的对话机器人有何进化能力的提升？",
        "answer": "ChatGPT在文本理解、生成和对话能力上都有大幅度提升，它结合了GPT3和InstructGPT的优势，并增加了聊天功能，使用户与系统间的交流更为流畅自然。同时，ChatGPT在多种任务上的表现较为全面，给用户一种包罗万象的感觉。",
        "time": "00:14:04"
      },
      {
        "question": "ChatGPT相比上一代技术在哪些方面有本质的区别？",
        "answer": "上一代技术主要基于检索，从大型语料库中寻找与用户query相似的内容返回，同时可能结合了一些基于RN的生成架构，但由于数据规模和容量限制，性能有限。而这一代技术则是以大规模语言模型为核心，通过优化和扩展，如ChatGPT基于InstructGPT并在对话场景下进行改进，具备了更好的复杂query理解能力、多轮对话建模能力和生成答案的层次性与逻辑性。",
        "time": "00:18:01"
      },
      {
        "question": "ChatGPT在情感社交需求处理上与类似贾维斯或玛塔莎的AI有何不同？",
        "answer": "ChatGPT被定义为通用任务助理，具有明显的机器属性，不涉及情感或决策层面的问题。而像贾维斯或玛塔莎这样的AI更侧重于满足人的社交情感需求。不过，在AGI时代，预计对话智能体会同时具备功能性与情感性，即既能完成机器功能性的任务，也能满足情感社交需求。",
        "time": "00:20:16"
      },
      {
        "question": "为什么当前对ChatGPT的复现做得不够好，其难点在哪里？",
        "answer": "复现ChatGPT的难点主要包括：1）OpenAI没有开源GPT3及其后续模型，仅提供了API，导致外界对其内部机制理解不足；2）模型训练过程中人工标注数据量大幅度增加，以及使用了大量未公开的语料库；3）强大的算力支持，尤其是微软提供的大规模并行算力用于试错和优化参数；4）许多增强学习和奖励机制的调整细节并未对外公开，这些都需要大量的实践和针对性的数据补充才能获得接近ChatGPT的效果。",
        "time": "00:22:36"
      },
      {
        "question": "是否可以通过加大投入来缩小与ChatGPT的差距？",
        "answer": "虽然加大投入（如增加标注数据量、优化算法等）有助于提升模型性能，但ChatGPT的成功背后涉及了规模效应和飞轮效应，即通过大量用户反馈实时优化模型。尽管如此，仍有可能通过走更多to b的路线、利用中文等特色数据等方式，在初始阶段超越ChatGPT，然后通过自身的迭代和飞轮效应逐渐缩小差距。",
        "time": "00:27:26"
      },
      {
        "question": "在AGI（通用人工智能）视角下，为何我们会认为ChatGPT在通用人工智能上具有里程碑意义？",
        "answer": "ChatGPT在2021年到2022年间，由于transformer神经架构的成功应用，模型容量大幅度提升，结合GPU等强大算力，其对话和语言生成能力取得了惊人的进展，达到了接近类人的水平。这一突破使得人们在认知智能和语言处理领域看到了更广阔的应用前景，并且ChatGPT通过多任务学习和自然语言理解与生成能力，让大家感觉到它在某种程度上体现了AGI的特性。",
        "time": "00:29:36"
      },
      {
        "question": "语言理解和智能之间为何有如此强烈的关联性？",
        "answer": "语言理解是认知智能的基础，只有理解了问题才能回答问题；而在思考推理链时，也需要用语言来体现。因此，在AGI中，语言理解与生成能力至关重要，它不仅关乎能否理解并处理不同类型的请求，还涉及能否通过语言组织和表达思考过程。",
        "time": "00:31:47"
      },
      {
        "question": "GPT模型相较于之前模型的优势主要体现在哪里？",
        "answer": "GPT模型的优势在于它以生成为核心，通过奖励机制确保模型在训练过程中同时提升了理解和生成的能力。相较于传统的BERT等模型，GPT利用transformer架构，更明确地追求生成目标，从而在技术上取得了显著的进步。",
        "time": "00:41:23"
      },
      {
        "question": "AGI的发展是否可以类比于iPhone或PC上网景浏览器的时刻？",
        "answer": "AGI的发展确实是一个划时代的里程碑事件，就像iPhone或PC上网景浏览器的时刻一样，它以低门槛的方式向公众展示了AI语言模型的强大能力，尤其是通过自然语言接口与用户交互，实现了物理世界和数字世界的联动，带来了无限的想象空间和商业化机会。",
        "time": "00:38:31"
      },
      {
        "question": "对于未来AI发展，特别是GPT系列模型的演变，我们应该如何看待？",
        "answer": "未来AI的发展难以预估，但作为跟随者，应跳出跟随思维，积极思考尚未被广泛认知的新方向和技术突破。同时，学术研究和工业实践都需要适应新的挑战，不断探索和调整研究重点与应用策略。",
        "time": "00:40:40"
      },
      {
        "question": "AI技术如ChatGPT如何将大学生的通用能力应用到不同领域，并通过微调实现专业水平？",
        "answer": "ChatGPT这类技术通过看遍全世界的数据，形成较强的模型和知识萃取能力。它能将输入信息转化为接近正确的输出，表现出了某种程度的思维能力。但在具体任务上，由于其通才性质，可能无法做到非常精通。解决方法是针对特定领域或任务，使用带标注的数据进行微调，就像高中毕业后进入大学深造并针对计算机专业进行学习一样，从而在特定领域达到专家水平。",
        "time": "00:44:27"
      },
      {
        "question": "在工程实践中，如何解决大模型带来的挑战和问题？",
        "answer": "工程实践中需要建立快速反馈循环，包括高效分析大量log数据、进行active learning重点标注，并将标注结果快速融入模型训练中。此外，部署层面需考虑模型轻量化以降低查询成本，以及解决大规模模型在实际应用中的效率问题。落地方面，ChatGPT虽然展示了通用人工智能能力，但在执行特定任务时还需提高精准度，例如金融量化分析或撰写高质量研报等场景。",
        "time": "00:50:18"
      },
      {
        "question": "大模型未来的发展方向可能有哪些？",
        "answer": "大模型未来发展方向可能包括：1）首先确保事实正确性达到至少80分，目前在这方面仍有欠缺；2）改进数学精确计算能力，现有方法可能需要结合符号推理等更先进的做法；3）实现多模态输入输出，适应真实世界的多模态信息，并结合场景需求；4）模型大小会根据问题复杂度和数据量等因素适度调整，而非一味追求更大规模；5）探索新的算法和架构优化，例如神经网络transformer架构的改进，以及像Meta的Llama等更高效的小规模模型。",
        "time": "00:48:50"
      },
      {
        "question": "开源模型如lama对行业和学术界意味着什么？",
        "answer": "lama作为开源模型，打破了ChatGPT的某种垄断地位，为国内创业者提供了新的机会，他们可以在lama的基础上继续训练中文或其他特定领域的模型，推动模型在更多应用场景中的创新和发展。同时，开源对于学术界和工业界来说也有积极影响，可以促进多方参与和共同进步，有助于解决ChatGPT带来的技术恐慌，鼓励科研人员专注于创新和应用开发。",
        "time": "00:54:57"
      },
      {
        "question": "对于不同类型的公司，在这波ChatGPT热潮中应该如何思考和定位自己？",
        "answer": "对于做大模型的公司，应致力于打造或超越ChatGPT级别的大模型；对于做应用的公司，则需聚焦自身业务，选择合适的大模型技术如T5、GPT-2等，并结合行业数据进行优化；对于研究机构，则可选择与大公司合作或利用开源项目试验关键算法，发表论文或专利。同时，关注AI伦理、可解释性和数据融合等方面的研究也是关键方向。",
        "time": "01:01:39"
      },
      {
        "question": "在这一波ChatGPT热潮中，你们公司是如何思考并确定要做的事情的？",
        "answer": "我们公司定位在垂类应用场景下，做AI技术的小型化，并结合行业数据形成数据飞轮，将这些技术应用到游戏、数字人等场景中。我们在锤炼的大模型基础上进行自研，并针对具体行业需求进行训练和应用。",
        "time": "01:05:16"
      },
      {
        "question": "ChatGPT为何能在中文理解和响应上做得如此出色？",
        "answer": "首先，多种语言在语义层面上存在相通性，ChatGPT通过学习大量的英文和中文等多语言数据，借助多语言模型和翻译能力，提高了对中文的理解和回复质量。此外，ChatGPT团队中有许多对中国文化、习惯有深入了解的员工，这有助于产品更符合中文用户的使用习惯。",
        "time": "01:07:27"
      },
      {
        "question": "对于ChatGPT的能力上限，是否有可能存在理论上的上限，还是可以通过不断加大算力和数据量来实现无上限的增长？",
        "answer": "我们坚信大算力、大数据和大模型是推动智能提升的重要途径，目前的智能涌现确实来自于量变到质变的过程。尽管已有显著进步，但其能力上限尚未被充分挖掘，随着训练时间、模型参数和数据量的增加，智能水平将持续增长。未来像GPT-4这样的模型，随着更多类型数据的输入，其智能增长将呈指数级态势。",
        "time": "01:09:39"
      },
      {
        "question": "在GPT模型中，用户使用中文或英文写提示词时，处理方式是否会依据用户使用的语言来组织信息？",
        "answer": "GPT模型在处理不同语言时，并没有单独激活中文或英文的能力。它会将所有语言视为一种语言，并通过同样的机制来生成对应输出。尽管中文语料在模型训练中占比较少，但输入中文后，由于训练时中文Q和r response成对出现，模型可能会优先选择中文词汇表。不过，在工程层面是否需要针对不同语言做单独处理，例如翻译后再返回原语言生成结果，目前不得而知。",
        "time": "01:12:04"
      },
      {
        "question": "ChatGPT的数据增长和神经网络参数量增加是否会因为信息过载而导致精确度下降？",
        "answer": "数据和神经网络参数量的增长（即暴力美学）确实存在一定的上限。数据增长到一定程度后，新的数据增长速度会减缓；而垂直领域的数据会逐渐增强，特定领域的数据在垂直领域的引擎上表现更好。至于神经网络，随着层数和参数量的增加，其泛化能力会增强，但到某个点后可能趋于平缓。",
        "time": "01:14:23"
      },
      {
        "question": "是否存在优化算法以减少模型大小和GPU数量的方法，从而降低成本和提高效率？",
        "answer": "这是一个学术界关心的问题，目前的研究方向是寻找减少模型大小和训练GPU数量的同时保持甚至提升模型性能的方法。有一些公司提出即使使用较小的GPU也能训练出强大的模型，这有待进一步验证。但该领域有很大的发展空间，旨在减少资源投入的同时提升模型效能。",
        "time": "01:15:37"
      },
      {
        "question": "通向AGI（通用人工智能）路径中，是否存在除了大数据、大参数量之外的其他有效路径？",
        "answer": "除了大数据和大参数量外，还有其他可能的路径。首先，一个优秀的网络结构至关重要，例如从卷积网络到transformer结构的发明就是一个质的飞跃。未来可能出现类似结构，能大幅提升AGI的表现。其次，数据的质量同样重要，高质量的数据清洗和利用更多高质量数据训练模型能够显著提升模型性能。此外，结合模仿学习、强化学习等方法，以及演化算法，让模型自我进化和对抗，也是通向更高级智能的重要方向。",
        "time": "01:17:44"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探讨ChatGPT技术革新与应用前景",
        "summary": "本期节目聚焦于ChatGPT背后的技术革命及其广泛应用前景。讨论重点包括大模型的技术进步、ChatGPT的特性和局限性，以及迈向通用人工智能的路径。嘉宾们还分享了在不同垂直领域应用大模型的见解和实践，强调了将ChatGPT技术应用于创新业务的潜力。"
      },
      {
        "time": "00:03:16",
        "title": "大模型的多元化发展及ChatGPT的影响",
        "summary": "自2017年transformer模型推出以来，大模型领域经历了显著的发展，出现了包括GPT系列、T5系列及国内的Albert等不同模型。这些模型分别代表了encoder only、decoder only及同时拥有encoder和decoder的三大流派。ChatGPT的出现，结合了GPT3和InstructGPT的优势，不仅提升了对话能力，还展现了在文本理解和生成上的强大功能，为实现通用人工智能(AGI)迈出了重要一步。然而，对于特定任务，如情感分析，使用相对简单的小模型可能已足够。ChatGPT的成功展示了大模型在处理多元化任务上的潜力，但也指出并非所有情境都需要如此复杂的大模型。"
      },
      {
        "time": "00:07:16",
        "title": "大模型在语义理解和生成中的应用及发展",
        "summary": "当前大模型主要应用于语义理解和生成两大领域，包括像BERT及其变种用于理解，GPT作为生成模型的典型代表。生成模型因处理更复杂，通常模型较大。从模型结构看，有仅编码的模型如BERT，编码加解码的如T5，以及解码型结构如GPT。OpenAI的GPT系列通过闭源策略和不断的数据优化，以及将模型输出对齐至人类指令和价值观，从而在众多模型中脱颖而出。开源模型虽然众多，但由于缺乏持续迭代的公开版本，其性能往往不及持续优化的闭源模型。专家还强调了对非技术背景听众进行科普的重要性，提出需以易于理解的方式解释技术术语，如Transformer、BERT、GPT、LLM等，帮助大众理解其背后的逻辑和关系。"
      },
      {
        "time": "00:10:46",
        "title": "自监督学习及GPT、Transformer模型科普",
        "summary": "自监督学习，又称无监督学习，无需对训练数据进行标注，通过预测给定序列的下一个词或恢复被掩盖的词来训练模型。此方法模拟人类学习过程，通过神经网络的调整优化预测准确性，是GPT等模型的基础。此外，还提及了通过打乱句子顺序让模型尝试恢复的训练方法。接下来，探讨了Transformer等其他相关概念，暗示其在自然语言处理领域的关键作用。"
      },
      {
        "time": "00:12:35",
        "title": "Transformer模型及其应用解析",
        "summary": "对话主要围绕Transformer模型及其在自然语言处理中的应用进行，特别强调了BERT和GPT模型的区别与联系。讨论指出，Transformer作为底层模型结构，支持了多种大规模语言模型的发展，这些模型在语言理解与生成方面展现出了卓越的能力。进一步地，对话通过对比传统的基于FAQ的聊天机器人与现代的ChatGPT，强调了ChatGPT在处理复杂查询、多轮对话建模以及生成有层次的回答方面的显著进步。这反映出基于Transformer的模型如何推动了自然语言处理领域的革新，尤其是在理解和生成任务的统一范式下。"
      },
      {
        "time": "00:17:18",
        "title": "从技术演进视角看AI对话系统的发展",
        "summary": "对话内容主要探讨了AI对话技术的演进，区分了上一代基于检索的技术和当前基于大规模语言模型的生成式技术。上一代技术受限于数据规模和模型容量，性能有限，而当前技术依托于强大的语言模型和Transformer架构，能够实现更自然、更复杂问题的理解和回答。此外，还讨论了AI在功能性与情感性方面的不同定位，以及未来AGI的发展方向，即融合功能性和拟人特征的对话智能体。最后，指出了情感对话处理与任务型对话处理之间的技术差异和面临的挑战。"
      },
      {
        "time": "00:22:18",
        "title": "探讨ChatGPT复现难点与背后原因",
        "summary": "复现ChatGPT的挑战在于其技术细节未公开，尤其是从GPT-3开始未开源，仅提供API。复现难度还源于对模型理解的限制、高质量语料的获取、大规模算力的支持，以及强化学习中数据标注的技巧和分布。这些因素共同构成了复现ChatGPT的复杂性。"
      },
      {
        "time": "00:26:21",
        "title": "探讨AGI及ChatGPT的飞轮效应和里程碑意义",
        "summary": "对话中提到，推荐引擎如抖音内的应用展现了显著的规模效应和飞轮效应，通过持续的流量注入和用户生成内容(UGC)的增加，能够不断优化和提高推荐效果。进一步讨论了GPT-3及其向消费者(to C)的转变所带来的巨大飞轮效应，及其对理解用户需求和满意度的重要性。同时，探讨了在追赶ChatGPT的过程中，通过聚焦于特定领域(to B)或引入特定语言和文化元素来实现突破的可能性。此外，对话中还讨论了AGI（通用人工智能）的重要性及ChatGPT在这一领域的里程碑意义，如何从AGI的视角理解和评估当前技术进展。"
      },
      {
        "time": "00:29:16",
        "title": "探讨AGI及语言处理技术的进展",
        "summary": "近年来，随着Transformer神经架构的成功应用，人工智能在对话和语言生成方面取得了巨大进展，特别从2020年到2022年。这一进展使得AI模型的容量得以大幅增加，能够处理海量数据并利用并行计算框架，如GPU，从而提升了对话能力，使其接近甚至达到类人水平。此外，通过多任务学习和处理能力，AGI不再仅限于单一功能，而是能处理多种任务，如写小说和编写程序，这显示了其综合性的能力。语言处理和理解在此起到了关键作用，不仅是信息传递的媒介，也是实现认知智能的基础。最后，通过提及ChatGPT的创新和对AGI的追求，指出尽管目前的进展尚未完全达到AGI，但已显著推进了AI技术，提高了人们对未来发展的期待。"
      },
      {
        "time": "00:34:36",
        "title": "探讨AGI的发展里程碑及其意义",
        "summary": "对话中提出AGI（通用人工智能）的发展是一个逐步逼近的过程，通过解决从简单到复杂的问题，展示了如何通过数据驱动的方法和自然语言与代码的转换能力，推动AGI的进展。强调了自然语言理解的突破，code与自然语言的交互，以及统一处理自然语言理解、生成、翻译和转换等任务的机制，这些被认为是AGI发展的重大里程碑。此外，还提到了通过对话形式展示AI能力，降低了AI使用的门槛，促进了全民科普，并对未来的发展和挑战提出了展望。"
      },
      {
        "time": "00:40:40",
        "title": "探讨GPT模型对AI研究与应用的影响",
        "summary": "在当前的学术研究和工业实践中，GPT模型相比于传统的BERT模型展现了显著的优势，尤其是在生成任务方面。GPT模型的这种进步，不仅改变了人工智能的研究方向，也为商业应用带来了新的可能性。GPT通过整合大量数据进行训练，从而能够处理多样化的任务，如客服、营销和创作等，表现出类似人类的灵活应对能力。这种转变强调了从基础的技能训练向全面知识学习的转变，预示着人工智能领域的一大进步。同时，这种通用性的增强也为特定领域的深化应用提供了基础，通过微调可以实现更专业化的功能，展示了未来AI研究与应用的广阔前景。"
      },
      {
        "time": "00:45:37",
        "title": "大模型未来发展方向探讨",
        "summary": "大模型的未来发展方向集中于几个关键领域：首先，提高事实正确性至至少80分，解决目前对于事实类问题的回答不准确的问题。其次，改善数学精确计算能力，寻求理论上的突破，可能需要与符号和精确推理相结合的方法。此外，多模态的发展被认为是大方向，适应真实世界中多模态信息的处理和应用。模型的大小可能会继续增大，以适应多模态的需求，但强调模型大小并非唯一考量，应与问题复杂度和场景数据量相匹配。同时，探讨算法和架构的可能创新，以及在工程上如何快速迭代和优化模型，以解决效率和成本问题。最后，大模型在具体领域的应用和落地也是一大挑战，需针对特定任务进行优化。"
      },
      {
        "time": "00:51:30",
        "title": "探讨ChatGPT带来的变革与挑战",
        "summary": "对话中首先讨论了ChatGPT如何标志着人工智能技术的根本性变革，特别是其在生成内容方面的突破，以及这一进步对教育、产业和学术界的影响。随后，讨论转向了其他科技公司如Meta（Facebook）在AI领域的动作，特别是其开源的模型和技术对行业的影响，以及这种开放性对于促进技术进步和创新的重要性。最后，一位嘉宾介绍了他的公司，讨论了他们如何在AGI领域工作，并应用这些技术于游戏、数字人和虚拟世界等领域。"
      },
      {
        "time": "00:57:36",
        "title": "中国大模型发展面临的挑战与策略",
        "summary": "在探讨中国大模型发展过程中，观点指出，尽管国内外对于AI技术，特别是大模型的研究与发展投入巨大，中国在此领域仍面临诸多挑战。首先，中美之间的技术竞争加剧，强调了中国需要发展自有核心技术的紧迫性。对于大模型的研发，存在资本和技术人才两大挑战，尤其是高效训练大模型所需的专业人才稀缺。同时，对于不同公司和研究机构而言，应根据自身实际情况，选择合适的发展路径，不必盲目追求复制现有大模型，而是应探索具有中国特色的技术创新之路。此外，还强调了开源合作、技术创新以及结合实际业务需求的重要性，鼓励在AI伦理、算法优化、可解释性等方面进行深入研究。"
      },
      {
        "time": "01:05:15",
        "title": "探讨ChatGPT技术及其对商业创新的影响",
        "summary": "对话集中在如何将AI技术小型化并应用于各行业，同时探讨了ChatGPT在中文理解与响应上的优异表现。指出语言间存在相通性，ChatGPT能有效利用少量中文数据达成良好效果。此外，讨论了ChatGPT的潜在商业应用和挑战，强调了对新技术的实际应用需要经过验证和培训。"
      },
      {
        "time": "01:09:22",
        "title": "探讨人工智能模型的发展与多语言处理",
        "summary": "在人工智能领域，特别是语言大模型方面，大力出奇迹的道路得到了信奉，主要依靠大算力、大数据和大模型的支撑。通过深度学习和强化学习的训练，模型展现出从量变到质变的智能提升，如橘色大模型和语言大模型的发展。未来，像GPT这样的模型将继续进化，纳入更多样的数据如图像、视频等，从而实现智能的指数级增长。特别提及GP4预计将比GPT3.5和ChatGPT性能提高一倍，显示出对人工智能能力边界的不断探索和扩展。同时，讨论了ChatGPT对不同语言输入的处理方式，表明了对所有语言采用统一处理机制的可能性，尽管中文的处理可能因其训练数据占比小而表现不同。这一讨论反映了当前AI技术发展的一个侧重点，即如何让模型在理解和生成多语言内容时更加智能和准确。"
      },
      {
        "time": "01:13:23",
        "title": "探讨ChatGPT的数据增长与算法优化",
        "summary": "随着ChatGPT等模型对数据量的需求日益增加，数据的暴力美学导致了对更大算力的需求。尽管数据量和神经网络参数量的增加提升了模型的泛化能力，但这种提升可能达到一个临界点后趋于平缓。同时，对于垂直领域的应用，特定领域的数据强化了模型的表现。此外，探讨了算法优化的可能，以减少对GPU数量和模型大小的依赖，这为降低运行成本和提升模型效率提供了新的视角。"
      },
      {
        "time": "01:16:40",
        "title": "探讨AGI发展路径及模型优化方向",
        "summary": "讨论重点在于分析当前人工智能尤其是AGI（通用人工智能）的发展方向，以及如何通过模型结构创新、提高数据质量与量、强化学习方法等途径来优化AI模型。特别强调了结构优化、数据的质量与量、学习方法的创新对于提升模型性能的重要性。同时，也探讨了是否应专注于通用大模型的发展，还是转向垂直领域的专业模型，以及这些决策对于未来AI研究方向的影响。"
      },
      {
        "time": "01:22:34",
        "title": "周明老师谈AGI大模型发展策略",
        "summary": "在对话中，周明老师分享了关于AGI大模型发展的见解，强调了不同主体在大模型研究与应用上的策略差异。他认为，有能力与情怀的团队应致力于开发先进的AGI大模型，而资源有限的团队则可基于现有的大模型进行垂直领域的创新。同时，周明老师也提到了合作的重要性，建议资源不足的团队与大模型研发单位合作，以促进生态链的形成与发展。他还警告不要陷入局部最优的陷阱，强调了审时度势、根据自身能力与条件制定合理策略的必要性。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "引发全球AI热潮"
                },
                {
                  "children": [],
                  "content": "语言类对话模型的突破"
                }
              ],
              "content": "ChatGPT的影响"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "大规模语言模型的进展"
                },
                {
                  "children": [],
                  "content": "从专用模型到通用人工智能"
                }
              ],
              "content": "大模型的发展"
            }
          ],
          "content": "主要议题"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "兰州科技创始人&CEO"
                },
                {
                  "children": [],
                  "content": "中国计算机学会副理事长"
                }
              ],
              "content": "周明"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "清华大学副教授"
                },
                {
                  "children": [],
                  "content": "聆心智能创始人"
                },
                {
                  "children": [],
                  "content": "人工智能学会吴文俊科技进步奖获得者"
                }
              ],
              "content": "黄明烈"
            }
          ],
          "content": "嘉宾介绍"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "基于transformer架构"
                },
                {
                  "children": [],
                  "content": "大规模语言模型训练"
                }
              ],
              "content": "ChatGPT的技术革新"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "生成式AI的能力展示"
                },
                {
                  "children": [],
                  "content": "处理复杂query的理解"
                },
                {
                  "children": [],
                  "content": "多轮对话建模"
                }
              ],
              "content": "应用与局限"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "大模型的多元化发展"
                },
                {
                  "children": [],
                  "content": "通用人工智能的探索"
                }
              ],
              "content": "未来方向"
            }
          ],
          "content": "讨论要点"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "语言理解与生成的统合"
                },
                {
                  "children": [],
                  "content": "多模态融合"
                }
              ],
              "content": "AGI的实现路径"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "数据质量与多样性"
                },
                {
                  "children": [],
                  "content": "模型的可解释性与可靠性"
                }
              ],
              "content": "面临的挑战"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "垂直领域应用"
                },
                {
                  "children": [],
                  "content": "情感理解与处理"
                },
                {
                  "children": [],
                  "content": "个性化与定制化服务"
                }
              ],
              "content": "创新机会"
            }
          ],
          "content": "未来趋势与挑战"
        },
        {
          "children": [
            {
              "children": [],
              "content": "ChatGPT代表了AI发展的一个里程碑，推动了对通用人工智能的深入探索。"
            },
            {
              "children": [],
              "content": "大模型技术的进展对行业未来发展具有重要意义，同时面临多项挑战。"
            },
            {
              "children": [],
              "content": "未来的AI研究与应用需聚焦于解决实际问题，探索新的创新路径。"
            }
          ],
          "content": "总结"
        }
      ],
      "content": "乱翻书节目讨论脑图摘要"
    }
  }
}