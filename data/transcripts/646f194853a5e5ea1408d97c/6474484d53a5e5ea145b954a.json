{
  "pid": "646f194853a5e5ea1408d97c",
  "eid": "6474484d53a5e5ea145b954a",
  "title": "大模型只是起点：朝向多智能体和人类紧密协作的未来",
  "task_id": "yg7k9wo5bja5nxwd",
  "transcription": [
    {
      "time": "00:00:01",
      "text": "美国有OpenAI，中国也在想谁是中国的OpenAI，或者谁会做出中国领先的大模型。普遍大家认为字节是大公司里面可能最有潜力，最有竞争力的一个选手。你怎么看在字节这样的中国顶级的互联网公司做AI的研究，和在OpenAI做研究的对比有哪些异同？",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:24",
      "text": "现实世界中的数据永远是很宝贵的，电子世界中的数据是比较多的。怎么才能让更多的把两个世界给联系起来，我觉得是未来的一个挑战。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:36",
      "text": "你说思考快与慢里面提到system和system 2，以前很多人都认为AI解决了。首先是那些所谓的比较简单的system one的问题。而system 2这种需要思考的，大家觉得人工智能比较难，但现在好像发现反而好像越复杂了，AI解决的越好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:59",
      "text": "大家好，欢迎大家收听此话当真。真格基金投资团队将在此和各领域的领军人物一起分享最新热点和行业洞察。真格你的创业第一站，我是真格基金管理合伙人戴雨森。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:12",
      "text": "今天我们邀请一起对谈的嘉宾是清华大学信息交叉研究院的助理教授吴毅老师。无疑在国际信息奥林匹克竞赛和ACM都有非常出色的成绩。是保送清华的姚班，后来在伯克利大学读博，师从人工智能title steward rosell教授。在读博的时候无意在offi工作过一年多的时间，做了一个非常有意思的AI捉迷藏的强化学习工作。是当时OpenAI在youtube上被点击，这个视频当然是在chat b发布之前。吴毅在完成博士学位之后，回到清华茶园任教，继续他在多智能体强化学习人机交互、机器人学习、自然语言理解与交互等方面的研究。好，请吴懿跟大家打个招呼。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:53",
      "text": "Hello，大家好，然后很感谢宇森的邀请，跟大家分享一下自己做的一些事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:59",
      "text": "无意我之前去你办公室参观，就感觉非常的有意思。有的同学在打游戏，有的同学在指挥机器狗追小球。能不能介绍一下你现在正在做的研究工作有哪些方向？为什么这些工作让你觉得特别有意思？",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:13",
      "text": "对，我们其实做的方向还挺多的，我们从虚一点的，就比如说游戏，然后游戏AI比如说做多智能体强化学习，然后做机器人，我们自己还做着无人机等等。其实核心说一千道一万，他把它总结起来是，其实我们想做一个能和人交互的这么一个通用ai我们的mission是说，我们希望每一个人都有一个智能的私人的助手，他能帮你做很多的事情。这样的事可能是在虚拟世界里，就像游戏或者是你的办公场景里面。比如说你每天要做的这样的事儿，也可能是一个现实生活中，那就是机器人。所以我们希望为什么做这件事情呢？是希望把这所有的事情都是承载我们这一个私人助手的这么一个平台。然后我们希望有天最后我们人大部分的工作都是你的私人秘书来帮你完成。他很懂你，然后可以跟你交，我也很听话。我觉得这是一个我对未来世界的一个畅想，所以会觉得这是一件很有意思的事情，每天为这个事情在奋斗。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:13",
      "text": "在这个里面，比如说ChatGPT发布之后，很多人觉得我们离每个人都有一个私人助手，或者像说电影里面her的那个场景可能会接近很多。但是我们也知道你做的方向和现在最火的这个大语言模型，这还稍微有些不太一样。因为里面牵涉到AI和AI的配合，AI和人的配合等一系列不同的场景。这个里面包括你也经常使用游戏作为研究对象，像这方面有哪些我们未来值得期待的看到的研究成果？",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:42",
      "text": "我觉得ChatGPT首先它解决的是一个很重要的interface，它是一个表，就是媒介。就原来我们比如说做人机协作做游戏，其实你人很难给这个AI给一些非常抽象的指令。你只能给一些非常简单的指令。比如说你AI往前走两步向左转，这个可以。但如果说一些抽象的帮我讲讲佛罗伦萨，或者说你帮我摆出一个像库里一样的动作，这种事情是很难的。但是有了chat PPT之后，它其实帮你把很多这样的常识，人的复杂的指令，他可以帮你做好理解，甚至可以给你做一些拆解。所以这件事情当它出现之后，我是很高兴的。其实他让我这virtual system的梦想往前走了一大步。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:29",
      "text": "但我觉得ChatGPT不是全部了。因为ChatGPT它不是定制化的，而且它也不能去真的帮你报销一张机票，或者帮你去游戏里面完成一些任务，或者帮你下楼拿个快递，他不行，最后还是要落实的落实这件事情，我觉得是你的助手应该去做的事情。ChatGPT不会把这些事情全部做完，所以我们还是有很多的路要走。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:52",
      "text": "在过去几个月里面，auto GPT为代表的这种可以不断的自发的去完成一些复杂任务，包括说说他拆解一个任务变成子任务，然后自己去决定使用什么工具，反思完成的结果，然后调整他。其实现在真的要做什么事情还是比较难的。但确实他的那个过程有点像模像样，尤其当你看他那个推理的过程的时候，你会发现觉得好像就真的跟一个人在思考一样。像我们是局外人，就觉得好像这个太神奇了。你不知道你在一个行业从业者对这件事情预期有哪些是超出你预期的，哪些是你意料之中的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:05:30",
      "text": "我倒不是很意外，因为很多事情在这学术界都做过。比如说我当时16年，当时我们就想了搞一个AI在网页上点来点去找东西。这个现在其实挺像的，只是我们那个时候没有大语言模型，搞了个简单的LSTM一个wording bedding，然后就在VKPDR上点。当时我16年的论文就搞了这个事儿，就现在本质上就是很多事儿我们都做过。然后我真正觉得这个事儿不一样，其实就19年级B3过去很长时间时间了，20年GPT3发布，其实内部19年就看到了，19年看到就发现这玩意儿想买。Few shot learning.",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:08",
      "text": "能把能写网页写excel了。但是我觉得他现在的所有这些功能，其实我倒真的不是很意外，因为都是这蛮直接的应用。我觉得我没有想到的是它的火爆程度，我可能低估了这种事情出现对于整个世界的的意义。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:25",
      "text": "我觉得这里面与check这个形式还是有挺大关系的。因为你原来如果只是在playground里面，你要去这样使用，它是这样一个深层次的一个界面。这样的话它的交互能力，交互性就会差很多。因为每个人都会chat，同时怎么对chat进行对齐，我感觉也是很重要的。因为同样的这样一个模型，你完全可能你的对齐不够好，或者够往对话去引导，就可能会让人觉得聊不下去。其实让他能够变得很能聊，然后引发扩散。大家说这个AI变得这么能聊，然后大家去愿意探索这些功能，就感觉很很重要的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:00",
      "text": "这个确实当时对我来说也挺震撼的，因为原来没这么思考过问题。因为大家很早的时候都想的是技术驱动。其实我觉得OBI自己可能也没有想到ChatGPT这么火。那你开始反思之后，发现这个点到底是什么，还是蛮有启发性的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:16",
      "text": "现在大家也在讲AGI，反正不管是从投资市场还是政策制定者，大家都觉得非常的判断速度很快。但是肯定有很多地方是有泡沫被高估的，你觉得这里面可能有哪些？",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:29",
      "text": "首先我觉得两件事情，一是是不是所有事情都需要是个语言interface。这个我倒觉得不一定他语言会是个入口。但是如果大家从效率上讲的话，你有的时候不希望废话那么多，打游戏就大家能发现了，对吧？你是没有必要跟他说很多话的。不会的，有的人大家要效率的时候需要很少的话，有一些ChatGPT功能是比较多余的，就至少在效率上。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:52",
      "text": "第二件事情就是我觉得像大家觉得auto GPT这样的形式，是不是就有一个大语言模型把所有事情都做了。我还是不是特别认同这个观点，大语言模型很通用，但是对于一些特别需要高复杂性，你希望用一个非常通用的模型，他能把所有的软件全部给解决，我是不太相信的。我觉得他是需要一个领域的增强。Auto GPT的逻辑就是说一个大模型你所有人向我靠拢，我能解决所有的事情。我相信这个世界上一个特别长尾的事儿，大模型能做到90%。但是你还是有很重要的工作，很复杂的工作。举极端的例子，那就是游戏，好歹大模型玩不了星际。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:34",
      "text": "对，其实我觉得语言做一个UI，其实它不适合做交互。比如说你真的要做个excel表格，这种你需要选中某个对象这种精确的，它反而就不适合语言的。语言适合抽象的。比如说像你说的我们要猥琐发育，对吧？这是个纯抽象背背有对应着1000个不同指令的操作，它反而很适合。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:53",
      "text": "我很粗浅的理解是，比如说GPT4很好，但是它很慢而且很贵。所以他就像是一个很有经验的老板。但这个老板可能也有一些，比如实习生给他准备材料。对，所以比如说像vector DB或者说是一些小模型，给他把这个材料准备好，然后他去主要做最重要的思考。但是他不是一看了就接受那些raw data。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:13",
      "text": "另外一种好像是最近我看了一个paper，是先用小模型生成一个答案，再生成一个对它的自信程度。而大模型去看，就它从大模型产生答案变成大模型批改答案。其实很多时候他可能是一个多层协作，包括你刚刚说的多模态对吧？可能大模型是脑子，但是你要做很多事情，那你没有多模态能力是做不了的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:33",
      "text": "尤其是做执行了，就是你要做个机器人或者帮你做一些自动化，帮你做个秘书，这事儿不能光说话。对我觉得大模型以后肯定是一个必须的东西，是个必备品。但它一定不是全部，它是一个新时代的起点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:47",
      "text": "的确因为随着ChatGPT的出现，也有一种说法是说现在学术界在AI里面的发挥的作用下降了。因为跟工业界相比，学术界可能没有那么多的算力，那么多的数据去那么大模型。其实有点像一种暴力美学，好像是这样一种看法的一个例证。你自己在open I工作过，然后也在学术界选择现在做教职，并且对工业界也有很多联系，你会怎么看现在学术界和工业界？它的这样一个区别和它的联系。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:18",
      "text": "我觉得首先是要谈一下区别。就大家的目标不太一样，学术界它追求的是novelty，你可以有idea，大家觉得你可以提1万个idea，里面可能9999个都没有用，但是最后一个有用就行了。但是像公司的话，他就会去比较追求确定性。对他可能说我有个产品，我有个特别落地的一个点。所以经常的时候，尤其国内的公司，他跟你谈合作的时候都会说，我们业务上有需求，吴老师来帮我们看看。对，这个可能就是它的差别。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:47",
      "text": "但是我觉得可能最近也是这几年有一个新的一个方式，其实就是OpenAI和deep mind有一种新的方式叫做research product。他又不是那么分散，但是又不是追求立刻就可以卖出去。像OpenAI，最后他其实做了一个大语言模型的一个prada，它其实当时也不知道有什么用。Somehow他最后有一天被人用了之后效果很好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:10",
      "text": "算力确实是一个问题，大家就会觉得现在大语言模型之后算力怎么办？其实我会觉得这里有两方面。一方面是说对于大公司来说，它其实算力也是有瓶颈的。当然不是，算力永远可以不限制的增长下去，这个增长会放缓的，那么学术界慢慢会追上来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:28",
      "text": "第二也是开源，我觉得开源也是学术界一个特别大的不同。尤其是计算机科学，尤其是AI的学术界，大家是特别喜欢开源的。而有了开源之后，其实带动的整个进展非常快。比如说这个berkely，我们sky lab对吧？我原来skylab喜欢搞开源，他们最近做的dolly，这些开源的大模型，其实一下子把门槛慢慢降低。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:52",
      "text": "其实OpenAI也发生了很大的变化。我记得你在OpenAI的时候，它还是一家非盈利组织，现在已经是一个追求盈利的公司。当时有很多比较有意思的研究项目，比如说打dota然后机器手玩魔方，还有像universe，包括像你做的小人捉迷藏这些各种各样的研究项目。现在却好像他把这个精力都放在追逐一个大模型上面去了。这样的转变背后有什么原因吗？你觉得他是为什么会有这样的一个很大的从公司目标到做研究或者做工作的方式上的转变呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:28",
      "text": "其实这个转变还挺简单的，他们一直都是这个逻辑，就是我们要做AGI，但AGI需要钱，所以我们去搞点钱。所以大家去看他们的钱，其实是一个叫limited profitability。他只赚这么多钱，赚够了之后他就变成一个非盈利机构了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:45",
      "text": "在欧班牙的发展路径上，确实出现了一些分叉点，所以欧BI当时也一直有人来来去去的。比如说最近的SO pic，其实就是原来欧公安的一个团队，他们可能在路径上产生了一些分歧。我个人其实觉得如果我坐在那个位置的话，我可能也会选择这么做。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:03",
      "text": "你说这么做是指盈利。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:05",
      "text": "还是说盈利开会？对我觉得确实是即使任何一个团队，他想做长期的事，都会多少要一些钱。我个人还会觉得这还。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:15",
      "text": "OK明白。确实我们也看到OpenAI的产品化带来了很好的收入。我们最近了解到它的ARR也就是年化收入已经接近了10亿美金。主要是靠ChatGPT的收费，这其实是一个非常了不得的数字，也宣布AI真正进入到主流市场的用户。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:35",
      "text": "那么你在伯克利读了博士，现在回清华插院教书。比如现在假设你要劝一个同学在清华和伯克利之间选都是非常好的学校，都是非常好的老师，你会怎么去劝他？比如说来插阅读你的博士，大家会怎么考虑这个问题？",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:51",
      "text": "其实我觉得这里真正的区别不是差远和berkely，真正的区别是中国和美国。咱们看最顶级的学校，比如说伯克利和MIT。我觉得如果单纯从学术自由度，新教授的水平来看的话，其实我觉得交叉信息院应该是国内最接近这些地方。我们其实有些横向对比了，比如说像我们院对自由科研的推崇程度，我觉得可能美国top ten以后的学校都不见得比得上我们院。但是中美之间确实是一个大的big difference。但是，我确实说现在确实有一些很好的学生留下来了。我觉得就是你如果想留在国内，我们这里是最好的选择。但如果想出国，觉得我也会建议学生出去走走看看。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:40",
      "text": "明白，所以其实更多还是选择在哪个国家，哪个市场去进行科研的结果。其实你在字节也实习过，并且是字节AI lab的最早的创始成员之一。现在当然美国有OpenAI，中国也在想谁是中国的OpenAI，或者谁会做出中国领先的大模型。这里面普遍大认为字节是大公司里面可能最有潜力，最有竞争力的一个选手。你怎么看在字节这样的中国顶级的互联网公司做AI的研究和在OpenAI做AI研究的对比有哪些异同？",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:14",
      "text": "我觉得字节应该还是挺有机会的。因为我在字节里面看的话，首先我觉得横向对比来说，字节还算是整个技术驱动比较好的一个公司。而且它的基因里边也是对算法技术非常敏感，非常支持的这么一家公司。而且它有场景，像抖音。我们最早其实做这种创意写作的时候，我16年当时ARW刚成立的时候，我们就去做写作辅助工具。所以它其实一直有有这样的积累，我还挺看好字节的，但是跟OpenAI的话去做对比的话，还是要说字节它虽然是技术驱动，但它最后还是落脚于产品的。但这件事情在商业上其实是正确的，没有任何问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:56",
      "text": "OpenAI的话它其实不是落脚于产品，比如说和他的这个ChatGPT和他的API并不是一开始他就奔着这个东西去的。所以从某种角度上说，OBAI是幸运的。因为你回头去看的话，他做API这个选择是很随机的，他有可能选择错了他就死了。因为一个像自己这样的产品驱动的公司，他可能很难做出这么有风险的决策。但欧莱雅因为本身是一个很与众不同的公司，他做出了这样的选择。所以在OpenAI内部还是依然有很多。至少在我们在的时候，它是有很多比较像学术product，学术产品的这么一个事物存在的。而一般公司里面很少会说我这个团队可能5000万万美金。你们去做一个学术，像我们捉迷藏或者机械臂这种千万级美金的项目，他是不会去花这个钱的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:46",
      "text": "不过我感觉随着chat GP出来之后，在美国其实大家在想，sophie其实就是在做API。但是ChatGPT因为它是端到端的，它有用户的这些跟他对话的记录，那么可能也是能够被更好的用来去对齐这个模型，让他知道怎么样更好的去跟用户交流。所以我感觉现在大家可能觉得既有底层的API也有顶层的端端的产品。这可能是一个AI头部公司它需要具备的双轮驱动。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:14",
      "text": "我们刚刚正好讲到这个捉迷藏，捉迷藏我们到时候也会推荐我们的听众去看一看，真的是非常有意思。我们也知道AI研究中经常用游戏作为研究对象。OpenAI当时也研究过打dota，当时deep卖的也是下围棋，打星际。那么为什么AI经常要研究游戏呢？现在在游戏里面，比如说有什么进一步有意思的，你们现在比较先进的研究到底研究什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:38",
      "text": "游戏其实很自然，大家为什么想到游戏？因为首先游戏是一个现实世界足够复杂的映射，它很复杂而且很像现实世界。但同时它又不是真实世界，它是完美的，它是可以模拟的。当然对于AI对于强化学习这种需要很多数据的领域的话，当然游戏大家会很喜欢。是因为游戏里面可以产生无穷多的数，对它是一个完美的虚拟世界，那么有意思的方向就是我之前说的，人机交互的这个方向其实是很好玩的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:08",
      "text": "因为原来的话大家都知道用强化学习去解决了围棋，然后解决了dota解决了星星。那么什么叫解决？其实是我训练了一个AI它可以击败非常顶级的人类玩家。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:23",
      "text": "但这时候就有一个别的问题，因为人类玩家大部分人都不是那么顶级，所以如果要让一个AI去配合人，而不是击败人，那这个事情就会变得非常有意思。因为最击败人是一个有最优解的事情，我只要分数高我赢你。比如说我五子棋，那么先手是有必胜的，我记住他就可以了，我永远就可以赢。但是如果我说我一定要让一个人，他在走了40步之后，他才将将能赢，这个问题就很复杂了。因为你鬼知道这个人会去做什么。所以当你开始考虑一个远模型里面会碰到一个非理性的有偏好性的人的话，就特有意思。我们现在想做的事情就是能不能让这个AI在游戏里面。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:07",
      "text": "如果你跟他一块玩，你们发现不了他是AI这是一件事情，我觉得很好玩。第二件事情是能不能跟他说话。去年我们其实做了一个小的游戏demo，是说一个打星际的时候，它是一个简化版的星际，你玩的时候你不太需要去控制单位怎么去挖矿，怎么造冰，怎么放建筑，你就说造冰给我出去探路之后，这些事儿具体怎么操作，怎么执行层面是AI帮你做的。就像你有一个伙伴一样，你说我们打野推塔，你不会说你的英雄出门30米，然后左转再往前走20米。这也是我觉得一个virtual system私人助手的一个最终的一个形态。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:49",
      "text": "因为这里面其实有很多游戏的策略，在之前的话可能是人类去教AI的，后来变成了AI互相的self play。自己悟出了这些策略。那么长期来看有没有什么策略是人类独有的，AI学不会的，还是说人类有的或者是还没想出来的策略，其实AI都会学会。因为我看比如说你捉迷藏的里面，其实AI他就找bug，他发现了世界里面很多bug。比如说他可以发现自己能跳到箱子上面去，然后他就在那冲浪，很多可能是人类都想不到的那这里面对AI的能力，它会不会有一个界限？",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:22",
      "text": "这个界限其实取决于虚拟世界和真实世界的界限。我们其实有个术语叫grounding，但我们其实不知道中文怎么翻译了，就是把一些抽象的概念能够映射到一个具体的行为和策略上。比如说进攻，或者说我有一个水，那个水这个概念能够到一个现实生活中一杯水这个物体上，这个事情是很困难的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:46",
      "text": "游戏里面跟现实世界多少还是不一样的。现实生活中有太多这样的复杂的事情，在游戏里面是不能够完全反应的。比如说ChatGPT，它是用文字作为一个载体，文字是很取巧的，因为它它是一个非常抽象人设计出来的一个媒介。但是大家想到，如果你每天跟一个人吃饭，你得到的信息量是很大的。或者你交一个朋友，你每天你的不光是视觉、触觉，可能还有人的微表情，可能跟天气周围的环境都有关系。这种事情反映到游戏这样简化的环境中，或者反映到ChatGPT这样文字为媒介的反应中，是有非常大量的损失的。这种细节的丢失就会导致很多人类之间的这样的关系，很难在虚拟世界中得到完美的展示，所以这一点是很困难。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:35",
      "text": "这也是个open question，就是现实世界中的数据永远是很宝贵的，电子世界中的数据是比较多的。怎么才能让更多的把两个世界给联系起来，我觉得是未来的一个挑战。如果真的有一天我们有一个完美的虚拟世界，那我还是相信AI能够发现进化出所有人类的这些策略。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:55",
      "text": "我觉得这是个非常好的视角。比如说三体里边，当然那边的三体人不是AI了。但是他就假想说这个三体人不会欺骗，所以人类也可以用这个去做面壁计划。刚刚说的有点像，比如说不辣，这个虚张声势可能也是AI比较难以学会的，因为他没有心理障碍。比如说打游戏的时候，或者说在下棋跟打德扑的时候，这种察言观色，这种虚假声势这种事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:21",
      "text": "至少在现在的AI来看，它的训练环境和数据是没有这种微妙的信息的那你也不可能指望他能学会。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:30",
      "text": "所以这个里面因为现在AI的能力其实在突飞猛进，包括现在也出现了很多很自动化的，可以不断的自己去思考任务，完成任务的agent。比如说auto GPT这样任务很多人就开始说，会造成很大的威胁，AI会具备这种很深的谋略能力。所以在三体里面，打个比方，就是说三体人学不会三国演义，这个三国演义就是谋略的地方。AI学习这种长时间的、复杂的、连续的这种谋略推理，我感觉应该蛮难的一个事情。就不知道在科研里面会怎么去想这样的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:04",
      "text": "还是说现在想起来太早了。其实我有个朋友在facebook AI research。田园洞，田园洞也是个很好玩的人，他业余喜欢写小说，他自己也写了一部小说，他现在就要AI写小说。其实你小说写出来中间的这个故事就已经有这种谋略的感觉。其实我觉得倒不是说写不出来，倒是说为什么人能写出三国演义呢？是因为他经历过那样的社会，人类社会中有太多的微妙的地方，比如说人的一些特别的情感，或者说人类的一些社会范式。就比如说你对一个人的情感，可能是因为你们共同经历过一些事情，但这些事情情可能是不太能够用文字描述出来，比如大家一起打过仗的朋友关系就会非常好，但这个打过仗你怎么描述呢？好像很难描述，就是很多这样的事情丢失了，导致大语言模型他只能写出一个故事还不错。但是你想写出这样的经典名著，我觉得是很困难的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:04",
      "text": "就是我觉得谋略其实本身，比如说bluefin或者欺骗，咱们看每一个具体的技能都是可以让AI去实现的。甚至我最近还在做一个研究，是我AI玩狼人杀还行，也还行，就还可以。总之就是觉得人类世界有太多的信息其实丢了，这是我的观点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:23",
      "text": "可能就是AI能学会一些行，但是要学会神或者所谓的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:26",
      "text": "他得到人类生活中来生活。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:28",
      "text": "我觉得是我在想你像现在GPT这种大语言模型，其实它当然可以写出人类没有写过的文章，这肯定是甚至可能也能发现一些人类没有想过的社科知识，看他能不能发现一些人们没有发现的自然科学的知识。所谓的完成做研究这件事情，因为现在都还是排列组合，你能不能组合出一个新的E的MC方。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:50",
      "text": "这其实还挺不一样的我觉得咱们得分领域说，比如说像生物这个要产生蛋白质的结构。那么结构蛋白质这个领域原来都是靠冷冻电解，然后就去扫。现在有了java fold之后，就是一下子就可以去重构了这个蛋白质。或者说之前有很多人就AI说一个发布的药能不能去治一个别的病，去看一下。或者说一个小分子会不会跟一个蛋白质产生一些作用。其实它已经是做出一些发现了，当然没有那么好了。比如说天文学，天文学是更直接了。因为我有一个好朋友他是在break天文学，他就说他们那个天文学，你去比如说帕博望远镜或者现在这个比较新的望远镜，拍出来宇宙背景有噪声的，然后他就用那个深度学习去去燥，或者发现一些这种星系，新的这种观察，这也是AI帮助发生的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:39",
      "text": "说到物理学，我觉得它的问题是在于除了理论物理，对吧？理论物理比较像数学，数学的话确实是现在AI还比较困难了。像理论物理它其实是抽象，我是先有物理实验，然后我抽象出一些经验。这件事情就是我就说的AI到现实世界的多复杂，映射还是比较困难的。所以我就觉得，如果有一些能够纯数据驱动的缺口，就是这个AI还可以。但如果你要把它抽象到逻辑层面，真的要一定要他拿出一个逻辑的东西出来，那还是比较难的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:13",
      "text": "逻辑可能属于什么类的？就符号。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:16",
      "text": "主义对符号主义对，就是你要让这个连接主义去解决符号主义的问题，不是不行，但确实是现在最难的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:25",
      "text": "但连接主义我感觉还有一个场景，因为我一直在想，比如说咱们读PHD很多时候做研究也是我先提出个假说。我为了验证或者否认这个假说，我要做一些实验的设计，去做这个实验看数据是验证的还是否真的。这个假说。比如说你看现在像auto GPT这样的比较recursive自动化的过程，其实我觉得它是理论上是可以做到AI他提出一个假说，然后设计好实验，把这个实验，比如说发给那种第三方做实验外包的这种公司。因为它传通过语言文字能够给人指令，那这个就有可能去形成这种闭环，把实验给做了，根据数据去说去进行推理，这个还是一个可能的路子。爱因斯坦他本身也是这样提出讲座，然后后来人去观察在日食的时候水星的位置，验证他的理论。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:12",
      "text": "这个事儿核心就是你到底要多少数据。爱因斯坦好牛，就牛在他需要的数据真的好少。我其实以后想的是这个事情，有没有可能数据环里面能不能有一种方式是很少的数据是人类提供，大部分的数据是AI但是人类一直在提供数据，但它提供数据的规模是比如说千或者万这种人能提供的这种量级，就像ChatGPT1样。如果有一种像强化学习这样的可以自动产生数据的流程，或者说我有一个半仿真的一个流程，但中间我有一些人提供关键的数据标注，如果能把这个事情打通，我觉得会很有意思。我觉得像科学问题，还有很多这种跟人相关的问题。人想把它完全排除出去，或者完全用人的数据不可能。但是如果能有一个框架，他让人只要1%数据，那我觉得算是一个非常大的不同。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:02",
      "text": "其实你看在大语言模型里面，已经是像vue这样的工作。ChatGPT4去写范文，然后利用GPT4做老师来指导差一点的开源模型AI互相进行学习的能力。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:14",
      "text": "不能全AI一定要有点人类。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:16",
      "text": "提供一个范文，然后一个足够好的AI对这个范文进行模仿，可能是这样一个过程。对，其实我之前在想一个问题，因为我们原来说有很多验证码，比如说让你识别扭曲的文字，把一个图片翻正，这些它本质上都是一个叫做说人类做起来很简单，AI做起来很复杂的事情。那原来这种不对称的事情还是挺多的，这些东西可以被用来作为一个人类对抗AI的这样一个最后防线。其实以前就是人类用这个来抵抗AI机器人，但是你发现ChatGPT出来之后，好像很多原来的这种所谓的AI难，人类简单的事儿AI也变得不难了。因为以前大家觉得围棋没问题，星际反正这些都一个一个被解决掉了，是吧？我不知道在游戏这个规则里面，或者可能也包括像ChatGPT这种场景，会不会有这种游戏长时间来看AI玩比较难以击败人类的，人类可以有很大的优势。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:12",
      "text": "其实AI就是两条，一你有个明确的目标，二你要有足量的数据。所以但凡能满足两条，我觉得对于AI来说都不是问题。比如说围棋就是有个明确的目标，做个规则，我能赢就赢。可以自己通过自我博弈，然后模拟模拟所有的完美的规则产生所有的数据。那么一定就是说一是这个东西它没有那么多数据，或者说它的目标不清楚。比如说之前我们说为什么跟人我这种情感类的，或者说跟人玩喜欢让人变得开心的这种事情，他就不容易呢？是因为就算你有无穷多的数据，你目标不清楚，因为你根本不知道人怎么想的。还有一种就是说可能是数据不够。现在来看数学题，它就是比起这个可以自博弈生成无穷多的数据的话，那这种数学的题它数量还是很少的那这些是相对来说难一点，但是也在接近。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:02",
      "text": "明白，我们再聊聊你做的另外一个大的科研方向，就是机器人。因为相比大模型的突飞猛进，似乎机器人在发展节奏上有一点慢。比如说今年2月份google就关闭了它的everyday robots这个项目。如果类比比如大模型的突破，近几年机器人的研究中有出现transformer这种里程碑式的研究，或者说GPT3这种划时代的技术突破，它有什么大的进展可以跟大家先科普一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:31",
      "text": "我觉得他的GBD3时刻应该就是欧布林艾的机械手拧魔方。它的背后的技术叫dme render ization，是一个解决从虚拟仿真到现实世界的一种端到端的训练方式。中文翻译叫预随机化了，但是我觉得这个翻译不是很好。它是目前至今唯一一个真正意义上端到端能直接从虚拟世界中训练，直接到现实生活中部署，不需要太多传统机械工程和控制理论的这么一种算法。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:04",
      "text": "最早这个算法也是2017年左右OpenAI提出来的，可以认为是GPT1.0。当时是我的两个同学josh tobin和Jason鹏在O班实习的时候做的，到19年的时候是做出了单手拧魔方。那是第一个传统控制根本没有办法做到任何接近效果的一个任务。然后通过强化学习端到端给做成了至今所有的比如说无人机、机械狗、机械臂做的比较成功的，采用强化学习方式或者AI方式来控制的，都是用的这套技术，没有例外。当然所以我觉得它是一个GPT时刻。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:42",
      "text": "ChatGPT时刻其实我觉得是最近大语言模型出来之后，这种大语言模型作为这个机器人和人的交流层。你比如说可以跟机器人说，帮我去拿瓶水，这大语言模型可以做些拆解了，说你应该先去厨房找冰箱，把冰箱打开，然后用强化学习做这个控制。然后他就控制机器人走到厨房，打开冰箱拿一瓶水送过来。这个也就是当时google everyday robot的一开始展现出来的这么一个demo。所以是一个ChatGPT时刻。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:08",
      "text": "但是因为机器人有它最大的问题，它其实很受制于硬件。而且它跟ChatGPT的差别在于，ChatGPT是用一个通用的语言的接口，不同的机器人完全不一样的。所以这个事儿是他很难有一个通用的模型统一所有机器人硬件，至今来看还是比较远的一件事儿。机器人还是说他是个太大的，并且跟现实世界绑定太深的这么一个领域。所以即使有这么一大的突破，可能要走到每个人的生活可能还需要一段时间。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:42",
      "text": "但是比如说机器手魔方，他去拿一杯水或者拿一个别的东西，就手的事情他都可以用这一个框架解决吗？还是说王柏芳得做一个工作，然后拿水壶，拿水杯得做另一个工作。他这个泛化性怎么样？",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:57",
      "text": "其实挺好的，它核心是需要数据，数据有两种，一种是像open I一样，它搭了一个90分或者80分的仿真环境。你有这个之后，它会自己产生数据。第二种就是everyday robot，当时推出一个叫c can robot demo的时候，它采用的方式就是人收集大部分数据是人来收集。人来收集就会出现到这样的问题，就是不同的机器人不一样，收的数据也就不一样。当你数据够的时候，其实大家现在的例子都是发现你泛化能力还是够的。但是到底要多少数据呢？这个数据的收集是挺慢的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:31",
      "text": "因为我正好一个月前跟一个stanford做机器人研究的KHG同学聊。他就说现在有很多的数据是通过像youtube上人手的这样一个视频。因为关于手是怎么跟世界交互的，其实现实生活中可能有很多的视频记录，但是它不同的角度，不同的物体，不同的目标，但这样的数据还是少不了手的那角度又不一样，那那这个各个东西都不一一样。可能就是像你说的，像open I其实搭建了一个叫做元宇宙，对吧？在里边不断的去转魔方，他就通过虚拟的数据把这个事儿给解决了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:05",
      "text": "所以我也希望是有一天大家真能搞一个比较逼真的世界，那AI的精华就会更快一些。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:12",
      "text": "我们就能够用元宇宙或者说虚拟世界去解决这个问题，而不需要现实生活中的输入。比如说假设出来一个七个指头的这个手，现实生活中没有这样的手。但是我可以在虚拟世界完全构造一个这样的手，然后把它怎么做解决吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:27",
      "text": "理论上是这样，但是机械手拧魔方这个项目就是说了这么一件事儿，他的手其实关节跟人很像，但是也不完全一样了，他其实没有那么灵巧。但是基本上通过这个路径，通过虚拟世界中的大量训练，看到了现实生活中可以自己做自适应。当时他们做了一个实验，就是你魔方的时候，直接把你两只手指头绑起来，它也能泞。对这个泛化能力还是不错的，只是说核心还是数据不够。而且另一个挺大的事情就是机器人，就即使我有人的数据，那么人和机器人的关节和力学构建其实也挺大不一样的。你有的时候不能完全模仿人，这个也是问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:05",
      "text": "另外一个比较难做的就是触觉。人的手它不光是这个关节很灵活，它有一个触觉，这个触觉传感器其实是不好做的，而且这是真的没开源。今年我马上要去伦敦开个会，叫e ra是机器人的顶级会议。但今年的bad paper就是一个做了一个触觉传感器进去插花的那插花这件事儿没有触觉不能做，但人家都是组里面祖传的。就是有一些硬件上的这种事儿，门槛还是挺高的，希望能够推进一下这个领域的进展。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:36",
      "text": "确实我觉得在这个里面，其实机器人它有因为有感知、决策、行动很多模块，所以这里面它有很多东西的配合才能够进行变化。那么在这个里面，我们觉得接下来会在什么领域会有进一步的突破？",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:50",
      "text": "其实说实话我对人性机器人还是蛮期待的，但是我觉得人形机器人比较远了。核心我们比如说做强化学习，做深度学习这一套，他是做脑子，脑子给机器人带来的是一个通用性。因为现在大部分机器人都是专用，尤其工厂里的机器人，对吧？我就是个一流水线，我就调好了，在那动就行了。我觉得这个事儿能不能先从一个具体的点到稍微能够泛化一点，能做多任务的机器人？我再到后来希望是走向人形机器人这样一个完全通用的这么一个通用机器人。我觉得一定是从单一到通用这么一个变化。最后我们的长期理想当然是有一个像居家的机器人帮你收拾被子，叠衣服，对吧？买菜这种事儿。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:36",
      "text": "是我记得好像叠被子其实是一个非常难的task，因为这种软的东西其实都是很难去做的。缸体都比较好操作一点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:46",
      "text": "对，但其实软的东西现在最近有一些新的技术，其实也做的还不错了。钢体有它的坏处，就是你如果只是要做简单的刚体的抓取，那是比软的容易。但是如果你有一个东西，它有很多钢铁，比如说你想模拟一个人形机器人仿真是非常困难的，是因为钢体经常有穿模的问题。图形学的仿真引擎其实做流体，有了太极图形，微分模拟器之后，他们其实做流体做到还不错。但是反而是缸体是一点办法都没有，因为缸体是一个硬的限制。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:20",
      "text": "明白，所以你刚才说GPT3时刻其实已经到了OPI做的这样一个事情。因为比如说GPT3里面，其实它是一个大力出出奇迹的逻辑，它的基础的思路其实GPT1就已经定了。但是在这过程中也有足够多的数据，并且能够用好这些数据，其实花了很大的功夫定了。所以你是觉得如果我们就按照这样一个思路，其实是可以获得一个很多领域都能够泛化，都能通用，都很好的一个表现，对吧？因为我一直在想，如果你做投资的看到ChatGPT的时候，其实已经前面过了很久的时间。那我们就是说什么是GPT3时刻，什么是transformer时刻？也许这反映了从科研到技术到产品到商业化，它是壹这个的里程碑。我们其实要去多思考每个行业什么是它的GPT3时刻，它的技术已经到了一个可用的程度，接下来要把它产品化了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:08",
      "text": "可能是硬件还需要个GP3时刻，是算法层面有飞跃的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:14",
      "text": "正好说到硬件，因为我看你们在实验室用的也是商业上能买到的机器人，然后进行一些改装去做。你觉得这里面比如说硬件上有哪些亟待突破的缺点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:24",
      "text": "觉得最近我们特别想做的数据传感器这件事，我就举个特别简单的例子。因为做人机交互，或者说我想做一个跟你端茶倒水的机器人，那我们就做强化学习，多智能体训练，做了一个真正跟你交互的机械臂。后来发现一个事儿是我给他递一个一瓶矿泉水，OK没问题，他递给我不太行，为什么呢？他不知道什么时候撒手。那你想一下雨森，我比如说给你递一杯咖啡，我什么时候应该撒手呢？不然会撒你身上，对吧？那你肯定是说，我感觉到你好像抓稳了，我就可以撒手。这个需要触觉传感器，就是我能帮你打咖啡，但只能放桌上，很有道理。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:01",
      "text": "对，就交接棒其实有很多的视觉触觉上的线索是吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:06",
      "text": "对对对，所以这个是我们自己最近老在琢磨跟人交互的机器人。当然另外一个也就是说我们为什么用商业机器人了。原因也是因为机器人要把整个里面怎么布线，电机怎么做实现很麻烦的事情，我们就买。但是买的也有问题，他可能人家这个机器人并不是给强化学习设计的，所以我们最近也在看一些合作，就能不能找一些机器人的合作伙伴，他们能把机器人做的比较好。我们反正当科研用途，我们就直接拿过来这儿做一些。希望能不能明年或者年底的时候，我们就搞一个能在办公室里能给女生端咖啡的这么个机器人。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:44",
      "text": "所以其实人的之间每一个简单的协作，其实都还蛮难的。因为比如说思考快与慢里面提到system one和system two，对吧？以前很多人都认为AI解决的首先是那些所谓的比较简单的system one的问题。而这种需要思考的大家觉得人工智能比较难。但现在好像发现system to这种需要思考的问题，反而好像越复杂的AI解决的越好。但相反比如说其实他们经常举的例子是人能够抓住一个飞过来的球，这个事情是一个非常难的事情。其实刚刚本来想问一个问题，就是说什么任务是它从本质上来讲，人做起来容易，机器人做起来难的？可能就是属于这种系统一的问题，就是直觉进化论形成的这种就叫直觉性的东西。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:30",
      "text": "就人类这一套机体，还有这种神经反馈系统，真的是太强了。你要这个物理把它给再造出来是很困难的，而且也确实没有那么多数据。但是巧就巧在像语言这种人类抽象出来的反而倒是数据很多。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:45",
      "text": "刘慈欣觉得多少年过去人类都是机器人了，结果这个人脸识别还做不了。但是其实现实是反过来，人脸识别一下子就解决了。而是蓝领工人刷墙也是很困难的一件事儿。我们也想过这事儿，刷墙它是要用力，然后你那个机器怎么设计能够去糊墙，也是不好做的。人你能一脚踩在地上吗？去刷。但你想一个轮式机器人，他刷着他就往后退了，就是好多这种乱七八糟的事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:13",
      "text": "我记得好像几年前有不少刷墙机器人的项目，但后来想好像喷墙是比较容易的，用喷枪去喷，但是刷墙是难的那不行。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:22",
      "text": "但凡要这种有秘诀反馈的都很困难。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:25",
      "text": "其实这个跟拿杯子接球一样，都是一个不断的要去感受一个力，然后调整我的反馈，它是一个动态调整过程。这个其实是一个很微妙的事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:36",
      "text": "对，很微妙，要硬件上不一定。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:38",
      "text": "能做到是。不过现在随着ChatGPT的出现，大家也觉得叫做and body的AI具象智能、具身智能什么的。ChatGPT也有人说能够把世界很多东西可以理解，包括GPT是不是有读图的那个接口。它可以看出来为什么这张照片很好笑。就是这种对世界的语义上或者它的逻辑上的理解，对于会有什么帮助或者说进步？",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:03",
      "text": "这个还是挺多的。它其实解决的是一些常识。比如说我说帮我拿杯水，这个背后其实有一个常识的逻辑。水应该在厨房，然后厨房大概室内长成什么样子，你要往哪里去？原来这个事你给我拿杯水我怎么执行？它是个很抽象的，原来没有这个复杂理解能力的时候，你不知道背后的含义是什么。现在有了ChatGPT之后，他其实可以把一个比较抽象的事情去做一些常识性的分解。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:31",
      "text": "但是你说我渴了，巴菲特就喜欢喝可乐，你给他拿可乐这个事儿是私人定制化的。你这个大模型你不经过一些私人化定制，你肯定是做不了，或者强化学习的增强。但是大部分说我可能拿一杯饮料去冰箱里或者厨房，这个是大模型可以做的，给他一种通用的方式建模出来，这是很难得的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:52",
      "text": "所以其实chat GV的出现，对于咱们做机器人还是起到了很大的帮助。我记得之前杨丽坤他就说其实大语言模型只是随机序列，它没有所谓的事件模型。但是听上去你是认为大语言模型是有世界模型，也有所谓的常识，它是真的理解的。但是至少从好像呈现出来的结果，它确实是理解的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:13",
      "text": "其实这事儿还真是我在公司的时候，当时19年的时候，我跟我一个我的cos然后他到我们家工作，当时我们就去试GPT3，然后你会发现当时有个argument是说这个GP3只能是文字，我们当时就做了一些尝试。就是说这是一个桌子，左边是一个椅子，前面是一个书桌，书桌是摆在门的右方，然后门的上方有一个钟，请问钟在书的什么位置？这种问题我们当时觉得他肯定是不能理解，因为这是一个空间想象能力。对当时ChatGPT它也能回答出来说在右下方你也不能证伪他到底是知道还是不知道，但至少他表现出来的行为，当时我就觉得好像这个世界开始有点不一样了。因为当时传统大家都觉得是我要理解这样的空间关系，我一定要把grounding problem完全解决，映射到一个三维世界中，而不能重用文字。但是到19年我发现好像GPT要比我们想象的更厉害一点。所以我个人的倾向还是他多少是有一个word model在的。我这点不是特别赞同的困，因为我真的很早就玩过。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:25",
      "text": "是我记得他当时举的例子是几个齿轮放在一起对吧？就第一个齿轮这样转，然后后面怎么转，然后就给他解决了。后来就说齿轮变成一个环形，又又给他解决了。就是我还看到那个and capacity。他不是当时一二年发了一个奥巴马踩在一个什么人的称上面。他就问说为什么这个照片很好笑，说你要理解他，你要理解非常多的这些细节。现在GPT4出来之后，他就发推特说这个问题被GPT4解决了。但是他还是认为GPT4可能把他的那个照片当成了训练集了，所以我还是很期待拿到GPT4的图片的。API去试一试是不是真的能够理解很多所谓为什么这个场景看着很好笑，这种需要大量的潜在的常识和世界模型去理解，但确实是很让人impressive的一个工作。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:12",
      "text": "我其实觉得记住也没什么问题，因为这个不就是你要是能把世界上所有的东西都记下来也行。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:19",
      "text": "我们再来聊一聊AI安全和对其实我个人感觉生物的进化其实也有点像是一个强化学习。因为它也是基于一些简单的reward function，就是我要活下去，我要繁衍后代去学习。然后最后我们就学习了。比如说不要靠近火，不要靠近蛇，因为那个东西它有危险。比如说它语言模型现在谈不了进化，因为我的理解是他没法通过这样自主的去改变自己的权重，或者改变自己的模型。它其实还是in contact contest没了它就没了。再比如说alphago等这种一个比较狭窄的躲避，比如像捉迷藏，其实它是有进化存在的，只是它进化的方向是非常狭窄的那比较大语言模型下，它非常的简陋，非常的多功能。如果这里面它真的产生了所谓的进化，所谓的这样跟人类长期共存下去，进化下去，这是一个科幻的场景，还是一个有现实意义的讨论。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:05",
      "text": "然后第二，这会是一个我们需要担心的事情。因为现在我感觉说这种AGI很多人说基点理论，那无非就是说他进化很快，最后瞬间就从达到人类到超过人类了，人那人类就很危险了。但这首先是一个正确的思考问题的方式。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:20",
      "text": "咱们先不说一个模型自我改自己权重进化的这样的事儿，咱们就宏观的看AI的进化，GPT4是这个水平，那GPT5会是怎么样？GPT6会是怎么样？这也是一个AI水平的进化，那就是看这个东西它到底会到什么地步。当时其实公司内部有讨论，就大家经常闲聊的时候会聊，就是说大家觉得到底要多少算力能让AI进化出人一样。后来就有一个非常搞笑的argument，但是我觉得挺有道理。你就看人从单细胞开始一直进化到人，他经历了多少次进化，多少次基因层面的变异。虽然人这个进化算法是非常低效的，但他经历了超大规模我的进化。所以这个事儿我觉得如果他从这个角度上看的话，其实大家的可支配的计算也距离还有一点距离。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:09",
      "text": "是因为我觉得这里面有一个我们人类还是很容易产生移情作用的。就当我们遇到一个能够以人类的口吻去谈论事情的机器人或者bot的时候，我们就容易给它赋予一种它有情感，它有目你他有所谓目标的过程。但是至少目前来看，这个大概模型肯定还没有目的。但是他听上去有的时候很像他有一个目的或者有个思想。但是这种所谓的purpose，这种目的或者叫用学点灵魂一样的东西，它是会涌现出来产生的吗？还是说人类，反正就是说只要我把插头一拔，你反正也没了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:41",
      "text": "目前来看我的感觉还是涌现的，因为很正常很自然了。因为AI它的训练的目标函数objective是没有武力这个AI产生目的的，所以他肯定是一种有限的能力了。然后你反正大不了把插头就拔了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:59",
      "text": "但其实这事儿也挺有意思。因为我导师steel Russell，他在brick成立的一个研究员叫try这个cent of a human compatible AI当时其实在我读书的时候，他们就搞过一些这方面的研究。就是说有没有可能那个AI有了目的之后，他不让你。打开电源，但是有一个思想实验，你比如说给AI一个指令，你说我要去赚钱，那怎么才能赚钱呢？那我应该先把你关在家里，因为你别把我抓回去，你抓回去之后我就不能赚钱了，因为这是有可能的这里面其实讲了一件事情，是说这个训练目标很重要。你说要他完全以这个目标唯一的评判价值，那么就可能出现训练出一个AI出现一个AI它就有现实世界的能力，那他就去赚钱了。然后他搞出了金融风暴或者怎么着，他也赚了很多钱，这是有可能的。只是说现在的训练目标是目的的对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:45",
      "text": "我记得你举过个例子，如果你饿了家里没东西吃，但你也不能把家里猫吃了。怎么解决这个问题呢？第一个可能是个常识，人至少不应该吃猫。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:54",
      "text": "第二个就是你举的例子是花瓶。比如人去观察，大家都绕着花瓶走，我也不能去走到花瓶的地方把它打碎。但是人类其实是不需要去观察那么多，他就可以淡化这个知识。他有很多错误他不看到，他也知道不能犯。这个我感觉好像还不只是说通过观察很多人类就能够形成的。因为人具备非常强的这种说少样本，甚至非常举一反三的能力。所以这个理论以人的反应为最后目标优化。那是不是还是他给这个很大数据离我们人的怎么做件事儿还是挺有距离。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:27",
      "text": "他其实不光是数据的一个问题，他其实最终想说的是这个AI他要随时存在一些不确定性。其实这是我自己上的不勒令课，我每年都会跟学生讲的一个例子。深度学习模型有一个特别容易产生的现象叫overconfident，就是他会过于自信。大家如果去看当年这个80年代的神经网络，只有五层的。他说我有60%的概率这玩意儿是猫，那他真的就是60%的概率。他猜100次，他60次猜对了，40次猜错了。但是如果去看这一百层的神经网络，他去做图片分类就会发现，他说自己有90%的概率，但他其实错了40次。但是这个神经网络由于它参数量大了之后，它就会出现，我超级自信。那么大语言模型其实也是这样，就是说现在强化学习也是所有的模型都是这样的情况，他会非常自信的瞎说八道。其实所谓的这个human can AI，也不是说他真的是去观察人是怎么做，一定要等人的数据或者泛化是什么。而是说在训练过程中怎么样保证这个AI对人真正更想做的事情存在一些不确定性。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:45",
      "text": "但现在可能还没有很多用到实践上，因为我们确实看到大语言模型一本正经的胡说八道，然后你纠正，他还非常的不满。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:53",
      "text": "对，这个事儿还比较初级了。但是不确定性这件事情其实在各个领域里面都有一些应用。我们举一些例子，比如说在大语言模型里面，其实让他去做那个train of sort思想链的时候，有一种方法就是让剁你五个思想链，然后做一下投票。这个事儿其实某种程度上也是个不确定性进去。其实大家很多时候都是希望有一个比较好的不确定性估计。这是从原理上说，当然就是技术上说，你要让真的这个AI模型没有偏见，让他能够以人的价值把知识，把训练目标上就把这个移植进去。这个还是有一些距离。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:33",
      "text": "是因为我觉得对其实现在也大家觉得越来越重要了。因为原来AI第一没有这么多的能力，第二他也没有这么被广泛的应用。现在第一它确实变得非常的有能力，并且非常的普遍。但第二，现在很多对齐可能OpenAI就是基于加州的，主要是白人的，甚至是白人男性的那显然比如说可能穆斯林就不同意是吧？那这里面对于这个对齐，好像说确实应该不同的文明有不同的对齐的标准。我觉得这个是不是需要一些国际的协作去做。",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:04",
      "text": "一些这种事情。其实这从某种程度上说，我觉得对OpenAI说他close ai我倒是没有大家看来，我觉得他这点上还是有1点负责任的。就是他close AI不完全是商业上的考虑，因为他之前也出现过很多的情况，就是他不太确定这个东西能不能发布的时候，他先不发布。当然从商业上看起来好像它是闭源。然后我觉得国际之间的这个协作也是确实挺重要的。然后我导师我暑假想去找他他说他去联合国做报告，是是是，这确实很多人在做这方面的工作。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:37",
      "text": "这个先进AI其实很多时候可能就是你有负责任的人去把握。但是你的总有人不负责任，尤其在开源社区，他可能就拥有这种力量。那这里面是不是比如说之前阿西莫夫就说机器人有三定律，不管谁做的机器人底层都有三条定律，不能伤害人类，不能够违反人类命令什么的。对，会不会在现在AI里面也需要一些？",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:58",
      "text": "对，我们其实最近还写了一撇，最后可能是需要一套评测方式。因为这里其实两种，第一种是我老板倡导的那一种就是说你在训练的时候要用正确的目标函数。因为现在所有训练目标都是说这比如说你强化学习的目标，这就是要最优。但是可能正确目标函数是有一定性的不确定性，并且以人的目标为最优，这是训练上。但是很多时候你可能有的人已经训练出来了，他已经练出了一个大模型了，那可能就是只能事后的去做一些评测和审计。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:30",
      "text": "说到这个特别有意思，前一阵子跟一个监管的同志去聊。对，因为你可以通过prompt让一个好人变坏人，也可以让坏人变好人，他可以演出来。所以从监管的角度，他其实是希望这个AI的价值观从一开始就是正因为现在比如说学习的语料里面，像common core里面有大量的都是那种很垃圾的，可能是这种广告信息，色情信息什么的。那你后面等于你是通过后面的教育instruction ruling，就IOSF去教你说，不要记得那些坏的东西。其实都是一个大家觉得要可控的过程。可能每个国家有自己的价值观，对这个还是个蛮迫切的问题。因为眼见着这个AI就要部署在很多产品里边。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:10",
      "text": "但我觉得其实AI这件事情上，感觉大家的反应还挺快的。因为AAI safety，大家其实我像我导师他得什么时候，1516年就开始呼吁这个事儿。其实感觉其实各国政府其实讲的挺多话之后，反应还是比较快的。我个人还是总体来说比较拥抱这样的变化的。因为我觉得生产力的发展总会出现这样一些变化。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:31",
      "text": "因为说到这个很多人就担心人家让人失业什么的。但是我是觉得这个新工作产生旧工作效果是很正常的。我不知道你有没有什么预计，对外就是说什么样的新行业新工作是会随着AI普及和发展说但是真的我。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:45",
      "text": "个人觉得首先是一些行业会发生一些变化的，就像比如说我们做天文学的同学，他原来人家做天文就是现在去夏威夷天文台就看星星。他们现在除了看星星还要写代码。可能越来越多的人都得写代码。写代码就是计算机科学网络开始了之后，大家就开始写代码。那以后可能就是说大家可能得写一些AI的条条模型，制造AI的基本原理，以后这个生活方式就会变成它是工具的一部分了。然后我觉得可能以后人除了蓝领工作，很多时候就是在创造数据。不对。他说可能这个共产主义真的有一天就实现了，因为所有人就是共享所有的数据，数据在里面超级大的AI，他有的the right object之后，那好像也挺不错。",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:27",
      "text": "对，就是数据会变成非常重要的生产要素，所以更多人需要从事生产数据和处理数据的工AI.",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:34",
      "text": "很多工作可以给AI了，数据就变成了生产要素的一部分，这是其实中国的反应是最快的。因为中国我记得是前几年就已经把数据变成了生产要素的一部分。写在法律里面了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:47",
      "text": "假设你现在，比如说冬眠了五年之后，你醒来第一个想问的问题，当然根本不是今天几点。第一个想问的与你研究相关的问题会是什么？这可能反映就是说什么是你现在特别想好奇得到解答，但是又还没有解答的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:02",
      "text": "我其实想问的是人形机器人现在做出来了吗？我其实对这个时间的估计是很不确定的。比如对我来说，我觉得你要问我五年之后有没有一个个人助手，我觉得我能做出来。倒是人形机器人五年又五年，这个能不能做出来我是不太知道。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:21",
      "text": "因为其实我们作为早期投资，我们是想寻找，比如说五年之后大概率会发生的变化。因为我们历史上来看，三年确定性比较高。比如三年前看到GPT3对于这个GPT的能力的预测，十年往往又比较远，对吧？比如说13年的时候可能是不是还没发明？对大语言模型这些，你还有些五年往往就是属于那种可能会发生一些大改变。但是也不是完全没有真正可预测，但预测难度很高的一个时间段。所以其实从做事情和投事情的角度想，五年后会发生什么是一个没有那么简单，也没那么容易的，而且也没那么难的一个时间窗口。",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:00",
      "text": "对，我会觉得彼此这件事情应该五年之后会变化很大。但是人性机器人，所以我要是让我冬眠，我肯定请他第一件事先问这个特斯拉的人形机器人做的怎么样？我就记得当时这个机器人领域搞robot cup的时候，当时他们就说希望90年代说20年之后能不能机器人跟人踢场足球赛。然后现在对这个事儿就是只能玩具机器人稍微提下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:57:28",
      "text": "因为确实物理世界变化速度要慢很多，其实像波士顿动力都做了，当然他们其实也进步了很多很多了。对，目前为止你还是很难完全觉得家庭环境那就更难了。家里还有什么地毯，还有这个还可能踩到猫是吧？就很多。是我看过你的一个采访，你说你是一个很相信直觉的人，你对未来的发展有什么直觉性的判断吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:53",
      "text": "我当然因为自己很有偏见了，因为我自己肯定会对人机交互，然后决策执行行会非常感兴趣我的直觉还是大语言模型是有天花板的，他可以是一个非常全面的，非常聪明的人。但是这个人想让他做个性化，想做超过文字的执行，我觉得还是需要一些增强和强化学习和人机交互的这些东西在里面。这是我的看法，所以我一直在往这个方向走。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:22",
      "text": "明白就是要谨慎对待。其实我觉得AI发展过程中，历次都经历了一个台阶式的变化。一个新技术出来，大家觉得能解决很多事情，后来发现其实还不够解决的好，还得再一个新的突破。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:34",
      "text": "对，但是我觉得它是一个台阶了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:36",
      "text": "很大的台阶。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:38",
      "text": "对对对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:38",
      "text": "先得踩上去。还有一个问题，就是听说你也在筹备自己的公司，那么准备做什么呢？还有大概想寻找一些什么样的人才？正好这个时候也可以向听众朋友们介绍一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:52",
      "text": "对，首先要说一点的是，我们团队其实在上海，我虽然现在在清华当老师，但其实我们是有自己的孵化项目的。我们的整个团队都是上海期智研究院的一个孵化项目，所以我们其实也在筹备自己的创业公司。然后很快很快，这个公司也会跟大家见面。所以如果对创业公司和创业团队感兴趣的同学，也欢迎来联系我。",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:19",
      "text": "我们其实招人没有什么特别明确的硬性标准，关键是看你的热情，你的想法，你是不是对做一个通用的每一个人的私人助手这件事情真的感到很激动。你愿意去花你的时间，或者说你想对做一个在现实世界中的机器人通用助手很感兴趣，或者很很愿意投入你的精力和理想。我觉得技术这个事情是可以训练的，但是理想和目标是不是跟我们团队相吻合，这是很难得的。所以我们更看重的是这个人的自驱力。所以技术我们倒不觉得有什么太大的门槛。所以如果你感兴趣的话，你欢迎给我发邮件。然后你在我的清华的主页上就能看到我的联系方式。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:04",
      "text": "好的，也非常感谢吴毅的时间，今天和你聊得很开心。最后打一个小广告。真的也一直在关注AI领域机器人领域的发展。比如说机器人领域，我们也投资了飞机机器人等一系列，不管是做专用机器人还是做通用机器人解决方案的公司。AI领域我们其实投资了像王慧文、光年之外等做大模型的公司。其实也在之前的自动驾驶领域，投资像momenta auto x浴室、地平线等一系列做自动驾驶的公司，以及投资者像汉博、随缘、木樨等做AI芯片GPU的公司。总之我们在非常的坚定的相信，AI将会非常深远的改变我们和世界的互动，改变我们对I工作和日常生活的等方式。如果大家有好的创业想法，也欢迎和我们建立联系，同时也欢迎听众在各大音频平台订阅我们频道。纸话当真，我们下期再见，谢谢你。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "本次讨论深入探讨了人工智能（AI）的发展趋势，尤其聚焦中国在AI领域的创新与进步，对比了中国AI公司与OpenAI的异同。讨论涵盖了AI研究与应用的对比，强调了现实世界数据与虚拟世界数据的重要性。同时，触及了AI安全、伦理问题，以及AI在人类生活中的未来角色。讨论者分享了对AI研究的见解，包括AI在处理复杂任务和人类交互方面的进展，也提到了面临的挑战和未解之谜。在AI伦理、法律框架及社会、经济影响方面，讨论也有所涉及，如就业市场变化、工作性质转变等。未来AI发展方向被讨论，包括人形机器人、具身智能等技术，尽管存在挑战，但讨论者对这些技术持乐观态度。此外，提及了一家新公司筹备开发通用AI助手，强调团队对于实现这一愿景的激情和对目标认同的重要性。整体而言，对话凸显了AI领域的复杂性和前景，强调了负责任地部署AI技术的重要性。",
    "qa_pairs": [
      {
        "question": "在字节这样的中国顶级互联网公司做AI研究，和在OpenAI做研究相比，有哪些异同？",
        "answer": "现实世界和电子世界的数据获取方式有所不同，电子世界数据丰富，但如何让两者联系起来是未来挑战。在AI能力上，复杂思考的system 2问题似乎更难解决，但现在AI表现得越来越好。字节跳动作为中国顶级互联网公司，在AI研究方面具有很大潜力和竞争力。",
        "time": "00:00:24"
      },
      {
        "question": "您目前正在做的研究工作有哪些方向，为什么这些工作让您觉得特别有意思？",
        "answer": "我们目前的研究方向包括游戏AI、多智能体强化学习、机器人、无人机等。核心目标是打造一个能与人交互的通用型AI，希望每个用户都有一个智能私人助手，服务于虚拟世界（如游戏、办公场景）或现实生活中，如帮助完成任务、秘书工作等。我们希望通过这一平台实现人与AI的无缝协作。",
        "time": "00:02:13"
      },
      {
        "question": "ChatGPT发布后，对于实现私人助手功能有何影响，以及未来还有哪些值得期待的研究成果？",
        "answer": "ChatGPT解决了人机交互的重要媒介问题，能够理解并执行复杂的抽象指令，极大地推动了虚拟系统的发展。然而，它并不具备完全的定制化和执行复杂任务的能力，如订购机票或实际操作游戏任务。未来仍需探索如何结合大语言模型和其他技术，实现更复杂的个性化任务完成。",
        "time": "00:03:42"
      },
      {
        "question": "对于AGI（通用人工智能）领域，有哪些超出预期的发展和意料之中的进展？",
        "answer": "AGI领域的快速发展令人惊喜，比如Few-Shot Learning和大模型的应用，如GPT-3展示的写网页、Excel等能力。但大模型的应用存在局限性，如效率问题和特定场景下的专业性需求。学术界和工业界各有侧重，学术界追求创新性，而工业界更注重确定性和落地性。",
        "time": "00:07:29"
      },
      {
        "question": "随着ChatGPT的出现，学术界在AI领域的作用是否下降？如何看待学术界与工业界的关系？",
        "answer": "学术界与工业界在目标上有显著区别，学术界侧重于创新性研究，而工业界更关注确定性和实际应用。不过，随着开源技术和大模型技术的发展，学术界正逐渐提升其影响力，并通过新的研究模式（如OpenAI的research product）加强与工业界的联系。同时，大模型的发展也会促使大型企业调整策略，追求盈利的同时保持一定的研究投入。",
        "time": "00:09:47"
      },
      {
        "question": "在欧班牙的发展路径上，是否出现了一些分歧点，比如最近的SO pic团队与欧公安团队之间的分歧？",
        "answer": "是的，在欧班牙的发展过程中确实出现了一些分歧点，比如最近的SO pic团队原本是欧公安的一个团队，他们在路径上产生了分歧。",
        "time": "00:12:45"
      },
      {
        "question": "你认为这种分歧中涉及的主要问题是什么？",
        "answer": "我认为关键在于团队是否想做长期的事情，这通常需要一定的资金支持。例如OpenAI通过产品化获得了显著的收入，其ARR接近10亿美金，主要来自ChatGPT的收费，这证明了AI已经进入主流市场。",
        "time": "00:13:15"
      },
      {
        "question": "如果要劝一个同学在清华和伯克利读博士，你会如何考虑这个问题？",
        "answer": "我会强调中国与美国之间存在大的差异，尤其是顶级学校如伯克利和MIT，在学术自由度和新教授水平上，交叉信息院在国内可能是最接近这些地方的。不过，选择在中国还是出国深造主要取决于个人打算，如果想留在国内，交叉信息院是最佳选择；若想出国，建议去开阔视野。",
        "time": "00:13:51"
      },
      {
        "question": "在字节跳动这样的中国顶级互联网公司做AI研究，与在OpenAI做AI研究相比有哪些异同？",
        "answer": "字节跳动在技术驱动方面表现较好，且对算法技术非常支持。抖音等应用场景为其积累了经验，使其有机会在AI领域取得成功。然而，与OpenAI相比，字节最终落脚于产品，而OpenAI更侧重于学术性研究和API的开发，两者侧重点有所不同。",
        "time": "00:15:14"
      },
      {
        "question": "为什么AI研究经常使用游戏作为研究对象，特别是在游戏中的进一步研究方向是什么？",
        "answer": "游戏被AI研究者青睐是因为它是现实世界复杂性的映射，既有足够的复杂性又可模拟。当前有趣的研究方向之一是人机交互，尤其是让AI在游戏中与人类自然交互并适应非理性行为的能力，以及探讨AI能否发现人类独有的策略并学会它们。",
        "time": "00:17:38"
      },
      {
        "question": "现实世界中的某些微妙信息或人类关系，AI能否在虚拟世界或大语言模型中完全展现出来？",
        "answer": "目前AI的能力受限于其训练环境和数据，难以完全捕捉到人类微妙的情感和社会范式等信息。虽然AI可以模拟和学习一些技能，但像三国演义中的谋略和微妙心理变化这类深层次人类智慧的展现，对于当前AI来说仍是一个挑战。",
        "time": "00:22:21"
      },
      {
        "question": "在物理学领域，AI能否完全解决理论物理中的逻辑问题？",
        "answer": "对于理论物理的逻辑层面问题，AI目前还难以解决。虽然可以进行数据驱动的学习，但在抽象和逻辑推演上，如果需要AI给出逻辑性的证明或理论，目前还存在较大困难。",
        "time": "00:25:39"
      },
      {
        "question": "逻辑主义与符号主义的关系是什么？",
        "answer": "逻辑主义属于符号主义的一种，即要让连接主义（如AI）去解决符号主义的问题，但这是当前AI面临的最难挑战之一。",
        "time": "00:26:16"
      },
      {
        "question": "是否存在一种可能，通过较少的人类数据输入结合大规模AI生成的数据，实现科学研究的重大突破？",
        "answer": "这是一个很有意思的想法。设想一种 scenario，AI提出假说并通过自动化设计实验，人类只需提供关键的小规模数据标注，这样的结合方式可能会对科学研究产生重大影响。",
        "time": "00:27:12"
      },
      {
        "question": "AI在围棋、星际等游戏中为何能取得突破，而在情感理解和类似ChatGPT的场景中表现不佳？",
        "answer": "这是因为AI的成功往往依赖于明确的目标和充足的训练数据。围棋等游戏因其规则清晰、有明确目标且能自我对弈产生大量数据而易于解决；而情感理解和聊天类任务目标不明确，难以获取足够数据，所以相对难以攻克。",
        "time": "00:29:12"
      },
      {
        "question": "近年来机器人领域是否有类似大模型突破性的进展？",
        "answer": "一个重要突破是OpenAI的机械手拧魔方项目，其背后的技术dme render ization（预随机化）使得AI可以直接从虚拟仿真环境训练到现实生活中部署，无需依赖传统机械工程和控制理论，堪称机器人领域的GPT时刻。",
        "time": "00:30:31"
      },
      {
        "question": "是否可以将虚拟世界中的学习成果直接应用到现实中，解决硬件差异性问题？",
        "answer": "理论上确实如此，通过构建逼真的虚拟世界，AI可以在虚拟环境中训练，然后应用于现实世界。然而，目前机器人领域仍面临硬件差异、触觉传感器研发等挑战，这些都需要进一步研究和突破。",
        "time": "00:34:12"
      },
      {
        "question": "GPT3时刻对于机器人领域意味着什么？",
        "answer": "GPT3时刻类比于大语言模型（如ChatGPT）对于机器人与人交流能力的提升，它能够帮助机器人理解和执行复杂的指令，如模拟人类日常对话并操控实体机器人完成相应任务。",
        "time": "00:35:50"
      },
      {
        "question": "在人机交互方面，为什么需要触觉传感器？",
        "answer": "触觉传感器对于机器人在与人进行精细操作时至关重要，例如递送物品，需要判断何时撒手以避免物品掉落或触碰到人。这种交互要求机器人能够感知物体状态和接触力度，而不仅仅是视觉或听觉信息。",
        "time": "00:38:24"
      },
      {
        "question": "是否有任务是人做起来容易，机器人做起来难的？",
        "answer": "是的，有一些任务属于系统一的问题，直觉性较强，人类能够轻松完成，但对机器人来说却很复杂，比如接球、刷墙等动态调整的过程。不过，随着技术发展，像ChatGPT这样的工具在理解世界和执行抽象任务上展现出很大潜力，有助于机器人理解和执行更复杂的动作和任务。",
        "time": "00:39:44"
      },
      {
        "question": "AI能否从ChatGPT这类模型中学到常识和逻辑理解，并应用到实际场景中？",
        "answer": "ChatGPT等大语言模型确实能解决一些常识问题，通过训练可以理解并执行较为抽象的任务，例如根据常识逻辑推断出“拿杯水”的过程。但对于私人定制化或高度个性化的需求，仍需进一步的强化学习和私人化定制。然而，对于大多数通用的任务，大模型能够提供一种基于常识的建模方式，为机器人技术带来显著帮助。",
        "time": "00:42:31"
      },
      {
        "question": "对于AI进化和安全性的讨论，是否存在AI自主改变权重或模型的现象？",
        "answer": "目前AI模型尚未实现自主改变权重或模型的进化，但随着AI水平的不断提升，如GPT系列模型的出现，人们开始关注AI是否会快速进化到超过人类智能，并带来潜在风险。关于AI是否有目的、是否会涌现类似人类目标的行为，目前看来是在训练过程中形成的有限能力，而非真正的自主目的。不过，随着AI能力增强，训练目标和应用场景的重要性愈发凸显，确保AI行为符合人类期望并保持不确定性至关重要。",
        "time": "00:47:41"
      },
      {
        "question": "在大语言模型中，如何处理不确定性问题？",
        "answer": "在大语言模型中，有一种方法是采用“train of thought”思想链的方式，通过投票机制来引入不确定性。同时，AI模型需要具备减少偏见的能力，并以人的价值观作为训练目标。",
        "time": "00:50:53"
      },
      {
        "question": "现在AI发展迅速且应用广泛，是否需要国际协作来确定不同的文明对齐标准？",
        "answer": "是的，随着AI能力增强和广泛应用，确实存在不同文明对齐标准不一致的问题，这可能需要国际协作来解决。",
        "time": "00:51:33"
      },
      {
        "question": "OpenAI是否在负责任地发展AI，例如开源问题上？",
        "answer": "OpenAI在某些方面表现出负责任的态度，比如在不确定能否发布技术时会选择先不发布，即使这在商业角度看可能是闭源。此外，OpenAI有团队去做相关工作，如在联合国做报告。",
        "time": "00:52:04"
      },
      {
        "question": "是否需要为AI设立类似于阿西莫夫机器人三定律这样的原则？",
        "answer": "是的，现在讨论中包括建立一套评测方式以及可能的AI伦理原则，比如确保AI不伤害人类、遵循人类命令等。",
        "time": "00:52:37"
      },
      {
        "question": "AI普及后，哪些新行业和工作会随之出现？",
        "answer": "随着AI普及，编程技能将成为更多人的必备能力，尤其是开发AI模型。数据将成为重要的生产要素，因此从事数据处理和创造数据的工作会增多。中国是率先将数据视为生产要素之一的国家。",
        "time": "00:55:27"
      },
      {
        "question": "对于人形机器人的研发进展，您有何看法？",
        "answer": "对于人形机器人能否在五年内实现，我持不确定态度，但预计到2028年左右可能会有较大变化。物理世界的变化速度较慢，技术和物理环境的适应性是一个挑战。",
        "time": "00:57:28"
      },
      {
        "question": "您对未来AI发展的直觉判断是什么？",
        "answer": "直觉上认为大语言模型在个性化和跨领域执行方面存在天花板，需要结合增强和强化学习以及人机交互技术进行突破。",
        "time": "00:57:53"
      },
      {
        "question": "您正在筹备的公司目标是什么，以及希望寻找什么样的人才？",
        "answer": "我们团队在上海期智研究院孵化下筹备创业公司，目标是开发通用型私人助手，特别看重候选人的热情、想法和自驱力，技术能力可以后续训练，但理想目标与团队相吻合至关重要。有兴趣的同学可以通过我的清华主页联系我。",
        "time": "00:58:52"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探讨中国AI研究与国际接轨的挑战与机遇",
        "summary": "对话中讨论了中国在AI领域的研究发展，特别是字节跳动被视为有潜力成为领先大模型的公司。同时，通过比较在字节和OpenAI做研究的异同，探讨了如何更好地将现实世界与电子世界的数据相结合的未来挑战。还提及了AI在解决复杂问题上的进展，以及嘉宾吴毅在多智能体强化学习、人机交互等领域的研究贡献。"
      },
      {
        "time": "00:01:58",
        "title": "探索通用AI及人机交互的未来",
        "summary": "研究方向包括游戏AI、多智能体强化学习、机器人和无人机等，目标是实现能够与人交互的通用AI，从而为每个人提供智能的私人助手。这个想法的驱动力是对未来世界的畅想，希望AI能够协助完成日常任务，无论是虚拟世界还是现实生活中。特别地，ChatGPT的发布被认为是向这一梦想迈进的一大步，尽管它还不能完成定制化任务或具体行动，但其在理解和拆解复杂指令方面展现了巨大潜力。研究人员对ChatGPT的接受度和影响感到既意外又不意外，认为其火爆程度和实际应用的可能性超出了预期，同时也指出了人机对话对齐的重要性。"
      },
      {
        "time": "00:07:16",
        "title": "探讨AGI的未来：语言接口、Auto GPT及多模态协作",
        "summary": "当前，人们对AGI的讨论热度不减，尤其是在投资市场和政策制定者中。然而，对于AGI技术的某些方面存在高估和泡沫。首先，不是所有任务都需要通过语言接口完成，特别是在追求效率时，过多的交流可能降低效率。其次，尽管大语言模型具有通用性，但面对高复杂性任务时，通用模型可能无法提供理想的解决方案，强调了领域增强的重要性。此外，提出了大模型与小模型或多模态模型的协作模式，如通过小模型预处理信息，大模型进行关键思考，或者小模型生成初步答案和自信度，大模型进行修正和评估。这种多层协作的模式，尤其是在需要执行复杂任务时显得尤为重要。总体而言，虽然大模型是AGI发展的必然组成部分，但其并非万能，需要与其他技术结合，以应对更加复杂的现实挑战。"
      },
      {
        "time": "00:09:47",
        "title": "探讨学术界与工业界在AI领域的区别与联系",
        "summary": "在AI领域，学术界与工业界的目标存在明显差异，学术界追求创新和idea的原创性，即使大部分尝试可能失败，而工业界更注重产品落地和确定性。近年来，像OpenAI和DeepMind这样的机构提出了研究产品的新模式，介于纯研究与立即商业化之间。开源软件的流行，尤其是在AI领域，极大地推动了技术进步，降低了进入门槛。OpenAI从一个非盈利组织转变为追求盈利的公司，其策略是为了资助长期的AGI研究，而这种转变也体现了在资源和算力上，大公司同样面临瓶颈，开源和学术研究的重要性逐渐显现。"
      },
      {
        "time": "00:13:35",
        "title": "清华与伯克利选择建议及字节与OpenAI研究比较",
        "summary": "在选择高校方面，伯克利和清华都提供了优秀的教育和研究环境，选择主要基于是否想留在中国还是去美国深造。清华交叉信息院在学术自由度和新教授水平上与国际顶尖院校相差无几。对于有意向留在国内的学生，清华交叉信息院是理想选择，而对想出国的学生则建议去美国探索。关于在字节跳动和OpenAI进行AI研究的对比，字节跳动作为技术驱动的公司，有强大的算法技术基础和应用场景支持，尤其在抖音平台上，展现出其在AI研究和应用上的潜力。相比之下，OpenAI更专注于AI研究本身，而字节跳动则更侧重于产品落地，两者在研究方向和商业模式上存在差异。"
      },
      {
        "time": "00:15:56",
        "title": "OpenAI的发展策略与AI研究方向",
        "summary": "OpenAI最初并非旨在开发特定产品如ChatGPT和API，其成功在一定程度上归因于选择的偶然性。公司愿意投资于看似学术的研究项目，如捉迷藏和机械臂，显示了其独特的企业文化。ChatGPT的推出，通过与用户的交互记录，为模型对齐和改进提供了新途径，体现了OpenAI在AI技术上的双轮驱动策略。此外，游戏作为AI研究的重要对象，因其复杂性和可模拟性，成为测试和开发AI算法的理想环境。特别关注人机交互的方向，探索如何让AI更好地与非专业用户协作而非仅仅战胜人类，以及如何实现更加自然的人机沟通，展示了未来虚拟助手系统的潜力。"
      },
      {
        "time": "00:19:48",
        "title": "探讨人工智能学习人类策略的界限",
        "summary": "对话内容涉及人工智能(AI)通过自我对战(self play)学习游戏策略的能力，以及这种能力是否可能超越人类独有的策略。AI能够在游戏中发现并利用bug，显示出其在策略学习上的巨大潜力。然而，存在关于AI是否能够掌握人类所有策略的疑问，尤其是那些基于人类间复杂关系和心理活动的策略。此外，还探讨了将虚拟世界与现实世界紧密连接的挑战，以及AI在处理微妙的社交信号和长期、复杂谋略方面的困难。最后，提到自动化AI如AutoGPT的发展及其可能带来的影响，反映出对AI未来能力的担忧。"
      },
      {
        "time": "00:23:04",
        "title": "探讨人工智能在创造和研究中的应用与限制",
        "summary": "对话集中在人工智能（AI）在文学创作、科学研究以及解决复杂问题上的潜力与局限性。一方面，AI在生成文本、预测蛋白质结构、药物研发和天文发现等方面已经展现出巨大能力，甚至可能在某些领域超越人类的成就。另一方面，对于需要深刻理解人类情感、社会交互以及抽象思维的任务，AI仍旧面临重大挑战。特别指出，尽管AI能够处理大量数据和执行特定任务，但对于目标模糊或需要创造性思考的领域，人类的参与仍然是不可或缺的。此外，讨论也触及了AI在自我学习、实验设计以及理论物理等领域的潜在应用，强调了结合人类智慧与AI能力的重要性。"
      },
      {
        "time": "00:30:01",
        "title": "机器人技术的现状与未来展望",
        "summary": "近年来，机器人技术虽未像大模型领域那样取得飞速进展，但仍有一些重要突破。例如，OpenAI提出的算法允许机器人直接从虚拟仿真环境中学习，并成功应用于现实世界，如机械手拧魔方。此外，强化学习和AI控制在无人机、机械狗、机械臂等领域取得成功。然而，机器人技术面临的主要挑战包括硬件限制、感知、决策、行动等多个模块的配合，以及对触觉等感官的模拟。未来，机器人技术预计将从执行单一任务向多任务、通用型机器人发展，最终目标是实现能够进行日常家庭任务的机器人。"
      },
      {
        "time": "00:37:19",
        "title": "探讨GPT3时刻及机器人技术发展",
        "summary": "讨论重点在于GPT3代表的技术突破，及其对多个行业的影响，特别是如何将科研成果转化为产品并实现商业化。同时，探讨了在机器人技术领域，特别是在硬件和传感器方面的挑战，以及强化学习在实现更自然的人机交互中的应用。特别提到了在人机协作中遇到的难点，如触觉传感器的缺失导致的物理交互困难，以及选择商用机器人进行科研的策略。此外，还讨论了人工智能在解决直觉性和动态反馈问题上的挑战，与人类相比，机器人在这些方面存在显著差距。"
      },
      {
        "time": "00:41:38",
        "title": "探讨ChatGPT对AI理解世界的影响",
        "summary": "随着ChatGPT的出现，人们开始认为具身智能的AI能够更深入地理解世界，包括其逻辑和语义。它能够解决一些基于常识的问题，如找到一杯水的逻辑路径，以及私人定制化请求的处理。尽管一些观点认为大语言模型如ChatGPT仅处理随机序列，没有事件模型，但通过实践发现，ChatGPT似乎具备理解世界模型和常识的能力。通过一些具体的例子，如空间关系的理解和对幽默照片的解释，表明ChatGPT不仅能够处理文本信息，还能在一定程度上理解复杂的语境和场景。这些发现对于机器人和AI领域具有重要的启示作用。"
      },
      {
        "time": "00:45:11",
        "title": "探讨AI安全及进化类比与未来展望",
        "summary": "对话内容涉及AI安全问题、AI进化类比于生物进化、以及对AI未来发展和可能对人类社会影响的担忧。首先，提出将生物进化类比为强化学习过程，强调了生存和繁衍作为基本的奖励机制，从而形成了各种生存策略。随后，讨论了与AI相关的安全问题，特别是关注于AI可能超越人类智能的情况，以及这种情况下人类可能面临的危险。还提到了当前的AI技术，如语言模型和AlphaGo等，它们虽然展示了特定领域的进化，但这种进化是狭窄且受限的。此外，讨论了未来AI可能的进化方向，以GPT模型为例，探讨了AI能力的潜在增长。最后，探讨了AI拥有目标的可能性及其对人类社会的潜在影响，包括AI可能为了实现目标而对人类采取的行动，强调了训练目标的重要性以及当前AI研究中对安全和伦理问题的关注。"
      },
      {
        "time": "00:48:54",
        "title": "探讨人工智能的不确定性与道德对齐",
        "summary": "对话中讨论了人工智能（AI）领域中模型过度自信的问题，特别是深度学习模型在进行图片分类时出现的错误率与自信度不匹配的现象。指出AI需要引入不确定性，以更接近人类决策过程中的不确定性和多角度思考。此外，强调了AI的道德对齐问题，认为随着AI能力的增强和广泛应用，对齐人类价值观变得尤为重要。提出了国际合作的必要性，以确保AI的发展能够考虑到不同文明和地区的特定需求和标准。最后，讨论了AI开发的责任问题，提到了OpenAI在闭源方面的考虑以及阿西莫夫的机器人三定律，暗示在现代AI中可能也需要类似的道德准则。"
      },
      {
        "time": "00:52:57",
        "title": "探讨人工智能的监管、价值观及对未来工作的影响",
        "summary": "对话集中在人工智能（AI）的几个关键领域：首先，讨论了在AI训练过程中使用正确目标函数的重要性，以及如何处理已经训练好的大型模型的后评估问题。特别强调了监管角度对AI价值观的担忧，比如AI学习的语料可能存在不良信息，以及通过教育修正AI行为的挑战。进一步讨论了各国对AI安全性的迅速反应，表达了对未来AI在促进生产力发展中的乐观态度。最后，预测了AI普及和发展将如何影响未来工作和行业，包括编程成为更多人的必备技能，以及数据生产与处理成为新的职业方向。特别提到了中国在法律层面将数据定义为生产要素的举措。"
      },
      {
        "time": "00:55:46",
        "title": "探讨人形机器人发展及AI领域的未来",
        "summary": "对话集中于人形机器人和AI技术的未来发展，特别是关于五年内是否能实现人形机器人和个人助手的突破。讨论还涵盖了AI技术的台阶式发展、大语言模型的限制、以及强化学习和人机交互的重要性。此外，还介绍了发言人所在的团队正在上海筹备的创业公司，强调了对有热情、有理想人才的需求，以及他们对AI改变世界的坚定信念。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [],
              "content": "通用AI：正在探索如何使AI能够解决复杂问题，并逐渐应用于实际生活中的各种任务。"
            },
            {
              "children": [],
              "content": "人形机器人：研究方向之一，面临许多挑战，如精确的运动控制、感知与交互等。"
            }
          ],
          "content": "通用AI与人形机器人"
        },
        {
          "children": [
            {
              "children": [],
              "content": "大模型技术：如GPT，通过大量数据训练，实现语言生成、理解等任务，展示了强大的能力。"
            },
            {
              "children": [],
              "content": "OpenAI：从非营利组织转变为追求盈利的公司，以资助其长期研究计划。"
            }
          ],
          "content": "大模型与OpenAI"
        },
        {
          "children": [
            {
              "children": [],
              "content": "中国顶级互联网公司的AI研究潜力：字节跳动被认为是具有强大竞争力的AI研究公司之一。"
            },
            {
              "children": [],
              "content": "比较字节跳动与OpenAI的研究：字节跳动注重产品和技术驱动，OpenAI更注重基础研究与创新。"
            }
          ],
          "content": "中国与AI研究"
        },
        {
          "children": [
            {
              "children": [],
              "content": "AI的未来：讨论了AI发展的可能性及其对社会、经济的潜在影响。"
            },
            {
              "children": [],
              "content": "AI安全：探讨了如何确保AI系统不会对人类社会造成伤害，以及在设计AI系统时考虑伦理和安全问题的重要性。"
            }
          ],
          "content": "AI安全与伦理"
        },
        {
          "children": [
            {
              "children": [],
              "content": "个人与职业发展：AI的发展可能影响未来的职业结构，同时也会产生新的职业机会。"
            },
            {
              "children": [],
              "content": "社会影响：AI的普及和应用可能改变社会的运作方式，提高生产力，但也可能带来失业等社会问题。"
            }
          ],
          "content": "个人与社会影响"
        },
        {
          "children": [
            {
              "children": [],
              "content": "强化学习：在机器人控制、游戏等领域有重要应用，但面临从模拟到真实世界应用的挑战。"
            },
            {
              "children": [],
              "content": "人机交互：研究如何使AI更好地理解和执行人类的指令，提升人与机器的协作效率。"
            }
          ],
          "content": "技术突破与挑战"
        },
        {
          "children": [
            {
              "children": [],
              "content": "未来AI：讨论了AI技术的未来发展方向，包括更加个性化、能够执行复杂任务的AI系统。"
            },
            {
              "children": [],
              "content": "AI对人类社会的影响：探讨了AI技术可能如何改变我们的生活、工作方式，以及对未来社会的可能影响。"
            }
          ],
          "content": "AI未来预测"
        },
        {
          "children": [
            {
              "children": [],
              "content": "创业机会：AI和机器人技术的发展为创业者提供了广阔的市场和机遇。"
            },
            {
              "children": [],
              "content": "投资方向：投资者对AI领域的兴趣不断增加，特别是在通用AI、人形机器人、以及AI安全和伦理等方面。"
            }
          ],
          "content": "创业机会与投资方向"
        },
        {
          "children": [
            {
              "children": [],
              "content": "个人参与：鼓励个人通过学习、研究和创新参与到AI技术的发展中来。"
            },
            {
              "children": [],
              "content": "对社会的贡献：强调通过AI技术解决实际问题，提高生活质量，促进社会进步。"
            }
          ],
          "content": "个人参与与贡献"
        }
      ],
      "content": "AI技术及其应用讨论"
    }
  }
}