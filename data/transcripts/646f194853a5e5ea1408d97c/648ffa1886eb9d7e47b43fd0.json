{
  "pid": "646f194853a5e5ea1408d97c",
  "eid": "648ffa1886eb9d7e47b43fd0",
  "title": "特别放送：一个 AI 创业者的反思、观察和预测",
  "task_id": "r28pn7e8maaaq5mz",
  "transcription": [
    {
      "time": "00:00:01",
      "text": "我们认为现在什么样的数据是最值钱的数据呢？我给它的定义叫做不属于你，但是与你共生的数据是真正的壁垒。LM大家之前对它寄予很高的一个期望，就觉得它到底有没有希望能解决AI落地难和复制难这个问题。LHF这个词非常火，但其实它不是目的，它只是一个手段。总结来说就是不要给AI做插件，而让AI成为你自己业务的一个插件。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:33",
      "text": "欢迎大家收听，此话当真，真格基金投资团队将在此和各领域的领军人物一起分享最新热点和行业洞察。真格你的创业第一站，我是真格基金管理合伙人戴雨森。本期节目我们想和大家分享一次真格基金内部的闭门会议。在这里我们邀请到了记忆超pick和我们分享他作为一个AI的创业者，对最近AI浪潮的反思、观察和预测。Pek是一个技术的小天才，他在十多年前高中的时候就独立开发了摩码浏览器，也因此登上了福布斯杂志的封面，获得真格基金的天使投资。后来他又主导研发了Maggie知识引擎以及相关的知识图谱信息检索LP等一系列的相关技术。话不多说，我们直接进入主题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:21",
      "text": "今天讲的这个标题叫做unpopular painting sunday AI但大家不用担心，这不是一个技术分享，称之为一个AI创业者的反思观察和预测。因为我也是有幸过于早的加入到了AI这个行业。然后从2013年V2V横空出世一到现在这个大模型，我都一直在技术和产品的一线。所以我相信无论是谁，就经过这么多个周期的反反复复，也能总结出一些经验，还有一些观察。今天分享其实就三部分，反思，回顾一下过去的一些经验偏感性。然后接下来观察和预测的话就可能更干货。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:51",
      "text": "先讲第一部分反思。第一点就是咱们可以回顾一下移动互联网的初期。在iphone刚出来的时候，我们发现整个市场的环境跟的有像。那时候感觉百花齐放，创业者敢做基础工具，对吧？那时候我也很傻的加入到这里头，同时那时候创业者也敢用最新的压缩算法，做以前人没有见过的新的社交的工具。同时还有人就敢挖掘每一种传感器，做出新的这些游戏来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:13",
      "text": "那这个时候我们为什么是这样呢？因为其实大家想想，在当时iphone one只有128兆的内存，还有缓慢的3G网速面前。其实创业者跟巨头是相对来说平等的。而且那个时候巨头其实跟我们一样，也都是在有限的这个舞台上跟我们去竞技。他们也在摸索最基本的这个模式，还有套路。这时候他们也没有特别多的精力来打我们。所以这时候都在带着镣铐跳舞的时候。其实创业者是可以凭借自己的洞见，跟一些细丝去有更多的机会去竞争的那是一段美好的时光，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:41",
      "text": "有很多公司从那时候出现，包括像类似快手的，甚至一直走到了现在。而在现在这个AI领域，其实感觉又有新的有限制的舞台诞生了。我们可以看到，其实在今天这个AI领域，我们可以类比一下今天的本地之于云端。很像当时比如说2010年前后，APP领域的手机之于PC它又是一个新的有限制的舞台出现了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:02",
      "text": "比如说我们现在在云端看AI几乎就可以发挥大公司所有擅长的东西。比如最近大家都都觉得微软是非常猛的对吧？他的这些工程能力，他的模型能力都能无限的去scale。我们创业者去跟他去竞争，这个真的希望不是特别大。所以如果是我的话，最近可能会更多看的两个方向就是to c方面。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:20",
      "text": "可能更多看一个on device的AI比如说一个很典型的例子就是前任很火的rewind到AI。他其实在跟大公司有一个稍微错位一点的一个市场。包括其实你看google最近发布的那个palm 2系列模型，其中有一个叫做jackal的最小的尺寸的模型，我们觉得可能是最有意思的。接下来很多的这些创新，我觉得to c端可以多看一看on device这个方向。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:40",
      "text": "而to b端的话，其实可以看到一个传统领域叫on prem。On prem这个东西其实在国内的话，我认为是挺值得做的一件事情。因为首先我们底下要提到的点就是信创指标这个事儿。目前信创指标其实大家都知道，很多公司都是有一些钱它是必须花的。因为它国产化替代要达到一定的这个比例。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:58",
      "text": "而比较好的一个消息是经过大概五年左右，我们发现其实国内这些所谓的AI替换基本是堪用的了。比如看像那个寒武纪MOU370，像什么天数智芯M100之类的。它这些特定的work flow下面，你如果在推理层面，它基本的性能能够达到NVIDIA的终端的卡的水平，就是A10A40这个级别的。所以如果你要做on cram，你仍然可以把你的这个隐私合规和成本作为leverage。所以这个on device on cram我认为可能是有点像十几年前的时候，我们这一批移动互联网创业者那能打的错位竞争的一个舞台。这是第一个观点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:31",
      "text": "然后第二点，这也是一个比较暴论的一个点，就是咱们老说这个数据。其实数据这个事儿我们要仔细去看一看。首先我觉得大家都比较公认的一点就是open accessible的数据真的是不值一提的。同样能爬的数据不这个都不说了。以前的话我们可能会吹，包括现在很多项目都会吹。说我什么深耕一个垂直领域，我有自己收集的很多数据，像比如说机器人说我们做了很多situation，或者我有很多传感器收集了很多东西。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:55",
      "text": "但目前我们看来有一点就是created数据其实也不是在那么绝对的安全了。举一个例子，还是就刚刚提到机器人，现在LM现在火了之后，你会发现很多之前用RL或者模拟得到的一些数据，其实它的价值都在下降。因为LN本身的word knowledge已经cover了一些你本来需要人类去编辑或者收集的数据。",
      "speaker": "发言人1"
    },
    {
      "time": "00:05:14",
      "text": "我们认为现在什么样的数据是最值钱的数据呢？我给它的定义叫做不属于你，但是与你共生的数据是真正的壁垒。这个是什么意思呢？就比如说还是举个on prem的一个例子，我们可能为很多企业客户做一些信息化的解决方案，那什么数据是你的呢？那你这个基础的模型，你train的一个foundation，这个东西是你的，但是客户的数据是你不能够拿走的。这部分东西其实就有点像你要跟客户之间构建一个不让他迁移的一个成本。",
      "speaker": "发言人1"
    },
    {
      "time": "00:05:39",
      "text": "这块就引出了第三个观点，其实现在LM的能力非常强，很多事情都可以通过in context learning就解决。这in context learning稍微解释一下，就是大家不是平时用prompt，对吧？你要解决的一些客户私有的问题，以前的习惯可能是为客户单独去翻译这么一个模型，而现在其实不需要。你可以把客户相关的信息或者知识直接放在里头，就直接就解决了。所以finding这件事儿其实是在90%的场景下是完全可以被忽视掉的。我听的这个概念其实也为了跟客户之间达成一种共建的关系。要不然其实在LM时代再往后发展，大部分的业务其实都可很简单的通过in context你给你换掉。我们得主动去跟客户去形成一种共建的这样的一个关系。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:19",
      "text": "最后一点也是一个观察，无论是做to b还是to c我们可能都会更关注能跟你共建的数据到底在哪里。目前我觉得也比较明显了，企业场景下所有的数据基本都汇集协同工具。企业内部协同工具像飞书，我觉得他们其实有很大的一个优势。因为你本来企业内所有人与人之间的沟通以及沉淀的文档都在那。所以我们可能会尽量的去靠近企业的数据源，也就协同工具这边。而个人场景的话，目前看来其实就是在设备端会比较多。同时设备端这也比较有意思，就是最近我在跟一些设备制造商也在聊。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:51",
      "text": "他们其实对于设备端的LM非常感兴趣的一个原因很逗。因为现在手机大家知道其实卷了很多年摄像头了，这个是一个很无聊的事情。而之前在LM之类这些东西诞生之前，所手机端的那些芯片的AI算力，其实基本都是为影像的服务。而现在对他们来说，其实有了一个全新的一个场景。他们现在非常急迫的想要把类似于siri这种东西在on device上做的更强。一个很简单的一个场景，现在siri做不好。就比如我有些设置我想让siri帮我去操作，但是siri他完全听不懂复杂的连续的指令。而这样有了一个on device LM的话，其实我们根据用户的在手机上的内容和他的需求，能为他完成端到端的操作，这会是会是非常好玩的一个做法。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:30",
      "text": "下一个观点，这个是比较好玩的一个，就是我们认为当前的limitations，其实在预言着下一个innovation trigger。这个也是我们经常在想的一个问题，总会想，下一个next big thing到底是什么？我认为预测next big thing是非常困难的一件事儿。但是我们可以预测的是next big thing它究竟会去解决什么样的一个问题。我们平时去思考这个的时候，可能会做很多的访谈，对吧？但是其实对于专家或者说我们这些从业者来说，我们的预测是非常有惯性的。比如说你问我LM未来是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:58",
      "text": "我可能会天然的说是based，因为我之前就是做这个的。但是当你聊了很多不同专家的时候，你会发现他们虽然都有自己的惯性，他们眼前的limitations是有非常强的共性的。这个是什么意思呢？如果我们回头看，从现在LM一直回看到2013年we're to back所有的变革基本都是能在之前有一个limitation这个点去引出来的。比如我们可以盘一盘，其实在2013年之前，我们那时候在做这个依存句法分析分词这东西非常土。然后我们天天就很羡慕那些搞CD或者搞信号处理的。我靠，他们居然能用连续的信号，用那些成熟的机器学习算法去做，一直就期盼，到了2013年底，t mac lab出了那个word vector paper，石破天惊，对我们来说简直太好了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:39",
      "text": "然后后来我们就开始做产品，做着就遇见了一个特别简单的一个问题。你有了virt back，你把一个文本变成向量。但是我发现苹果这个水果它的向量跟苹果公司这个向量是完全一致的那这我们想到底我们能不能有一个contextualized的一个表达方法呢？果然再过一会儿就有了elmo。Elmo这可能现在很多人都没有听说过了，它是1 embedding的模型。但是我们开始把elmo去产品的话，这时候大概已经到了2015前后了。然后发现这东西太慢了。然后这时候我们就想到底谁能把这个elmo这个玩意儿给加速一些呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:10",
      "text": "位置发现果然有了transformer，在后面就有bird。其实一步一步都是在这样有limitation在演进的，去往后去引导它的变革。而到了现在，接下来我要讲的几乎所有的预测也都是从这个点出发。所以我可以比较自信的待会儿会预测一些下面到底会发生哪些变化。他们不一定是next big thing，但一定是next big thing要去解决的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:29",
      "text": "接下来我要讲的就是我血的教训，就不要把解决了最显眼的limitation当做自己唯一的护城河。这是什么意思呢？我但是我之前用了七年的时间，我们做的magi就解决了一个很难的学术问题，叫做基于不可靠的文本自动构建知识突破。用学术界的角度就是life long learning with open information exception，这个东西非常难的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:48",
      "text": "但是我当时怎么说呢，还是有点满意的是什么？因为所有人都知道我们要解决的问题就是知图谱构建中需要很多的人力，这是最大的limitation。我们想把人从整个loop中优化出去，这整个学术界都知道这件事儿。我们19年终于做出来的产品很火人很飘。我当时很高兴，后来才知道微软当时已经在跟OpenAI接触了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:07",
      "text": "这是什么意思呢？就是当所有人都知道一个东西最大的limitation的时候，你跑的是最快的，但你不一定跑的最好的。我用了很苦的办法解决了这个问题。你觉得你解决了最显眼的limited，那很多人其实可能在用一个包抄你的方法来解决这件事儿。所以对于任何一个技术创业者来说，绝对不要把最显眼的limit当做自己唯一的一个护城河。一定要找到自己除此之外的点，要不然就会重蹈我的覆辙。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:29",
      "text": "接下来讲的就是这一个叫三年内的是经验剩下的历史包袱。这句话其实既是对人，其实对公司来说，我也觉得也是比较适用的。因为首先有一点，AI产品它的AI的发展其实不是顺序递进的。你会感觉周期性的有点另起炉灶这种感觉。我们经常过几年就会发现，曾经很流行的东西已经再没有人提这个事儿了。而从AI的发展，你如果落实在产品层面来说，这我觉得对于创业者来说是很好的，在不断创造新的可能性。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:55",
      "text": "但是从技术的角度来说，其实技术一直是在替换过去的既有的实践。虽然来说底层技术是确实有一些延续性的，但是做过真正AI创业人都会发现，所谓的AI创业，哪怕咱不谈所有的销售或者这些商业化的东西。你80%的东西是产品工程，20%的是底层的技术。甚至好如果你是这个时候创业，而你恰好不是open a或者anodic的话，你可能有10%的技术，技术就不错了。而这个时候我们会发现，所有这些新来的人，他不仅是技术、行业规模，甚至利益分配，这些东西都是历史包袱。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:29",
      "text": "这举一个什么例子，像google就很典型。Google为什么说new病？现在风风火火的google到现在其实也不敢非常大方的全量的去把它放到它的search产品里头。第一，首先你这个规模下，导致你google要全量上一个LM的话，它的成本非常高，它的甚至都无法cover。第二点，它的利益分配也是问题，你怎么跟google最赚钱的广告部门去交代。所以综上所有这些东西，我们现在看就是年轻人和新公司的灵活性在任何时候其实都是有优势的，不用特别担心就是所谓的过往的经验。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:58",
      "text": "再一个也是一些经验谈方面东西，就是监管与合规。我认为其实是一种可以利用的竞争维度。首先第一点就是我们客观来说，大部分的监管无论是国内国外，只要你没有谈什么准入之类的，总体来说还是一个一视同仁的事儿。那你只要是一视同仁，其实作为创业者也就没什么好抱怨的了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:15",
      "text": "但更重要的一点就是要提前意识到这件事情。提前在你产品的规划期间，你就把这个事儿当作一个产品工程的问题，提早去规划。在国内的话可能会多想一件事，就是说合规是一个动态的一个问题。你千万不要想着说我要训练一个所谓的符合中国国情的大模型，你不要指望去这样去做一个一劳永逸的一个解法。所以一定要把moderation这个事与核心去解耦。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:39",
      "text": "这方面我们发现其实open I做的反而还很好。Open I有一个服务叫做open IAPI的moderation API。它是把它的积累的一些，无论是什么涉及个人隐私偏见，还有这些什么恐怖之类，它都包装成了一服务。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:52",
      "text": "这目前国内的话，可能大家还是更多的in house在做这件事儿，没有一个很好的一个统一的解决方案。而接下来这一波所有大模型创业，他们早晚会遇见这件事儿。所以我觉得对于我们的背投来说，也是让他们提前一定要想好这个东西。第四点其实也是一个经验，就是说跟监管去沟通的时候，主动报备，坦诚沟通，然后你就可以去做那些别人不敢做的事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:13",
      "text": "这是反思中的最后一个小天才变成技术派其实是个危险信号。对，这个也是一个个人经历。虽然比较不要脸，说确实早期是小天才，然后慢慢熬成了技术派。然后现在在做操盘手，然后估计快要当老司机了。但是我认为其实小天才从创业后变成技术派，其实是一种zoom a ability的丧失。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:32",
      "text": "这前几天群里看这个词儿，我觉得特别好。我在写这页的时候就在想这个词该怎么说。因为是这样在早期，比如能为真格看上这些小天才，一般来说是已经搞出点名堂的。而搞出点名堂的人从来不是一个单独的一个维度的的。好，但是AI这个领域是特别容易让人陷进去的。你如果你在创业之后才变成技术派，其实我认为这是对你创业的一个人的画像的一个损失。所以这件事是一定一定要要去回避的。不过反过来说，其实小电竞很有可能不是变主动变成技术派，而是没得选。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:02",
      "text": "这在很多很多年前徐老师跟我聊过一次，就说其实pick你应该找一个CEO。我是很认同这件事的，但是这个东西其实没什么办法，就是我们后来真的去尝试去招一些比较senior的这个人，你发现他从观点甚至风格上都是很难与你融入的。所以这个问题其实我也想怎么说，我到现在我也没有很好的回答这个问题。就是究竟比如说对于一个真正特别年轻的创业者，到底怎么去找到一个能力的自己的人。接着就是观察了，观察这部分可能就会更稍微干货一些，然后会稍微就有一些比较unpopular的painting了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:32",
      "text": "第一点，这两页可能都是更多在讲目前AI to b的一些直接的一个感受。虽然现在感觉好像这事儿才过了半年左右，但是目前我们发现low in fruits已经在迅速的去耗尽。我们发现跟客户聊的过程中，其实有65%的需求，你最后都可以集中理解成信息的检索、汇总和再生成，这是非常浅的一件事儿。其实国外你发现很多人都在做着什么，帮到AI之类些，这就是大家一眼就能看见的一个需求，也确实很多人都在做，非常卷。大概有20%的客户其实有流成自动化和决策辅助的需求。说白了就比如像那个BI取数l to SQOO这些东西。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:05",
      "text": "然后让我比较意外的其实是文生图，还有代码生成。其实客户的需求是蛮低的这也是一个比较意外的一个观察。因为我以为很多人真的会很希望有写代码这东西，看来大家都是比较清醒的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:17",
      "text": "然后这回也可以补充一下，就是写代码这个事国内其实也有几个难点。第一就是我们国内缺乏一个像github这样又大，我们又相信它的一个平台。所以你没有这样的一个土壤去串出一个很好的这样的一个模型。第二点就是写代码这个事儿，其实不单纯是一个写代码的模型，你得了解需求才能写出代码。为什么get up copilot做的比较好？因为其实你还同时有github上下文的需求。你的注释，包括甚至web on stack flow这些东西都是英文的，他的理解英文需求能力比较好。中文目前这事儿稍微有点误解。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:43",
      "text": "最后一点，其实也就是主流方案各家都有。我们去跟各种客户去谈时候，发现这几个老面孔都在。第二点观察也稍微有一点暴露的，其实就是LM大家之前对他寄予很高的一个期望，就觉得他到底有没有希望能解决AI落地难和复制难的这个问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:57",
      "text": "我们发现其实现在这个答案是偏向于负面的。首先先说好的一部分就是LM确实加速落地，这是一个比较好的一个现象。但不确定的原因是什么？第一个就是现在做的还是刚才那些low hin fruits，是可能是客户的需求撞上了我们，而不是像长期发展中一个正常的一个状态。第二点就是我们虽然是成功加速了单个客户的落地的时间，但其实发现落地难这件事依然是没有解决的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:21",
      "text": "举一个很简单的例子，就是生成式AI跟我们过往做的很多AI产品最大区别是它的随机性其实非常的大。而目前比如大家看项目也发现很多人自己给的说法就是我们先做一些大客户，央企、国企、银行。但这些人他其实对于可靠性的要求是非常高的。所以我们发现有很多场景我们就聊到最后，是在最后PUC阶段之后被毙掉的。必掉的原因是什么？就是你达不到它的一个半，甚至其实他们还有一类客户就最后想通了，我要的其实不是LM，我要更好的搜索。其实生成JI也会面临一个新的落地难的问题，而且跟之前相比还有点更烦的就是它的优化周期会更长，这个很难你去控制住一个大模型。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:56",
      "text": "还有一点就是复制难这件事，LM确实来说它是统NOP的范式。大家做AR大头A这么多的方式，其实客户要根本不是AR不是模型，要的是一个解决方案。我们发现其实NOP的范式统一了，我们开发的过程中可能只会面对一个大模型了。但是它上面的解决方案交付方面的压力依然是非常巨大的。而且反而现在客户了解到了很多相关LM的知识，他们的需求变得天花乱坠。之前的话大家可能做AI还经常能说清楚自己在哪个赛道上。因为我是做安防的，我是做人脸什么东西的。现在真的我们觉得大家就是外包这个会非常难受。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:27",
      "text": "你的复制难的问题，我觉得反而被LM有一定程度去放大了。第四点是之前做to b的大家都没想到的一个点，以前不会遇见这个状况，我们就有一个C端产品比你们都牛逼的多。现在客户的这个期望已经被ChatGPT提到了一个离谱的一个高度。他们见过最好的，这是非常尴尬的一件事儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:44",
      "text": "接下来就说到我们可能现在已经逐渐很多人客户已经到了一个幻灭的一个阶段了。我们现在发现运营能力这件事开始凸显出来了。运营兜底这件事是什么意思？待会讲一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:54",
      "text": "首先讲一下背景。刚才提到了我们如果看过往所有的产品化的AI跟现在LM相比，LM的精准度其实偏低的。之前大家可能知道我们要做什么，人脸的话你识别的精准度可能99%点几几几几个九，大家都在这么吹。但是LON的精准度，首先它评测就很难，第二用户用一会儿就会露馅。所以我们给他的一个总体评价是LM惊艳但不可靠。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:15",
      "text": "那接下来我们要做的是什么呢？其实就是大家都在拼一个运营兜底的这个能力。就刚才提到比如说对于一些央企，一些大的客户，他对幻觉这件事几乎是零容忍的。那么我们其实就必然会引入一些在LM之外的东西去强行控制它。比如说一些配合一些传统的搜索，或者干脆就hard code的一些东西进去。但这个流程我们希望它是能在场内去建去完成的，而不是说所有的需求都打回我们核心团队去做。而这块我们刚才提到的一点就是跟客户去做一个能够共生的一个数据。所以目前来看LM大家提供能力很接近。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:46",
      "text": "我们在卷的地方其实就是一个把运营和反馈机制建立更好的一个过程。我们发现这也是一种与客户共生的途径，它更不容易去切换到另外一个供应商。所以目前我们虽然看到有很多做LM ops的公司，我可能真的觉得值得往l mot这个方向发力的。其实是能不能把运营能力作为一项服务供应给所有的大模型，这只是我的一个想法。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:08",
      "text": "当然未来的话长期来看，可能从技术角度我们会遇见一个新式的一个LM是什么？就是运营能力可能以online learning的形式融合进LM本身，就好比说任何企业都知道如何去培养一个员工。那么你能不能用培养一个员工或者说纠正一个人错误的方法来实现现场的运营。这可能是未来一个比较有趣的一个方向。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:28",
      "text": "还有一点观察先行者现在其实已经陷入了premature optimization，这是什么意思呢？就是说这是一个偏工程化的一个词，就所谓的过早优化。我们其实这一波中文的大模型的启动，完全是被ChatGPT1脚给踢起来的。我们现在这些人跑的飞快，但实际上大家也知道中文基座能力现在仍然还是非常弱的。但我们已经开始在这个上面去去构建应用了。我们哪怕就不跟未来理想中的世界去比，我们现在就跟英文世界相比，我们其实能改进的东西还有非常多。所以现在我们这些提前跑起来的先行者，已经开始卷入一些产品细节。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:00",
      "text": "我们一直会理想的认为这些都是一个workaround，都是一个临时方案。做工程都知道你产品倒闭的那天，你的临时代码还在里头，这是一个必然会发生的事情。所以我们相信这一次浪潮会的多轮的技术创新的刺激下持续比较久。新的团队总是有后发优势的这可能对创业者来说是一个比较好的一个消息。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:18",
      "text": "下一个论点就是说创业者现在不要过度关注模型本身。前一阵我们群里在聊这个measurement这件事儿，我们发现现在有很多的benchmark，包括我们自己也做真笨这些东西。实际上这些benchmark evaluation它的局限性都是很强的。比如说在学术上，我一般刷榜也都会说我们的模型在某一个奔驰mark中达到了sota，或者说我们要在同一个奔驰work下超越了过往模型。比如多少个point。但实际上这些benchmark本身离你的业务就相差比较远。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:44",
      "text": "这会儿可以扯一个稍微远一点的话题，大家可能会觉得奇怪，为什么GPT这个东西现在scale这么厉害，而bert为什么没有scale？这其实除了一个token利用率以外，更重要一点就是bird这个东西它不能直接使用，它一定要经过fine to。我其实给大家或者是给新的创业团队一个建议，就是你在规划你的产品的时候，你可以稍微乐观一些。你可以假设或者默认自己可以access到目前最好的模型，或者你非常乐观，就觉得OK一年后的今天我能拿到一个跟GPT41样好的可控的一个模型。然后再基于此去设计你这个产品，你就先不要看着眼前这些事儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:16",
      "text": "同时也有一点就是LM它是一个非常标准化的产品。大家想它这个输入输出形式就是文本或者多模态的数据流，这个决定了它其实非常容易被替换的。作为创业者或者创业团队，我们不应该关注那些公开的benchmark evaluation。而我的建议是大家做好自己业务的一个抽象层，把自己的大模型的应用跟你上层的业务逻辑和你的这个别的工程代码进行一个比较好的抽象，建立一个属于自己业务的baseline，然后平台尝试去快速迭代。比如说我现在可能每周到周末都会试一试hanging faste上排出新的那几个他那个leader board上那些模型，看看切到我的业务里头会不会有一个变化。这个我觉得会比过度关注measure们要重要很多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:52",
      "text": "下一个开始就是更暴论一点，就是我认为低代码的平台目前是个伪需求。低代码这件事儿解决的是什么？咱们去回顾一下之前迭代码一般用在哪儿？叠代码这件事最常见一个就是所谓的在业务后台或者后台系统构建一个东西，它解决的问题是什么呢？是标准问题下面的复杂问题呈现，这什么意思呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:10",
      "text": "我们可以回顾一下比较火的这些低代码的平台，比如像air table local DB他们的上游是什么？他们上游是SKL数据库，非常标准的一个东西。中间我们需要从零搭建一套后台系统是非常繁琐的。但是你最后后台系统长什么样，要做什么是非常标准。比如你可能需要一个看板，需要一个多维表格，需要怎样的一个审核系统。所以它的流程从一个从标准到繁琐到标准的一个过程。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:33",
      "text": "但是LM上面的建立是与这个是不一样的。首先我们看LM的上游是什么？是大模型本身。这是一个极其标准化的产品，它的使用方法现在已经是前所未有的标准。就是你基于prom，然后以流的形式给你返回一个东西。但是我们拿大模型在做的事情其实是在创新。这个对于至少现阶段来说，我们认为第一代在的话，我认为还是为时尚早。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:53",
      "text": "然后下一个也是现在最火的玩意儿，相应数据库。首先它的原因先从技术角度来讲，特别简单，你向量数据库无法让模型突破自身的context limit。这说的有点不好理解，但是大家还记不记得前一阵雨森做了一个小测试，就是把张一鸣所有历史发过的微博，给了cloud 100K然后让他预测。现在都没有告诉他是张一鸣和字节的调整，让他预测这个人和现在这个公司的一些现在的情况，预测的非常好。但是这件事他完全就依赖于更长的context。而你想象一下，如果相应数据库，你不能把张一鸣的一条微博分时的喂给他，然后让他给出一个统一的结论，这是相应数据库所不能解决这件事儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:28",
      "text": "第二点也是要强调一个可能偏技术。但是现在非常很多人都有的一个误区，就是所谓的这个ebel ding并不是直接输入给LOM的。LN不能直接读这个ebel ding，它其实只是你相关文档的一个代理，一个surrogate。它只是为了通过embedding获取到相关的这个文本来输入给LM。所以其实你最后输入给LM的只是文档文本而已，并不是这个。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:51",
      "text": "甚至还有一个词儿，大家老说什么GPT evidence GPT ebel ding，不是的，这个词儿也是一个以讹传讹的一个错误。Embedding模型其实独立于GPT之外的一个encoder结。所有的一个模型，它跟GPT没有直接的关系。只不过最早OpenAIr的那个texin bedding ada它的初始化用的是GPT3的权重。所以这是一个细节，不要被这个东西忽悠了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:09",
      "text": "同时唇向量化的召回，在一些bencher上它的表现其实不如BM25。BM25是什么？其实说的通俗一点，就是关键词搜索这个事儿是很严重的一个点。就是现在很多人在用向量化召回和向量数据库的原因，这可能有我有点暴露，它的原因是因为这个东西很方便，且OpenAI提供了一个无脑的API传统意义上的搜索和召回。你需要调的feature非常多，而你用bedding的话，对不起一个参数都没有调什么效果就是这样。同时也恰好欧米亚的evidence确实不错。所以实际上这并不是一个理性的一个火，而是大家选择过后临时的一个结果。如果你真的应用在你的产品，或者说你要把它商品化的话，你一定要仔细想想这个东西到底适不适合。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:47",
      "text": "因为举一个很简单的例子，所有的evidence都是对语义的编码。而实际上我们想想用户的习惯是这样的吗？很多时候用户还是习惯像在百度那样，关键词空格关键词。这时候你获得的ebel ding质量是奇差无比的。我要强调一点，不是在diss相邻库数据库本身，而是diss他现在在强蹭LOM这件事儿。相邻数据库本身比如说在推荐系统，还有些semantic search，这是本身是非常有用的东西。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:09",
      "text": "然后下面结尾就顺着这个相应数据往上讲一讲，就相对数据库本身是一个阶段。其实我们现在忽略了相应数据库，再往上面一层很重要的东西，就刚才提到了一直在讲的embedding模型，evidence模型。这个刚才讲的它其实不是GPT，是一个单独的模型。而这款目前不知道为什么，可能在国内我没有看到一个非常promising的一个产品。它实际上目前无论是国内的还是开源的这些m bedi模型叫open a和cohered的专有模型差距是非常大的。他们open I跟cohere的embedding模型，他们能够处理各种类型的需求。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:38",
      "text": "比如大家可能知道相似度跟搜索是完全不一样的事儿，这个我怎么解释呢？就比如说我说两句话，一个是今天天气不错，因为今天天儿不错，这两个相似这个叫相似性。而搜索是什么？我问了今天天气怎么样，它回答的我不是今天天气如何，他我要找到的是今天北京多少度，所以这是完全两个problem domine。而这些专有的模型，他们甚至能把这些抖音给融合。目前开源的最好的像sota的，可能还需要struction之类这些东西，所以差距是非常大的。但是目前这块可能有一点被忽视掉，可能大家还没有意识到这一个层面的价值。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:09",
      "text": "还有一点更无聊的一件事儿，就是PDF这个东西，或者说任何这些文档从其中正确的获取信息提取出来是非常复杂的一件事儿。国内我记得有一家公司叫庖丁，还是什么东西，它可能是国内做的相对来说比较好的。但实际上PDF或者说文档的处理是咱们刚谈到的一切。无论你是向量数据库还是外置知识的一个前提。这些东西目前来看整体是被低估了的。而且还有一点比较好，就是embedding跟文档模型的应用场景，跟相应数据库也类似，用场哪些远不止于LM。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:36",
      "text": "接下来这个其实有点老生常谈的话题，就是懂AI的产品经理真的是稀缺资源。这个先说一下区别，就是我们目前做生成式AI产品感受的是它的不确定性，响应速度跟服务成本，跟之前都有非常大的区别。一个最简单的例子就是以前我们还会说一个词叫QPS，就是你每秒能承载多少的并发。但一吹都是几百几千的，现在都是零点几。甚至包括像google bard，它的其实这个并发能力都非常差。而产品经理如果还按以前那些惯性思维去做的话，你可能会把公司给玩死。所以我们认为懂AI的产品经理，你要在既懂之前的这些东西，你更要明白这其中的一个差别。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:10",
      "text": "第二点就是我经常举的一个例子。大家在用那个major ney时候会发现，你让它生成一张图，它永远会给你返回四个小的结果，能让你去挑一个。这个过程中其实它就完成了一个数据飞轮的构建。因为它默认你人选的那一张图应该比另外三张没有选的要好。所以对于my journey来说，它的数据飞轮的反馈率是百分之百。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:29",
      "text": "只要用户使用了一次major ney，其实就帮助他构建了一次feedback的数据集。而这点你看ChatGPT做的可能就稍微就弱一些，它只有一个thumbs up sum stone。但实际上又有多少用户真的会去使用这个呢？所以我认为一个好的产品经理在AI产品中去构建数据飞轮是非常重要的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:44",
      "text": "然后第三点，其实很多人也都知道，目前至少国内，我们也感觉to b方向的产品，它的用户体验和交互感觉比C端的要落后3到5年以上。所以to b方向我们认为懂A的产品经理是更稀缺的一个资源。同时即使你自己不是在做AI方向的创业，对于所有人来说一定要做好一点，就是要考虑如何应对AI的冲击。这个AI的冲击，我认为接下来会有一个非常大的一个挑战是什么？就现在我们还能有一个前提，就是说我能辨别说哪个是AI哪个不是AI但至少在比如说文生图这个领域，我相信可能到了今年年底的时候，应该就会发展到我们无法去区分到底一个东西是不是AI生成的那这时候对于比如像小红书之类的平台，可能会面临非常大的一个信任的一个问题。这方面可能技术我们已经帮不了了，那剩下的就只能从产品层面去解决了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:29",
      "text": "然后下面一个也是比较老生常谈的了，就是不要用技术热点指导创投。但关键是后半句，尤其是现在大家都知道顺着技术发展的脉络做产品，很容易卷到大公司的这个行道上被搞死。这个是大家都知道。但是为什么说尤其是现在不要太信这个技术热点，因为这是一个很无奈的一个现象。大家知道学界现在很尴尬，你真的你要上规模的时候，对不起，我没有那么多的坎，没有那么多资源，做了很多的事情，其实都是一个局限下面得到的一个妥协。所以我们现在接受到的每天读到的众多的技术创新，无论是来自于学界，还是这hacker搞的东西，其实这些热点都是妥协后的结果。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:03",
      "text": "我们经常看有人说，什么prompts of any prompts on me，不不不，我腻的东西可多了。但其实现状是prompt is all I have，我只有一个open ADAPI，我只能搞这些活。所以大家会发现什么china a tree of thought什么什么这些东西他其实对模型的权重一丁点都没有碰，大家只能搞这些了。但是我说这几点不是说让大家就不太关心技术，然后我就了解技术还是很重要的。至少对于创投角度来说更了解锤子，可以很好的避免拿着锤子找钉子这件事儿。因为你发现真懂的人，你问他做哪个方向时候，这些人都是支支吾吾比较害怕的。就是越是那些半瓶子水的这帮人，他越觉得自己拿着这个大锤子好，然后接下来就到了紧张刺激的预测环节。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:40",
      "text": "刚才那是基于现在的观察，这我开始暴论了。首先第一点就是我们只有垂直应用，没有垂直模型。其实大家看这个项目的时候，经常会发现一个借口，就是说我们现在先用这个ChatGPT或者用open I的API。我们以后自己要训练自己的模型，在垂直领域做什么东西，这是非常常见的一个说法的对吧？这个其实是有一定惯性的。在GPT或者这种通用大模型出来之前，讲真其实你要做一个业务，它是根本不存在一个所谓的不垂直的模型的。你要做任何一件事，其实之前都在使用是垂直模型。所以大家一是有这样的一定惯性。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:11",
      "text": "第二点我们看一看现在仍然很多人吹说我到了LM时代，我仍然要做一个垂直的大模型，但是这有什么意义呢？首先我们看垂直模型其实没有解决任何通用模型的本质的缺陷。比如说我们现在需要的可解释，对不起，垂直模型不能解释。我们需要能运营垂直模型，不能运营，我们要溯源，垂直模型也不能溯源。然后很尴尬的是，比如看前一阵市面上很火，像bloomer、GPT还有law GPT之类的。市面上目前大部分垂直模型在它的领域内，甚至其实性能是不如GP4的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:40",
      "text": "这个原因是什么呢？因为我们现在对于通用大模型来说，我们的数据和规模远远没有达到饱和。任何有价值的领域直接就会被整合进通用模中，不存在任何的trade off。所以这是一个完全免费的提升，所以终归会被合并进去的。因为你任何增加新的这个领域，其实也会不仅让模型在这一个领域内的能力提升，它会影响整个横向的提升。这是大模型我们觉得非常吸引人的一个点。就之前我们做一个领域的时候，我们的积累只能让我们在这一个领域有提升。而做大模型，我们发现我们的模型的横向的生长，这是非常棒的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:10",
      "text": "所以总结来说就是垂直应用之间的差异应该在业务不在模型。接下来就讲到多模态这件事儿，多模态这个稍微有一点technical，但我觉得有必要去辟一个谣，就是真正的多模态模型远远还没有来。现在市面上大家看到很多多模态模型，好像谁都能搞一些，像我们之前什么mini GPT four之类的，但是他们的做法其实是什么呢？就是它本身只是一个预训练好的语言模型，注意它是拿文本去训练的。他们做的只是把图片或者音频等其他的模态，它通过一个适配转成一个能够融入文本特征文本相特征相对空间的问。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:40",
      "text": "这个时候它带来最大的问题是什么？你这个模型它所有对于世界的认知仍然来自于它文本的预训练，它没有一个game。而我们理想中的真正的多模态模型的世界知识，不应该来自于文本预训练。而是因为他在训练的过程中见过这世界的大千世界。他可能看过youtube知道这个梗到底是怎么回事，而不是只是看过那些文本。所以目前来看的话，也确实在学界有一些比较新的进展的，国内国外都有。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:03",
      "text": "这回头再细讲，总体来说我仍旧interleaved的多模态输入输出是值得投入的目标。就是说你可以理解成输入的是一篇图文，而它输出也是图文，甚至是音频。这样这个模型它的整体能力会有一个质的一个飞跃，而不是现在这样的一个翻译这种感觉。然后多模态模型接下来可能会对工程还有算力都提出更新更高的要求，甚至可能要高1个到2个数量级的要求。但是我认为多模态模型确实可能解决一些跨出领域的问题。比如说之前的无论是做机器人还是自动驾驶，我们总会有些h case或者一些传统化难以解决的事儿。假如我们有一个很好的多模态模型，且这个多模态模型它的速度已经到了一定程度的话，也许有一定希望它能解决之前一直没有解决好的很多的那些比较烦人的点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:42",
      "text": "我接着继续了。Lemon这个非常火，RHF这个词大家都听烂了，但是实际上还有一个暴论，就是align on并不需要RHHHF human feedback，不需要reinforcement learning feedback g不需要human。首先要强调一点，就是LHF这个词非常火，但其实它不是目的，它只是一个手段，而且它本身其实是非常非非常不稳定的。实际上我们在做的所谓那个supervised fine tune和RLGHF都是为了什么？就是align and task，还有就是human preference。所以RHF这件事它本身真的不是一个必须的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:10",
      "text": "现在这个东西有点过于暴露在了大家的视野中。实际上它是一个非常偏research的一个东西。而如果你真要讲research，你会发现一些近期研究，比如像那个DPO证明了什么呢？就是说如果你有足够多的feedback data，就比如说人的preference的数据的话，你不需要RL你可以直接你省掉这个reward model，你就直接去优化你的large model。用一个自然估计去优化一个最大自然就可以了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:32",
      "text": "第三个点就是我们自己的实验中一个发现，就是LM很好玩，他似乎知道自己什么时候搞砸了，这是什么意思呢？就是大家知道LM其实在一个token的往后生成，而每一个token其实它都是sample，就是有一定随机性的选取的。你一个token搞砸的时候，后面整个sequence大概率都不怎么样。然后我们做了一个测试，就对于同样一个前缀的prom随机，比如说让它采样3到10次，我把这3到10次问自己，同样这一个大模型，你觉得你自己哪次搞砸了，哪次搞得最好？他说的其实挺好的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:59",
      "text": "甚至我们发现用GPT4，现在很多人都在干一件事，就拿GPT4代替人去打分，做human preference。像之前那个lima那个paper里面也讲到，它其实GP4总体来说的的偏好跟人是非常接近，至少从排序上来说是一致的。所以如果你激进一点的话，你如果你想做基于这个preference的调优的话，甚至都不需要H就不需要human。你直接让LM自己feedback，可能都能达到一个不错的一个效果。所以对于创业团队来说，真的不要在RHF上投入特别多的精力，是很亏的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:27",
      "text": "然后下面就讲到了精彩的context这件事，这是我偏主观的一个预测，就是认为更长的context一定会带来一个质变。首先还是回到刚才相邻数据库这件事。举个例子，就是现在的LM加相邻数库这个范式，其实它就很像一个硬盘巨大但内存很小的电脑。就是你的这个硬盘里存了一堆你过往工作的word，但是每次你只能看200个字。你痛不痛苦？你能得到什么很关键这个结论吗？你不能，所以这个就是相当于数据库的一个局限性。所以接下来其实无论是学界还是业界，其实都在追寻的一件事，就训练更长的context。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:57",
      "text": "但这件事客观来说是非常困难的这是一个科学问题，它不能仅靠堆算力去完成。因为实际上你要不做part spars优化的话，你窗口从2K到4K你的算力要求不是翻两倍。为什么说这个context会带来质变？首先先说一个比较小的一个点，就是现在比如如果大家关注lyn chain或者那些agent的话，我们现在很多场景的现因为有这context的限制，所以我们在用一些很复杂的chain prom。就比如说一个接一个。大家知道环节只要多，很多事情就是不可逆的。你一个环节出错，后面全都完蛋了。所以目前main chain大家会发现，实际上使用下来它的成功率是很低的。而如果有更长的context，我们可以一次描述更长的任务。让他在自己更好的mary内把这个事情一步完成。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:34",
      "text": "但这个我觉得不是最关键的，最关键一点就是说long connex的终极目标是能够高效的利用原本面向人类的教学资源。这是什么意思呢？就是说我们现在如果要让模型学会一个人曾经工作的，我们可能会为他训练一个要提到的垂直模型。智能很贵，然后也不是很好做，他说效果也不一定好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:53",
      "text": "但是我们回想一下，任何公司都会有知道怎么去培养人。比如说我们可能积累了对于新员工的培训的材料，要使用一个工具。我们可能有说明书，他可能这个说明书蛮长的。对于一个专业的软件可能几十页上百页。如果我们能有一个更长的context的话，对于要实现一个新的任务，我们不需要让模型去单独训练，不需要去用它。而是说我们把原来给人的材料让这个模型看一眼。他可能通过说明书学会了使用一个资源。所以我认为这个东西对于模型的潜力是一个巨大的提升，绝对不只是一个输入长度这么简单的事儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:24",
      "text": "这接下来是一个预测，是说AI创新可能会诞生在很多看不见的地方。这国外目前不也看很多人说，投AI不要投那些大AI域名结尾就有几个比较值得看的地方。比如说可能会更值得关注的，像自然语言跟结构化的边界。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:38",
      "text": "大家可以看到微软最近出了一个开源项目的guidance，是一个模板语言，它的解决的问题是什么呢？就是我们实际上想把LM用在很多现有软件的改造的过程中，而它现在的输出是自然语言。而我们终究要利用大模型能力，得把它转化成一个结构化的控制。比如Jason之类的这个东西目前可能会带来很多的改变。比如说对于所有的企业的这些软件，之前我们可能OA软件、财务软件抱怨非常大。你如果想用你的大模型技术去改良这个东西的话，你终究要把你的自然语言转向结构化。这部分可能会有一些中间的这个工作可以去做。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:10",
      "text": "第二点，我们看见现在很多的AI的创业项目都是发生了跟用户交互层面，或者至少说用户就能直接感受到是一个实时的使用了AI的这个过程。但是此时有很多像数据分析、实验模拟等一些场离线场景也是非常有用的。比如说之前很多人做所谓的email的data mining，可能用一些比较传统的算法在做。实际上LM的话能帮你把很多的过程都更好的去润滑它，起到一个胶水的一个作用，同时也能提升更好的效果。所以很多不直接跟用户打交道的地方，其实LM也有很大的发挥的一个潜力。目前可能看到的不是很多，总结来说就是不要给AI做插件，而让AI成为你自己业务的一个插件。最后中间的一个预测肯定就是AI这个事会消失于无形，然后便默默的改变世界。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:52",
      "text": "稍微悲观一点，就是我现在感觉是AI人才其实在面临一个价值危机。首先第一点就是比较简单，就是新一代在产品的竞争优势，其实大家也都不在技术上，而且即使是在技术上，讲真至少咱们国内的话，又有多少人真的在之前做了很久LM呢？但基本都是在同样的一个起跑线上。而你真正做AI创业的话，你必须要有技术之外的弄好，所以我们单纯的AI人才这点上就比较吃亏。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:15",
      "text": "第二点我觉得是一个比较讨厌的，是一个长期的一个隐患。以前我们做AI无论是to b还是to c你会发现AI的流水线是比较长的。就是说你各个梯队的人其实都有事儿可以干。所以以前在各个AI公司大厂的中层，其实培养了很多技组合产品两头都比较硬的人，这也是很符合这个创业者画像的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:33",
      "text": "但现在其实有了LM等一系列新的开发范式之后，我们发现其实分化特别严重。就逐渐只剩下最精英的一群人做核心技术，剩下全都是做交付。这样的话，这两者都不是创业者的这个画像，对吧？懂技术的离市场太远，而离客户和产品近了又完全没有什么竞争力。所以长期来看，可能符合创业者画像的人才的供应会减少。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:54",
      "text": "接下来第三点也是偏学术界的一个问题。首先由于各个技术路线在逐渐收敛，然后其实领域。逐渐大一点，你会发现无论是LPCV什么，大家用的底层技术越来越接近了。再加上一些客观的算力，大模型这些诸多这些客观现实比较无奈，学术界级现在稍微有一点点边缘化。所以这个带来一个比较必然的结果，就是大牛带队的这种阿克海尔。像之前那谁是hinton，还是就那种大牛带学生可能会少一些。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:18",
      "text": "最后一点就是我虽然很喜欢开源，但我逐渐意识到一个问题，我现在第四年我也不是特别成熟的思考。就是以前我们做开源软件，其实在让工程师避免重复投入。因为我们之前做所谓的开源公司就做open core，把自己的一些基础的部分开源，自己业务是自己私有，去不断去迭代。这样我们让别的工程师能帮我们去feedback我们的核心的技术，同时也为他们省去一些重复的投入。但我渐渐觉得，现在这些开源AI无论是模型本身还是开源的LM ops这些东西，其实渐渐的让AI人才自身成为重复投入。这是一个有点无奈的一个感觉，对我们不是一个非常成熟的一个观点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:54",
      "text": "然后最后稍微乐观一点，至少我认为好的时候还没来。首先一点，就前一阵Monica在群里不是发了一个调研，美国人多少人听过x GPT这个事吗？我很惊讶，哪怕真的在美国，还有42%的人完全没有听过。至少我们都可以看到，这是一个前所未有的一个技术平权，是一个全新的开始。但正是因为是一个全新的开始，我觉得现在也不用特别着急。你想iphone当时初代到iphone 4，无论你们怎么认为，我认为可能iphone 4是一个成熟的一个阶段。咱们现在还处在farting APP，在calculate手电筒这个阶段，所以也不用特别的着急。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:22",
      "text": "但是这次我发现也有一个比较好玩的一个现象，就是说这是很罕见的。就是因为我们现在中文领域有一些客观的技术，或者也许有一些合规的现好多事情，大家在等一个发令枪，而美国那边已经先跑着，前所未有，给我们提供了很多很充足的playbook。最后一点，就无论是对于投资人还是创业者来说，大家这至少10年感觉还是比之前要成熟很多。甚至不止创业者跟这个投资人。其实我们感觉就无论监管机构还是中国广大用户，其实也都比十年前要成熟多了。所以总体来说这一次是大家是有备而来的，相信最后结局应该会更好一些。好，讲完了，反正最后就落在一个正面一点的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:57",
      "text": "大家好，今天这期内容到这里就一段落了。Pick的分享我觉得非常的有深度。在现在信息非常的过载，充满着各种喧嚣和夸大的不实信息以及不实理解的时候，我觉得pick给我们提供了非常好的反思和对未来的预测。希望大家不管是面对变化多端的AI革命，都能够保持一颗开放、包容、批判的心态，去看待这里面发生的很多变化，去仔细思考未来潜在的机会。如果你想在AI领域进行创业或者探索，也非常欢迎和真格基金和我联系，谢谢，我们下期节目再见。",
      "speaker": "发言人2"
    }
  ],
  "lab_info": {
    "summary": "本次讨论深入剖析了数据价值、AI落地难题、LHF技术及其应用挑战，以及AI创业的未来走向。强调“共生数据”为真正的壁垒，AI落地与复制难题待解。AI创业者需反思，AI应为核心而非插件。LHF技术火热，但重点在于理解而非模型本身，需构建有深度AI理解的产品团队。讨论还展望了AI技术平权与新机遇，强调开放、包容与批判性思维对于AI革命的重要性，对未来持乐观态度。",
    "qa_pairs": [
      {
        "question": "在AI领域，您认为当前最值钱的数据是什么？LHF（此处可能指代某种AI技术或工具）在解决AI落地难和复制难问题上能否发挥作用？",
        "answer": "我认为最值钱的数据是不属于你，但与你共生的数据，这种数据能够形成真正的壁垒。LHF虽然很火，但它不是目的，而是一个手段。关键不在于给AI做插件，而在于让AI成为业务的一个插件。",
        "time": "00:00:01"
      },
      {
        "question": "您能否分享一下这次真格基金内部闭门会议的主题以及主要内容？",
        "answer": "这次会议的主题是“unpopular painting sunday AI”，主要围绕AI创业者的反思、观察和预测展开，我将分享过去的经验、移动互联网初期的创业经历以及对当前AI浪潮的见解。",
        "time": "00:01:21"
      },
      {
        "question": "在AI领域，是否可以类比移动互联网初期的情况，并且现在的AI创业机会在哪里？",
        "answer": "当前AI领域确实出现了一个新的有限制舞台，类似于当年APP领域的手机之于PC。创业者可以关注to c端的on device AI，例如与大公司错位竞争的产品；to b端则可以关注信创指标下的on prem解决方案，利用隐私合规和成本优势进行创新。",
        "time": "00:02:41"
      },
      {
        "question": "关于数据的价值，有什么新的认识或看法？",
        "answer": "open accessible的数据价值有限，而私有数据虽然不是绝对安全，但与业务共生的数据才是真正的壁垒。例如，企业内部协同工具中的数据和设备端数据具有很大潜力。",
        "time": "00:05:14"
      },
      {
        "question": "当前LM的能力强，是否意味着大部分业务可通过in context learning解决，从而忽视find数据？",
        "answer": "是的，随着LM能力增强，很多场景下in context learning可以有效解决客户私有问题，因此找到共建关系中的数据变得尤为重要。",
        "time": "00:05:39"
      },
      {
        "question": "下一个技术创新点会是什么？它会解决什么样的问题？",
        "answer": "预测具体的next big thing很难，但可以预见的是，下一个重大突破将会解决现有技术局限性所引出的问题。从历史变革来看，每一次重大突破往往源于对原有局限性的突破和创新。",
        "time": "00:07:30"
      },
      {
        "question": "在AI技术的发展过程中，您们遇到了一个什么样的挑战，是如何解决的？",
        "answer": "我们遇到了一个挑战，即文本向量的相似性问题，例如“苹果”这个词在不同语境下的向量表达是相同的。为了解决这个问题，我们引入了Elmo模型，它是一种可以实现文本内容依赖的、具有上下文信息的表达方法。然而，在尝试将Elmo应用于产品时，我们发现计算速度较慢。随后我们关注到transformer模型，并在此基础上发展出了Bird模型，这些技术进步推动了AI领域的发展。",
        "time": "00:08:39"
      },
      {
        "question": "从您的经验来看，创业者应该如何看待解决技术难题的重要性？",
        "answer": "创业者不应仅将解决最显眼的技术难题作为唯一的护城河。以我们公司为例，虽然我们成功解决了基于不可靠文本构建知识图谱的重大问题，但后来发现微软等其他公司也在研究类似方向。因此，创业者必须寻找除核心技术之外的竞争优势，否则容易被快速跟进的其他团队超越。",
        "time": "00:10:07"
      },
      {
        "question": "AI行业的快速迭代对创业者意味着什么？",
        "answer": "对于AI创业者而言，AI领域的创新周期性明显，过去流行的技术可能很快不再被关注。这为创业者提供了不断创造新可能性的机会，尤其是在产品层面。尽管底层技术有一定的延续性，但80%的AI创业过程实际上涉及产品工程，而非底层技术研发。新来的创业者由于灵活性高，在技术、行业规模和利益分配等方面的优势明显。",
        "time": "00:10:55"
      },
      {
        "question": "对于初创公司来说，如何应对监管与合规挑战？",
        "answer": "监管与合规是一种可以利用的竞争维度，关键在于提前规划和正视这个问题。创业者需要在产品规划阶段就考虑合规要求，并将其视为一个产品工程问题来解决。在中国，合规问题具有动态性，创业者不应试图通过单一模型一劳永逸地解决所有问题，而应将内容审核与核心业务解耦，并主动与监管机构沟通、报备，以获得更广阔的操作空间。",
        "time": "00:12:15"
      },
      {
        "question": "创业者在成长过程中，如何看待从“小天才”转变为“技术派”？",
        "answer": "从早期的“小天才”转变为“技术派”可能意味着创业者的“zoomability”（洞察力）丧失，尤其是在AI领域，这对创业成功不利。创始人应避免因团队扩展而失去对技术和市场的敏感度，同时也要注意寻找能与自己理念相契合、能力互补的高级人才，以适应公司发展的需要。",
        "time": "00:13:13"
      },
      {
        "question": "目前AI to B市场的现状如何？",
        "answer": "目前AI to B市场的需求逐渐清晰，其中65%的需求集中在信息检索、汇总和再生成等浅层应用，20%的需求涉及自动化和决策辅助。意外的是，对于文生图和代码生成的需求相对较低。此外，主流解决方案中，各家供应商提供的服务在一定程度上能够满足客户需求，但LM模型在解决AI落地难和复制难问题上的表现并不理想，目前更多是加速了单个客户的落地时间，而未能从根本上解决问题。",
        "time": "00:14:32"
      },
      {
        "question": "生成式AI与传统AI产品的主要区别是什么？",
        "answer": "生成式AI与传统AI产品最大的区别在于其随机性非常高，对于可靠性要求较高的大客户（如央企、国企、银行）来说，在应用场景的后期可能会因为达不到所需的可靠性而被毙掉。此外，生成式AI在优化周期上更长，难以控制。",
        "time": "00:16:21"
      },
      {
        "question": "LM（可能是大型语言模型）在复制难的问题上面临什么挑战？",
        "answer": "复制难的问题在LM中被放大了，因为客户需要的不是一个单一的模型，而是一个解决方案。虽然使用了NOP范式统一了开发过程，但解决方案交付方面的压力依然巨大，并且随着客户对LM知识的增加，他们的需求变得多样化和复杂化。",
        "time": "00:16:56"
      },
      {
        "question": "客户对C端产品的期望为何会提高到一个离谱的高度？",
        "answer": "客户之前对于AI产品的期望可以通过具体赛道（如安防、人脸识别等）来理解，而现在ChatGPT等技术提高了客户的期望值，使得他们在选择AI产品时有了更高的要求。",
        "time": "00:17:27"
      },
      {
        "question": "当前业界面临的主要痛点是什么？",
        "answer": "当前业界主要痛点在于运营能力的凸显。由于LM的精准度偏低且易出现不可靠情况，运营团队需要引入额外手段来控制风险，例如结合传统搜索或硬编码等方法，并努力实现这些操作在场内完成，同时与客户共生数据以提供更好的服务。",
        "time": "00:18:15"
      },
      {
        "question": "未来技术发展趋势可能是什么？",
        "answer": "未来可能会出现一种新型的融合了运营能力的新式LM，其能像企业培养员工一样通过在线学习的方式自我优化和纠正错误。",
        "time": "00:19:08"
      },
      {
        "question": "创业者在当前阶段应关注哪些方面？",
        "answer": "创业者不应过度关注模型本身，而应该做好自己业务的抽象层，建立属于自身业务的baseline，并尝试快速迭代，利用最新的模型进行实验，而不是过分纠结于公开的benchmark evaluation。",
        "time": "00:21:16"
      },
      {
        "question": "对于低代码平台的需求是否存在误区？",
        "answer": "低代码平台目前存在伪需求的问题。传统低代码平台解决的是标准问题下的复杂问题呈现，而LM的应用创新性更强，其上游是大模型，使用方法极其标准化，现阶段不适合直接套用低代码平台模式。",
        "time": "00:21:52"
      },
      {
        "question": "在一些benchmark上，唇向量化的召回表现不如BM25，BM25是什么？",
        "answer": "BM25是一种基于关键词搜索的传统方法，用户习惯于使用关键词进行搜索，而唇向量化的召回虽然便捷且方便调优，但其效果依赖于高质量的embedding，而实际用户搜索行为可能产生较差的embedding质量。",
        "time": "00:24:09"
      },
      {
        "question": "为什么说embedding模型和文档模型的应用场景重要性被忽视了？",
        "answer": "目前，人们对embedding模型（如OpenAI和 Cohere的专有模型）和文档模型的价值认识不足，尽管它们在处理各种类型需求时表现出色，包括融合相似度和搜索任务，并且应用场景远不止于自然语言模型（LM）。",
        "time": "00:25:09"
      },
      {
        "question": "懂AI的产品经理在当前环境下为何是稀缺资源？",
        "answer": "在生成式AI产品中，产品经理需要理解并应对AI带来的不确定性、响应速度和服务成本的变化。例如，与传统QPS并发能力相比，现代AI产品的并发能力较弱，产品经理若沿用旧有的惯性思维去做产品，可能导致公司失败。此外，好的产品经理应懂得构建数据飞轮以优化用户体验，并在AI冲击下考虑如何应对，比如在无法区分AI生成内容的情况下，从产品层面解决信任问题。",
        "time": "00:26:36"
      },
      {
        "question": "现在是否应依赖技术热点指导创投？",
        "answer": "虽然了解技术热点对于创投有帮助，但不应完全依赖。目前学界的技术创新往往是妥协后的结果，且大部分垂直模型在性能上可能还不如通用大模型，尤其是随着通用模型在更多领域内的整合和提升，其横向生长的优势更加明显。因此，在创投时应避免拿着锤子找钉子的情况，即不要仅因为某个技术热点就决定项目方向。",
        "time": "00:28:29"
      },
      {
        "question": "对于垂直应用和垂直模型的看法是什么？",
        "answer": "当前存在一种普遍观点，即先使用通用模型如ChatGPT或openAI API，未来再训练垂直领域专用模型。但实际上，随着通用大模型的发展，有价值的垂直领域会被整合进去，无需过分关注垂直模型。真正重要的是垂直应用的设计和业务逻辑，而非仅仅依赖特定模型。",
        "time": "00:29:40"
      },
      {
        "question": "对于多模态模型现状的理解是什么？",
        "answer": "目前市面上所谓的多模态模型实际上并未完全实现真正的多模态，它们大多基于语言模型并通过文本预训练来处理其他模态信息。理想的多模态模型应具备跨模态认知的能力，而不仅仅依赖于文本预训练。目前学界已有新的进展，但真正的多模态模型尚未到来。",
        "time": "00:31:10"
      },
      {
        "question": "多模态模型是否值得投入，并且它可能带来的变革是什么？",
        "answer": "我认为多模态模型是值得投入的目标，其整体能力能实现质的飞跃。多模态模型将对工程和算力提出更高要求，可能需要高一个到两个数量级，但这种模型有望解决跨领域问题，如之前机器人或自动驾驶中难以处理的h case。",
        "time": "00:32:03"
      },
      {
        "question": "LHF（无需人工反馈的学习）是否是必须的，以及近期研究对此有何证明？",
        "answer": "LHF并非目的，而是一种手段，且其实非常不稳定。实际上，supervised fine tune和RLGHF是为了align and task以及human preference。近期研究如DPO表明，如果有足够多的feedback data（如人的preference数据），可以省掉reward model，直接优化large model。",
        "time": "00:33:10"
      },
      {
        "question": "在实践中，LM模型是否能自我评估并优化自身表现？",
        "answer": "我们的实验发现LM模型确实能识别何时生成错误，通过多次采样同一前缀prompt，LM能自行判断并反馈较好的生成结果。甚至使用GPT4代替人工打分进行human preference调优，效果良好，这意味着在某些情况下无需人工反馈，让LM自我优化即可达到不错的效果。",
        "time": "00:33:59"
      },
      {
        "question": "更长的context对AI模型的影响和潜力是什么？",
        "answer": "更长的context对于AI模型将带来质变，目前受限于硬盘（数据库）大小而内存（处理能力）较小的问题，更长的context能帮助模型一次性描述更长的任务并在内部更好地完成任务。更重要的是，它可以高效利用面向人类的教学资源，例如通过查看培训材料让模型快速学会使用特定资源，从而提升模型的潜力。",
        "time": "00:35:53"
      },
      {
        "question": "AI创新可能会在哪些意想不到的地方发生，以及LM在其中的应用场景？",
        "answer": "AI创新可能出现在看不见的地方，例如自然语言与结构化数据的边界。像微软开源项目guidance就是一个模板语言，旨在将自然语言转化为结构化控制，以改进现有软件的改造过程。此外，在数据分析、实验模拟等离线场景中，LM也有很大的发挥空间，让AI成为业务中的“插件”。",
        "time": "00:36:38"
      },
      {
        "question": "当前AI人才面临的挑战和未来发展趋势？",
        "answer": "AI人才面临价值危机，新一代产品竞争优势不在技术上，且技术人才与市场、客户需求结合的能力受限。长期来看，符合创业者画像的人才供应可能会减少。学术界由于技术路线收敛和技术底层趋同，也面临一定程度的边缘化。开源AI技术虽然有助于避免重复投入，但也可能导致AI人才成为重复劳动的一部分。尽管如此，AI领域的变革仍处于早期阶段，未来机会与成熟度都有待提高，同时强调了在面对AI革命时保持开放、包容和批判态度的重要性。",
        "time": "00:37:52"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "AI创业者的反思、观察与预测",
        "summary": "在真格基金内部闭门会议上，一位AI创业者分享了他对AI行业的反思、观察和预测。他强调了共生数据的价值，探讨了AI在实际应用中遇到的挑战，并提出AI应作为业务的插件而非独立存在。此外，他还回顾了个人在AI领域的经历，提出了对AI未来发展的看法。"
      },
      {
        "time": "00:01:51",
        "title": "移动互联网与AI时代的创业反思与展望",
        "summary": "回顾移动互联网初期，创业者在资源有限的条件下与大公司处于相对平等的竞争状态，成功孵化出许多创新项目。在AI时代，提出创业者应关注on device的AI技术和on prem（本地部署）的解决方案，尤其是在考虑到信创指标和隐私合规性的背景下，国内AI替换方案已逐渐成熟，为创业者提供了错位竞争的机会。"
      },
      {
        "time": "00:04:31",
        "title": "探讨数据价值与企业共生数据的重要性",
        "summary": "在当前技术环境下，公开可访问的数据价值被低估，而通过努力收集的数据也因语言模型的发展而价值下降。真正宝贵的是与企业共生的数据，即那些虽然不属于你但与你共同成长的数据。这种数据构建了与客户之间的强有力联系，降低了客户的迁移成本。通过上下文学习（in context learning），可以有效地利用客户的相关信息或知识直接解决问题，无需单独定制模型。在企业与个人用户场景中，共建的数据主要集中在企业内部协同工具和个人设备端。设备制造商对设备上的语言模型显示出极大兴趣，希望通过改进如Siri等功能，实现更复杂的用户指令处理，以满足用户需求并增强用户体验。"
      },
      {
        "time": "00:07:30",
        "title": "预测下一个科技创新的方向",
        "summary": "讨论重点在于如何通过现有的局限性预测未来的科技创新方向。指出预测下一个重大科技突破（next big thing）极其困难，但可以预测这些突破将解决的问题。通过回顾过去的技术发展，如从依存句法分析到word vector的引入，再到contextualized表达方法的需求，以及ELMo和Transformer的诞生，展示了技术是如何基于存在的局限性进行演进的。强调未来的技术预测也应从当前的局限性出发，虽然这些预测不一定是下一个重大科技突破，但它们将是这些突破所要解决的问题。"
      },
      {
        "time": "00:09:29",
        "title": "技术创业的教训与AI产品发展的思考",
        "summary": "讲者通过自身经历强调，解决一个领域的明显局限不应是技术创业者的唯一依靠，因为这可能会让竞争对手找到绕过的方法。他提到了自己花费七年时间开发的产品，虽然解决了学术难题并一度获得成功，但后来发现微软和OpenAI已在接触，说明即使解决了最显眼的问题也可能不是最好的解决方案。此外，讲者还讨论了AI产品的非线性发展和周期性创新，强调了新来者在技术和行业规模上的优势，以及如何应对这些变化。他指出，成功的技术创业者不仅要看到眼前的问题解决，还要寻找更深层次的创新点，以避免被市场淘汰。"
      },
      {
        "time": "00:11:57",
        "title": "监管与合规在大模型创业中的战略意义",
        "summary": "监管与合规被视作大模型创业中的一个可利用的竞争维度，强调了一视同仁的监管原则及提前规划产品合规性的重要性。特别指出，合规是一个动态问题，不应寻求一劳永逸的解决方案。强调了与监管机构主动沟通、坦诚报备的重要性，以及从小天才转变为技术派可能对创业项目带来的负面影响。同时，探讨了年轻创业者在寻找合适合作伙伴时面临的挑战。"
      },
      {
        "time": "00:14:31",
        "title": "AI技术在企业应用中的挑战与观察",
        "summary": "在AI技术向企业级应用的推广过程中，观察到低层次成果迅速被消耗，客户需求主要集中在信息检索、汇总与生成。尽管部分客户对流程自动化和决策辅助有需求，对于文生图和代码生成的需求相对较低。国内在代码生成方面面临难点，缺乏类似GitHub的平台和对需求深入理解的挑战。生成式AI的随机性大，使得在高可靠性要求的客户中落地困难，同时优化周期长和复制难问题仍然存在。客户对AI的期望因ChatGPT而提高，导致目前处于幻灭阶段，运营能力变得尤为重要。"
      },
      {
        "time": "00:17:54",
        "title": "大模型运营能力的挑战与未来方向",
        "summary": "讨论重点在于当前AI产品的精准度与LM（可能指Language Model）相比偏低，LM虽然惊艳但不可靠，尤其在央企等重要客户面前对“幻觉”零容忍。因此，必须引入额外的控制手段，如结合传统搜索或硬编码等，同时强调运营和反馈机制的建立，与客户共生数据，以及将运营能力作为服务提供给大模型的重要性。展望未来，提出运营能力可能以在线学习的形式融入LM本身，解决提前优化（premature optimization）问题，指出中文大模型基础能力较弱但应用开发迅速，强调技术创新将持续推动行业发展，新团队具备后发优势。"
      },
      {
        "time": "00:20:18",
        "title": "创业团队应关注业务逻辑而非模型基准",
        "summary": "讨论强调创业者不应过度专注于模型的评估基准，因为这些基准与实际业务需求存在较大差距。指出许多benchmark评价具有局限性，并以GPT和BERT的比较为例，说明直接使用大模型的困难以及调整策略的重要性。建议创业团队在规划产品时，应乐观预设能获得最先进的模型，并专注于建立与业务逻辑紧密结合的抽象层，从而快速迭代和改进产品。同时，也提出低代码平台当前可能只是一种伪需求，因为大模型的标准化使用方法与传统低代码平台解决的问题有所不同，强调在创新领域直接应用大模型的挑战和机遇。"
      },
      {
        "time": "00:22:53",
        "title": "向量数据库的误区与实际应用挑战",
        "summary": "向量数据库在技术上存在局限性，不能突破模型自身的context limit，导致无法有效处理长文本上下文，例如无法准确预测基于部分信息的整体结论。此外，存在一个普遍误区，即embedding并非直接输入给语言模型（LM），而是作为相关文档的代理，通过embedding获取文本输入给LM。向量化召回在某些基准测试中表现不如BM25，其流行部分原因是由于OpenAI提供的便捷API，而非其绝对的优越性。在实际应用中，需仔细考虑向量数据库是否适合，因为用户的搜索习惯往往基于关键词，而向量数据库的ebel ding可能无法满足这种需求。强调向量数据库在特定领域如推荐系统和语义搜索中的价值，但批评其在尝试强行结合语言模型方面的应用。"
      },
      {
        "time": "00:25:09",
        "title": "探讨嵌入模型和文档处理的重要性",
        "summary": "在当前技术发展中，嵌入模型和文档处理的重要性被相对忽视。特别是嵌入模型，尽管在国外有强大的专有模型如OpenAI和Cohere的模型能处理多样需求，国内在此领域的优秀产品稀缺，与国外的差距明显。此外，文档处理，尤其是PDF文档的信息提取，是一项复杂但被低估的技术。国内有公司在这一领域表现出色，但整体上，这些技术在应用和认识上都存在不足。这些模型和技术对于向量数据库和外置知识的构建至关重要，其应用场景远不止于语言模型。"
      },
      {
        "time": "00:26:35",
        "title": "懂AI的产品经理：稀缺资源与未来挑战",
        "summary": "生成式AI产品的特性，如不确定性、响应速度与服务成本，与传统产品有显著区别，要求产品经理不仅要理解AI技术，还要懂得如何在AI环境中构建产品。特别强调了数据飞轮的重要性以及在to B产品方向上，懂AI的产品经理尤为稀缺。此外，还提到了应对AI冲击的重要性，尤其是在无法区分AI生成内容的未来，将对平台信任造成挑战。"
      },
      {
        "time": "00:28:29",
        "title": "探讨技术创投误区与多模态模型的未来",
        "summary": "对话中强调了避免盲目追求技术热点指导创投的重要性，指出追随技术发展脉络易导致与大公司竞争的不利局面。此外，指出了学术界在实际应用方面的局限性，以及目前的技术创新多为妥协结果。特别地，讨论了垂直应用与模型的关系，认为垂直模型并未解决通用模型的缺陷，且垂直模型的性能往往不如通用模型。最后，探讨了多模态模型的现状和未来发展方向，认为真正的多模态模型尚未到来，目前的多模态模型仍存在局限，但多模态模型对于解决跨领域问题具有潜力。"
      },
      {
        "time": "00:32:42",
        "title": "大模型的未来趋势：无需人类反馈与长Context的重要性",
        "summary": "当前，对于语言模型（LM）的训练和优化，存在一个误解，即认为强化学习（RL）和人类反馈（HF）是必不可少的。实际上，通过监督微调和基于人类反馈的强化学习（RLHF）等方法，目标是使模型对齐于任务和人类偏好，而不仅仅是优化反馈。近期的研究显示，如果有足够的反馈数据，可以直接优化模型，而无需通过奖励模型。此外，实验发现LM能够自我评估其输出的质量，表明在某些情况下，可能不需要人类参与反馈过程。对于创业团队而言，过度投资于人类反馈可能并不划算。未来，更长的context将带来质的改变，类似于电脑硬盘和内存的比喻，目前的限制类比于只有很小的内存却有巨大的硬盘空间。长context不仅能够提升任务执行的效率和成功率，还有望使模型能够有效利用原本面向人类的教学资源，大大提升模型的潜力和实用性。"
      },
      {
        "time": "00:36:24",
        "title": "AI创新的未来趋势与挑战",
        "summary": "AI创新预计将出现在许多目前尚未被充分探索的领域。特别关注点包括自然语言处理与结构化数据的边界，以及AI在非直接用户交互场景中的应用，如数据分析和实验模拟。此外，AI技术的整合方式正在发生变化，强调不应将AI视为附加组件，而应让其成为业务的一部分。AI领域面临的人才价值危机、技术同质化、以及开源AI对人才的影响等挑战被提出。尽管存在挑战，AI技术的普及和应用仍处于早期阶段，未来有巨大的发展空间和机遇。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [],
              "content": "共生数据：不属于你，但与你共生的数据是真正的壁垒。"
            },
            {
              "children": [],
              "content": "数据的定义：开放可用的数据价值不大；创建的数据的安全性也受到挑战。"
            },
            {
              "children": [],
              "content": "数据价值：客户共生的数据成为竞争的关键。"
            }
          ],
          "content": "一、数据的重要性"
        },
        {
          "children": [
            {
              "children": [],
              "content": "移动互联网类比：AI领域的现状与移动互联网初期类似，创业者面临大公司的竞争。"
            },
            {
              "children": [],
              "content": "设备端AI：强调设备端AI的重要性，如on device AI。"
            },
            {
              "children": [],
              "content": "云AI的优势：大公司在云端AI领域具有明显优势。"
            },
            {
              "children": [],
              "content": "企业数据源：企业内部协同工具数据的重要性。"
            }
          ],
          "content": "二、AI落地的挑战"
        },
        {
          "children": [
            {
              "children": [],
              "content": "AI创业经验：技术迭代快，创业者需要不断适应。"
            },
            {
              "children": [],
              "content": "技术与市场：AI技术与市场需求的匹配至关重要。"
            },
            {
              "children": [],
              "content": "AI创业误区：不要过于依赖技术热点进行创投决策。"
            }
          ],
          "content": "三、技术与创业"
        },
        {
          "children": [
            {
              "children": [],
              "content": "垂直应用与模型：强调垂直应用的重要性，而不是垂直模型。"
            },
            {
              "children": [],
              "content": "多模态模型：预测多模态模型的发展，将带来AI能力的显著提升。"
            },
            {
              "children": [],
              "content": "模型训练的局限性：模型的训练数据量与质量决定了模型的性能。"
            }
          ],
          "content": "四、AI模型的未来"
        },
        {
          "children": [
            {
              "children": [],
              "content": "AI普及的挑战：AI普及过程中面临的各种挑战，包括技术、市场和监管等。"
            },
            {
              "children": [],
              "content": "AI人才的价值危机：AI技术发展可能导致AI人才供需失衡。"
            },
            {
              "children": [],
              "content": "开源AI的双刃剑：开源AI对AI人才可能造成的影响。"
            }
          ],
          "content": "五、AI行业的未来"
        },
        {
          "children": [
            {
              "children": [],
              "content": "AI的无形融入：预测AI将融入日常生活中，改变世界但不显山露水。"
            },
            {
              "children": [],
              "content": "AI的商业模式：探索AI的创新商业模式，如将AI作为业务的插件。"
            },
            {
              "children": [],
              "content": "AI创业机会：面对AI革命，保持开放和批判的心态，探索潜在的创业机会。"
            }
          ],
          "content": "六、AI应用的前景"
        },
        {
          "children": [
            {
              "children": [],
              "content": "未来机遇：尽管面临挑战，但AI领域仍然充满机遇。"
            },
            {
              "children": [],
              "content": "合作共赢：倡导行业内外的合作，共同推进AI技术的健康发展。"
            },
            {
              "children": [],
              "content": "保持学习：AI技术快速发展，个人和企业需要不断学习以适应变化。"
            }
          ],
          "content": "七、结论与建议"
        }
      ],
      "content": "AI行业观察与预测"
    }
  }
}