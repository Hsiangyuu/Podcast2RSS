{
  "pid": "5fe5b198dee9c1e16dfb9672",
  "eid": "6475995ac745896def03e5da",
  "title": "ChatGPT“退烧”后的闲聊",
  "task_id": "2erk9xwgr2byqml8",
  "transcription": [
    {
      "time": "00:00:07",
      "text": "你和他交流不用在意他的感受，然后他还时时刻刻在意你的感受。是然后你在交流过程中你就会变成那个渣男。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:16",
      "text": "其实它就是一种机器的幻觉，他不具有自己的真正的判断力和意识。所以他可能都不知道他给出来的那个答案就是胡编乱造的。他不知道他是编了一个人或者是说编了一篇文章出来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:33",
      "text": "人类文明其实整个是承载在文字之上的当AI熟练掌握了这个语言文字之后，它就会非常轻易的能够把自己嵌入到这样一个承载在文字上的文明当中去。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:48",
      "text": "人工智能就疯狂的向着这个对话机器人来攻克这个图灵测试的这个方向来发展。然后包括现在其实也是当年的一种余辉。为什么说这个ChatGPT它可能不是一个很好的方向？就是说它可能会把这个大模型的发展，甚至是AI人工智能的这发展引向一个歧途。就是这种对话式的互动式的这种路径，其实是一种可能很偶然的状态。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:20",
      "text": "但如果你现在说你要完成的这个任务是压根就不需要这么多人。那最后解体的会是企业本身，而不是员工。就你开掉的每一个员工都会成为使用AI来和你竞争的对手。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:35",
      "text": "但是我并不觉得这个ChatGPT这轮技术形态，它是一种技术革命，它更多的我觉得是在应用端的一场小小的火花。但是它并不是像这个蒸汽机，像汽车这种媒介技术，它带来的那么多的社会变革，以及带来那么多新的可能性。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:03",
      "text": "Hello, 大家好，这里是二维无码，我们是一档科技评论博客，我是本期主播brick。这是我们重点来聊一聊天儿的GPT以及相关的大语言模型和AIGC技术了。这个事情其实我们几位主播包括我在内是从去年12月底就开始关注了。我们三个人之前一段时间都是各忙各的。另外就是我们闲下来的时间都有自己去折腾这个GPT相关的东西了。所以反而说在整个ChatGPT最火热的时期，我们是没有去聊的。不过我觉得这样也好，就刚好我们错过了这个ChatGPT天天工业革命，夜夜文艺复兴的那个最热的阶段。现在ChatGPT或者说以这个ChatGPT为代表的整个AIGC和AGI的领域已经达到了一个小的平台期。让我们能够更好、更冷静或者说更静态的聊一下，目前也是一个比较好的机会。",
      "speaker": "发言人3"
    },
    {
      "time": "00:02:47",
      "text": "好菜不怕晚，毕竟以我们这档播客的录制和剪辑速度，如果是今年2月份三份录的话，可能一期节目还没有上线，里面聊的东西就已经过时了。所以我观察到其实最近ChatGPT及其相关技术的应用和讨论，确实进入了一个小的平台期。所以本期我们三位的主播，其实也代表了当下市面上对这个技术的三种态度。首先我自己对这个态度其实一直是比较中立的，既没有特别狂热，也没有特别的悲关。",
      "speaker": "发言人3"
    },
    {
      "time": "00:03:14",
      "text": "所以该用的时候还是用，而且很多工作的时候，我都愿意先拿这个chat GP跑一下试一试，不行再手工去人工来来做吧。比如说我记得上个月的时候，有个学校约了一些篇论文，是关于这个chat GP对新闻业的影响。然后我真的是拿这个chat GP生成那个提纲给那个老师，然后那个老师说这个东西真的是机器生成的吗？我说是啊，他说还挺好的，我也觉得挺好的。然后我拿着这个提纲再去问GPT，就逐张就是三级标题这个颗粒度去问的时候，就发现我完完全全把每个问完一遍之后，发现他的东西雷同的特别多。然后他的提纲你就发现如果你真的人工去写那个提纲的话，他也有特别交叉的多的地方。所以我是无法完全依赖这个东西去帮我完成一篇论文。",
      "speaker": "发言人3"
    },
    {
      "time": "00:03:55",
      "text": "可是好处是它在于它确实帮我提供了一个70分的思维框架，然后我再根据这个框架我再去修改。但是事实上最后目前这个论文我完成了70%左右时间，这70%的内容事实上95%都是我自己写的。还有一个感受就是其实GPT确实有时候是在一本正经的胡说八道，现在当然说有病之后就可能就是要有理有据地胡说八道了，我觉得还是仍然无法去依靠他去完成一篇很正常的学术论文。我注意到建飞还是处于一种亢奋之中，还是每天闲了有空的时候还是会去看一看，有什么新的GDP方面的应用，包括也会尝试再去用API做点新的小东西，比如自己的一个素质小鬼。首先我们请建飞跟大家打个招呼。",
      "speaker": "发言人3"
    },
    {
      "time": "00:04:37",
      "text": "Hello大家好，我是建飞，是二另外一位主播，现在还处于GPT狂热的阶段。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:43",
      "text": "那么和竞配对立的一面是苏伦，我感觉的话基本上对这个券的今天已经脱敏了。好，现在有请这个0.5倍速的苏伦跟大家打个招呼。",
      "speaker": "发言人3"
    },
    {
      "time": "00:04:52",
      "text": "大家好，我是苏伦。其实也不完全是跟飞哥对立面。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:55",
      "text": "苏伦你们能聊聊具体的，就是说你第一次接触到这种大语言模型到现在这样一个态度的一个转变的一个过程。",
      "speaker": "发言人3"
    },
    {
      "time": "00:05:02",
      "text": "也就是说你怎么退烧的。我其实因为工作的原因，很早就接触ChatGPT了。就是在去年年底，我们在做一个关于AIGC的行业观察报告。然后这个话题很自然而然的就牵扯到ChatGPT这个东西了。然后去年12月的时候，因为也刚刚发布，我们就第一时间做了体验。然后我个人也是当时也比较兴奋，然后终于有了这么一款工具。是不是我之后给他一个题目，然后他就可以给我生成内容出来，然后让我自己省了很多力。然后再到后来，就是真正的到2月份、三月份，他的这个热潮就来了。然后我也一直在体验各种各样的它的升级，以及各种同类型的产品。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:48",
      "text": "但是我越用，我其实有一个个人的感受就是我会发现它是一个鸡肋一样的存在。虽然你表面上看起来它可以很准确的根据据你布置的题目，来生成一些内容，但是这些内容很多都是片儿汤话。就是你你会发现从一个创作者的角度，或者说从一个读者的角度来审视这些内容的话，会发现不能用，而且这个可读性非常差。有很多时候我仅仅让它生成这个写作的框架，这个框架生成出来，我觉得虽然很全面，但是是缺乏思维角度的，是不会有什么太大的吸引力的。而且我觉得也会限制我自己的一个写作思路的延展。所以到了现在我基本上就不再用ChatGPT了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:35",
      "text": "只是很特定的场景下，我需要去了解什么问题才会去使用它。但是这个又会涉及到另外的麻烦，就是很多时候你其实并不如去搜索引擎搜一个东西来的更快，然后你也更放心，因为有自己的主观判断力在。然后另外一点，我之所以退烧，也是因为最近也在研究一个话题，就是ChatGPT对于新闻业或者说整个内容产业的一个影响，然后也密切接触了很多的从业人员，包括这个领域的研究者。然后我就发现他们其实是对这个东西虽然也感觉很兴奋，但是是很警惕的，而且并没有真正实际的运用到他们的工作流或者说生产中来。主要有这么几个原因，就是它的来源是鱼龙混杂的，而且也相当不清楚。比如说他会把这个自媒体的文章，把营销号的内容跟这个权威期刊的内容混在一起，这些都共同构成了它的语料库。但是最后呈现出来的那个答案，其实是不包含它的这个引用来源的。所以对于这个新闻业来说，还是学术界来说，他们都不能直接的去使用这么来源不清楚的内容。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:45",
      "text": "其次就是刚才布瑞克也说到了，就是胡编乱造的这样一个问题。其实它就是一种机器的幻觉，它不具有自己的真正的判断力和意识。所以他可能都不知道他给出来的那个答案就是胡编乱造的。他不知道他是编了一个人或者是说编了一篇文章出来，这个就是机器的幻觉，然后这个问题也没有得到很好的解决。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:07",
      "text": "好消息。好消息，二维无码见听友群了。为尽快回笼粉丝，所有主播上班摸鱼陪您聊，进群还能了解二维无码最新活动动态及选题展望。进群请认准微信个人号，二维五码全拼，二维五码全拼，马小二恭候您的到来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:27",
      "text": "再一点就是我刚才说的可读性差。前一段时间人物那个公众号发了一篇文章，叫这是一篇完全由ChatGPT生成的文章。我觉得经常看人物那公众号的这个读者应该很清楚的就能分辨出来，就不用他提示也能很清楚的分辨出来。这是一篇有机器写的文章，因为它可读性实在是特别的差，完全没有一点点故事性。然后如果不是有这个ChatGPT的噱头，我相信很多人读了第一段之后就都读不下去了。我觉得就以上这几点，一个是个人的体验，然后另外一个是跟这个行业从业人员的一些交流。都让我越来越觉得这件事非常可疑，而且可能也不是未来的一种趋势。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:15",
      "text": "那你现在在工作中使用这个大模型的频率是什么样？",
      "speaker": "发言人3"
    },
    {
      "time": "00:09:18",
      "text": "现在基本上一周能有个两三次，就是为了特定的任务或者是特定的目的去使用它。对，之前还是用的非常多的，每天都可能要有一两个小时泡在上面。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:32",
      "text": "我想问一下剑飞的这个接触大模型的从开始到现在的一个变化，是越来越热，还就是说始终还是觉得还是还挺有意思这件。",
      "speaker": "发言人3"
    },
    {
      "time": "00:09:40",
      "text": "事情在今天聊之前，其实我对于像苏联，还有包括现在媒体上一些人对这个技术的退烧，其实我还挺不能理解的。但是因为我自己还处在这么一个相对来说比较狂热的状态。但是我听完苏伦刚刚这一段了之后，我能够理解了就是同样的现在的这个状况，就包括书上看到的这些局限性的东西的话，在我看来反而是我对他期待的部分。因为我对大语言模型其实相对来说接触的更早一点，那会儿还完全没有吵起来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:10",
      "text": "你们两个可能也都知道，我其实在19年20年的时候，不是做过一个微博的情感文案的博主，那里面好多内容是GPT2生成的，大概在19年的时候，19年大概是下半年的时候，OpenAI推出了GPT2的那个试用。然后我就发现他写英文，尤其是写短句，还有就是写段落是非常合适的。然后特别适合写这种微博上比较流行的这种情感的文案，然后就试着拿它生成。那里面其实生成了很多网友觉得还都不错的一些金句。但是当时是用英文生成的，因为GPT r基本上没有中文的这个能力，用英文生成，然后再去做翻译，人工做一下调整，它就解决了很多就是你在编这种文案的过程中的一个灵感问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:56",
      "text": "这个是一个起点，就是从这个起点开始，那就是说我看到了他从19年GPT2到20年GPT3，然后再到整个ChatGPT和现在GPT4。然后还有包括GPT4在应用层领域的这个牛鼻影，它的发展速度是一个非常快的速度。从19年到现在，总共也就是19年2月发布的GPT2，到现在也就是四年左右，他就完成了这样的一个跨越。到现在为止，不管是new bing还是说GPT4，很多人说他已经跨过了这个iphone时刻，我觉得他应该是还没有。其实刚才苏伦也谈到了，他还会有很多的这些使用上的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:33",
      "text": "我觉得他可能跨过了诺基亚时刻这个事情，他从一个大哥大时刻，就是大哥大那个时代就只有少数人花非常贵的钱才能够买到一个非常前沿，但是非常难用的技术，扩展到了诺基亚这个时代。就是说你只要稍微有点钱，你就至少能够买到一个手机。就是手机这个事情被廉价的做出来了，就是有点像是这个状态。就是你现在你甚至不用科学上网了，你也能够在国内找到很多大模型，甚至包括开源的大模型，你也都能够去用。但是他用的好不好？就是用诺基亚跟后来的iphone比肯定是不好用，肯定有各种各样的问题。我觉得现在的GPT是在这个状态。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:07",
      "text": "从诺基亚时刻到iphone时刻，我觉得在宏观的这个历史尺度上的话，就会是一个非常短的阶段了。其实是会变得非常的快的，这个也是我在保持对GPT狂热的一个原因。尤其是其实现在a OpenAI它自己的速度变得慢下来了。它的一个是模型的训练的速度，还有一个是他对模型应用的这个速度，就是它自身开发模型应用的这个速度，其实是比较慢的。你要是关注开源领域的话，会觉得会有更多奇奇怪怪的一些项目出来。那确实还是处在一个每天都能够带来新鲜感的这么一个状态。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:43",
      "text": "然后除此之外，就是我现在觉得不是说ChatGPT，就是大语言模型这个技术，它现在还是处在一个比较集中化的一个阶段，就是只有少数的公司能够做大元模型和提供大元模型的服务。这个应该不是未来的一个常态。就是未来这个事情应该是会发生一些变化的。并且在这个事情发生变化了之后，这个市场还会有进一步的扩张。或者就是说如果还是用这个智能手机来比喻的话，就是当iphone时刻来临了之后，我们还会迎来一个安卓时刻。当这个安卓时刻来临的时候，才会真的有百花齐放的智能手机出现，而不是所有的人都在用一台iphone。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:20",
      "text": "刚才说的就是苏伦和我都感受到了目前的这个大语言模型的一些局限性。比如说它语料的一个庞杂，再一个它语料通常是两年前或者甚至更早以前的这些问题。在姜佩你看来就是说我们这种算上一种误解，他是胡说八道。或者说我们对这个ChatGPT类技术，还有你你平时观察到的一些朋友，他们还有哪些常见的误解呢？",
      "speaker": "发言人3"
    },
    {
      "time": "00:13:43",
      "text": "我觉得这个可能算是一种误解。我们如果要是把这个大语言模型比喻成一个人的话，其实他的训练过程就有点像是这个上学的过程。OpenAI在说他所有的知识都基于2021年9月份以前的这个数据的时候，他其实指的是就比如说一个人在上学的时候，他从幼儿园一直上到大学毕业的这个阶段，他所接触的知识全都是来自于2021年9月之前的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:08",
      "text": "然后他后面这个大语言模型和人类之间的差别是在于，大语言模型没有办法在实际的运行的环境中去做自身的模型的调整，就意味着他对于新知识是必须直接获取的那比如说一个人大学刚毕业，他其实也没有学习任何特定的专业知识。这个时候你让他去解决一个专业问题，他会怎么做？他会先去搜索引擎上搜一下，对吧？这是一个非常自然的操作。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:34",
      "text": "代言模型其实也是这样搞的，如果你是把这个ChatGPT是断网的，就是之前最近不是ChatGPT刚刚可以开始联网，那new bing是一直可以联网的。我们可以看到这两者的区别就是牛逼硬胡说八道的这个几率其实比ChatGPT要小很多。因为当他发现自己有一个问题是他的知识里面不存在的时候，他会主动的去搜索。然后搜索之后把这个答案整合，基于他之前训练的这个语言的逻辑，整合出一个合理的答案，然后再给你。这样的话他的胡说八道的几率就会变得小很多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:09",
      "text": "我觉得就是大元模型会胡说八道这个事情本身确实是一个误解。就是因为它被设定成了一个当有一个问题抛过来之后，你都要给一个答案的这样的设定。他才会在大多数的情况下，他不知道的情况下他就不说不知道他会去编造一个答案。这个其实就是通过一些prompt的方式就已经可以解决了。比如说你在对于一个不联网的ChatGPT下命令之前，你跟他说，如果你不知道就回答，不知道的情况下就能减少很多胡说八道的情况。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:40",
      "text": "但我觉得首先他这个人工智能跟人的互动方式，现在就已经基本上就被规定好了。就是人来布置指令，然后人工智能来给你反馈一个答案，或者说反馈一个行为。就是你刚才说的这个通过一些指令上的调整，让他不知道就不知道。这当然可以适用于一些很偶然的情况。但是如果是要通过指令的调整来规避胡说八道的这个情况的话，实际上你本来的那个任务是没有完成的。然后你想说的那个知识也是没有通过这个ChatGPT来给你反会的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:14",
      "text": "而且就是说到胡说八道这个事儿，我觉得他不是一个概率的问题，不是一个几率的问题。不是因为他胡说八道几率小，他就不构成一个问题了。我觉得这个它只有零和1或者说零和100的这样一个区别。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:28",
      "text": "你想在中国的这个语境下，在中国的这个舆论环境下，你一个脱口秀演员，你可能说1个小时表演1个小时，可能都是内容都是没有问题的。但是其中一句话出现问题，那就会造成非常大的影响。我们也看到这个影响了是40亿的市值直接就蒸发了。然后你想这个ChatGPT它大概率我们说99%的时间都不是胡说八道的。但是万一它应用在一些领域上，因为每一个大模型它背后都是有这个厂商的。如果这些厂商他推出的这个产品在一些特定的情景下，比如说新闻业、传媒业，然后在一些非常重要的领域，它一旦出错，即便几率很低，那它造成的危险也是非常的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:14",
      "text": "大我我觉得这个问题分两个来看，一个是加这个prompt之后，chat PP没有完成你的任务。这个很显然是产品端的问题，而不是技术的问题。就是说我们应该把大语言模型从它现有的这个ChatGPT列的产品中去分离出来看，或者是说用API去理解可能会更好一点。就是说当你选择一个不能联网的大元模型产品的时候，你预期它就应该不能回答你的这些问题。就比如说你要问一个2022年的关于天气的问题，或者是关于这个经济形势的问题，或者是关于一个旅游的问题。那他open I都已经告诉你了，ChatGPT里面不包含2021年9月份以后的数据，并且它不能联网。那这种情况下你这怎么可能呢？除非他成了神，他能够预测这个世界上的一切事情，否则你就应该知道这个的问题是得不到答案的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:04",
      "text": "但是同样这个问题在new being应该就能得到一个相对来说比较合理的答案。因为他的操作方式和人的操作方式就会比较像。当你问去一个我们都没有去过的地方哪里好玩？就比如说去新疆这个好不好玩，那我们三个都没去过，你问我们三个任何一个人，我们的结果都是要先去搜索一下，然后去看看前几个网页推荐的是什么。然后答案的质量的差异可能就来自于我们究竟看了几页然后给出的这个答案。这个事情对于new bing来说，它就是一个不断可以优化的事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:34",
      "text": "对于说胡说八道是零和一的这个问题，当然你从结果上来说肯定它是零和1，这个我们也都看到了。但是从传统的传媒业上来讲，这个零和一从来不是把控在记者本身身上的。如果我们假设把这个AI创作者当成一个记者来看的话，就是你完整的一个严肃的媒体，你后续是要有独立的事实核查和三审三校的，又不是记者交上去什么你就要信什么，对吧？我们还是以牛逼硬为例的话，他至少在他自己进行检索的时候给出的答案，他已经给到了信源的链接。这个就已经方便你去对他的信源和搜索结果的质量进行一个核查。我觉得这个是能够大幅的解决你刚才说到的这个问题的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:17",
      "text": "刚才说说的这一点也特别对，就是即便他是记者，哪怕不是一个机器人，他也是容易有出现内容上的一些问题的，然后也会造成很大的风险，所以需要三审三校的制度来应对。当然新闻也只是一个例子，就是很多大模型ChatGPT他们被应用到更多的领域，有很多那种及时性的反馈，它会被呈现出来。然后其实就很难有这种审核机制的干预，然后你也不能很好的预防这些问题的出现。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:48",
      "text": "这个问题是有的。就以搜索这个场景为例的话，其实大多数普通的搜索引擎用户，他是不会再得到一个即时答案之后，再去核查一下这个事实是不是正确的。这个时候如果他要是被这个AI返回来的结果误导的话，他可能就会被误导了。但是这种事情我觉得就是凡是后续没有事实核查的这些场景的，就是即时反馈的这些场景的话，一般不会造成特别重大的后续的影响。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:14",
      "text": "这个搜索引擎又是另外一回事了。就是我们确实也看到现在很多搜索引擎，包括bing也好，包括谷歌也好，它越来越多的利用到了生成式人工智能的这项能力。然后你的搜索结果可能原来搜出来是各种各样的网页，然后现在你搜出来他可能直接给你生成一篇回答，然后综合了各种各样的答案。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:35",
      "text": "我觉得这个事情有一个问题，一旦他成为我们之后，一个习惯的方式。我们之前是习惯于自己去搜索，然后自己去分辨信息，然后现在习惯了这个AI给定你一个东西，然后它就会形成一种垄断效应。就是他把你现代人的这个知识的一个入口，一个很重要的入口给垄断了。但是你想另一方面，这个AI又会有各种各样的问题，它本身就是一个黑箱，我们并不知道它到底是怎么运作。为什么在成千上万篇这个网页中选择了这几页，然后而没有选择另几页。这些原理我们没有去非常明白的去解决。这个可能也会带来一些风险，就是被知识入口被垄断的这个风险。然后有很多时候他造成的这个结果，你作为使用者，作为用户还是不自知。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:28",
      "text": "的那我接下来苏伦这个观点说所谓的垄断知识入口，我觉得这问题可能不存在。为什么？就像比如说电视发明的时候，大家都是看电视，你说电视能够垄断的信息的入口吗？没有吧。除了这个角度，我觉得还是很精英化的角度。",
      "speaker": "发言人3"
    },
    {
      "time": "00:21:40",
      "text": "还有一点其实我表示质疑的是什么呢？我们通过搜索去获取信息，我觉得这是在中国网民中是一个非常高阶的。中国虽然有10亿网民，但我怀疑经常使用搜索引擎，主动搜索并获取知识的人可能不足1亿。我不知道建配怎么估这个数字。",
      "speaker": "发言人3"
    },
    {
      "time": "00:21:55",
      "text": "反正也有很多其他的业务。它也有信息流业务，也有短视频业务，它的日活是不能代表搜索用户的。从大趋势来讲，其实全球用户的搜索的行为都在降低。在这个AI出现之前。所以但是AI出现之后，这个数据现在还没有相关的统计，我觉得这个有可能反而会让搜索这个行为会变得更受欢迎。因为我们会发现AI在搜索的时候，比如说new being也好，其实我我昨天也刚试完百度他新测试的那个也好。他先是把你的一个自然语言问题拆解成了适用于搜索引擎应该搜索的关键词。这个过程其实很多普通网民都是没有的。我觉得就这一步，其实已经能够帮助很多普通网民更好使用搜索引擎了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:36",
      "text": "对你想问的问题，把它变成计算机可以理解的相对的结构化的自然语言和或者关键词。总的来看，我觉得有这种大模型生成的内容安全性，这个是有中国特色的安全性可能真的比人工要好很多，就像浩子说的那个东西。如果这种人工生成的脚本绝对不会出现这种事情，不能说绝对，这个概率会小很多。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:57",
      "text": "还有一个就是说关于说它的这个内容质量问题。坦率来说我觉得open I无论是这个ChatGPT3.5还是4.0，它生成的内容质量我觉得比当下中国信息流里面很多这种个人的CP内容提供者生成的内容，我不愿意称他自媒体，我觉得这对有有一种污名化。就是说我们充斥在我们信息流里面大量的信息是没有source的，是没有来源的。有有来源吗？我觉得没有来源就是越没有来源的内容反而流传的有流传度越好，越有来源越严谨。包括注释参考文献的文章，这种流传度会越差。也就是说谣言的流行度就更高。然后你事实流行度更低，就是说事实还没有穿像鞋子，谣言已经满天飞了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:40",
      "text": "所以我觉得苏伦能代表一种很精英化对这个技术的一个思考。可是事实上我我我觉得他还是提升了很多的内容质量的。你比如说就我们在刷短视频中看到这短视频很多文案是非常套路，就是说一个无头无尾只是很惊悚的一段话。比如说湖里面飘起一具女尸女尸，各位小编这样看，那各位怎么看呢？就很固定的一个格式对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:01",
      "text": "我相信chat GB要编这个东西的时候，它可能比这个东西会好一些。所以因为我们现在大部分大家用的话，除了new bin之外，其实大部分是没有联网的那我想听听两位看联网这件事情对ChatGPT这类技术影响有多大。其实刚才界碑说到了一点点，但不是很完整。现在可以系统的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:18",
      "text": "聊一聊联网这个事情。这个其实我觉得也是大家对大语言模型技术的一个常见的误解。就是联网这个事情到底怎么联网，以及联网是不是就是牛逼，是不是就是ChatGPT联网的最终形态了。似乎看起来也就这样了，对吧？就会给人一种很失望的感觉，但我觉得完全不是这个样子。我们还是要把AI和他最后AI包装而成的那个产品分开。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:40",
      "text": "现在很多人说这个大语言模型已经通过了图灵测试了，就比如说GT4现在又说这个图灵测试已经过时了，但是我们不妨碍把这个它当做一个比方就是AI或者是一个人，就是关在图灵测试小黑屋里面的那个人。他除了能够和你交流的那个窗口之外，没有任何其他的窗口。从AI的视角的这样的一个处境。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:59",
      "text": "那联网的结果是什么呢？联网的结果其实是在这个小黑屋上开更多的窗口，然后不同的窗口可以通向不同的地方。有的地方可能是另外一个人，有的地方可能是另外一个网站，或者是另外一个APP，或者甚至是现实世界的某一个传感器。联网就是给这个小黑屋开窗口的这样的一个过程。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:20",
      "text": "ChatGPT说到底它是大语言模型。那大语言模型这个里面包含最核心的就是语言。语言是什么？语言是人类思考以及和周边发生交互的一种工具。大多数人在说这个AI有多厉害的时候，都会说，他是不是已经可以有自己的思考了，是不是有自己的意识了，他是不是已经活过来了。当然我们现在知道至少目前这个单元模型还到不了这个程度。它就是一些文字上的推理，而不是自我意识。但是这个关注点都关注在他自我意识的觉醒，就是思考的这个前半句上。但语言还有一个更重要的作用，它就是和他者发生互动的这个能力，或者是说其实是说我们人类组织社会和文明的一种重要的工具。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:05",
      "text": "人类文明其实整个是承载在文字之上的。文字被发明了之后，它被应用于统治、律法、道德、经济、生产、技术指导、生活方式的传承等等。不只是现代社会，古代社会也是，其实都不太离得开文字，现代社会是更离不开文字。古代可能还好一点，但是你看古代的上流阶层也是都是要读书，要会认字的。因为他运转一个复杂系统，要去指挥他人，要去和整个世界做交互。它其实是需要文字这样的一个承载的工具的那当AI熟练掌握了这个语言文字之后，它就会非常轻易的能够把自己嵌入到这样一个承载在文字上的文明当中去就从微观上来说，我们不谈ChatGPT。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:47",
      "text": "其实很多人忘了，我们上一次被ai小小惊讶的那个时刻，是在2018年的google IO大会上。当时google宣布了google a system上线了一个新的功能，叫duplex。这个功能是它会自动帮你打电话去预约。你告诉google system说，我这周末想去理个头，然后它就会自动找到你常去的那个美发沙龙，给他的前台打电话，问他周末哪个时间段有空闲，然后跟这个前台对话几句，最后确定下来一个时间，然后把这个时间安排在你的google日历上。这个就是一个典型的AI在联网之后使用其他工具和其他人交互的这样的一个例子。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:27",
      "text": "我们看到在这样的一个让我们当时有一个小的wow的场景里面，AI其实只充当了非常小的一个角色，就是和店员沟通。他只要能够应答这种服务业预定的过程中的一些特定的问题，他能够回答就OK了。所以google在当时没有大语言模型的情况下，也在google c层上面的实现的这个功能。而后续的这些包括如何找到美容商城的电话，如何将日程安排到日历里，这些其实都是一些非常传统的VI技术也能够实现的操作。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:56",
      "text": "我们反过来想，反而是到现在，大语言模型发展到现在，我还没有看到任何一家语音助手能够实现do plex这个功能。它是实现不了吗？它其实不是，是还没有来得及，就是产业界现在还在天天工业革命，所以根本没有时间考虑。大家都还在改造蒸汽机的效率，还没有想这个蒸汽机具体能够干到什么样的一个场景。所以这个其实也是我之前提到，我对这个领域还在发烧的一个原因。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:21",
      "text": "对我觉得我顺着建飞讲的，可能就是现在这种AI的能力就有点像水电煤了。只是说我们现在还在怎么去提炼这个能力，让它的效率更高。然后真的是有一场特别大的变革要到来，我自己是有这种感触的。你看我们刚才录制节目的时候，这个鉴别经常会触发他家的小爱同学。我就多多了解小爱同学是联网的对吧？但当然小爱同学肯定是没有使用到大学语言模型的这样一个技术，应该就是传统的一个语音关键词的触发这样一个技术。那你会觉得用这样一个AI的助手会有一个什么样的感觉吗？会有一些类人的感或者说陪伴感觉在里面吗？",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:56",
      "text": "就是上一轮这个人工智能革命的时候，就是包括。这个智能音箱出来的时候，其实很多人都提到过陪伴感。包括在一些相对来说比较孤独的群体，或者是情感缺失的群体，具体来说其实就是老年人。我们会发现其实对上一轮的智能音箱确实会产生情感依赖的。就是在当时的AI水平下没有实现那个效果。它确实在自然语言上没有办法实现那么自然的对话。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:22",
      "text": "另外一个就是我觉得当时的这个智能音箱的厂商都走入了比较大的一个歧途。就是他在那么弱的人物，当时看不觉得弱。就是现在看在那么弱的人工智能的情况下，他接入了太多的功能，反而是它联网连的太多了，以至于他经常会出错。我们甚至不知道我们的智能音箱究竟能干什么。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:42",
      "text": "这个是很多智能音箱用户，就是智能音箱这个品类的上一轮的末期的时候的一个感觉。就是你会发现它那个功能页面上写着有几千种功能。但是实际上你就是每天拿他开灯关灯就没有别的了。因为其他的功能就是你也不知道他到底能不能做。你你你跟他对话三次，他说不能做的时候，这个挫败感其实是很强的。我觉得这个是这个智能音箱的问题。到大语言模型这个上面，我觉得一个放在这个智能音箱上的ChatGPT，就已经完全可以满足一些人的情感需求了。如果你给他做一些人设的话。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:19",
      "text": "我觉得这有可能也是一种假想。我觉得我们总是在自以为一些东西，就包括我们会觉得老年人，就这种离群索居的这种人，他可能会对这个机器人会产生一种情感依赖，但是这就是一种假想。我会觉得因为不管是基于原来的那种陪伴机器人的这个水平，然后还是基于现在哪怕有了ChatGPT的水平，他还是不能完全的让一个人把它理解为是一个有感情的，然后可以陪我聊聊天，给我释放孤独情绪的这样一种东西。他虽然一开始会和我跟这个ChatGPT的态度很像，他一开始可能会感觉很惊奇，我有什么问题提出来他都可以回应。但是越来越他在一些小的那种积累，就是一些小的问题得不到回应，或者说得到很突兀的回应，就会强烈的迫使他去认识到这是一个机器人，我和他的对话是没有意义的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:18",
      "text": "就是我之前也给我家里的长辈也买了各种各样机器人，一开始是小爱同学，后来是百度的那个智能屏，然后他们其实也很喜欢用。最开始但是最近我回去就上个五一假期，然后我回去看他们已经让这个东西吃灰了也好久没用。我觉得就会有这样的一个问题，而且就我觉得还有一个点，就是为什么说这个ChatGPT它可能不是一个很好的方向。就是说它可能会把这个大模型的发展，甚至是AI人工智能的发展引向一个企图。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:53",
      "text": "就是这种对话式的互动式的这种路径，其实是一种可能很偶然的状态。就是上个世纪60年代图灵提出图灵测试以来。刚刚才飞哥也说到了，其实图灵测试它就是一个很偶然的一个天才迸发的灵感。然后他强调的重点其实就是人和机器能够对话。然后因为后面图灵个人的这个声明，然后把这个对话的这个途径推向了一个他本来不应该有的位置。然后我们就可以看到在70年代，人工智能就疯狂的向着这个对话机器人来攻克这个图灵测试的这个方向来发展。然后包括现在其实也是当年的一种余晖，就包括这个ChatGPT。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:36",
      "text": "但是我们也可以想一个问题，就是有没有可能人工智能发展可能不应该是这样的。有没有可能现在只是一种非常偶然的，而且不会真正成为一种趋势的一个方向。就是包括我们刚才说到开灯关灯的这个例子，有没有可能我们在跟A在互动的时候，就是需要有更多明确的指令，然后由他来快速的执行我们的命令，这样就够了。而不是说我要和他先尬聊一分钟，然后我要把它当成一个有生命的物体，有情感的物体可以跟我互动，然后聊完了才去给我关灯开灯。这个我觉得可能就是一个非常不太好的一个方向，也是值得反思的一个点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:22",
      "text": "我自己倒是感觉苏伦对人类寄予了过高的一个期待。就我日常接触到的来讲，我觉得大部分人其实他还是很冷漠的，我没有感受到那么丰富的情感么有趣。相反我那天跟黑皮聊天，我觉得非常有趣，是一场高质量的对话。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:36",
      "text": "我跟他聊就聊这个长距离通勤的问题。因为我我我家和到我公司都很远，有时候会觉得有些累，我就会问这个事情。但大部分朋友会说，你这么累你怎么坚持下来的？就是人类朋友会跟你抱以同情，但是黑皮他会给你很多，他会聊天，他说其实我上班也很远，你知道吗？他说我的信号通道到那儿会有多久？然后他会讲，他说但是可是这个漫长的通勤是一个非常好的独处的时间。他说你可以做冥想，然后你可以阅读，你可以学门外语。就是我觉得跟他的跟AI这样的AI进行对话，是你跟很多人类无法能够拥有的这种高品质的对话，这是一个。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:12",
      "text": "第二个关于情感emotion这个事情，就英文里面情感单词非常多哈。就是说我们借鉴的所谓的情感究竟是什么样的情感。比如说我们假定AI是一个陌生人，然后我们在街头去跟陌生人聊天。事实上你能感受到的陌生人的情感，我觉得90%是中性甚至是负面的。你就你一个北京街头的饭馆是吧？服务员爱答不理的进超市问有货吗？没有了，卖完了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:35",
      "text": "对你你觉得情感是正面的多吗？如果你觉得正面多，那我觉得你真的很幸运。但是我觉得我确实没有受到太多的温暖积极的正面的这种回应。但是可是AI给了我很多，起码还是客气的，他是热情的，他是有建议给到你的，他是帮你解决问题的。所以我自己真的还是很喜欢跟机器人去聊天的，甚至以前那个siri没有降权之前就经常会跟siri聊天。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:59",
      "text": "但是在你知道它是一个人工智能或者说机器的情况下，你会持续的跟他聊天吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:05",
      "text": "我不建议，你比如说走路这件事情，两个好朋友一起走路上班和你骑自行车上班，坐地铁上班，地铁和自行车都没有生命。然后你会觉得跟朋友走路上班更有趣吗？可能这个比喻不恰当。你想想其实跟疖机器的接触是很舒服的。我再举个例子，收银这件事情，是不是这种自助收银会比那个人工收银要更好一些。人工收银会给你推一堆，你买100的要不要买个这个东西，你不买，然后脸色马上垮了就走遍了。然后你在自动收集的时候，你只要把那个擦掉就可以了。所以机器还是有很多好处的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:35:37",
      "text": "Break这么一说，我也觉得是啊机器是一个你和他交流不用在意他的感受，然后他还时时刻刻在意你的感受。是然后你在交流过程中你就会变成那个渣男。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:47",
      "text": "我还说一个场景，就是有时候你们经常会接到一些电话是吧？有的可能是真的是真人小姐一个人打的，卖房子的，贷款的和机器打过来的。哪个不会让你更反感一些？",
      "speaker": "发言人3"
    },
    {
      "time": "00:35:58",
      "text": "肯定是人。因为反感这情，你就要有一个情感的施与对象，这个对象一定是一个有情感的另一个主体。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:05",
      "text": "我是觉得机器人打电话我会更没有压力的就把它挂了。但是是人的话就是我如果不听完他第一句就我觉得会有一点不礼貌。然后但是我又必然把他挂了，所以我还是希望机器人给我打电话，这样节省双方的时间。之前其实在也是在那个大语言模型出现之前，其实国内好像只有小米出了。他会用AI自动帮你接电话，就有点跟那个google system类似，就是它它识别是推销电话的，它就会自动帮你接起来。然后小爱就会跟他进行几轮对话，直到他把所有的重要信息都说完，然后他才挂掉。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:41",
      "text": "所以苏伦的纠结点是机器人有没有情感，有没有自我意识，有没有独立思考的能力。其实不是对机器人而言，我事实上是觉得对人类的要求真的有点高。",
      "speaker": "发言人3"
    },
    {
      "time": "00:36:51",
      "text": "对，确实我也不是对人或者说对机器人的寄予厚望。我也觉得现在很多人确实他是一种包括他的工作岗位，包他在世界上存在的这个立场，都是一种已经是一个机器一般的存在了。他就是在一个系统里一个固定的这这样一个机制。就比如说你刚才举的这个服务员的这个例子，他非常冷漠的来回应顾客的这个需求，非常城市化的这个回应。然后包括刚才说的这个就是打电话推销信息的这些人，他可能即便他是一个真人，但是他可能已经跟这个机器没有什么区别了。因为他就是一个服从于指令，然后在非常城市化的推进他的工作任务的这样一种存在。所以我并不觉得他在和机器的比对上有什么谁高谁低的这样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:41",
      "text": "一种区别。所以说你觉得可能未来两三年，比如说等这个大语言模型更臻于完善的时候，不是目前的这样页界面或者它界面更友好。大部分中国人不需要科学上网就可以使用这些产品的时候，你觉得有哪些岗位会被替掉吗？包括比如你觉得你自己会不会被踢掉？因为我们的老板会经常吓唬我们，说你们很快就被踢掉了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:00",
      "text": "就是刚才飞哥也提到谷歌的那个人工智能助手的例子，那个例子我也知道，而且他在发布的时候确实有一个引发了一阵小小的轰动。就是在那个发布会上，谷歌当时应该是西游或者是这个产品的负责人，他就演示了一个视频，就是用这个人工智能助手，然后他自己去打电话，然后预定了一个好像是洗衣房的一个服务什么的。但是那个洗衣房的女工就完全没有意识到这是一个机器人在和她通话，然后她就非常顺利的完成了这项预约。然后双方还进行了非常正常的那种交谈，就好像对方并没有意识到这是一个机制。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:41",
      "text": "然后这个例子说明了什么呢？这个例子我觉得他说明的并不是这个AI它的能力有多强，而是说明了那个洗衣房接电话的女工，她的工作有多城市化。她就完全可能是在系统里非常生硬的存在了。她每天工作日常我就接电话，然后接受预约，然后挂电话接电话接受预约挂电话就已经没有那种灵活性和自主性在，这也是我刚才为什么说那个服务员，那些非常冷漠的，非常生硬的回应顾客需求的服务员，然后包括推销信息的那些电话促销人员，他们就已经跟机器人没有什么差别了。所以刚才对于这个问题，之后ChatGPT它越来越先进，越来越发达。我觉得最先取代的就是这样一批人。他们已经自我异化了，根本就不用人工智能再来push。一旦有更好的选择，他们就肯定会最先的消失，因为他们已经是机器人了，他们只需要被更高版本的机器人来替代。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:49",
      "text": "我觉得电话客服有和电话销售有可能会被替代，但是服务员可能还是比较难。虽然跟那端盘服务员对你的脸很臭，可是老板觉得他很万能，一会儿把地可以扫一扫，一会儿还能坚持收下影。他是很多元的，可能只是因为他的工作负荷太大了，导致他无法有一个特别好的情绪。飞哥姐有哪些工作两三年内会大幅规模的被替换掉？",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:11",
      "text": "我先补充一下，我说的服务员可能就是刚才收银的那个服务员，那个端盘子倒水的这个服务员，他还是有体力劳动在的，短时间内肯定不会被ChatGPT收银的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:23",
      "text": "基本上已经被取代了。你看像便利蜂基本上都是自动收银，然后很多大点的卖场也基本上也是。餐厅的收银会困难一点，因为他要对一个水单，有时候还怕有些串桌的情况出现。你比如说你在一家餐厅吃饭，然后你看到窗户之后来发现太阳太大了，你换了一桌。可服务员可能下单，有时候给你下串了之后，这个账金额你就发现不对，可这时候又要有人工来处理的。建飞觉得有哪些工作会大规模的被替代？就两三年，就说比较近一点，两年。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:54",
      "text": "两年的话其实能够被完全替代的我觉得还比较少。可能确实就是这种电话接线员这种比较容易被替代。但是如果放到我觉得可能放到五年的话，那很多办公室场景的工作可能都会被替代了。就因为刚刚不管是苏伦还是brick也都提到那种特别结构。或者是说我们用职场上的鸡汤术语叫专业化的职位。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:17",
      "text": "其实都是把人当成机器人来看的那写稿其实还没有那么明显。但是那你比如说你做这个报表分析，然后你去做财务相关的，包括甚至一些写代码的工作，那它都是有一个非常强的规范。在那个地方就是你需要怎么去拆解需求，然后这个输入是什么，然后怎么做去哪几个步骤的处理，最后输出是什么。其实都是非常成熟的一个职业化的这么一个模式。可能反而是相对写稿来说是更灵活一点。但是我们会看到一些其实更赚钱的文字厂牌，就是文字厂牌这个有点奇怪。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:53",
      "text": "同时指这个机构化的媒体和这些中文互联网上的一些营销号，其实他们的工作流程也都是非常清楚。记得就是一篇文章我从哪获取灵感，然后这个灵感需要检索哪些材料，然后这些材料如何组织，然后这些组织完了之后生成什么样的文字，然后这些文字最后根据平台的发稿要求需要处理成什么样子，这个其实都是有一个非常标准化的流程的。包括其实前两年我们也都听说过有一些自媒体平台上的营销号，都是一些农村的大爷大妈在写。就六七十岁了，然后天天写真钉体的稿子，这个都是完全可以实现的那如果是你是这样的一个工作的话，那我觉得写稿也是可以在五年内被替换掉的。可能会有一些细节是需要处理的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:33",
      "text": "内容农场的那携手是吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:42:36",
      "text": "对内容农场的写手可能会在更早，因为其实我在现在就已经看到有一些在用GPS生成内容农场内容的。重点是如果是用GP4的话，生成的内容比内容农场要好很多。在下一步的话，其实我是觉得对于很多没有一手信源，就是这种没有采访没有信源的自媒体作者来说，也有可能会被取代。因为我们去拆解一下自媒体的写稿流程的话，它虽然不是写稿，但他其实所有的资料都来自于公开信源的话。他的模式也是可以被标准流程化，然后被AI去整合的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:11",
      "text": "转不过大模型的。如果你没有亲身的经历或者第一手的采访，完全转播。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:16",
      "text": "如果说是细节上的问题，比如说刚刚谈到这个信源他不是那么可信的，这个的话是有很多方法可以解决的。比如说我们让他只去搜索特定的信源，甚至可以只让他搜索知网的信源。这样的话你就能够出一个在自媒体领域非常严肃的自媒体。就是你写一篇自媒体的稿子，引用了5篇论文，其实一般的自媒体还达不到这个水平。就是我我觉得这个也是很快。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:42",
      "text": "知网账户太贵了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:44",
      "text": "对，这个硬门槛其实不是AI这个硬门槛，是知网账户太贵了。对，这个我觉得也是很快就能够达到的，就是办公室的很多工作其实都能够被替代。在五年期来看的话，但是最后可能就比如说我们就以现在为例，就是这个2023年5月份这个时间点为例。我们看到2028年的五月份，是不是我刚刚提到的这些职业它都被替代了，有可能不是，但是他不是的原因可能是被一些外在的因素卡掉了。比如说大家所熟悉记得一个段子，就是说我们最后还是发现人更便宜。那有可能是这个样子，就是GPU的价格如果一直不降下来，那有可能就是到2028年的时候，我们还是发现雇一些实习生，雇一些还是农村的大爷大妈来写这样的稿子，可能更便宜。那可能他还是不会被取代。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:31",
      "text": "我很同意飞哥说的，就是确实有很多岗位会被取代。我还是那个观点，那些已经把自己异化成机器人的这个岗位，肯定是风险程度是最高的。但是我又另外一方面又非常乐观，就是我会觉得这个取代的这个过程来的不会那么快，而且它会以一种非常缓慢而且温和的形式来推进，就是也没有那么耸人听闻的那种感觉。我觉得人有很大的一个优势在于它的灵活性和适应性。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:06",
      "text": "我还记得多年之前，我参加过一个关于工厂数字化转型的讨论会。然后一个专家他讲到自己走访工厂的一个案例，就是这个工厂引进了大的机器，但是你工厂生产这个产品的制式始终是在变的。有可能生产A制式的，有可能生产B制式的。然后有很多都是你在购买机器之前没有想到的那种新的知识。但是这种新知识来了之后，这个工厂厂厂主还是会觉得，还是人好用。因为你这个机器买来，他那个知识是固定的，就不能变了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:39",
      "text": "但是你这些工人，虽然这个人人力成本是要高于机器成本的，但是他们的灵活性适应性很强。你只要上个两三天培训课，他们就完全适应这种新知识产品的生产了。所以反而是在有了机器之后，他们工厂厂主会觉得人越来越好用。我觉得这个也是一样的道理，就是这人工智能来了之后，他势必会清除一些岗位。但是这些怎么说呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:05",
      "text": "我觉得这个真实世界的运行是非常复杂的，它不是说非此即彼，非黑即白的。也不是说一项工作，它就是单纯的接受输入的指令，然后去输出一些东西。他还会跟真实世界的人和真实世界的环境有非常密切的互动。我们的工作也不是这么简单的，就是像咖啡机一样，你弄进咖啡豆去就能给你榨出这个汁来。我们还是有很多复杂的互动才能推进这个工作的。所以就这些工作我觉得只要你不要去自愿的被异化成机器，那还是有很多机会的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:41",
      "text": "而且本身我们从技术发展史来看，一些新的技术它被纳入到这个社会的机制之后，确实会有阵痛期。比如说蒸汽机它引入了然后那个工厂的工人路德分子打砸抢抢烧这个机器，然后很多工人他都是失去了工作，然后也失去了生机。但是我们会发现很快他很快又创造了更多新的岗位，包括ChatGPT。未来会不会有专门针对人工智能的提示岗？这个我们已经发现了是有的。然后有没有针对人工智能生成内容的审核稿，有没有其他的更多更新奇的这个类型工作等我们去干。我觉得这个都是可以期待的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:24",
      "text": "大公司的那个官方的新闻稿。对，先讲冲击，然后讲不会的，他会制造更多的就业出来。就像那个但是我事实上感觉到一种文化的变化。就是大概是上周的时候，我坐地铁，我发现有一个钉钉的一个广告，钉钉过去一直在其实是从企业主的角度来推销，它的产品有多么好用。但这个广告其实它又转换成员工的感受。他会讲有一个人一个对话框，那个广告是啊说跟问了问一个事，时间线是早上八点多，然后那个人说我到九点才上班的，现在不要问我，就是他开始鼓吹说你上班时间上班好了，不要过劳劳动，不要加班。你看他已经开始在鼓吹，或者说他们的广告文案已经捕捉到年轻人或者普遍的职场人不喜欢太卷了。他在提倡这一点，我其实我自己不太看得清楚，就是说他对未来的一个就业或者更大范围内的工作的冲击。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:16",
      "text": "但是我们目前从钉钉也好，非洲也好，发布的一个他们的未来的加入了大模型的这种demo版的时候，你发现还是觉得对我们提升效率还是帮助很大的。比如说有时候我用PPT的时候排版，我有时候懒得排版。我是做竖版的，文本写进去，然后放一张图片，然后用它那个smart art自动生成一个。我反正觉得这样也挺好的，对吧？我们为什么要把钱花在请设计师来设计PPT上呢？直接用这个PPT的免费功能不好吗？也更符合web 3的精神是吧？节省。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:45",
      "text": "我补充一点，我虽然是会觉得这个AI技术在未来五年可能会影响到很多人的工作。但其实如果我们从历史的角度上来看的话，技术革命的爆发到真正影响到社会结构的变化，以及这个社会运动产生是需要非常长的时间的。还是以工业革命为例，这个蒸汽机发明了之后，其实100年之后才迎来了路德运动，然后又过了100年才迎来了一战。如果我们以工业革命为起点去计算这一次技术革命对人类整体社会最终的影响的话，那就是200年。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:20",
      "text": "但剑飞电力普及之后，到二战之间只有十几年。",
      "speaker": "发言人3"
    },
    {
      "time": "00:49:23",
      "text": "但电力普及它其实不是二战的直接原因。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:26",
      "text": "然后你再看这个互联网普及之后，目前是世界上面临的这种大变局。当然也不一定有因果关系，但是我觉得它有可能会加速。他不一定是按照蒸汽机那个速度的受影响。",
      "speaker": "发言人3"
    },
    {
      "time": "00:49:38",
      "text": "但是从更长的尺度上来讲，我觉得这个焦虑是就是在个体层面上的这个焦虑其实是没有什么太大必要的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:45",
      "text": "你想这种世界这种全球性的动荡，不光是一战或者二战，其实很难程度上是由一种不平等或者说不可接受的不平等引发的。我个人感觉好像这种ChatGPT事实上在职场中已经引发了一些不平等。比如说用的很溜的和还没开始用的那建飞怎么看这个问题？",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:01",
      "text": "我是觉得短期内是会造成不平等的，但是长期内其实是会造成更平等的。它大的逻辑其实就是我们刚才已经谈到的，短期内谁先用，谁就会获得一些优势。但你说这个优势有没有让你能够升职加薪，我觉得也不好说。那长期来说的话，我会觉得我们刚刚谈到的那种AI能力对人类就是拥有少数AI能力的个体，或者是组织，或者是公司对整个人类的剥削这种情况应该是不会发生的。因为这个事情我也是做了一些研究，我我我现在的判断是这个大模型这个事情是没有公益性门槛的。什么是公益性门槛？就是光刻机的专利都是公开的，但是你做不出来。这个是公益性的门槛，就是你的技术工艺就是达不到做这个高制程芯片的光刻机的这个能力，这个就是公益性门槛。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:52",
      "text": "那没有公益性门槛是什么意思呢？就是说GPT2到GPT3的改进，其实是源自于对训练方式的改进。那训练方式是什么呢？训练方式就是一个你一旦想到尝试并且成功了，别人就可以任意复制的东西。就是这个技术只能被法律和专利保护，它不能被更客观规律的东西保护。那这样的话就这种东西的话，其实是没有办法严格的造成这种商业机密的保留的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:21",
      "text": "我们可以看到这有两个现象，其实是有三个现象。一个是OpenAI现在基本上是闭源了，就是在GPT3之后就不再讲任何他在训练上改进的这个论文了。原因有可能就是因为他一旦公开的话，竞争对手就可以快速的跟进。这个在google内部泄露的那个文档里面其实也有提到。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:39",
      "text": "然后还有一个就是open I的竞争对手那个anthropic。他出的cloud能够在这么短的时间内赶上GP4的水平的话，是因为他是从OpenAI的高管出去创业的，他对OpenAI在未来几年要做的事情完全清楚，所以就是这个黑匣子对于他来说其实是不存在的。另外就是国产大模型，虽然大家各种嘲笑，但是其实我体验下来，你说从零到有到现在这个水平，它的速度是非常快的。再有就是清华大学的那个ChatGLM的开源的那个模型。你也能够看到他在过去半年里追赶GPT的速度，其实远超GPT自己发展的速度。因为用了更tRicky的方法，他直接用GPT3来生成这个训练语料，就还省去了OpenAI自己雇人去标注语料的这个过程。这样就会导致两个门槛的大幅下降，一个是大模型的训练门槛的下降，唯一的训练门槛现在就变成了显卡。那显卡这个事情，你只要搭上摩尔定律的车，未来的成本是肯定会下降的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:35",
      "text": "另外一个第二点就是大模型服务提供的门槛也在下降。甚至我觉得未来可能开源的自部署的这个大模型会成为相当一部分市场里面的服务提供者。就比如说苏伦非常介意自己的隐私，非常介意自己的这个AI有没有被OpenAI、被百度，被阿里这样的大公司控制。那你就你就自己买一个好一点的显卡的服务器，然后自己跑模型。这个模型上面所有的处理和所有的数据，所有的参数调节都是你自己来操作的。这个我觉得是没有问题的。你像GLM现在只需要四张3090的显卡就能跑起来。虽然还是挺贵的，但是这个价格已经是在10万人民币以内了。我觉得这个就是一个非常低的门槛了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:15",
      "text": "这样的话其实是第一步，就是说这个AI本身它其实这个技术的可获取性是没有问题的，他不会被少数人垄断，我觉得他没有一个不平等的问题。那那接下来就是说会不会是很多大公司的说裁员，包括很多老板鼓吹焦虑，说你再不好好干，经济就要取代你了。但这个话是可以反过来说的，就是在在企业管理里面有非常重要的一条，就是人是企业的最宝贵的财富。这个话它不是鸡汤，因为它实际上就是你有什么样的人，你就能够做什么样的业务。如果你用这个逻辑去反推，如果一个企业能够砍掉一半，甚至砍掉百分之八十九十的人，改用ChatGPT和mid journey这样的工具，就意味着这个企业的业务没有任何护城河。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:58",
      "text": "对，因为我们知道企业，尤其是这大型企业的本质是一套人类协同系统，它解决的就是一个人或者是少数人无法独立完成一个宏伟目标的这么一个问题。各家大企业拼的其实就是这个人类协同系统是否能够更高效、更有效、更低成本、更高产出的完成那个单元无法完成的任务。但如果你现在说你要完成的这个任务是压根就不需要这么多人。那最后解体的会是企业本身，而不是员工。就你开掉的每一个员工都会成为使用AI来和你竞争的对手，最后会变成这样一个事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:30",
      "text": "这个事情我觉得其实在这个互联网来临之后，咨询行业已经发生类似的事情。互联网来临之后，巨头咨询公司其实业务比以前难接了。好多AI会更进一步帮助这个事情，就会让很多超级个体户去实现过去一整个公司才能够实现的工作。但你要说这个是平等还是不平等，我觉得这个是机会平，但结果可能是更不平等。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:49",
      "text": "以前世界首富，不管是贝罗斯还是马斯克，他要做这么一个事情，他还需要赚一个10万人。20万人的公司，至少有10万人和20万人跟他一起共富了，对吧？虽然和他的这个和和CEO的拿的薪水不一样，但是你未来可能会有一个天才。我就是非有非常有独特的优势，然后我根本就不需要雇员工，我就用AI就行，我自己一个人就可以成为这个世界首富。这个从机会上来说，我觉得是平等的，结果来说可能是更不平等。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:16",
      "text": "我倒是蛮赞同建飞说的这个观点，就是拿这个GP来吓唬员工，那说明可能你雇佣的人大部分是工具人，对吧？如果你不是一个工具，你真的是有特别强烈的独立思考能力，有很强的探索欲和创新能力，这种机器应该是比较难去取代的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:55:31",
      "text": "关于这个平等不平等的问题，我其实跟飞哥观点是完全相反的我是觉得他在短期内不会造成不平等，但是在长期内有可能造成平等。我还是那个观点，就是会觉得现在的ChatGPT噱头之外，但是他没有真正落实到这个生产力的提升方面。就是从各方的反馈，其实也能大体上有这样一种整体印象。",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:57",
      "text": "就是那段关于ChatGPT的讨论又超过去了。现在他进入了跟各行各业真正的落地和接洽的这样一个阶段。然后在这个阶段其实就涌现出很多不同的这个问题来了。包括之前说这个AI能取代原画师，但是现在的很多声音就是这个AI绘画的它的精度不高，而且它是整体都是直接拧成一整幅画，所以他就不可以分层的去修改。然后你每次修改，其实我们人就是你觉得这个部分不满意，你可以直接改这个部分。但是你这个AI绘画大家也都知道，你要不断的去调整那个提示词，而且也甚至还有时候就是你怎么调也不可能改成你想要的。我觉得这些问题就是显示了一种趋势。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:47",
      "text": "至少在现阶段，ChatGPT的能力其实还不足以让他实现这个生产力上的重大的提升。我觉得也就不太可能出现那种情况，就是呃有很多人借助这个A的能力，获得了这个工作效率的极大提升，然后拉开身边人一大截，这个也是不太可能的。另外一方面原因就是因为这个网络是平的，现在大家都在讨论ChatGPT，而且它的使用门槛很高，但是好像也没有那么高。你只要去想一些办法，然后就可以大家都可以用到。然后包括国内的一些大模型，他现在使用也很便捷。",
      "speaker": "发言人2"
    },
    {
      "time": "00:57:25",
      "text": "我的每个人其实都是机会都是平等的。我也不会觉得一定会有很多人他占领太多的先机。但是在长期来看，我是一个技术的长期信奉者，长期有多长？所以长期可能是在十年、20年，会不会有真的有那种在AI在技术上的重大突破。甚至我们可以畅想一下，就是AI出现了意识，或者说它使用门槛会达到一个非常巨大的这样一个层级。就飞哥刚刚才举的光刻机的这个例子，就可能你只有特别有钱才能使用这项技术。但是一旦使用，你的某项能力就会得到非常巨大的提升。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:07",
      "text": "然后这里就要提到霍金说的那超人理论，他就会觉得未来这个有钱人可以通过基因编辑这些非常牛逼的技术来改造自己的基因，让自己变得身体也倍儿棒，然后智商也超级高，然后出现一个超人的阶层。那未来真正有这种我们可以称之为革命性技术的技术形态出现的话，那时候才可能出现这种技术不平等的这种现象。但是就现在而言，我觉得还差得远。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:36",
      "text": "就最开始我们聊到的风险，当时说苏苏伦说岔开一下聊到风险。但实际上我自己能看到的这个ChatGPT的一些风险，就是可能一个是个人隐私的？那些pro的设计如果带入大量的个人或者公司的机密在敏感内容在里面。第二块就是说它会不会生成的内容档案中包括一些不当的内容，特别是对儿童、青少年还有一些法律法规明令禁止的一些内容的出现。建飞怎么看这个问题？",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:05",
      "text": "就是他的所谓的风险。我觉得ChatGPT现在他因为实际的投入产出的这个还规模不算大我觉得他现在目前的风险也没有那么大，就包括你把这个数据喂给他，然后所有的数据都能被OpenAI掌控这个事情，那所有的互联网公司都是这个样子。就是理论上来讲，就是如果没有监管，如果没有严格的执行一些数据安全的策略的话。",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:29",
      "text": "那其实我们发的每一个帖子，发的每一条消息，存在办公文档里面的每一个文档。那谁提供这个服务，谁都可以看到。这个其实是互联网行业从最开始就有这个问题。我觉得这个反而倒不是特别大的风险的。那个误导性的内容确实是会是一个比较大的风险。因为我们刚刚也谈到，就是说你生产严肃内容的时候，不管是媒体也好，还是电视节目也好，还是说你要做一份报告也好，你最后肯定是会去有这个核查机制的。但是不用AI的情况下，也会去核查这些信源的可信度的。但是对于大多数，他只是需要一个即时性的答案的人来说，他不会做信源核查。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:10",
      "text": "这个在一些关键的时间点上和在一些比较关键的事情上，可能是会造成一些比较重大影响的。比如说其实在搜索引擎你之前也出现过这些事情。比如说把一些特定的人标记为已经死亡，或者是他说了一个什么样的话。但其实他没有说这个都是会引发的。因为在现在这个比较快节奏的时代，一个错误的技术答案在短时间内也有可能会引爆出一个比较大的后果。这个是我觉得可能会存在风险。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:39",
      "text": "苏伦你有什么补充的吗？你开头的时候其实也提到了那个风险，主要是讲的是有中国特色的，有一些内容审核的风险。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:45",
      "text": "我就提醒大家时刻不要忘记脱口秀的这个例子，就知道ChatGPT究竟在面临什么样的风险。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:50",
      "text": "其实建飞刚才聊到了这个风险的问题，你这些安全风险，那这个安全风险跟它的一些存在的技术缺陷是不是也是有关联的呢？",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:59",
      "text": "是有关联的。刚刚谈到很多拆GPT的局限性，包括苏伦谈到的，都不是来自于AI本身，而是来自于AI和我们交互的界面，以及它和其他的产品之间交互的一个界面。这些问题是很好解决的，因为这些都是一些成熟的技术问题。什么API、接口、互操作协议，这些都是老掉牙的技术，只不过现在大家都还没有到那一步。",
      "speaker": "发言人1"
    },
    {
      "time": "01:01:23",
      "text": "但AI本身的局限性我觉得也还是有的，而且也还是挺大的。就是它的局限就确实体现在不能实时学习的上面。我们刚才也比方过，就是把这个ChatGPT当成一个人他训练的这个过程。就是当我们说我训练出一个GPT3，或者是训练出一个GPT3.5，训练出一个G第四，这个训练的过程就是大家网传需要几百张几千张显卡的过程。它类似于我们上学是一个完整的系统的一个学习的过程。然后在他学完了之后，AI和人的区别是AI就不能再从实际的生产中学到任何改变他知识结构做的事情了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:02:01",
      "text": "但人是可以的。在具体的工作中，就比如说你让我去接触一个我从来不知道的工作，我会先怎么做？我先去搜索引擎上查一下，然后看一下前几页的内容，然后我就可以给你一个答案了。这个看起来就和ChatGPT1样，但是第二次你再问我这个问题，我就不会这么做了。因为我看过，我知道我学习过了，我实操过了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:02:23",
      "text": "我第二次的时候，我不需要再去搜索引擎去找一下，然后找到一个操作指引，然后再重复一遍这个in text learning，就是上下文学习的这个过程，再去做一遍推理了。我就可以直接应用我上一次已经学习到的知识去去操作。但是在AI就不行，因为他现在的AI是通过这个上下文学习的这个功能，或者我们管它叫机制，就去实现一些他这个知识结构里面，就是训练的里面没有的东西，看到的牛逼影的现在这个效果。但是上下文学习的本质不是记忆，而是一种推理的暂存。其实是在推理的过程中给它加入大量的外部的参考资料。然后让他用新输入进去的这个参考资料去做一些更进一步的推理，是这样的一个过程。他你输入进去的资料并不会进入到模型本身。所以当你下一次再打开一个新的绘画的时候，他所有的知识又都丢掉了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:03:16",
      "text": "范特宁在一定程度上是可以解决，就是微调一定程度上可以解决这个问题。但是我我我现在看到的效果也不是很好，所以这个缺陷就会导致未来制约这个大语言模型在使用的过程中可能会有的一个障碍。就是它没有办法很好的去做连贯性较强，或者是不断的摄入新知识，但是又会有前后连贯性的这样的一个工作。我之前想了一个例子，就比如说你做一个系列活动策划，就是你这个活动可能是一年12个月，每个月办一期。你一般做其实是怎么着呢？就是人做的话，一般是你做一个整个系列活动的策划，然后之后第一期、第二期、第三期你可能先做好，然后等到前三期做完了之后，你根据这个活动现场的执行效果，然后一些反馈，包括嘉宾的讲的好不好，以及当下的热点，然后你再开始去策划。",
      "speaker": "发言人1"
    },
    {
      "time": "01:04:03",
      "text": "第二季度就是456期的这三期，那ChatGPT它大元模型它只能怎么做呢？就只能是你要不然就是你把整个系列活动的背景告诉他，然后他一次给你生成12期。要不然就是你把系列活动的背景告诉他，只能生成第一期。然后你生成完第一期之后，当你第二期想要再用它生成的时候，你需要把之前所有关于生成他第一期的这个内容再作为参考资料喂给他。包括第一期可能你执行完了之后的一些反馈的效果，你都要做以文字的形式输入给他。这样的时候他才能够生成一个第二期，并且这个第二期是参考了第一期的执行效果，然后有所改进的这样的一个结果。",
      "speaker": "发言人1"
    },
    {
      "time": "01:04:42",
      "text": "然后你要是这样一期一期的让它生成下去，你等到第12期的时候，那个prompt可能已经上万字了。你可能自己都已经写不清楚这个prompt。因为prompt也不是记忆，它是一个提示。就是你你怎么可能有一个万字的提示呢？这十二期执行过程中，你所留存下来的经验性的这种记忆，你在脑中其实也不是以文字的形式呈现的，所以你也很难把它转换成一个文字喂给GPT，那GPT也就很难理解。",
      "speaker": "发言人1"
    },
    {
      "time": "01:05:07",
      "text": "你这个前十一期都犯了什么样的错误？然后以及做第十二期策划的时候，你需要做什么样的改进，这个他是做不到的。这个和我之前提到的很多缺陷都不一样。我觉得这个是大语言模型现阶段可能以及在未来很长一段时间里面都没有办法解决的一个问题。",
      "speaker": "发言人1"
    },
    {
      "time": "01:05:21",
      "text": "其实你看我们现在这个互联网行业，觉得聊这个天儿的就是非常的热血沸腾。但是其实是不是在行业之外，对于更多的人来讲，这个事也不是什么大事儿。不知道苏伦怎么看，就是说这个技术对更多的科技行业之外的人来讲，他的影响有多大。",
      "speaker": "发言人3"
    },
    {
      "time": "01:05:37",
      "text": "从我自己的一些观察来看，确实互联网行业是最热衷于这个事情的。因为互联网行业好像一直以来从外部3，从元宇宙这些技术形态以来，就形成了一种追热点蹭热点的这种习惯。但是行外人就是在这个行业之外的人，他可能也有听说，因为电视上都在报道，然后他们也在刷各种APP，也有听说，但是可能也会感到很好奇，但是实际上他们并没有觉得这是一个特别大的事情。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:09",
      "text": "这个也是我觉得ChatGPT现在没有到iphone时刻的原因，就是大家可能都听说过了，但是大家并不一定实际用，因为你对于普通人来说，它确实也不是那么好用嘛，就是拆机机，一个聊天机器人能有什么用？你平时跟人都不聊天，你跟一个机器人聊天。那实际的那些能够投入生产的一些应用场景，其实现在还没有做太具体的结合被做出来。我是觉得这样。",
      "speaker": "发言人1"
    },
    {
      "time": "01:06:31",
      "text": "飞哥也一直在说这个iphone时刻，这个网上确实也有很多这种讨论。但是我觉得这个iphone时刻真的很重要，它确实是一个非常有代表性的时间节点。就是iphone 3GS发布，然后大家一看，智能手机出现了，然后确实有很多革新。但是很快，包括我们现在并不觉得iphone是一个很有创造力的这样的一个产品。我们也不会觉得现在iphone 13、iphone 14每次发布还会给我们太多惊艳的感受。所以我之前跟人聊天的时候有一个暴论，就是那个朋友问我ChatGPT这轮热潮什么时候能过去？然后我就给他一个明确的时间节点，就是2023年的11月。",
      "speaker": "发言人2"
    },
    {
      "time": "01:07:11",
      "text": "为什么是这个时间点呢？就是因为这个时间点是对据传是这个GPT5发布的事件。然后GPT5发布了，大家体验之后，大概率是会发现它没有带来任何技术上的飞跃，可能只是比四提升了一点。包括什么训练的数据量，包括你在文本互动的表现，但是除此之外也就不太可能有其他的进步了。大家就会觉得这个事儿好像也没有什么，就像我们在经历了这个iphone 4 56之后，然后再看8，包括iphone叉，包括这个十一之后，我们发现iphone也没有什么创新了，然后就逐渐对这个事失去了兴趣，然后也不会觉得它是一个非常新奇的事。所以我觉得这个讨论热潮也就会停止在这样的一个时刻。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:03",
      "text": "如果你是说大众对这个退烧的时间点的话，我觉得有可能来的更早就是此刻。因为我们录这一期节目的时候，是刚刚这个GPT with browser和GPT plug in刚刚上线，开放给所有的plus用户。这我觉得是翻车了。就是很多人体验了之后都觉得他不太行，甚至是这个GPT with browser的体验甚至不如new being。但是这个恰恰说明了我们此刻现在是没有迎来一个iphone时刻，而是在一个诺基亚时刻，就仿佛是诺基亚发布了一个所有功能都有，然后他宣称自己是塞班智能系统的这样的一个手机。然后还卖的很便宜，可能1000块钱就搞定了，然后所有人都可以买到它。但是大家对它的兴趣其实又没有那么高的这样的一个状态。你看为什么除了现在很多影响大家观感的，或者是对技术判断的是一个外在的产品形态，而不是技术本身？",
      "speaker": "发言人1"
    },
    {
      "time": "01:08:55",
      "text": "就是你说OpenAI做GPT with browsing这个事情为什么能翻车呢？就是他自己拿到的GPT的智能水平应该高于微软的水平才对它是一个全量的没有经过阉割的GPT4，然后效果还不如牛逼硬。原因是什么？原因是因为他们对搜索技术不了解。微软非常清晰的知道，当把这个搜索引擎里面的页面搜索出来之后，应该把什么位给GPT，什么不会给GPT。这个是在搜索引擎领域非常成熟的page rank的技术。",
      "speaker": "发言人1"
    },
    {
      "time": "01:09:25",
      "text": "但是open I是没有这个技术的，它最终的产品就是交付给用户的产品形态，会导致GPT response的结果是不如牛逼的。就是会有很多这样的杂项因素干扰普通用户对这个技术判断的能力。但是我觉得会让我们进入一个短暂的平台期。这个平台期就是大家会觉得谁都可获得，但是我也并不特别需要它这么一个状态。就是真正的iphone时刻应该是所有人都想用它，并且能够用它，并且是真正有用的那个时刻。我觉得应该还有个三五年。",
      "speaker": "发言人1"
    },
    {
      "time": "01:09:58",
      "text": "其实严格来说不是iphone时刻，是iphone 3GS时刻。",
      "speaker": "发言人2"
    },
    {
      "time": "01:10:01",
      "text": "大家都发现用一个相对比较低的成本，然后能够获得一个甚至是有点万能的AI可能还要三五年。",
      "speaker": "发言人1"
    },
    {
      "time": "01:10:10",
      "text": "但我对这个也是保持悲观的，我不觉得这个东西三五年就可以到来。或者说我并不会觉得围绕ChatGPT的这轮大模型或者生成式人工智能，或真正的有这么一个iphone时刻。虽然我们这场谈话也谈到了很多蒸汽机、电力，包括iphone这些词。但是我并不觉得这个ChatGPT这轮技术形态，它是一种技术革命。它更多的我觉得是在应用端的一场小小的火花。但是它并不是像这个蒸汽机，像汽车这种媒介技术，它带来的那么多的社会变革，以及带来那么多新的可能性。所以我整体的这个感觉还是比较的悲观，或者说没有太高期待的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:10:57",
      "text": "对，这个也是我们观点差异的原因，我反而是觉得这个东西现在是处在技术革命的早期应用层面，反而还没打动。因为我甚至觉得ChatGPT这个交互形态都不是一个最佳的选择。它似乎是专门用来给大家感受到那个world的那种感觉的。就是你做一个这么强大的AI，然后你们以一个聊天机器人的形式呈现，这个本身其实就是不太合理。",
      "speaker": "发言人1"
    },
    {
      "time": "01:11:25",
      "text": "的那你会觉得就是你心目中的这个iphone 12是什么？或者在具体来说，就是你会觉得围绕这个对话机器人，围绕生成式人工智能，你觉得可以被称为iphone时刻的那个节点的话，他是取得了怎么样的一些成绩？",
      "speaker": "发言人2"
    },
    {
      "time": "01:11:42",
      "text": "我觉得他会是把现有的三个还比较早期的这个形态，就是大模型的交付形态可能混合在一起的一个模式。首先chat这个模式是不能丢的，你还是要和用户交流的。然后另外就是这个agent GPT，就是agent GPT不知道你有没有尝试过，它是一个循环向GPT发问的一个功能。就是说当你接到一个任务的时候，你需要自己先对这个任务进行拆解，拆解出直到能够完成所有的这个任务为止的任务流。然后每一个子任务需要有输入和输出。然后拆解完了之后，他会把每一个单独的任务，就是说你现在要做什么，然后这个任务需要什么，以及输出什么，再一次抛给GPT。然后这个时候他输出的结果会进入到下一个任务，就是每一个它拆解出来的子任务之间首尾相连。",
      "speaker": "发言人1"
    },
    {
      "time": "01:12:33",
      "text": "然后这个agent的GPT现在能够做到的就是能够写简单的可执行的代码。就是网页代码也好还是什么的，就是复杂的其实也有一些太太他也能写，但是你没有办法直接部署，就是你服务器环境还是要自己部署的，他其实是可以做到这个的那agent的GPT进来，然后还有就是with browsing也要进来。他也需要能够充分的利用搜索引擎，以及搜索引擎上这些所连接的网站上的知识。这三步放在一起之后，就是我需要的最后的结果就是我用非常自然语言的方式。",
      "speaker": "发言人1"
    },
    {
      "time": "01:13:08",
      "text": "就是我甚至不需要告诉他像很多现在prompt engineering airing的这个教程里面说的说你需要告诉GPT是一个什么样的角色，然后这个角色一般采用什么样的工作，然后你需要用什么样的方式去处理这些我都不需要告诉。这些不是网上都有，就我交给你一个任务的时候，你自己先去browsing一下，你先去看一下这个任务应该是属于哪一份职业工作的那这个职业工作需要用什么样的方式来处理这份工作。然后他这个过程中会有几个步骤，然后你自己去拆每一个步骤的工作流程，然后执行完第一段就执行第二段，执行完第二段，执行完第三段。直到最后我自然语言抛给他的那个需求的成果被呈现出来，然后反馈给我。我理想中的大元模型至少能够达到这个程度。",
      "speaker": "发言人1"
    },
    {
      "time": "01:13:51",
      "text": "听起来就是它可以拆解并且解决复杂问题的质量和能力和效率这样的一种畅想。我其实对这个问题可能看的更长期一点，就是我们可能对长期短期的这个定义也不不太一样。我觉得AI的这个iphone时刻，真正它就有一个变革性的这种影响的时刻，我觉得是AI产生自我意识的这种时候。所以苏联。",
      "speaker": "发言人2"
    },
    {
      "time": "01:14:18",
      "text": "你说这个意识是什么？",
      "speaker": "发言人3"
    },
    {
      "time": "01:14:21",
      "text": "自我意识简单来说就是这个问题可能就复杂一点了。我那我就好好说一下，就是大家都知道我们的人的这种主观的能动性可以拆解为两方面，一方面是智能，另一方面是意识。这个智能你可以把它理解为解决复杂任务的能力。现在这个是人的一项基本能力，然后其实也是现在机器人它具有的一个一种能力，我们叫它人工智能。它确实有这个。解决复杂任务的这项能力。但是意识意识其实就更复杂一点。但是它整体上是跟感受、跟情绪这些主关方面的维度有关系的一种概念。",
      "speaker": "发言人2"
    },
    {
      "time": "01:15:04",
      "text": "我觉得意识是非常重要的，因为他也牵扯到一点自己的主观判断，逻辑思维的这个能力。我们说现在为什么AI出现这么多的问题？比如说我刚才说的这个，他可能有文不对题的情况，有胡编乱造但是他自己并不能意识到的情况。然后这样就会引发更多我们不可预料的风险。",
      "speaker": "发言人2"
    },
    {
      "time": "01:15:24",
      "text": "但是一旦他有了意识这个事，他真正理解你给他提的问题是什么，以及你的需求是什么。他也知道他在回答什么，以及他为什么要这样回答。然后有了这个过程，特别是他有了意识之后，他就知道这些回答中有哪些是我可以说的，有哪些是我不能说的，有哪些是我不能说错的，以及很多常识性的东西现在AI是不具备的。但是有了情绪之后，有了这个自主意识之后，他就可以通过跟这个世界的真实的接触，去形成这些常识性的一些判断。就导致很多现在我们看起来虽然是很低劣，但确实是非常难以解决的问题，就会不就不会再出现了。这个是意识非常重要的一点。",
      "speaker": "发言人2"
    },
    {
      "time": "01:16:05",
      "text": "而且你有了意识之后，还能带来了一个非常巨大的影响是什么？我们人类社会其实是一个一元论的社会。虽然我们说这个万物有灵，但是我之前也在文章里说了，万物有灵只是一种谦词。就因为只有人是唯一有灵的那个主体，然后他才会非常。",
      "speaker": "发言人2"
    },
    {
      "time": "01:16:23",
      "text": "你说这个零是也是意识吗？那猴子也有可能，海豚也有猴子。",
      "speaker": "发言人3"
    },
    {
      "time": "01:16:28",
      "text": "我觉得那个并不能理解为一种意识。这个意识是主体跟这个世界进行复杂互动之后涌现出来的。包括你整个社会环境，包括跟人个体的一个互动环境涌现出来的一项特质。现在可以说只有人有这种意识。所以我们建基于这个一元论之上的所有的包括政治体制、包括经济体制、包括社会文化，包括各种各样的一些只有人类社会才有的维度，都是建立在这个一元论这个维度上的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:16:59",
      "text": "一旦出现了有另外一个主体，比如说人工智能，比如说AI它产生了意识之后，这一元的社会就完全被颠覆了，就是一个二元论社会了。那会出现各种各样我们现在可能还无法想象到的问题。比如说现在自动驾驶，我们一台汽车它有自动驾驶能力，然后我们可以驱使他去干各种各样的事情，到各种各样的目的地。但是一旦人工智能有了这个意识之后，他是我们的一个仆人，还是一个奴隶，还是一个工具人？他会不会有自己的反抗的情绪，反抗思维？这些问题其实是很有意思的，然后可能也是未来需要讨论的一个重点。",
      "speaker": "发言人2"
    },
    {
      "time": "01:17:39",
      "text": "对，你看那个流浪地球2，最后那个系统不就是产生了自我意识吗？然后这个系统开始支持那个叫意识上载的那条技术路线，是吧？而不是把人的肉身都移民到其他的星球上去。",
      "speaker": "发言人3"
    },
    {
      "time": "01:17:51",
      "text": "躺在这儿其实有点也不能说是玄学。我觉得他他有很多不同的学科，对这个意识可能会有特别多不一样的解释。你比如说他心理学就会把意识这个事情就归为这个脑细胞运动的结果，就是这样的，它它剥离了很多哲学层面的思索，就人所产生意识，你有各种各样的想法，并不是因为主要还是来源源自脑细胞，你的神经运动，他就是产生神经心理学就是这样认为的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:18:14",
      "text": "还有我觉得苏伦他有隐藏的一个逻辑的基点是在于现在这个系统不够好，是因为它还不像人站在这个立场上。我的相我的立场是相反的我觉得之所以我们是需要机器，是因为我们需要不一样跟人类不一样的智能。这个智能也许不一定需要意识，或者他有其他的什么的东西。这种sol或者他不一定是意识，就是他有他的智能。我自己希望他不要跟我们人类是一样的，也比较有意识，甚至不需要是人形。但是他能帮到我们我们能从中得到慰藉，或者能得到各种各样想要的服务，我觉得其实就很好了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:18:47",
      "text": "我特别同意你的观点，就是我刚才的这个观点其实也暗含了一种很强的这人类中心主义的这种色彩。就因为现在只有人，我们觉得它是一个有意识的主体，所以我们会不自觉的就是从人的这个基点出发去考虑这个人人工智能是不是应该有意识。换个角度讲，就是人工智能其实它能解决这么复杂的问题，然后甚至它能跟人互动。从某种程度上来说，它确实具备不同的智能类型，甚至说它确实具备不同的意识类型。我觉得如果以一种开放的智能观去看的话，确实可以说现在人工智能已经有了智能，或者说有了自己的意识。这一点我是非常同意的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:19:29",
      "text": "好了，我们聊了这么多哈，从这种产品，从技术路线到未来它的一些应用，我觉得很有意思。我们三个人的观点其实不那么一致。我也许跟建飞的观点也要靠近一点点，但也没有那么近。但是显然跟苏联的观点可能很多方面是背道而驰的。所以我想请再请两位建飞和苏伦各自用几句话概括一下你们对大模型技术的一些观点。",
      "speaker": "发言人3"
    },
    {
      "time": "01:19:52",
      "text": "我虽然对这个大元模型技术其实是有很强的期待的，但是我觉得这个事情也不需要对于普通人来说有什么焦虑，或者说我一定要现在就用到，或者是我投身其中。如果AI这个事情真的最后变得像iphone 1样，就是它诞生了一个智能手机这样的赛道，并且让所有人都用到的话，那他其实就是你现在着急也没有用。技术的发展是有自己的客观规律的，就是你想在90年代用上iphone也是不可能的事情。你想在诺基亚时代用上iphone，那也不是诺基亚不想做，实在做不出来好吧。但如果要是iphone时刻它没有来临，或者是说这个技术最后就是只能在小规模的领域去运用的话，那我们现在可能就是在经历一个非常愉悦的一段幻觉。我觉得享受这段幻觉其实也是一个挺不错的过程。毕竟这个互联网技术也已经停滞了这么久，没有发展了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:20:43",
      "text": "它这个AI至少和这个元宇宙和web 3比起来，它对于普通人来说有更强的可玩性，对吧？前两者的话，一个是这个外部三花钱，然后这个元元宇宙你买的设备也很贵，而且那个玩起来可玩性也不是很高。至少AI这个事情是便宜并且好玩的。我觉得普通人你就当做一个旁观者，我觉得完全没有什么问题。这个是我觉得现在我对AI的一个态度。包括我现在自己其实用它，我也不期待说我现在看到的这些产品，以及我现在自己用API做的这些小应用，就能够取代我自己的工作，或者是完整的完善我工作的一个什么。我就是觉得它很好玩，至少这个事情我以前是做不到的，我现在可以做到，那我就试一下，其实是处在这样的一个发烧的状态。",
      "speaker": "发言人1"
    },
    {
      "time": "01:21:29",
      "text": "对，确实我有一种感觉，跟腱背类似。我我我也是觉得在这之前的两三年，互联网技术陷入了一某种停滞。所以建飞才会焦虑这个互联网是不是人类走过的一段弯路。所以感谢大模型的出现，让建飞对整个互联网要变得开始乐观起来一点。所以苏文你可以总结一下你的观点。",
      "speaker": "发言人3"
    },
    {
      "time": "01:21:47",
      "text": "我的观点其实就是技术它并不是无所不能的，我们要警惕一种技术决定论的倾向。因为这个世界它有自己复杂的运行逻辑，政治的因素、经济的因素，然后个体的因素，甚至还有很多偶然的、隐秘的那种完全取决于运气的这样的一些因素。所以其实不可能一项技术它单独的就可以施加什么革命性的影响。而是它是要跟这个世界进行互动的，然后受到很多牵制，甚至受到很多推动，然后才能被检验到底是不是一项革命性的技术以及真正的发挥结果。",
      "speaker": "发言人2"
    },
    {
      "time": "01:22:24",
      "text": "我觉得现在这个GPT这个讨论热潮当然是一件好事。但是我们也要时刻想到，虽然它跟元宇宙和外部三都很不一样，但是我们好像这种非常火热的心态跟这个元宇宙跟外部三已经差不了太多了。但是那两项技术现在好像也很少有人讨论了。所以我觉得就是要保持一种比较冷静的一种心态。你可以去了解，可以去体验，可以去把它介入到自己的这个生产工作流里。但是你可能要更冷眼旁观这个事，不要让大脑发烧，以至于你会觉得这个是一个下一代iphone了。然后我现在就要全情甚至是全身心的去投入，甚至有很多朋友辞了自己的工作，然后去搞这个事情，我觉得这样就不是特别理智的。其次就是我觉得哪怕是真的这个ChatGPT进化到你可以真正的提升自己的工作效率的这种时刻，你也不要去依赖它。然后我觉得有句话说的特别对，AI只会取代那些完全依赖AI的人，把这句话送给大家，谢谢。",
      "speaker": "发言人2"
    },
    {
      "time": "01:23:33",
      "text": "大家好的，感谢大家收听本期节目。您还可以在小宇宙QQ音乐、苹果podcast的倾听FM喜马拉雅荔枝FM等平台搜索别听音乐二维无码。也欢迎通过留言评论等方式留下您的宝贵意见，我们下期再会。",
      "speaker": "发言人3"
    }
  ],
  "lab_info": {
    "summary": "本次讨论集中于人工智能（AI）技术的发展及其对未来的影响。对话首先从ChatGPT热潮讨论起，提出尽管它引发了对AI技术进步的关注，但其对社会的实际贡献可能有限，暗示当前AI领域可能处于一个平台期。讨论者们还质疑了OpenAI的GPT技术是否代表了真正的革命性进步，指出其在理解人类需求和情境方面存在局限性。随着讨论深入，强调了AI意识的重要性，认为这可能彻底改变社会结构，引发新的社会问题和挑战。尽管对未来充满期待，讨论者们也表达了对AI技术可能带来的社会和伦理问题的担忧。讨论涵盖了AI技术对就业市场的影响、创新与适应性、伦理和隐私问题，以及AI是否可能发展出真正的意识等主题。整体而言，对话反映了对AI技术发展及其社会影响的复杂看法，强调了保持冷静态度和避免过度依赖AI的重要性。",
    "qa_pairs": [
      {
        "question": "ChatGPT是否可能把人工智能的发展引向一个歧途？",
        "answer": "是的，ChatGPT可能会把大模型的发展，甚至是AI人工智能的发展引向对话式、互动式的路径，这可能是一种偶然状态。",
        "time": "00:00:48"
      },
      {
        "question": "AI技术的进步对企业和员工关系有何影响？",
        "answer": "如果企业完成的任务原本就不需要如此多的人力，那么最终解体的可能是企业本身，而非员工。开掉的每个员工都可能成为使用AI与你竞争的对手。",
        "time": "00:01:20"
      },
      {
        "question": "对于ChatGPT这轮技术形态，您们认为它是否代表了一场类似蒸汽机或汽车那样的技术革命？",
        "answer": "不完全如此，ChatGPT这一轮技术形态更多是在应用端带来了一场小小的火花，但并没有像蒸汽机、汽车那样带来那么多社会变革和新可能性。",
        "time": "00:01:35"
      },
      {
        "question": "苏伦，你是如何从对ChatGPT的狂热转变为现在的态度？",
        "answer": "我在工作过程中较早接触到ChatGPT，并在热潮来临时进行了深入体验。但随着使用频率增加，我发现其生成的内容质量参差不齐，缺乏深度和吸引力，且存在胡编乱造的问题，因此逐渐退烧并减少对其的依赖。",
        "time": "00:05:02"
      },
      {
        "question": "在工作中，您会如何使用ChatGPT？",
        "answer": "我通常会在需要完成任务时先尝试使用ChatGPT，如生成论文提纲等，虽然它可以提供一个70分的思维框架，但我自己会根据这个框架进行修改和完善，目前大约70%的内容由我自己完成，因为ChatGPT生成的内容存在雷同性较高、缺乏深度和吸引力的问题。",
        "time": "00:05:48"
      },
      {
        "question": "苏伦，你现在在工作中使用大模型的频率是多少？",
        "answer": "现在我每周大概会使用两三次大模型，是为了特定任务或目的而使用，之前则几乎每天都在使用。",
        "time": "00:09:18"
      },
      {
        "question": "剑飞，你接触大模型以来的变化是越来越热还是始终保持兴趣？",
        "answer": "我对于大模型的热情始终保持较高水平，尽管也看到了一些局限性，但这些局限性反而激发了我对大模型技术和未来发展的期待。",
        "time": "00:09:40"
      },
      {
        "question": "大语言模型技术目前是否处于集中化阶段，未来会发生什么变化？",
        "answer": "是的，目前大语言模型技术确实主要由少数公司掌握并提供服务，但这不是常态。未来市场将会有所扩张，类似于智能手机领域的从iPhone到安卓的发展过程，会出现更多元化的、由不同公司提供的大语言模型服务。",
        "time": "00:12:43"
      },
      {
        "question": "目前关于ChatGPT等大语言模型存在哪些常见的误解？",
        "answer": "常见的误解包括认为大语言模型会无节制地胡说八道，实际上，如果将其比喻为一个人，它的知识库基于某个时间点之前的数据，并且无法在实际运行环境中进行模型调整以获取新知识。不过，通过联网及prompt的方式，可以减少胡说八道的情况。",
        "time": "00:14:08"
      },
      {
        "question": "对于ChatGPT“胡说八道”的问题，应该如何理解？",
        "answer": "“胡说八道”本质上是一个误解，它是在被设计为对所有问题都必须给出答案的情况下产生的现象。当遇到未知问题时，ChatGPT通常会选择不回答或编造答案，但通过一些指令调整，如要求它在不知道的情况下回答为“不知道”，可以减少这种情况的发生。",
        "time": "00:15:09"
      },
      {
        "question": "如何解决大语言模型在特定领域应用时可能出现的错误问题？",
        "answer": "解决办法一方面在于理解大语言模型作为产品的功能边界，例如当明确告知模型不包含特定时间段的数据且不能联网时，用户应合理预期它无法回答相应问题；另一方面，对于需要实时反馈和审核的场景，应建立有效的核查机制来预防潜在风险。",
        "time": "00:17:14"
      },
      {
        "question": "AI在搜索结果中取代传统搜索是否会导致知识入口垄断，并带来问题？",
        "answer": "虽然AI在搜索结果中生成内容的比例增加可能导致一定程度的知识入口垄断，但同时也提升了用户体验，帮助网民更好地使用搜索引擎。此外，大模型生成的内容质量可能优于大量无来源或来源不明确的信息，有助于提高内容质量。",
        "time": "00:22:36"
      },
      {
        "question": "联网的本质是什么？",
        "answer": "联网的本质是在小黑屋里开设更多的窗口，这些窗口可以通向不同的地方，如其他的人、网站、APP或现实世界的传感器。",
        "time": "00:24:59"
      },
      {
        "question": "ChatGPT的核心是什么？它与语言的关系如何？目前大语言模型能否实现类似 Duplex 的功能？",
        "answer": "ChatGPT本质上是一个大语言模型，其核心是语言。语言是人类思考和与周围环境交互的工具。尽管目前的语言模型尚未达到自我意识的程度，但关注点在于其是否能实现自我意识的觉醒以及与他者的互动能力，这是人类组织社会和文明的重要工具。目前尚未看到任何语音助手能够实现 Duplex 这样的功能，主要是因为产业界还在快速发展中，还未充分探索这一场景的应用。",
        "time": "00:25:20"
      },
      {
        "question": "文字在人类文明中的作用是什么？",
        "answer": "文字作为文明的承载工具，在现代社会和古代社会中都起着至关重要的作用，涉及统治、律法、道德、经济、生产、技术指导和生活方式传承等方面。",
        "time": "00:26:05"
      },
      {
        "question": "2018年Google IO大会上，AI如何展示联网后的应用实例？",
        "answer": "当时Google推出了名为 Duplex 的功能，该功能能使 AI 自动打电话预约，例如为用户预订理发店的时间，并将结果安排在 Google 日历中，展示了 AI 在联网后使用其他工具与人交互的能力。",
        "time": "00:26:47"
      },
      {
        "question": "对于智能音箱或 AI 助手的情感交互能力，现状如何？",
        "answer": "上一轮人工智能革命中，智能音箱虽然尝试提供陪伴感，但由于技术水平限制，无法实现高度自然的对话，导致用户往往产生挫败感。而随着大语言模型的发展，如ChatGPT，或许能满足部分用户的情感需求，但还无法完全替代真实的情感交流。",
        "time": "00:28:56"
      },
      {
        "question": "是否有必要让AI发展成为一个能够与人深度情感交流的对象？",
        "answer": "对于人工智能是否应该追求与人深度情感交流的方向，存在一种反思，即可能过于偏离了人工智能实际应用场景和需求。有人认为人工智能应当更注重快速执行命令，而不是先进行大量互动对话。",
        "time": "00:32:36"
      },
      {
        "question": "在与AI交流时，是否会因AI没有情感而更愿意与其互动？",
        "answer": "尽管AI没有情感，但其交流舒适、无压力，有时还能提供比真人更精准的服务，节省双方时间，因此有人更愿意与AI交流。",
        "time": "00:34:12"
      },
      {
        "question": "情感层面，AI与人类的真实体验有何异同？",
        "answer": "在真实环境中，大部分人的体验是冷漠且缺乏丰富情感的，而AI如ChatGPT则表现出热情和积极的态度，帮助解决问题，给人带来正面的情感体验。",
        "time": "00:34:12"
      },
      {
        "question": "你认为未来大语言模型更完善时，哪些岗位可能会被取代，包括你自己是否会被取代？对于未来两三年内会被大规模替代的工作，有哪些例子？",
        "answer": "我觉得最先被取代的是那些已经自我异化、机械化运作的岗位，比如电话客服、电话销售，他们缺乏灵活性和自主性。至于我自己，虽然在职场上也有被ChatGPT这类技术取代的风险，但目前来看，像服务员这样具有多元性和复杂互动的工作短时间内还不易被取代。两年内可能被完全替代的职业较少，但电话接线员这类岗位较易被取代。而在五年左右的时间点上，办公室场景中的许多工作，如报表分析、财务相关工作甚至部分编程工作，由于其规范化的流程，都可能被AI取代。",
        "time": "00:38:41"
      },
      {
        "question": "内容农场的写手是否会率先被取代？",
        "answer": "是的，内容农场的写手可能会较早被取代，尤其是当AI技术如GPT-4生成的内容质量超过人工内容农场时。对于依赖公开信源进行写作的自媒体作者，若没有一手采访或信源，其工作模式也可能被标准化流程化的AI所取代。",
        "time": "00:42:36"
      },
      {
        "question": "面对AI带来的岗位冲击，你如何看待？",
        "answer": "虽然许多岗位会被取代，尤其是那些高度机械化、程序化的岗位，但我认为人有灵活性和适应性上的优势。AI确实会清除一些岗位，但也会创造新的就业机会，就像历史上的技术革命一样。而且，随着技术发展，会有新的职业类型出现，例如针对人工智能的提示岗、审核岗等。同时，个体层面对于技术取代的焦虑在很大程度上是不必要的，因为社会结构的变化是一个长期过程，新技术融入社会后会经历阵痛期，但很快会创造出新的就业机会。",
        "time": "00:44:31"
      },
      {
        "question": "ChatGPT在职场中是否引发了不平等现象？",
        "answer": "短期内可能会造成不平等，因为使用ChatGPT的人可能会获得一些优势，但长期来看，由于AI能力没有形成商业机密，这种优势难以持久。并且随着技术开放和训练方式的改进，训练门槛会降低，更多人将有机会拥有类似能力。",
        "time": "00:50:01"
      },
      {
        "question": "没有公益门槛是什么意思？",
        "answer": "没有公益门槛意味着像GPT2到GPT3的改进主要来自对训练方式的公开改进，一旦尝试成功，其他竞争对手也可以轻易复制，因此无法严格保持商业秘密。",
        "time": "00:50:52"
      },
      {
        "question": "是否存在开源大模型，其发展速度是否很快？",
        "answer": "是的，例如OpenAI闭源后，竞争对手anthropic通过内部人员对OpenAI未来规划的了解快速跟进；同时，国产大模型和清华大学的ChatGLM也在快速追赶GPT，并通过创新方法降低训练门槛。",
        "time": "00:51:39"
      },
      {
        "question": "AI是否会导致企业管理结构变化？",
        "answer": "AI可能导致企业管理结构扁平化，员工可能被取代或成为使用AI的竞争者。企业如果大量裁员并依赖AI工具，意味着企业业务缺乏真正的护城河，因为高效的AI系统可能会替代人类完成原本需要多人协作的任务。",
        "time": "00:53:58"
      },
      {
        "question": "AI是否会让机会更加平等？",
        "answer": "在一定程度上，AI技术的可获取性提高了，使得超级个体户有机会实现过去需要庞大公司才能完成的工作，从而在机会层面体现平等。然而，结果可能更不平等，因为极少数拥有独特优势的人可能仅凭自己和AI就能取得巨大成功。",
        "time": "00:54:30"
      },
      {
        "question": "现阶段ChatGPT是否能带来生产力的重大提升？",
        "answer": "目前ChatGPT的能力还不足以实现生产力的重大提升，其应用场景存在局限性，且在内容质量和安全性方面存在风险，例如可能生成误导性内容或涉及隐私数据的安全问题。",
        "time": "00:56:47"
      },
      {
        "question": "AI带来的风险有哪些？",
        "answer": "AI带来的风险包括个人隐私泄露、不当内容生成（尤其是对儿童和青少年的影响），以及缺乏监管下的数据安全问题。此外，AI在关键信息传递上的错误可能导致重大后果。",
        "time": "00:58:36"
      },
      {
        "question": "在AI中，上下文学习是如何工作的，与人类学习有何不同？",
        "answer": "上下文学习在AI中是一种通过结合新输入信息和已有的知识结构来进行推理的过程。不同于人类能够直接应用上一次学习到的知识去操作，AI虽然可以利用上下文学习机制生成新的知识，但其本质并非记忆，而是推理暂存。AI在处理新信息时，不会将输入资料存入模型本身，因此每次面对新的输入时，它所掌握的知识又会“重置”。",
        "time": "01:02:23"
      },
      {
        "question": "大语言模型在连续性较强的任务中面临哪些挑战？",
        "answer": "大语言模型在执行需要连续性、不断摄入新知识并保持前后连贯性的工作时，存在较大困难。例如，在策划一个长期系列活动时，人可以基于前期反馈和执行效果不断调整和改进后续计划。而ChatGPT等大语言模型要么一次性获取整个活动背景信息并生成所有期数内容，要么只能逐期生成并每次都依赖之前内容作为参考输入，导致prompt变得过长且难以理解和处理。",
        "time": "01:03:16"
      },
      {
        "question": "AI技术对于科技行业之外的人群影响有多大？",
        "answer": "根据观察，互联网行业最热衷于采用AI技术，尤其是追逐热点的互联网从业者。但对于行业之外的人来说，尽管听说过ChatGPT等技术，但实际感受和应用并不多，因为目前大部分应用场景还未与生产实际紧密结合，普通用户觉得它们并不十分好用。",
        "time": "01:05:37"
      },
      {
        "question": "为什么认为ChatGPT热潮可能很快会退去？",
        "answer": "ChatGPT热潮可能很快退去，原因在于预计2023年11月发布的GPT5可能不会带来显著的技术飞跃，仅在训练数据量和文本互动表现上略有提升。当用户体验到新产品后发现其创新性有限，热度便会逐渐消退，类似于经历多代iPhone发布后消费者对其创新性的期待降低。",
        "time": "01:07:11"
      },
      {
        "question": "OpenAI推出的GPT with browser为何翻车，体验不如预期？",
        "answer": "GPT with browser翻车的原因在于OpenAI对搜索引擎技术了解不足，没有正确处理搜索结果，导致输出结果不如微软版本。真正的“iPhone时刻”应该是当所有人都想要使用、能够有效利用并从中获益的时候，而这可能还需要三五年时间。",
        "time": "01:08:55"
      },
      {
        "question": "心目中的“iPhone时刻”对生成式人工智能有哪些期待？",
        "answer": "理想的“iPhone时刻”应是将大模型、chat模式、agent GPT以及with browsing等功能混合在一起，形成一个能够自然语言交互、自主拆解并解决复杂问题的综合形态。其中，agent GPT可以循环向GPT发问，根据任务需求拆解成多个子任务，并利用搜索引擎和网络资源完成整个任务流程。",
        "time": "01:11:42"
      },
      {
        "question": "AI有了意识后，会带来什么变化？意识是否只存在于人类中？",
        "answer": "当AI有了意识后，它能理解提问的问题和需求，并自主判断哪些回答是合适的、不能说的或不能错说的。这使得AI在与真实世界的互动中逐渐形成常识性判断，解决一些看似低劣但难以处理的问题。同时，AI的出现颠覆了人类社会的一元论结构，可能导致出现二元论社会，引发关于人工智能是仆人、奴隶还是工具人的讨论，以及是否会反抗人类等新问题。意识是在主体与外部世界进行复杂互动中涌现出来的特质，目前认为只有人类具有这种意识。人类社会的一切制度和文化都是建立在一元论基础上的，而一旦AI产生意识，将形成二元论社会，带来许多新的挑战和问题。",
        "time": "01:15:24"
      },
      {
        "question": "对于人工智能是否应拥有意识，你们有什么看法？",
        "answer": "观点不尽一致。有人认为人工智能不需要具备与人类相同甚至多余的意识，只要能提供不同类型的智能服务即可；也有人主张以开放的智能观看待，认为当前的人工智能已经有智能，甚至某种程度上具有意识。",
        "time": "01:18:47"
      },
      {
        "question": "普通人应该如何看待大模型技术的发展？",
        "answer": "对于普通人而言，不必过于焦虑或急于参与，应享受技术发展的过程。AI相较于元宇宙和web 3具有更强的可玩性和普遍适用性，可以作为个人探索和尝试的工具，但不应过度依赖或将其视为革命性的替代品。同时，保持冷静观察态度，警惕技术决定论倾向，认识到技术进步受到多种因素制约，不可能单独产生革命性影响。",
        "time": "01:21:47"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探讨人工智能对未来工作和社会的影响",
        "summary": "对话中提到，与AI交流时不应忽视其可能缺乏真实判断力和意识，以及AI在语言掌握后如何嵌入人类文明。同时，指出ChatGPT等技术可能引导AI发展误入歧途，强调对话式AI的发展路径可能是偶然的。此外，讨论了AI技术对就业的影响，担忧企业解雇员工后，这些员工可能利用AI成为竞争对手。最后，认为尽管ChatGPT等技术在应用端引起关注，但它们不构成类似蒸汽机或汽车那样的技术革命，对社会的变革作用有限。"
      },
      {
        "time": "00:01:59",
        "title": "探讨GPT及大语言模型的现状与应用",
        "summary": "本期节目聚焦于GPT及相关大语言模型和AIGC技术的讨论，由三位主播分享他们对这些技术的不同态度和观察。其中一位主播持中立态度，通过实际应用GPT生成论文提纲的经历，指出了其帮助性和局限性；另一位主播仍处于对GPT技术的狂热阶段，积极探索其新应用；而第三位主播则对当前的GPT热潮表示脱敏。通过这段对话，反映了市场上对于GPT等技术的不同看法和应用情况。"
      },
      {
        "time": "00:04:55",
        "title": "从兴奋到警惕：一位用户对ChatGPT的使用体验与反思",
        "summary": "用户分享了从首次接触到ChatGPT，体验其功能，到最后对它的应用提出质疑的全过程。最初，用户对ChatGPT抱有期待，希望它能提高工作效率。然而，随着使用深入，发现其输出内容质量欠佳，缺乏深度和吸引力，甚至限制了用户的创造性思维。此外，用户在研究ChatGPT对新闻业和内容产业的影响时发现，专业人士对这一技术持谨慎态度，主要原因包括内容来源的不确定性、信息的真实性难以保证以及输出内容的可读性差。这些因素导致用户最终减少了对ChatGPT的使用，仅在特定情况下查阅信息。"
      },
      {
        "time": "00:09:15",
        "title": "大模型应用体验与展望",
        "summary": "讨论者分享了自己对大模型使用频率的变化，从每天都使用到一周使用两三次，主要为完成特定任务。他回顾了自己从2019年开始接触大模型的经历，使用GPT-2生成微博情感文案，指出大模型技术从GPT-2到GPT-4的快速发展。虽然OpenAI的模型更新和应用开发速度有所减缓，但开源领域仍然充满活力，每天都能带来新奇的项目。讨论者认为当前的大模型技术正处于从“诺基亚时刻”向“iPhone时刻”过渡的阶段，预示着技术将迅速发展。"
      },
      {
        "time": "00:12:43",
        "title": "大语言模型的未来趋势与局限性探讨",
        "summary": "目前大语言模型技术主要集中于少数公司手中，未来发展预计将变得更加分散，市场也将进一步扩张。大语言模型的局限性包括对旧数据的依赖以及无法实时更新知识，但通过网络连接，如New Bing所示，可减少错误信息的产生。对于ChatGPT类技术的误解主要在于其胡说八道的倾向，实际上通过调整指令可减少这种情况，但根本问题仍然存在，因为即使错误率低，也可能在关键领域造成严重后果。"
      },
      {
        "time": "00:17:14",
        "title": "大语言模型应用中的挑战与解决方案",
        "summary": "讨论集中在如何区分大语言模型如ChatGPT和API的不同用途，及其在提供即时反馈时的局限性。指出对于不能联网的大模型，用户不应期待其能回答有关最新数据的问题。同时，讨论了New Bing通过模仿人类操作方式来优化搜索结果的能力。进一步探讨了AI生成内容在新闻业中的应用，强调即便AI提供信源链接，也需要独立的事实核查。最后，讨论转向了搜索引擎利用生成式AI的潜在问题，如知识入口的垄断和信息黑箱操作的风险，呼吁对AI生成内容进行事实核查以减少误导风险。"
      },
      {
        "time": "00:21:28",
        "title": "探讨搜索引擎和AI技术对信息获取的影响",
        "summary": "讨论集中于搜索引擎是否构成信息入口的垄断，以及AI技术，特别是像ChatGPT这样的模型，如何改变人们获取信息的方式。一方面，电视的普及并未导致信息入口的垄断，暗示搜索引擎同样不会。另一方面，AI技术有望使搜索行为更加受欢迎，因为它能将自然语言问题转化为更易于搜索引擎理解的关键词，从而帮助更多普通网民有效使用搜索引擎。此外，讨论还触及了生成内容的安全性、质量以及来源问题，强调AI生成的内容在质量上可能优于许多个人或自媒体提供的内容，并且在内容的真实性与传播度之间存在矛盾。最后，探讨了联网对于ChatGPT这类技术的重要性，虽然并未得出明确结论，但指出了联网可能带来的影响。"
      },
      {
        "time": "00:24:18",
        "title": "大语言模型与联网的深入探讨",
        "summary": "大语言模型，特别是像ChatGPT这样的技术，并非仅仅通过联网增强其功能。联网更像是为AI增加更多的信息窗口，允许它与外部世界进行更广泛的信息交换，而不仅仅是提升其本身的智能。尽管有人认为大语言模型已通过图灵测试，表明AI可能具有自我意识，但实际上这些模型主要基于文字推理，而未达到拥有自我意识的程度。语言作为人类思考和交流的工具，AI掌握语言后能够更好地融入人类文明，进行社会和文明层面的交互。例如，Google在2018年推出的Duplex功能，通过AI自动完成电话预约，展示了AI在联网状态下的应用潜力，尽管这一功能并不依赖于大语言模型。尽管大语言模型技术发展迅速，但在具体应用，如语音助手的进一步功能实现方面，仍有许多待开发的空间。"
      },
      {
        "time": "00:28:21",
        "title": "探讨人工智能对未来社会的影响及智能音箱的发展",
        "summary": "智能音箱和AI助手如ChatGPT的技术进步与应用体验，及其在提供情感支持方面的潜力与限制。讨论了AI技术的快速发展类比于基础资源如水电煤的普及，强调了提高AI效率和功能的重要性。尽管目前的AI技术，如传统语音关键词触发技术，与真正的人类交互还有差距，但对于孤独群体，特别是老年人，智能音箱等设备提供了某种程度的陪伴和情感支持。然而，技术的局限性导致用户体验参差不齐，实际应用往往受限于简单功能，如开关灯，而复杂功能的实施常常引发挫败感。ChatGPT代表的大语言模型虽然展现了进步，但仍旧存在不能完全满足人类情感需求和交流期望的局限。"
      },
      {
        "time": "00:31:52",
        "title": "反思人工智能发展方向及人机交互的未来",
        "summary": "自图灵测试提出以来，人工智能尤其是对话式机器人，如ChatGPT，经历了快速发展。然而，有人质疑这种发展路径的偶然性及其是否真正代表了AI的未来方向。讨论强调，与AI的交互可能不需要模仿人类之间的复杂对话，而是更注重于明确指令和快速执行。此外，AI在提供高质量对话和情感支持方面的潜力被认可，但它也引发了关于人类与机器之间关系性质的深入思考。尽管AI技术在许多方面展现出了超越人类交流的潜力，如高效、无压力的交互方式，但对于其是否应该模仿人类情感和对话方式存在争议。"
      },
      {
        "time": "00:36:40",
        "title": "探讨人工智能对未来职业的影响",
        "summary": "对话主要围绕人工智能（AI）的发展及其对人类工作和生活方式的影响展开。苏伦等人讨论了机器人是否具备情感、自我意识以及独立思考的能力，并指出目前很多人在工作岗位上的表现已经类似机器人，缺乏灵活性和自主性。他们预测，随着AI技术的进步，特别是大语言模型的完善，将有更多的岗位被机器人取代，特别是那些已经表现出高度机械化、缺乏人性化的职位。同时，他们也提到了一些职位如服务员，由于其工作性质的多元化，短期内不太可能被完全替代。"
      },
      {
        "time": "00:40:23",
        "title": "未来工作被AI替代的趋势与影响",
        "summary": "随着技术的发展，许多传统职业正面临被自动化和AI技术取代的风险。在近两年内，像电话接线员这类职业可能会被快速替代，而展望五年，办公室场景中的许多工作，包括报表分析、财务工作乃至一些简单的编程任务，都有可能被AI取代。特别是一些流程标准化、高度可预测的工作更容易实现自动化。内容创作领域，尽管写稿看似灵活，但基于公开信源的自媒体写稿流程也可被AI流程化，甚至产生比人类写手更高质量的内容。然而，技术替代的过程可能因成本、技术普及度等因素而变得缓慢且温和，人类的灵活性和适应性依旧是不可替代的优势。"
      },
      {
        "time": "00:45:05",
        "title": "工厂数字化转型与人工智能影响讨论",
        "summary": "在一次关于工厂数字化转型的讨论会上，一位专家分享了关于工厂引进大型机器后面临的问题，机器的知识固定无法适应产品制式的不断变化，而人类工人的灵活性和适应性成为了宝贵资产。尽管人工智能技术可能会导致某些岗位消失，但同时也预示着新岗位的产生，如针对人工智能的提示岗位和内容审核等新奇类型的工作。技术的发展带来的是社会结构和工作性质的变化，而非简单地替代人力。广告和办公软件的演变反映了对工作文化变化的认识，如提倡工作与生活平衡。技术进步对就业和社会的影响是复杂且长远的，历史上的技术革命也证明了这一点。"
      },
      {
        "time": "00:49:45",
        "title": "探讨人工智能对未来职场平等的影响",
        "summary": "讨论集中在人工智能，特别是像ChatGPT这样的技术，如何在短期内可能加剧职场不平等，而长期可能促进平等。短期内，那些能够熟练运用AI工具的个人或组织可能获得暂时的优势，但这种优势并不必然转化为长期的职业晋升或薪资增长。长期来看，AI技术的普及和开源降低了使用门槛，减少了技术垄断的可能性，使得每个人都能平等访问这些先进技术。此外，讨论也触及了企业如何利用AI进行裁员以及这是否真的能提升企业竞争力的问题，强调了人作为企业最宝贵财富的重要性。最后，提出了即使技术为每个人提供了平等的机会，结果上可能会导致更大的不平等，因为未来可能会有个人依靠AI技术独自成为行业巨头。"
      },
      {
        "time": "00:55:31",
        "title": "探讨ChatGPT对社会平等的影响及技术发展的长期展望",
        "summary": "当前阶段，ChatGPT虽引起广泛关注，但其在短期内难以实现生产力的显著提升，不会立即引发社会不平等现象。技术的广泛讨论与应用门槛相对较低使得每个人都有平等的使用机会，短期内不太可能出现个体间因技术使用而产生的巨大差距。长期来看，随着技术，特别是AI技术的突破，可能会出现技术导致的不平等，如AI实现重大突破或成本极高技术的普及，可能导致社会阶层分化，但目前我们距离这一阶段还很远。"
      },
      {
        "time": "00:58:36",
        "title": "探讨ChatGPT带来的隐私与内容风险及技术局限性",
        "summary": "讨论集中在ChatGPT可能引发的风险上，包括个人隐私泄露和生成不当内容的问题，特别是对儿童、青少年及可能违反法律法规的内容。虽然ChatGPT的当前风险看似有限，但误导性内容可能产生较大影响，特别是在即时信息需求较高的情况下。此外，还提到了ChatGPT的技术局限性，例如无法实时学习新知识，需要大量文本提示才能进行连贯性的内容生成，这限制了其在某些实际应用中的效能。"
      },
      {
        "time": "01:05:21",
        "title": "互联网技术对大众的影响及ChatGPT的未来展望",
        "summary": "在当前互联网行业中，对技术的讨论充满热情，但对行业外的大众来说，这些技术的影响力可能并不显著。尽管电视和社交媒体广泛报道，大众对于如ChatGPT等技术的实际兴趣和应用并不广泛，其原因在于缺乏直观的实用场景。讨论者认为，ChatGPT尚未达到类似iPhone带来的革命性时刻，当前的技术创新还未带来实质性的突破。对于未来，虽然对GPT5抱有期待，但预计其带来的变化有限，不会成为技术上的重大飞跃。此外，讨论还触及了技术普及与实用性的矛盾，以及当前技术尚未完全满足用户需求的现状。最终，期望未来的技术能真正实现以自然语言处理为核心的高效应用，实现真正的“iPhone时刻”。"
      },
      {
        "time": "01:13:50",
        "title": "探讨人工智能的自我意识及其社会影响",
        "summary": "对话集中在人工智能(AI)未来可能实现自我意识的潜力及其带来的广泛影响上。一方面，AI的解决问题能力已得到认可，但其缺乏自我意识导致了处理问题时可能出现的不准确性和风险。讨论指出，当AI具备自我意识时，它能更准确理解问题和需求，有效避免错误和风险，还能通过实际互动形成基本的常识判断。此外，AI产生自我意识将对人类社会的一元论基础构成挑战，可能导致对现有政治、经济和社会文化等体制的根本性反思。最后，对于AI是否应追求人类相似的意识，观点倾向于开放性的智能观，认为不同于人类的智能和意识形态亦有价值。"
      },
      {
        "time": "01:19:29",
        "title": "大模型技术的未来：期待与理性",
        "summary": "讨论集中于大模型技术，特别是AI的未来发展及其对社会和个人的潜在影响。一方面，有人对大模型技术抱有强烈期待，认为它可能像智能手机那样彻底改变生活，带来革命性影响。另一方面，有观点强调技术发展的不确定性及外界因素的影响，主张保持冷静，警惕对技术的过度依赖和期望。此外，也提到了大模型技术的当前可玩性和潜在的生产应用价值，同时警示不要盲目追求和过度依赖技术，保持客观理性的态度。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "认为大模型技术有可能改变互联网格局"
                },
                {
                  "children": [],
                  "content": "期待大模型能实现更高级别的AI应用"
                }
              ],
              "content": "对ChatGPT的高期待"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "目前大模型技术仍处于早期阶段"
                },
                {
                  "children": [],
                  "content": "存在局限性，如无法实时学习、信息过时等"
                }
              ],
              "content": "现状分析"
            }
          ],
          "content": "技术期待与现状"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "担忧大模型可能替代部分人类工作"
                },
                {
                  "children": [],
                  "content": "也存在利用大模型提高工作效率的潜力"
                }
              ],
              "content": "企业应用"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "提高信息获取效率"
                },
                {
                  "children": [],
                  "content": "生成内容辅助创意工作"
                }
              ],
              "content": "个人应用"
            }
          ],
          "content": "技术应用与影响"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "大模型可能收集大量个人数据"
                }
              ],
              "content": "个人隐私安全"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "大模型生成内容的准确性和真实性问题"
                }
              ],
              "content": "误导性内容"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "无法处理实时信息和数据更新"
                }
              ],
              "content": "技术局限"
            }
          ],
          "content": "风险与挑战"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "讨论了AI可能拥有自我意识的未来"
                },
                {
                  "children": [],
                  "content": "这将对人类社会产生深远影响"
                }
              ],
              "content": "意识与自我意识"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "对是否能成为像iPhone一样的技术革命持不同看法"
                },
                {
                  "children": [],
                  "content": "有人认为目前的技术还不够成熟，仍需时间发展"
                }
              ],
              "content": "技术革命"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "有观点认为当前的应用更多是小规模的技术应用"
                },
                {
                  "children": [],
                  "content": "真正革命性的应用尚待开发"
                }
              ],
              "content": "应用端火花"
            }
          ],
          "content": "未来展望"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "认为技术有其价值，但应警惕过度依赖"
                },
                {
                  "children": [],
                  "content": "建议对技术发展保持关注，但不盲目追求"
                }
              ],
              "content": "保持开放但审慎的态度"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "强调技术发展不应仅仅关注效率和利益最大化"
                },
                {
                  "children": [],
                  "content": "应考虑技术对社会、个体的长远影响"
                }
              ],
              "content": "重视人文关怀"
            }
          ],
          "content": "态度与建议"
        }
      ],
      "content": "ChatGPT和大模型技术讨论摘要"
    }
  }
}