{
  "pid": "5fe5b198dee9c1e16dfb9672",
  "eid": "656ebd98d58c3a885b587f25",
  "title": "我们的下一步是成为机器的朋友还是敌人？｜硅谷AI观察",
  "task_id": "klrbn2yw34e395zy",
  "transcription": [
    {
      "time": "00:00:07",
      "text": "现在的模型训练的或者说包括给他喂的这些文本的尺度来说，它并不具备什么觉醒的能力。他可能可以回答很复杂的逻辑推理的问题，但是我觉得意识和知识其实完全不是在同一个层面。如果他真的强大到可以管控人类，为什么一定是个坏事？现在人类说白了就是也可以完全当面可以去8081，但是我们也并没有说有一个人类目标要消灭所有的蚂蚁。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:42",
      "text": "人本身的这个意识形态可能也有很多不同的冲突。我们说去规范大元模型的时候，以哪一套标准为主？人不会被替代，因为人本身的工作其实就是被摄像头设计的，职位本身就是被人发明的。对我说我现在找到了一个更好的方案，我们可能都会在某些层面上被替代，对替代掉。但是找一个不那么容易被替代的脱口秀演员。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:12",
      "text": "是的，这种给人提供情绪价值的对对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:15",
      "text": "上次。",
      "speaker": "发言人3"
    },
    {
      "time": "00:01:16",
      "text": "心理咨询。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:17",
      "text": "我们非常有幸福。在家的一个快速变革快速增长的一个时代，我们可能要更愿意去接受这个变革，去找准自己的变革过程中可能有价值或者存在的位置。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:40",
      "text": "Hello, 大家好，欢迎收听二维无码。这是一档科技评论播客，我们关注科技对社会与人的影响，我是二维无码的主播建飞。前段时间我在腾讯研究院的两位好友，袁晓辉和曹建峰，参加了世界经济论坛的人工智能治理峰会。在会场外我的两位朋友也跟硅谷的一些技术从业者深入的交流了近期AI相关的技术进展和社会影响，一起来聊聊与人工智能有关的故事。",
      "speaker": "发言人4"
    },
    {
      "time": "00:02:06",
      "text": "本期节目是这个系列的第二期，这期的交流对象是马鸿旭，王旭是berkeley的博士，目前在一家全球知名的互联网大厂做工程师，本身也是AI的从业者。本期主要探讨了AI技术的发展对社会的影响，以及对未来教育的一些反思。接下来我们就将现场交给小辉和建峰。",
      "speaker": "发言人4"
    },
    {
      "time": "00:02:29",
      "text": "大家好，然后这是我们在硅谷湾区录制的第二期节目，就是我是小辉，然后还有我的同事jeff。今天我们又请到了一位也是多年的朋友。同时他也是在硅谷的科技行业从业的一些年，包括之前也在这边上学。他应该算是在机器学习，包括人工智能这波，他有相关的背景，也是非常欢迎这位大咖。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:59",
      "text": "很开心借着这个平台认识大家。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:00",
      "text": "对我是战斧，我们这一次在硅谷这边还是有挺多的收获。我们要不请大咖来先介绍一下自己的一些背景。",
      "speaker": "发言人3"
    },
    {
      "time": "00:03:09",
      "text": "我叫叫matt。然后之前15年到19年在berkely读KHD，然后相当于也在一直在弯曲。然后毕业了之后就加入了某大厂互联网大厂，对，然后开始勤奋德尼罗斯。这些年就基本上在不同的项目里边去做很多machine learning和AI的这种application以及落地的一些工作。然后从做时间序列，做competition到现在做大元模型，可能都浅显的接触过一些。然后就属于那种术业不专攻，但是各个涉猎很广泛。对，所以今天就谈不上这个分享，但是可能就是把自己浅显的一些经验，以这样的形式简单介绍一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:56",
      "text": "这个太谦虚了。对，因为我们知道现在大语言模型很火，就是这波人工智能的浪潮。其实早在这个大语言模型之前，其实已经有很多学界的一些尝试，包括业界的一些尝试，都在用这个叫人工智能。当时我们还叫机器学习，包括神经网络。你觉得这一波大语言模型的这个浪潮中最大的改变是什么？或者说为什么一下子就这么热？",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:22",
      "text": "我觉得从最基本上机理上来说，就是大语言模型它解决了一个叫做基础模型或者叫foundation model的问题。因为传统的比如说无论是传统的模型learning也好，刚才提到这些declaring，包括这些后续的发展，它都是专业化的模型。就比如说我们有一个具体的领域的问题，然后我根据这个问题来去串收集数据，然后串一个model，然后只能应用在这个领域。然后当这个系统稍有变化的时候，我们可能都会涉及到比如说这个模型的迁移学习或者说迭代的问题。但是单元模型或者垃圾on model以及其不代表的这个防御阵model为主，他们其实是解决了一个方法问题，它更有普适性。就比如说他可以说我这个模型它并不是专门为了解决某个问题，它可以去理解所有的图像，理解所有的文本。然后再以此之像你在做后续的开发就会简单的多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:05:19",
      "text": "相当于是把一些很通用的能力先给你铺垫好了。然后所谓泛化也是说就是同样在一个领域中，他的能力也可以应用到其他很多领域中去。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:28",
      "text": "甚至他可以构成跨领域的知识的或者说这种逻辑的建立。另一点优势就是像提就是人其实是能力是有限，是很渺小的。哪怕说非常聪明的大脑，他可能也是在某一个具体的领域，它可以了解的非常清楚。但是cross domain比如说这个不同的领域之间的联系，人类并没有一个通才去了解各个领域，并且把各领域之间的逻辑连接建立起来。我觉得房地产报现在可能没做到，但它未来完全有这个趋势是找到这些黑的那就是这些被人类忽略掉的这些联系。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:03",
      "text": "就是说很多这种人类可能以前发现不了的很多这种知识，可以通过他的这个发现。其实我听下来就那你觉得我们是现在这个大模型，它距离这个A级，就AG，就是什么通用人工智能，也就是未来人可以做的所有的认知任务，人工智能都可以做。你觉得我们还已经到了吗？",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:22",
      "text": "还是说还是更遥远？OK我觉得HI定义可能有这种狭义的和广义的那比如说所谓的AJI，你可能就跟我们刚才聊的findon model可能有在狭义上是可能有一些相关性。比如说原来我们去做图像的问题，我要有图像的识别、图像的分割、图形学或者说commission的处理。那现在可能就已经有一个很好的关于图像的foundation model去可以handle所有的任务。我们可不可以理解变相拥有的一个在图形领域的一个AG除了在理解的基础上，我还可以做生成。他其实就完全代表了说人类在图形领域的有的知识的结合，并且能延伸出去。但比如说跨领域的，比如说从图像到文本，从图像到视频，那可能目前还没有。但我并不觉得这是一个比如说十年之后才会实现的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:12",
      "text": "所以就是通用人物是看到底多通用和这个深度到底怎样跟我们一般人理解的这个模型产生的意识，或者是可能是另外一个层面的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:22",
      "text": "就是说推理的层面。对，或者说就现在人工智能虽然可以做很多任务，但他人是有自我的一自我察觉。",
      "speaker": "发言人3"
    },
    {
      "time": "00:07:31",
      "text": "包括动机等等这些问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:33",
      "text": "我觉得好像在好多科幻电影、美剧里面讨论的比较多。对对对，可能我觉得会有很多这种自我觉醒，意识觉醒是吧？对我我可能非常片面的理解，就是以现在的模型训练的这个或者说包括给他喂的这些文本的尺度来说，它并不具备什么觉醒的能力。他可能可以回答很复杂的逻辑推理的问题。但是我觉得意识和知识其实完全不是在同一个层面。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:02",
      "text": "因为那个科幻电影里面描述的就是人工智能这个自我意识觉醒之后，他就要反抗人类，他要奴役人类。你就会不会担心这个人工智能未来失控，就是不可控的这种随便发生好问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:08:16",
      "text": "我这可能说说出来会有一些争议。但是第一个想问的就是说，如果他真的强大到可以管控人类，为什么一定是个坏事？人其实也是这个世界里面的一类角色。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:28",
      "text": "这个跟人类中心主义的观点就产生分析。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:32",
      "text": "对我们人类是万物的主宰。",
      "speaker": "发言人3"
    },
    {
      "time": "00:08:34",
      "text": "然后第二是说为什么他有了这个能力，就一定会发展到想去管理人人类，或者说去要征服人类。哪怕具备了这个能力，但他有多个选项，比如说我可以跟人类共生，然后彼此更好的进步，和谐的社会。举个例子，现在人类说白了就是也可以完全当然可以去霸凌蚂蚁。但是我们也并没有说有一个人类目标叫消灭所有的蚂蚁。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:00",
      "text": "对，但是曾经消灭过所有的什么蟑螂。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:04",
      "text": "蟑螂什么的也没消灭的了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:06",
      "text": "举的例子很贴切，就是说人类跟蚂蚁之间，可能现在人工智能是个蚂蚁。那未来可能这两个角色会互换，人工智能成为人人成为蚂蚁。但这个就取决于说智能足够强，它不一定是一件坏事。就是我们这样的做一个对齐的研究就是个value element。",
      "speaker": "发言人3"
    },
    {
      "time": "00:09:22",
      "text": "我们解释一下价值对齐呗，就是价值对齐叫alignment是吧？它是一个学术工作概念，主要是讲的是让大模型的这个价值观能跟人类的保持一致。比如说在一些情景下他要做选择的时候，他能够选择一些跟人类比较认可的这个价值观的方向一致的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:39",
      "text": "对对对，这个可能就是如果我们举个简单的例子，比如说这个大模型的你的输出的一些内容，如果他老是一些色情这样暴力的对吧？那那肯定跟人的价值观不一样。就是说你问一些这种敏感的问题时候，他可能就比较能够很好的去heddon处理这些问题。那他就可以能够更好的去满足这个用户的需求，不就不容易把一些有害的资源给出来。因为这个现在，但是未来就是说他的这个目标跟人类整体的目标会被冲，因为人类想发展繁衍生存，那它会不会产生其他的一些目标。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:11",
      "text": "那还很有意思，这方面的接触其实很少，我就是能从我的本能上去推理或者理解。首先人的价值观也不一致。是的，人本身的这个意识形态可能也有很多不同的冲突。那我们说去规范大元模型的时候，以哪一套标准为主呢？首先对于大元模型可能是一个很好的工作，同时对于整个人类社会也是一个梳理的工作？我们我其实可能过去历史上并没有一个很成体体系的一套工作。说来梳理一下我们整个人类的价是这样？那正好借这个机会，我们在想影响大元模型之前，我们自己先梳理一下，自己先定义一下啥是我们人类的价值，人类先对齐一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:57",
      "text": "也没对我们这次开会的时候也有专大家提到这个问题，我们问比如说现在我们遵循的这个价值观，就是让让AI对齐的到底是什么？大家会说比如说大家有共同共识的，有联合国或者一些国际组织，它都有一些这种价值标准。那这个可能是大家认可的方向。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:17",
      "text": "对对对，而且我们觉得其实可能不一定是价值观的堆积，是吧？因为这个不同的社会，不同文化。他有不同的价值观，他很难去在价值观层面去推。可能就是说在这种大家都需要安全？公平等等。",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:30",
      "text": "可能一些尊重和诚实这些。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:32",
      "text": "对这些美好的人类体现上？对，懂了。那我觉得这个其实还挺有必要的。但他甚至都不只是人类的这个所谓的价值观，很可能是更是一个宇宙的运行指南。对，就比如说诚信，比如说尊重，比如说这些对于美的追求。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:52",
      "text": "互惠互利？这个就我们教导小孩要有的这些品质，就是希望我们也希望在训练模型的时候，让这模型也能够去学到。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:02",
      "text": "其实我们我们上次还在上海开了个会，就是讲这个对齐的。但有一个叫齐的一个理论，就是这种社会化的理论。其实你教育小孩，小孩一开始也是一张白纸，啥都不懂。你慢慢通过这个学习交互对吧？跟人之间的这种各种礼仪，他就变得社会化了。人工智能可一开始他学了很多的这个数据，他可能一开始也是在这个价值，或者哪些是可以做的，哪些是不能说的，这样的话可能一场白痴。就是我们能不能有一些方法可以实现这种人工智能的一种社会化，融入到这个社会，这个群体遵循的一些基本的规范里面。",
      "speaker": "发言人3"
    },
    {
      "time": "00:12:39",
      "text": "好消息。好消息。二维无码见听友群了，为尽快回笼粉丝，所有主播上班摸鱼陪您聊，进群还能了解二维无码最新活动动态及选题展望。进群请认准微信个人号，二维五码全拼，二维五码全拼，马小二恭候您的到来。",
      "speaker": "发言人4"
    },
    {
      "time": "00:13:00",
      "text": "对，其实我想借着这个topic，想请教jeff一个问题。就是比如说在训练模型的时候，我们是会倾向说把这个训练的语料提前进行标注。比如说哪些是反正确价值观，哪些是反映错误的，只去使用正确价值观吗？还是说无论好坏都给他，然后再相当于是通过这样的正面和负面的对比的学习，然后让他得到一个正确的价值观。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:27",
      "text": "对这个问题其实很关键，就是他大家有一些争论，如果你只学这种好的内容，就是完全这种clearly就干净的数据，那他以后就在用的时候，用户问一些这种恶意的问题，他完全不懂，那他他就很难去做出一个很好的一个回应。所以这个就是你如果只给他在一开始的训练阶段都是这种干净的数据，那他可能后面他会带来一些新的问题，就像之前这个太一样？在推特上发布一些这种不好的一些言论。所以现在可能比较流行的一种方法就是我在训练阶段尽可能给他多样化的数据，我让他能够知道哪些是坏？这种一些恶意的、暴力的事情他都知道。所以我在最后面那个阶段，我再给他一些正向的这种人类的这种反馈，然后还能知道说虽然你学到的坏的东西，但是你知道这是坏的，我在一些场合是不能说的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:17",
      "text": "这个模型见证了世间一切的恶，然后出淤泥不染是吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:21",
      "text": "对，就是类比小孩子培养。因为像如果你在温室里培养花朵，那外面其实是有暴风雨的。对他如果是一开始就能够在这个环境下长起来，但同时它又能保持着正直。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:35",
      "text": "我们每个人也是一样。我肯定也知道这个世界有很多恶。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:38",
      "text": "我觉得这可能是更理性的一个去做regulation的一种方式？不是说完全的说我只给你价值观正确的东西。然后他学的东西可能会用一个AI的术语，就是overfeed到这样的一个非常精细化的一个场景。我们都办法管控未来的用户如何使用它的时候，他可能在很多领域他并没有见过example的情况下，可能会得出很多并不负责的一些答案。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:08",
      "text": "您觉得这个比如说从技术上，我一开始给他很多各样各种各样的数据，那我最后后面再调教，这个技术上调教能调教的很好吗？",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:17",
      "text": "非常坦诚的说，这并不是我专业的领域。对，因为我自己其实过去的经验都是做相对说比较客观的一些问题。比如说图像里面的识别，识别的出来就是对，识别不出来就是错。或者说预测，那你预测的越精准那就是越好。但是的确发现AI随着可能刚才我们聊到更接近于这种AGI的场景下，我们的判断标准就会更广泛、更带味、更多样化。那就不只有唯一的一个指标叫做准或者不准，而是有很多复杂的评价体系在里面。我觉得这其实也是还是说回来对我们人类很有好处的一个重新思考的一个机会。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:59",
      "text": "是的，这个反思还挺重要的对，因为刚才我们讲的其实还是在这个模型的技术层面，包括训练，价值对齐，但其实可能大部分人还是很关心我们对日常生活的影响？包括我们后面的这个职业生涯是不是会被替代等等这种问题。就是从从你们的视角，因为你们在一线和这个也是正好这个领域对他的进展也比较了解。你觉得就是从目前你的工作和这个日常的角度，你觉得是有一个什么样的感觉？",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:29",
      "text": "对我觉得个人体验这个东西太有用了。稍微介绍一点，也就是哪怕我在美国读的PHD，然后工作这么多年，其实英语一直是我以来比较弱小，又不是native speak。然后特别随着你的只为稍微晋升，然后你需要做越来越多管理的能力，就涉及到跟其他team之间的这都不说直接的争吵或者争斗是吧？你肯定有很多讨论的地方，那你的这个语言就形成了一个相当于说瓶颈。对，就是吵架吵不赢，这就很关键了。然后因为你你比如说在junior level的时候，我只要把code写好就行。对那越来越多的涉及到比如说一些功能的定制，或者说是一些非常的讨论？那我们就涉及到很多的争吵在里面。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:14",
      "text": "我觉得这个有了大语言模型，对我最好的一点就是我写email的时候不慌了？那个写邮件对我可以让他rewrite我的邮件，然后带不同的情绪对吧？比如说我需要稍微的尖锐一点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:29",
      "text": "还会这个叫fine too，就是微调精调一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:32",
      "text": "因为你毕竟不是在这个语言情境下长大的。然后我之前屡次开会的时候在想，这要用中文，我分分钟虐死你是吧？用英文可能就不太行，但是现在就有了这个帮手。我觉得第一是比较直观的那就包括说把我的邮件，比如说retry更友善一点一点，礼貌一点。然后第二的话就是会发现我的team在写code的时候就不特别。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:57",
      "text": "依赖于写代码的时候不再依赖于这种初级工程师。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:01",
      "text": "或者说一个高级工程师，他在large a model的support下，他的生产能力也会成倍的上升。原来我们team结构会说资深的工程师会带几个初级工程师，那他们的成长其实是有时间的，会有成本投入的那现在的话就是属于很基础的很枯燥的活。包括一些简单的逻辑，然后包括一些这种test就是测试，包括甚至做简单的这种系统设计，其实都可以由large larger model来做。资深公司的责任就是去review一下，然后去accept是吧？你身上的code是能用的，然后注入到我们的这个code base里面。所以就发现大家工作效率都在提升。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:45",
      "text": "就是写代码就不再需要初级工程师的一些搬砖的活了。对，这个搬砖就交给机器了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:50",
      "text": "对，非常直观的体验就是写unit test，比如写测试。对，测试其实是一个很枯燥的，然后它有非常具体各种方式，各种的场景，各种corner case要考虑到是吧？往往是靠一个初级工程师，然后他花几天把这个测试写好。现在的话large model可能在五分钟之内就能生成一个事无巨细的，各种counter case都考虑的非常全面的一套测试程序。所以对我来说就是生产力。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:21",
      "text": "极大提升。对那你们组的那些初级工程师怎么办？",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:26",
      "text": "我觉得其实这是一个挑战。你也发现硅谷这些年，或者说最近一段时间，刚毕业的学生找工作其实很难的。然后甚至包括burkey stanford的CS的PVT，也有很多好找工作的时候遇到一些阻碍。我觉得这个的确是我们面临的一个问题。就是如果只具备写扣得的能力，可能竞争力就会越来越差了。那比较需要强调的就是你的对于比如说某一个具体领域产品落地思考这些综合性的能力。有点像我们之前说的那种。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:00",
      "text": "虚的这种虚的软实力。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:02",
      "text": "的类似于这种判断力。对，好奇心。",
      "speaker": "发言人3"
    },
    {
      "time": "00:20:06",
      "text": "对，还有就包括说你如何在大语言模型以及这些好的工具的加持下，更好的去专注于你本身能够提供的价值。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:17",
      "text": "还是那个问题，就是你很多初级工程师没有了成长的土壤，他怎么成为高级工程师，他连这个机会都没有了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:24",
      "text": "好问题就是说我想招个实习生，前提说你有实习经历是吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:28",
      "text": "所以这个大厂锻炼的机会了，以后不给他这个机会了。对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:20:33",
      "text": "首先硅谷的很多大厂，它首先有一个社会责任感在。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:37",
      "text": "就是会承诺去招应届生。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:39",
      "text": "对，因为他可能对社会输送人才本身也是他的社会责任的体现，哪怕在这个大专规模没有火之前，其实他每年也会优先招很多刚毕业的学生，然后给他这个成长空间。然后包括很多这种叫做早期工程师，我们早期的项目经理这种成长的项目。比如说你在还包括。美国这种比较好的这种实习的环境，也可能都会有一些辅助。但是这不是说这个作对在现现在在学校的学生就会觉得高枕无忧。就说你这些有人去考虑。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:11",
      "text": "我这个有限。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:12",
      "text": "对，所以其实还是要调整这个心态。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:15",
      "text": "对现在只能靠大厂的这种社会责任感，这个不是一个可持续的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:19",
      "text": "对，而且你大厂给设计个责任，还他也留不下来大厂对吧？他最终还是很少人可以留下来。",
      "speaker": "发言人3"
    },
    {
      "time": "00:21:25",
      "text": "怎么定义大厂？我觉得很多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:28",
      "text": "厂很多或者是就这个行业，就是行业的这个整体的。因为我们也在做做一些专家访谈去问大家认为在编程替代的这种情况下，大家以后对这个就业市场的冲击，就对程序员的需求是会变多还是变少？对这个岗位的人是不是会越来越少，包括数据分析，也是另外一个方面。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:50",
      "text": "对，包括我刚才我就是你讲的，现在可能还是比较senior的对吧？他来辅助他可以提高生产效率。那如果说他这个能力再强的时候，那是不是说这个也不需要了？我是一个AI的服务员，我老板开公司所有的工作AI都可以做了。未来只需要一个PM是吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:10",
      "text": "对，只需要一个老板带着一个可能C.",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:13",
      "text": "TO我想要这个产品，然后剩下就让他让这个agent自己去点自己。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:18",
      "text": "会不会意味着大家以后都不需要工作了？",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:21",
      "text": "这不是理想社会吗？挺好啊，我们有诗和远方。我之前一直跟我老婆开玩笑，就是说等退休就回东北开个小卖部。有有这个人工智能可以做这么多事儿，那我就老老实实回去是吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:38",
      "text": "所以您算算未来这个人跟机器到底是一种怎样的一种关系？就现在可能确实有这种辅助，然后生产力的提升，再往前发展就是他可能确实会取代，就不光是程序员，可能很多这个行业。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:52",
      "text": "我再次推荐一个科幻动画片，因为里面都有讨论到未来的一些场景。对，叫万万神殿。对刘宇坤的作品改编的这个科幻动画片。然后这个里面也讨论了很多，就是这个未来其实刚才你有讲到，其实可能会是一种共生的状态，就可能既没有被毁灭也没有毁灭。但是这种是一种理想的，就是说两个新物种共生，这是一种可能性。",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:18",
      "text": "两个物种人不会被替代，因为人本身的工作其实就是被上层设计的，对吧？举个例子，比如说原来有个叫做高速公路站收费员，是吧？对，那你说这些人现在可以动画了，自己本身被替代，没有被替代，因为他这个职位本身就是被人发明的对，只不过说我现在找到了一个更好的方案。如从社会的角度来说，其实可能50年之后，压根儿人们都不会记得有叫高速公路收费员这样的一个职业。但是对于个体来说可能影响会比较大，对吧？那我觉得可能对于现在的年轻人来说就会一个挑战，就是要有一个鉴别能力。就是我们可能都会在某些层面上被替代，所以替代掉。但是找一个不那么容易被替代的脱口秀演员。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:06",
      "text": "是的，这种给人提供情绪价值的一些图片。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:10",
      "text": "对，上次心理咨询教授也说这种情感的这种经济，对能够提供情感价值的这样一些职位，咨询师或者说这种会有更多的前景。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:22",
      "text": "很多人批评的时候，我说话总愿意抬杠，所以请原谅我就我还想说人类为什么害怕被替代呢？你本身的价值观来自于现在社会定了一个所谓的成功。我们要去好大学找好工作，然后赚了钱，然后有很多消费主义的这种胡萝卜在我们面前，我们要实现它。然后在追逐这个胡萝卜的过程中，我们担心有一个比我跑跑得更快的这个自动化的东西，然后他是去会抢我的胡萝卜。本身说这胡萝卜就不是给他的，就是为了让人跑起来了，其实他跑的更快。那时候并不是说他把胡萝卜抢走，是这个胡萝卜会被设计者拿走。我们再回头想一下，我们追逐胡萝卜的原因是啥来着？",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:03",
      "text": "为啥想要那胡萝卜？对，有的时候可能你都不不一定需要很多的物质的东西，是吧？就是被社会建构出来的一套理念。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:12",
      "text": "对对对，这个我觉得也是一种体会。其实之前看过一本书，他就讲人类其实在漫长的历史时期，其实大部分时间不用工作了。我吃饱之后我就在这个草原上躺着，然后围着我跳舞晒太阳。只有到了这个工业时代之后，每个人在这个办公室？才发明了这个所谓的996啥的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:30",
      "text": "我觉得就是我最近看哔哩哔哩上有很多所谓叫躺平主义的博主。然后他们可能也只是攒了可能一些钱，然后就回三四线的小城，然后用力气去养活自己，然后每天其实也活的田园牧歌？其实好的有价值的情绪也好，知识也好，是很便宜的。你30块钱一个月的微信读书，你可以看世界上所有的名字。20块钱的腾讯会员？可以看所有的视频。是的，其实并没有那么多所谓的胡萝卜需要追逐。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:04",
      "text": "对，就是最极端的是看到前一段时间有一个人，他好像就是在公园里住着，房租就不用掏房租。然后工作那可能就是我想工作的时候去工作一下，不想工作的时候我就躺着。真的是躺平，就是一个躺平的极端案例。他也没有很颓废，他也很平静。这个是让人很意外的，就是他完全是一种自己选择了这样的状态，他也可以去打工，但他没有去选择。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:30",
      "text": "对我就是觉得今天咱们聊的主题总会落实到借着这个机会思考一下人类的意义？我们的确就是从第一层面，我们不会担心人工智能取代了人类，取代了很多职业怎么办。第二个层面，如果取代了一些本身就是被人设计出来的职业，是不是对于整个人来说还挺好的？你说我原来比如说没有这个机械化的时候，每个人都要拿着锄头去耕地。对那有了机械化说，我们很担心他替代了好多的农民，这些农民没有工作怎么办？其实现在有更高效的种地的方式，更环境负责的这种耕地的方式，其实全整个人类也觉得是个好事。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:13",
      "text": "反而创造做一些有闲阶级就带来了知识的诞生。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:18",
      "text": "未来人们也可以找创造更多的新的这种工作岗位，是吧？可以可能也不需要工作那么久，可能一天工作两三个小时，其他时间会有更多的分享。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:28",
      "text": "是的，这个是乐观派的一种设想，就是当包括像OpenAI他们等等也讨论过，就当人工智能带来生产力的极大提升的时候，这个人均GDP其实是非常高的，是可以把很多人养起来的。所以他们在设计那个word coin就是那个世界币。就类似于你只要扫完了你的红信息，我就确认你的唯一标识之后，就会给你每个月发钱。对那他们也做这样的实验，就叫叫basic IUBI叫universal base income。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:57",
      "text": "比如说你这个工厂的工人被这个机器人取代之后，那我每个月给你发工资就行。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:01",
      "text": "对，一两千美金对吧？就是你看看你能过什么样的生活，他们也在做这样的实验。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:06",
      "text": "好的共产主义不就实现了吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:09",
      "text": "能保证你基本的这个生活水平。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:10",
      "text": "这种也是一种可能性。当然就是大家在讨论，学界也比较担心的会是另外一种，就是什么替代是吧？就包括被机器操控，被控制，然后包括这个存在主义的危机，然后甚至是说会有让大家变得很懒惰。大家都已经不需要去思考了，就把思考这件事情已经交给机器来做了。以前我们说就是体力劳动替代，现在是脑力劳动替代，甚至是智力活动替代。你看比如说你一开始要写个什么小说或者写个邮件，你还是需要动动脑子的。你要怎么表达是吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:44",
      "text": "要对对对，我昨天听到一个词，就是那个段中国的缎教授段伟文教授，他讲的是什么？废智，就类似于我把智力废除了，人现在其实最核心的是智力劳动。你说的这个不需要起草邮件，不需要写写书的标题，对吧？什么东西写了，这个代码都开发那天你把这里废掉，这意味着就是你把这里废掉之后，它不再进化了。进化说你一个东西用的越多，它会变得越好。如果你不再用自己的脑子的时候，你的脑子会变得越来越差。",
      "speaker": "发言人3"
    },
    {
      "time": "00:29:13",
      "text": "这里面可能会有一个关键问题，就是说智力活动能不能给人类带来愉悦感。创造会给人带来愉悦，让你产生那种有reka？就那种很很愉悦的感觉，那人还会去追求。对对对，但是如果是说你的这种愉悦感都是来自于信息摄入，什么小视频、短视频，关键是看人类还享不享受这个过程。对，思考的过程我。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:35",
      "text": "觉得可能就会分人就会被人类会退化。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:38",
      "text": "会分化。有的人可能会两极分化是吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:41",
      "text": "对，可能喜欢智力挑战的还会依然喜欢，哪怕人工智能可以回答所有复杂的问题，他可能也很享受这个推理的过程。但也有很多人所以我不知道这个词叫我之前听一个词叫奶头乐。就是让你用最低的成本，然后让你用最少的精力的投入，然后享受最大的快乐。就被动的去给你呈现一系列的视频也好，然后这个被搅得很碎的信息。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:09",
      "text": "我感觉这个可能未来有可能不是这个人工智能控制人，而是1%或者2%喜欢思考用脑的人控制。另外说一个。",
      "speaker": "发言人3"
    },
    {
      "time": "00:30:20",
      "text": "好问题，但为什么这些喜欢思考的人会同时会喜欢控制别人呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:25",
      "text": "因为他会有财富的积累，他可能也会追求权利，是不是？",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:31",
      "text": "或者说他觉得这是我的使命感，我得让这些有一个比较cozy的life。",
      "speaker": "发言人3"
    },
    {
      "time": "00:30:35",
      "text": "好像之前看过一个比较穿越小说？什么一眨眼就全世界人的智商都变成了1‱，只有他一个职场不变是吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:43",
      "text": "对，就是尤瓦尔的那个人类简史里面也说了这种情况。对，就是什么神人还是什么就分分了层，就是少数人拥有大部分资源，对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:54",
      "text": "然后可以控制未来。他说98%和99都是这种平庸的。这些人其实被那种神人，他有AI的这种能力控制的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:03",
      "text": "他有算力有显卡。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:05",
      "text": "未来可能是算力显卡在控制。现在不是已经靠资本，我们也是被控制的。我们大部分98%的普通人也是在被通过资本在被少数的人控制。是他只不过换了一个方式而已。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:18",
      "text": "是换了一个方式被控制。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:20",
      "text": "我觉得我们还是得得乐观一点，还是乐观的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:24",
      "text": "可能对他会还是那种历史周期，就被控制以后会反抗，然后反抗以后打破。但问题就是说你还有没有反抗抵抗的能力和机会，所以这个也是为什么在社会中要让大家要多思考，然后多讨论的一个原因。就让更多的人有这样的共识，在现在我们还能干预的情况下去提出自己的声音。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:47",
      "text": "这个给了我们普通人一次机会。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:49",
      "text": "或者有没有给普通人去拥抱这个时代的一些比较实在的一些建议。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:53",
      "text": "是我我们也不用考虑的这么遥远。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:56",
      "text": "建议谈不上，我觉得就是个人的一分享经验有点觉得有用的地方。就是当你做任何事的时候，想想如果这个东西靠large larger model来帮助你做的话，会怎么做。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:07",
      "text": "能不能更对更高效。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:08",
      "text": "对，因为你会发现节省自己非常大的精力，而且这个是必然。你养成了这样的一个思维方式之后，我觉得对未来的这种冲击感，屌的这种冲击或者替代的抵抗性会强一点。因为你会有一个很好的辨别能力，说哪些是容易被替代的，哪些是他们擅长做的活。我觉得可能在这个时代比较有优势的一批人是说能够快速驾驭这些技术。因为它的生产力的提升不再是像机械化，比如十倍、百倍的，它是成千上万倍的提升。拥有或者不拥有这个能力，可能在短期内，可能一个月之内你可能就能看到分晓，看到区别。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:48",
      "text": "最终还是要利用工具。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:50",
      "text": "所以第一条建议还是要持续去学习新的东西，对，尽早拥抱技术，达到跟你的这个结合。",
      "speaker": "发言人3"
    },
    {
      "time": "00:32:57",
      "text": "但这个其实是有一些阻力的。可能你日常生活中你每天都很忙碌，很多事情都已经排满了。然后你可能用传统的方式你就直接就干掉了。然后你可能说稍微多花一点时间，但是你要用新方式，你需要打破一个舒适区，要去学习，你要走出去。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:14",
      "text": "出去这种心态和行为习惯上的变化。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:18",
      "text": "对这个有一个建议，就是让形成一个圈子。就比如说你经常使用工具的人，要经常交流一下，大家是在怎么用，然后互相了解一下？学习一下同同被激励。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:29",
      "text": "对，多听这个播客。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:31",
      "text": "是对于这种除了日常工作之外，你在生活中也会用吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:37",
      "text": "生活中也用的挺多的。因为在美国其实很多的新的生活的场景是之前没有接触过的。随便举个例子，比如说处理车的保险的问题，保税保税。对，然后还有其实很多都是这个感觉跟在国内生活的时候不一样的。然后对于我来说，我又没有直接可以借鉴的人。这个拉手郎包的事无巨细的针对我的case来回答。因为在美国做咨询去雇人去，比如说律师也好，会计也好，做咨询还挺贵的对，那我直接问？20块钱一个月可以回答我各种方面的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:12",
      "text": "然后我觉得这个还是那你这个很值。对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:14",
      "text": "是美国这边有那个公司叫做阻挠的pay，他就可以帮你去处理。那你路边停车被贴了个罚单，你拍下来传给他他就很快给你写个邮件传给这个监管部门，然后去阿里邮箱。对，可以把这个罚款拿回来之前要聘个律师，可能得花几千美金，但是那可能就罚款只有200块钱。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:32",
      "text": "你这个是一个细分领域的这个对对对，相当于代理。对，那那未来AI有可能也会出现。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:39",
      "text": "AI其实已经我已经在用这个东西来帮我去跟商家去吵架了。之前买了个东西不喜欢，然后想退货，然后回复了很官方的邮件，然后我就让很长很多条款细节我也懒得看，其实也看不懂，然后就让垃圾那个model帮我总结一下，帮我总结一个回复邮件，然后告诉他强硬的要求我要退货，然后帮我找到相应的支持的条款。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:04",
      "text": "做的很棒。这个有点很很像代理了是吧？对，已经很像所谓代理，就是说他帮你去完成一个特定的目标和任务。对，就相当于不只是提供信息。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:14",
      "text": "对，其实现在比较广泛的大家理解large land model是一个chatbot，就一个对话体现形式。其实更多的是它可以就像你说的，刚才作为代理也好，或者作为一个叫做语言链条，就是有一个很好的框架。就long chain，就是language chain的可能缩写。他实现的功能是你给他描述一个你的目标，然后他large language model会根据你的目标拆解成细分的问题，然后他在回答自己的同时去分析自己每一步的思考，然后他再去做出下一步的去响应。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:47",
      "text": "对思维链能力。对对，这个也是大模型，可能最近也比较火，可能下一波也会更加的引起关注。就是agent这个问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:55",
      "text": "对我觉得代理肯定是一个趋势。为什么需要代理？刚才你一开始也讲，就我的人的知识是有限的。其实代理就是一个中介，让我买车买保险对吧？这个纳税我都需要找一个懂这个专业的对代理人帮我来处理这些事。是的，那为了这个agent他就成了一个虚拟代理商。",
      "speaker": "发言人3"
    },
    {
      "time": "00:36:13",
      "text": "比如说两个人吵架，或者说两个人有一个问题，都派自己的代理去AI然后他两个去接洽，会有一然后。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:21",
      "text": "两个人等着谁告诉我谁赢了是吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:24",
      "text": "谈好之后再反馈，就节省很多时间。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:27",
      "text": "可以。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:28",
      "text": "最后就变成一个AI设备了，人就坐在沙发上看看电视就好了。又回到这个其他东西都做了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:36:35",
      "text": "对，我们要乐观一点，那就从下一代的角度去讲一讲。因为我们面临的这个时代已经变化这么快了，下一代他们可能面临更多新的东西，那我们的教育怎么跟得上这个时代的发展？因为这个麦克也有小朋友，你觉得在下一代的这个培养方面有什么思考吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:54",
      "text": "对于他们这一代孩子，因为我儿子今年六岁快七岁了，等他长大的时候，整个世界就完全不一样。我觉得我并没有能力去支援他，或者说给他什么所谓的过来人的建议。然后因为我也是被过来的建议坑过的，一对过来人。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:10",
      "text": "的建议其实是最好少听。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:12",
      "text": "对，最好的建议就不要听。",
      "speaker": "发言人3"
    },
    {
      "time": "00:37:14",
      "text": "过来人的这是个很好的过来人的建议。对，但是对他的期待就是说他有一些基础的能力要掌握。比如说我比较看重的就是他阅读的能力和吸收新知识的这种接受度也好，或者思维能力。比如说他愿不愿意去接受一个新的他没有做过的一个挑战，或者了解一个新的领域。那如果他被给予一个新的，比如说他不了解的领域的问题的时候，他有没有这种收集信息，然后去整理信息去解决这个问题的能力。我觉得这些可能所谓的叫语言知识也好，语言能力也好，可能会对未来是有用的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:50",
      "text": "然后第一是阅读，第二就是对于美，对于价值观的鉴赏的能力。因为我觉得他这一代长大之后，会有非常多元的这种文化的冲击。就包括在美国现在有各种不同的主体意识是吧？那并没有一个说完全统一的东西。他等他长大的时候可能会越来越多。他可能会根据自己的成长，对于自己的喜好，会选择他的价值观的或者是一套体系。我希望他具备一个辨别的能力，而不是简单的说看了几条新闻，然后看了说别人忽悠一下，然后他就轻易的就加入了这个阵营。我接受他未来可能跟我的价值观不一致，我希望是他在经历过非常认真的思考，在对自己的生命和人生负责前提下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:38",
      "text": "选择了这个阵营，就是反思是吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:40",
      "text": "要经常反思。对，我是我很开放，说对于某些意识形态问题他跟我产生争吵，但是他如果能争吵的起来，我会非常欣赏。然后第三的话我觉得就是数理的能力，因为它代表着人类推理能力的一个体现。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:57",
      "text": "或者是理数数学数学脱离。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:01",
      "text": "我觉得这个其实是脱离不开了。未来可能拉伸number model或者说这些所谓的HI可以帮你做所有的数学问题。但是你一个人的推理能力或者说这个逻辑能力其实还是可以通过数学或者这些统计等等一系列的训练得到很好的成长。然后第四个可能就是身体上人工智能模型跑不快是吧？人类的价值就是我可以跑得快一点，然后活得久一点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:27",
      "text": "很有意思，你没有提到叫沟通能力。因为我们之前还说对人类来说剩下的还有啥沟通能力。但是想了想，如果真的有代理的话，是不是沟通能力也没那么重要。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:39",
      "text": "就看你跟谁沟通。如果你是跟商家去沟通，那不需要沟通。但如果你跟一些朋友啊亲密的这个伙伴，他是更多是一种情感的这种连接。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:49",
      "text": "因为你居然没有提我就很很。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:51",
      "text": "好奇或者同理心之类的。其实跟沟通。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:53",
      "text": "也是有对同理心或者在情绪控制方面的这些。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:57",
      "text": "我可能沟通就成问题。那可能就是你觉得。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:00",
      "text": "这个没有那么重要。对，就因为很多其实像工程师背景的，也不应该说能力问题。就是有的人他不想沟通，或者说我没有那么的外向，他其实也不是个太大的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:12",
      "text": "对我觉得可能回过来就是他找到了自己喜欢的生活方式，而且是基于他谨慎的思考和认真的这种梳理之后做出的决定。哪怕他不喜欢跟人沟通，我觉得也可以。对，就像刚才这样说的，就是未来可能对于沟通没有那么高的要求。可能越早期的社会，你比如说我们很多事情都完全依赖于沟通，对吧？我们需要跟商家去沟通，跟同事、跟客户等等去沟通。那未来这些可以去有AI去代表我去沟通的时候，那些之前有个叫A人艺人的概念？这个爱人是不是也可以活得更自在一点？",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:50",
      "text": "但可能带来一个问题，就是这个人不沟通的时候，就是人与人之间就越来越疏远。未来的沟通不是我们现在。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:57",
      "text": "这种形式的，所谓的表面上的，他可能这种更加深度的对，有个词叫叫领导力，有个词叫领导力leadership。对对对，leadership就是说这种leadership是说凝聚共识的能力，或者说你让别人理解你，或者你能理解别人，这个可能是一个可以替代的一个词。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:16",
      "text": "对，包括领导力，他是给大家找到一个共同的目标的，就是让我们这些人未来找到继续努力的或者奋斗的一个方向，一个目标。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:26",
      "text": "使命感我懂了，这也是可能从整个的人类共同的角度或者发展的角度，我可能就更会关注他自己孩子自己个体的发展可能会有点小家子气，但我会在意他自己喜不喜欢沟通，对吧？如果不喜欢东风，其实也无所谓。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:43",
      "text": "是的，这个肯定是没啥问题的。这里面的很多问题都是值得去深刻的去想。而且今天我们能想到这些，也是受限于我们今天接触到的信息和知识。就是随着跟大模型的共同演进，我觉得肯定会有很多新的想法出来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:00",
      "text": "我们处在一个非常好的时代，就是以纵观历史，其实人类并没有说是线性的发展了，都是停滞很长一段时间突然的。对，是。我们非常有幸在这样的一个快速变革快速增长的一个时代。这个时候对于比如说我们人类个体每个就比如说现在学生也好，或者工作的这种中年也好，可能要求会跟历史上不一一样，我们可能要更愿意去接受这个变革，去找准自己在变革过程中可能有价值或者存在的位置。然后我反而希望说我接下来的我的下一代或者未来的这些孩子们，可能又回到了这个比较稳定的历史的周期中，他们可以去enjoy life。但是至少说我们是被选中的一代，这一代估计是我们这一代可能很难在享受平静的说说跟前几代人都同样的生活。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:59",
      "text": "我比较希望我们还是对外乐未来保持一种这种审慎的乐观。还是要以这个虽然今天讨论了很多，这种感觉有点悲观，但还是要以乐观为主，但同时有一定的这种审慎对吧？对于风险和警醒定的这种警醒。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:13",
      "text": "非常开心跟大家聊这么多，这期我们就到这儿，然后大家再见，希望后面还有机会。",
      "speaker": "发言人2"
    }
  ],
  "lab_info": {
    "summary": "讨论者们集中探讨了人工智能（AI）对社会、教育及就业市场的深远影响。虽然当前AI在复杂逻辑推理方面表现出色，但其本质缺乏真正的意识和自我觉醒能力。对话中，正面效应如自动化、提高生产效率得到认可，同时也指出了潜在的负面影响，如就业结构变化、隐私安全威胁等。强调了对未来技术保持乐观态度的同时，需对可能的挑战保持警惕，并鼓励通过教育和终身学习来适应这些变化，提升个人竞争力。整体而言，对话倡导审慎乐观的态度，呼吁社会为AI时代的到来做好全面准备。",
    "qa_pairs": [
      {
        "question": "在大语言模型这波浪潮中，最大的改变是什么？或者说为什么一下子这么热？",
        "answer": "大语言模型这一波浪潮中最大的改变是它解决了一个基础模型或称为foundation model的问题。传统的模型学习是专业化模型，针对特定领域构建，而大语言模型具有普适性，可以理解多种类型的数据（如图像、文本），为后续开发提供更通用的基础，并且能够应用于不同的领域，甚至建立跨领域的知识和逻辑联系。",
        "time": "00:04:22"
      },
      {
        "question": "目前的大模型距离实现通用人工智能（AGI），即能够完成人类所能做的所有认知任务，我们是否已经到了那个阶段？",
        "answer": "就狭义上的一些任务而言，某些特定领域的基础模型确实有所突破，比如图像领域已经能够处理多种任务。但在跨领域结合应用和深度理解层面，例如从图像到文本、视频的转化等方面，目前还没有实现，但并不认为这是一个十年之后才会实现的问题。",
        "time": "00:06:22"
      },
      {
        "question": "对于当前的人工智能模型，它们是否具备自我意识或觉醒的能力？",
        "answer": "根据目前模型训练的数据量和文本尺度来看，现有的人工智能模型并不具备觉醒的能力，即自我察觉和动机等高级认知层面的能力。尽管它们能够回答复杂的逻辑推理问题，但意识与知识所处的层面并不相同。",
        "time": "00:07:33"
      },
      {
        "question": "如果人工智能强大到可以管控人类，为什么这件事一定是坏事？",
        "answer": "这个问题与人类中心主义的观点有关。人类认为自己是万物的主宰，但人工智能强大到管控人类时，是否一定是坏事，则取决于后续的发展。例如，人工智能可能选择与人类共生并共同进步，而非单纯的征服或消灭人类。",
        "time": "00:08:34"
      },
      {
        "question": "什么是价值对齐（alignment）？",
        "answer": "价值对齐是一个学术概念，主要指让人工智能模型的价值观与人类保持一致，在面临选择时，能够选择与人类认可的价值观方向一致的行动。",
        "time": "00:09:22"
      },
      {
        "question": "在规范人工智能时，应遵循什么样的价值观标准？",
        "answer": "规范人工智能时，可能参考联合国或其他国际组织所认可的一些价值标准，但更深层次的是人类社会普遍接受的一些基本原则，如安全、公平、尊重和诚实等。",
        "time": "00:10:57"
      },
      {
        "question": "是否倾向于在训练模型时只使用反映正确价值观的语料？",
        "answer": "在训练模型时，并非只使用正确价值观的语料，而是倾向于提供多样化的数据，包括好与坏的例子。这样可以确保模型在面对恶意或极端问题时能做出恰当的回应，经过训练后，模型能识别好坏，并在最终阶段通过正向反馈强化正确价值观，同时避免在未知情境下产生不负责任的答案。",
        "time": "00:13:00"
      },
      {
        "question": "在AI技术进步，特别是接近AGI的场景下，我们对判断标准有哪些变化？",
        "answer": "随着AI技术更接近AGI，我们的判断标准变得更加广泛、多样和复杂。不再仅关注单一的准确率指标，而是涉及多维度的评价体系。",
        "time": "00:15:17"
      },
      {
        "question": "对于日常生活和职业生涯的影响，您有什么个人体验或感受？",
        "answer": "大语言模型的应用极大地提高了个人工作效率，比如在撰写邮件时能够进行润色和改写，适应不同情绪表达。同时，在编码过程中，大型语言模型可以协助完成基础的逻辑编写、测试及简单系统设计，使得团队工作效率提升，初级工程师不再局限于做一些基础搬砖工作，而高级工程师则可以更专注于高级编程和代码审查。",
        "time": "00:18:01"
      },
      {
        "question": "那么对于初级工程师来说，面对这样的技术进步，他们的发展和成长面临什么挑战？",
        "answer": "初级工程师如果仅具备编写代码的能力，可能会在就业市场上竞争力减弱。他们需要提升综合性的能力，如对特定领域产品落地的思考、判断力以及好奇心，并学会在大语言模型等工具的帮助下，更好地专注于自己能提供的价值。此外，各大科技公司通常会承担社会责任，为应届毕业生提供实习和成长空间，但这并不意味着学生可以高枕无忧，仍需调整心态适应不断发展的就业市场。",
        "time": "00:19:26"
      },
      {
        "question": "未来是否会因为AI技术的发展，导致人类只需要管理AI，不需要具体工作？",
        "answer": "未来可能会出现这样的情况，AI辅助下的高级工程师能大大提高生产效率，甚至当AI能力足够强大时，一些工作岗位可能被取代，人们可能只需要负责高层次的产品管理或项目协调。不过，这也引发了对未来理想社会的思考，即人类与机器之间可能形成一种新的、高度协作的关系，而非完全取代。",
        "time": "00:22:38"
      },
      {
        "question": "在科幻动画片《万万神殿》中探讨了怎样的未来场景？",
        "answer": "在《万万神殿》这部科幻动画片中，讨论了一个理想的未来场景，即两个新物种共生共存，既没有被毁灭也没有毁灭对方，形成一种共生状态。",
        "time": "00:22:52"
      },
      {
        "question": "对于年轻人来说，在面对职业被人工智能替代的问题时，需要具备怎样的能力？",
        "answer": "对于现在的年轻人来说，他们需要有一种鉴别能力，能够意识到在某些层面上可能会被替代，但也要寻找不易被替代的工作领域，例如提供情绪价值的岗位，如脱口秀演员或心理咨询师等。",
        "time": "00:23:18"
      },
      {
        "question": "为什么人类害怕被人工智能取代？",
        "answer": "人类害怕被取代是因为当前社会定义的成功标准往往与物质财富、学历等紧密相关，追逐这些“胡萝卜”以实现社会设定的成功目标时，担心自动化技术会抢占先机。但实际上，这些追求并非必需，而是社会建构出来的理念。",
        "time": "00:24:22"
      },
      {
        "question": "是否存在人们选择“躺平”，不追求传统成功状态的例子？",
        "answer": "是的，有些博主提倡“躺平主义”，他们选择在三四线城市过着简单宁静的生活，认为有价值的知识和情绪其实很便宜，不需要过多物质追求来换取。",
        "time": "00:25:30"
      },
      {
        "question": "人工智能带来的生产力提升会对人类社会产生何种影响？",
        "answer": "当人工智能极大提升生产力时，人均GDP会提高，甚至有可能实现普遍基本收入（universal basic income），让被取代的职业者也能得到保障，从而部分解决就业问题。但也有人担忧，人工智能可能会带来被机器操控、存在主义危机以及让人变得懒惰，不再思考，丧失智力活动能力。",
        "time": "00:27:28"
      },
      {
        "question": "智力活动对于人类的意义是什么？",
        "answer": "智力活动对于人类而言非常重要，因为它能带来愉悦感和创造性发挥，这是目前机器无法替代的。但如果人们过度依赖信息摄入而不去思考，可能导致智力退化。是否继续享受思考过程所带来的愉悦感，将决定人类是否会因技术发展而退化。",
        "time": "00:29:13"
      },
      {
        "question": "在人工智能技术的发展下，未来是否会出现少部分人通过AI控制大部分人的现象？",
        "answer": "是的，未来可能会出现这种情况，就像尤瓦尔在《人类简史》中描述的那样，少数人拥有大部分资源，并通过AI能力控制其他人。",
        "time": "00:30:43"
      },
      {
        "question": "为什么喜欢思考、用脑的人会同时喜欢控制别人？",
        "answer": "这类人可能追求财富积累和权力，也可能是出于他们的使命感，想要让其他人过上舒适的生活。",
        "time": "00:30:25"
      },
      {
        "question": "对于普通人如何应对这个时代的技术冲击，有什么建议吗？",
        "answer": "建议大家持续学习新的东西，尽早拥抱技术并与之结合，养成利用大型语言模型的习惯，以提高效率并增强对未来的适应能力和抵抗性。",
        "time": "00:32:50"
      },
      {
        "question": "是否有一些具体的生活场景中可以应用AI工具的例子？",
        "answer": "在生活中，可以使用AI工具处理诸如车险理赔、解决罚单等问题，甚至在与商家沟通时，通过AI模型帮写邮件要求退货等，这些都相当于AI代理功能的应用。",
        "time": "00:34:39"
      },
      {
        "question": "AI在未来是否有可能成为人们进行交流谈判的代理人？",
        "answer": "是的，AI作为代理的趋势将会越来越明显，它能够根据用户的目标拆解问题、分析思考过程，并做出下一步响应，就像一个虚拟代理商，帮助人们节省时间和精力，进行高效的沟通交流。",
        "time": "00:35:14"
      },
      {
        "question": "在下一代的培养方面，您有什么思考吗？",
        "answer": "对于下一代，我并不认为自己能给出过来人的建议，但对他们的基本能力有所期待，比如阅读能力、吸收新知识的接受度、思维能力以及面对新挑战时收集、整理信息并解决问题的能力。此外，培养他们对美的鉴赏力和价值观辨识能力也非常重要，让他们在多元文化冲击下具备辨别和思考的能力，而非轻易被外界影响。",
        "time": "00:37:14"
      },
      {
        "question": "您提到的四个重点能力是什么？",
        "answer": "首先是阅读能力，其次是鉴赏美和价值观的能力；第三是数理能力，因为这是推理能力的体现；最后是身体运动能力，即人类能够跑得快、活得久。",
        "time": "00:38:40"
      },
      {
        "question": "沟通能力在未来的社会中是否重要？",
        "answer": "沟通能力的重要性取决于沟通对象。在与商家等无需情感连接的场合，沟通需求降低；而在朋友或亲密伙伴间，则更多关乎情感交流。随着AI的发展，部分沟通需求可能被替代，但深层次的领导力（leadership）和共鸣能力依然重要。",
        "time": "00:39:39"
      },
      {
        "question": "是否认为沟通能力和同理心在未来的社会中不再那么重要？",
        "answer": "虽然某些情况下，如工程师背景的人可能不太注重沟通，但如果能基于谨慎思考和认真梳理后做出决定，即使不喜欢沟通也没问题。未来社会中，AI可以代表个体进行沟通，但人与人之间的深度交流和理解他人的情感控制能力（同理心）仍然至关重要。",
        "time": "00:40:12"
      },
      {
        "question": "对于未来社会中个体的角色定位和个体发展，您怎么看？",
        "answer": "在快速变革的时代，个体需要更愿意接受变革，并找准自己在变革中的价值和位置。对于下一代，希望他们在相对稳定的时期能享受生活，但同时也要认识到我们这一代面临的挑战和风险，保持审慎乐观态度，并对未来发展保持警醒。",
        "time": "00:42:00"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探讨AI技术对社会的影响与未来教育的反思",
        "summary": "本期节目聚焦于AI技术的发展及其对社会带来的影响，同时对未来教育方式进行了深入的反思。讨论中强调，尽管AI在逻辑推理方面取得了显著进步，但它并不具备真正的意识或觉醒能力。此外，通过与硅谷科技从业者的交流，揭示了AI技术的最新进展及其社会影响，同时也指出了人类在面临科技快速发展时应如何找准自身定位，接受变革，寻找价值。"
      },
      {
        "time": "00:03:56",
        "title": "大语言模型对人工智能领域的影响及未来展望",
        "summary": "大语言模型的兴起标志着人工智能领域的一个重大转变，其核心在于解决基础模型或foundation model的问题，使得模型具有更强的普适性。与以往专注于解决特定领域问题的专业化模型不同，大语言模型能够理解广泛的图像和文本，从而简化后续开发工作，并在多个领域中实现能力的泛化。此外，大语言模型在探索跨领域知识连接方面展现了巨大潜力，有可能揭示人类之前未曾发现的知识联系。尽管当前的大语言模型在图形等领域展现出一定程度的通用性，但在实现真正意义上的通用人工智能（AGI）方面，仍面临挑战，尤其是在跨领域应用、自我意识觉醒等方面。对未来而言，虽然存在不确定性，但大语言模型的发展为实现更加通用和深度的人工智能奠定了基础。"
      },
      {
        "time": "00:08:16",
        "title": "探讨人工智能与人类共生及价值观对齐",
        "summary": "讨论集中于人工智能（AI）的发展及其与人类社会的关系，特别是AI的强大是否必然对人类构成威胁，以及AI与人类共生的可能性。提出，即便AI发展至能管控人类的程度，也不一定是坏事，强调价值对齐的重要性，即让AI的价值观与人类保持一致。讨论还触及如何定义和统一人类的价值观，作为规范AI发展的基础。同时，提出在训练AI模型时，应教导其学习人类的基本品质，如诚信、尊重等，以促进AI和人类社会的和谐共存。"
      },
      {
        "time": "00:12:01",
        "title": "探讨人工智能的社会化与价值观对齐",
        "summary": "讨论集中在如何使人工智能（AI）实现社会化，以及在训练AI模型时应如何处理含有不同价值观的数据。一方面，通过提供多样化数据让AI学习到社会的基本规范和道德价值观，从而更好地融入社会。另一方面，担忧仅提供正面数据可能导致AI无法应对恶意问题。因此，提出在训练阶段给予AI多样化的数据，包括正面和负面信息，最后通过正向的人类反馈，让AI理解并遵循正确的价值观，即使面对恶意或暴力信息也能保持正确的应对方式。这种方法类比于人类对孩子的教育，强调在面对世界各种情况时，保持正直和理性的能力。"
      },
      {
        "time": "00:15:08",
        "title": "AI技术对日常工作的积极影响",
        "summary": "AI技术，尤其是大语言模型，显著提高了工作效率。在管理工作中，通过AI辅助邮件撰写，能够更好地表达情绪，减少语言障碍。此外，AI还能够处理写代码、单元测试等基础且重复性高的任务，减轻了工程师的负担，使得团队能更高效地完成任务。这种技术的应用减少了对初级工程师的需求，让资深工程师能专注于更重要的工作，如代码审查和系统设计，从而提高了整体的工作效率和生产力。"
      },
      {
        "time": "00:19:21",
        "title": "硅谷初级工程师面临的挑战及成长困境",
        "summary": "在硅谷，初级工程师特别是刚毕业的学生在求职过程中遇到困难，即便是一些名校的毕业生也不例外。这反映了市场上对仅仅具备基础编程能力的工程师需求减少，而更加重视具有综合能力，如产品落地思考能力和软实力的工程师。尽管大厂承担着招聘应届生的社会责任，提供成长空间，但这种情况的可持续性受到质疑，对于许多初级工程师而言，成长的机会变得越来越稀缺。因此，调整心态，增强自身在特定领域的综合能力成为关键。"
      },
      {
        "time": "00:21:25",
        "title": "探讨人工智能对未来职业的影响",
        "summary": "本次对话围绕人工智能技术的发展对就业市场，尤其是程序员和数据分析师等职业的潜在影响展开讨论。讨论内容包括专家访谈中对编程替代可能引起的就业市场变化的见解，以及人工智能增强工作辅助能力对未来工作岗位需求的可能影响。此外，还讨论了科幻动画《万万神殿》中对于未来人与机器共生关系的想象，以及人工智能技术可能带来的社会与职业变迁，强调了识别不易被替代职业的重要性，如提供情感价值的职业。"
      },
      {
        "time": "00:24:22",
        "title": "探讨人类对被替代的恐惧与生活意义",
        "summary": "对话围绕人类对被人工智能替代的担忧展开，讨论了现代社会对成功的定义如何驱动人们追求物质财富，以及这种追求如何受到自动化技术的威胁。进一步地，讨论了人们对于工作、生活价值的反思，指出历史上大部分时间人类并不需要繁重的工作。随着工业时代的发展，人们开始质疑追逐物质财富的必要性。同时，探讨了躺平主义的生活态度，以及人工智能进步可能带来的社会变革，如基本收入保障的可能性和智力劳动被替代的担忧。最终，反思了智力活动给人类带来的愉悦感和生活意义的探寻。"
      },
      {
        "time": "00:29:35",
        "title": "人工智能对未来社会的影响与人类分化",
        "summary": "讨论集中在人工智能如何可能导致人类社会的分化，以及对个体智力挑战的喜好的影响。一方面，部分人可能因享受推理过程而继续追求智力挑战，而另一方面，可能产生所谓“奶头乐”现象，即通过低成本、低精力投入的方式获得极大快乐。此外，还探讨了未来社会可能由少数喜欢思考和用脑的人控制，他们通过财富积累追求权力，甚至可能基于使命感希望为他人创造舒适生活。最后，提出在社会中鼓励更多思考和讨论的重要性，以促进共识和可能的反抗，防止完全被技术和资本控制。"
      },
      {
        "time": "00:31:47",
        "title": "适应技术革新，提升个人竞争力",
        "summary": "对话强调了普通人应如何拥抱时代变迁，尤其是技术的进步。建议人们在做任何事情时，考虑是否可以借助大型模型提高效率，从而节省精力。这种思维方式有助于增强对技术冲击的抵抗力和辨识能力，指出能够迅速掌握技术的人将在这个时代更具优势。技术的运用可以使生产力成千上万倍提升，因此学习新技术、早拥抱技术并与之结合变得尤为重要。尽管日常生活中存在学习新事物的阻力，但打破舒适区、形成学习圈子和互相激励被看作是克服这些阻力的有效方法。此外，经常交流工具的使用方法和倾听相关播客也被推荐为提升技术应用能力的途径。"
      },
      {
        "time": "00:33:36",
        "title": "适应美国生活与利用AI解决问题的智慧",
        "summary": "讨论重点在于如何在美国这个全新的生活环境中，利用AI技术来解决日常遇到的问题，如处理车辆保险、停车罚单等。通过使用AI代理服务，人们可以以较低的成本获取专业的建议和帮助，这不仅体现了技术的进步，也展现了人们对于新技术的接受和利用。此外，对话还触及了对未来教育的思考，强调培养下一代面对快速变化世界所需的基础能力和思维能力，如阅读、吸收新知识的能力，以及对多元文化的理解和鉴赏力。"
      },
      {
        "time": "00:38:38",
        "title": "反思、沟通与未来：人类价值与能力的探讨",
        "summary": "本次对话集中讨论了个人反思的重要性、对意识形态的开放态度、数理能力的培养、身体能力与人工智能的比较、以及沟通能力在未来社会的重要性减弱等问题。特别强调了尽管未来技术可能替代人类执行某些任务，但推理能力、同理心和领导力等仍然是人类不可或缺的特质。此外，也触及了人类如何适应快速变革时代，以及对未来持审慎乐观态度的必要性。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "不具备自我觉醒的能力"
                },
                {
                  "children": [],
                  "content": "可以解决复杂逻辑推理问题"
                }
              ],
              "content": "AI模型的觉醒能力"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "大语言模型的兴起"
                },
                {
                  "children": [],
                  "content": "通用人工智能（AGI）的讨论"
                }
              ],
              "content": "AI技术的发展"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "价值对齐问题"
                },
                {
                  "children": [],
                  "content": "人类价值观的多样性与冲突"
                }
              ],
              "content": "社会规范与AI"
            }
          ],
          "content": "人工智能与社会发展"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "提升邮件撰写效率"
                },
                {
                  "children": [],
                  "content": "代码编写与测试"
                }
              ],
              "content": "AI在工作中的应用"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "职业替代的担忧"
                },
                {
                  "children": [],
                  "content": "人力资源的重新配置"
                }
              ],
              "content": "对职业的影响"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI代理的可能"
                },
                {
                  "children": [],
                  "content": "新型工作模式的出现"
                }
              ],
              "content": "未来工作的展望"
            }
          ],
          "content": "AI技术应用与影响"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "阅读能力"
                },
                {
                  "children": [],
                  "content": "数理逻辑能力"
                }
              ],
              "content": "基础能力培养"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "接受新知识的能力"
                },
                {
                  "children": [],
                  "content": "问题解决能力"
                }
              ],
              "content": "对未来社会的适应"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "培养独立思考"
                },
                {
                  "children": [],
                  "content": "面对多元文化的适应能力"
                }
              ],
              "content": "价值观与个性发展"
            }
          ],
          "content": "教育与未来准备"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "从执行者到设计者"
                },
                {
                  "children": [],
                  "content": "从劳动者到管理者"
                }
              ],
              "content": "人类角色的转变"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "生产力的极大提升"
                },
                {
                  "children": [],
                  "content": "社会结构与工作方式的变化"
                }
              ],
              "content": "AI带来的社会变革"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "教育内容与方法的革新"
                },
                {
                  "children": [],
                  "content": "培养面向未来的技能与思维"
                }
              ],
              "content": "对未来教育的反思"
            }
          ],
          "content": "人与AI共生的未来"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "持续学习与自我提升"
                },
                {
                  "children": [],
                  "content": "接受并适应技术变革"
                }
              ],
              "content": "个体层面"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "价值观的共识构建"
                },
                {
                  "children": [],
                  "content": "公平、安全的社会环境构建"
                }
              ],
              "content": "社会层面"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "对技术进步的积极看待"
                },
                {
                  "children": [],
                  "content": "社会与个体的共生发展"
                }
              ],
              "content": "未来的乐观态度"
            }
          ],
          "content": "对个体与社会的建议"
        }
      ],
      "content": "对话脑图摘要"
    }
  }
}