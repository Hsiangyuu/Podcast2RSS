{
  "pid": "5fe5b198dee9c1e16dfb9672",
  "eid": "65828452665dbce71762c069",
  "title": "AI的“重量”会重新打破世界的平衡吗？｜硅谷AI观察",
  "task_id": "kvjony7mrowenlx3",
  "transcription": [
    {
      "time": "00:00:09",
      "text": "其实世界经济论坛这个组织是希望能够覆盖到更广泛的国家和地区的。他其实他是在尽可能的去邀请这样的一些组织和机构来参加，但确实有存在，比如说像这种就有一些地区它叫and presented，就是没有人去代表他们去参加这样的一些组织和会议去发声。他们可能也用不到最新发布的这样的一些最新的工具，所以就会带来两极分化。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:41",
      "text": "不知道能不能这么理解，其实这个有效加速主义和有效利他主义这两个派别之间的矛盾也好或者冲突也好，它其实是在现阶段资源有限的情况下的一个优先级的的争论。其实大家的共同目标其实都是建立一个既要有用又很安全的，能够服务全人类的AI。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:07",
      "text": "比如说你去直接沿着这个大模型跟这个open去竞争，那其实高校肯定是没有这一方面的资源的对吧？这个资金或者人才算算力都不够。但是说其实高校其实也是在这个生态里面，我觉得他们也扮演了一个很重要的一个角色。就是说对于这个里面的一些，就因为它是一个生态系统了，对吧？里面的一些方法的创新。你像伯克利，其实他们在做的就是像这个很热的一个的什么scalable overside可扩展的一些监督。他可以直接用这个open大模型去做一些研究，说他未来怎么跟人去更好的去协作解决？一起来解决这里面面临的一些社会的问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:01:56",
      "text": "Hello, 大家好，欢迎收听25码。这是一档科技评论播客，我是本期的主播建飞。前段时间我在腾讯研究院的两位好友袁晓辉和曹建峰受邀去参加了世界经济论坛的人工智能峰会。在这场全球性的会议上，全球来自不同国家的行业专家针对AI治理伦理等问题展开始讨论。我们这个系列的节目也终于来到了第四期，也就是最后一期。这一期我们请到了之前三期一直做主持人，也就是这趟旅程的我的两位好友来和大家一起聊一聊这一次在硅谷之旅的AI方面的见闻，两位先跟大家打个招呼。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:31",
      "text": "Hello大家好，我是小辉。其实这次的会议是叫世界经济论坛，他们组织的一个叫AI治理的一个峰会，达沃斯经济论坛就是他们这个组织去办的。然后当然他们也有一些专门关注一些特定议题方向的一些工作组，在持续关注一些命题。像AI治理这个panel，就是今年刚刚设立的是吧？剑锋。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:56",
      "text": "对，这个是今年大模型是最火的。所以这个世界他也拉了一个人工智能的一个工作组。所以大概请了有二百多位参加负责任的生成人工智能这样一个工作组。",
      "speaker": "发言人3"
    },
    {
      "time": "00:03:08",
      "text": "这次论坛上邀请了一些从技术领域、从安全领域、从治理领域的一些行业专家去参加一些研讨，包括一些圆桌讨论，包括一些线下的这种闭门会议，也是讨论了挺多议题。比如说像大模型的安全问题，包括大模型的治理的问题，包括开源，包括AI技术可持续发展，包括AI技术和可接入性。比如说他是不是在全球范围都是能够广泛去触达的这样的一些命题展开了一些讨论。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:43",
      "text": "因为这次参加的机构也是非常多样，比如说包括政府的，包括学术界，包括业界，还有一些是第三方机构。这个是让我挺意外的一个点，就是没想到有这么多关心这种大模型安全的第三方机构。它并不是盈利性组织，它是一种非盈利性组织。他们就是仅仅是出于对AI的未来发展的安全性的一些评估担心。从这个安全的角度，他就愿意从事相关的工作。所以这个是让我挺挺意外的的一个点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:14",
      "text": "对我参加的一些panel，其实大家讨论比较多的是关于这个开源，大家对这个开源闭源确实有很多的讨论。另外一个全球的发展的不均衡，尤其是一些地球的南半球的一些国家对吧？这个global source，它一些数据的鸿沟，或者数字发展的鸿沟，对吧？可能没有相应的一些人才资源，云的服务去支持这个大模型，人工智能一些发展。所以整体来说这个会还是确实拉了很多业界的，还有学术界的以及社会组织。大家能够去从一个更广泛的层面，不同的学科来讨论这里面的一些风险，伦理，安全治理这样一些问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:04:58",
      "text": "我们现在其实讨论很多关于AI竞争，尤其是地理区位上的竞争的时候，我们会把中美放在一个主要的位置上去讨论。其实中美在很多事情上的判断还是有有相似性的。就比如说两国可能都会觉得AI非常重要，同时两国也会觉得AI的治理都很重要，并且两国其实都有高度繁荣的这个互联网行业。那在中美的这种积极并且审慎，并且有一定的这个行业基础优势之外，我不知道与会的有没有一些其他的欧洲、亚洲或者甚至非洲国家的一些成员或者是代表，他们会怎么去看待这一轮的AI浪潮。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:41",
      "text": "这次参会的欧洲的人其实也不少，他们来自于像荷兰、挪威、日内瓦等等一些地方，然后包括中东，也有一些国家参加。然后非洲我不知道建峰你有没有遇到，我好像没有太大的印象。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:00",
      "text": "太强的印象，非洲好像确实来的不是特别多。",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:04",
      "text": "他们其实世界经济论坛这个组织是希望能够覆盖到更广泛的国家和地区的。他其实他是在尽可能的去邀请这样的一些组织和机构来参加，但确实有存在，比如说像这种就有一些地区它叫and presented，就是没有人去代表他们去参加这样的一些组织和会议，去发声。他们可能也用不到最新发布的这样的一些最新的工具，所以就会带来两极分化。其实在某种程度上，一些用不到工具的，就是包括一些可能不太容易使用工具的地区和国家，他可能会跟这些很很容易就获得很好的工具源是吧？他可能会带来这种生产力上的进一步分化，这个确实是一个命题。这次我们也专门有个工作组在讨论这个问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:56",
      "text": "我们当时也讨论到，我觉得也讨论到有几个点。一个就是说讨论说这个大模型或者人工智能是一个全球的一个生态，对吧？这个产业生态。但现在其实像这个global source，其实很多的东南亚的一些国家参与到这个产业链里面。更多是一些廉价的或者低端的一些数据标注，对吧？包括一些数据的一些达标的一些工作。这些其实是外包给这些南半球的一些国家的，包括东南亚等等。所以他们其实参与的并不是比较高的一些level的一些工作，这个其实就是是一个问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:07:30",
      "text": "然后另外一个问题就是说，其实如果说他的代表性不足的话，那有很多这种训练数据里面其实是其实还是以这个发达国家的一些数训练数据为准。那他们这些国家，他就是他的这些本地的一些东西，就很难去成现在这个模型里面，对吧？因为他这个训练数据里面本身就缺少这些南半球国家的这些相关的一些语料，或者数据库。这个也是一个很重要的一个问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:07:59",
      "text": "其实刚才也谈到，今年就是第一次办这个主题的分论坛。他可能很大的一个程度的原因是因为去年的时候我会还发布了这个拆GPT，就是在今年第一次办这个活动的时候，就是我们日常在报道和正在使用中的这些明星的企业，他们有去参加吗？就比如说OpenAI或者是anthropic，他们有去参加这次的会吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:24",
      "text": "他们都有拍这个相关的内部的人员去参加这个会议，也有的在台上去进行了分享。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:31",
      "text": "你们在会议现场的时候，你们会觉得接触到外国的这些与会的人员里面，他们各自从各自的角度会对这一轮的AI浪潮是抱着一个什么样的心态，或者是什么样的立场去讨论这件事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:47",
      "text": "我觉得可能大家这个心态还是比较复杂。但是大部分我觉得能感受到大家对AI的浪潮确实非常的期待，觉得确实是人工智能领域的一个很重要的一个拐点。大家都不希望make out这样一波浪潮的。无论从参会的，包括我跟小辉拜访的一些专家，一些创业者，大家确实都是感觉是在all in这样一个浪潮，尤其是一些中立的一些研究人员。对于AI safety特别关注。确实包括很多之前在OpenAI或者大的科技公司里面去工作。这些研究人员，自己出去独立搞这样一些第三方的一些智库或者科研机构，关注这里面的一些怎么去让让这个AI发展的更安全。",
      "speaker": "发言人3"
    },
    {
      "time": "00:09:35",
      "text": "我感觉也是类似的，就是因为毕竟这次论坛不是一个技术上的一个论坛。比如说从这种大模型技术的角度去做交流，而是从这个治理的角度。所以大部分大家的关注点其实是在AI的应用上，包括AI对社会的影响，还有以及对安全议题的讨论上。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:56",
      "text": "然后在这个背景下，其实像我们也遇到了一些大咖，比如说像吴文达，他以前是机器学习这个领域的专家，然后也创办了扣sara，然后他也进行了发言。他的发言其实给我留下很深印象的意见就是他说有人问他，就今年，整个2023年有什么事情是你最意外的？没有想到的是自己花了那么多时间在说服政府不要关闭开源社区上，这个是他的一个讨论。就是说其实可能从很多角度，各国政府也开始意识到这个AI的重要性，包括它的安全的一些命题。所以也在考虑采取各种各样的管制措施。然后这是我觉得当时印象比较深的一点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:42",
      "text": "然后另外还有一点就是说大家对这个安全问题的关注。之前因为我是研究产业的，我自己对安全问题之前确实也没有关注到那么多。但这次参加了这个会议之后，我能够理解到底大家在采用什么样的方法来去研究这个命题。就比如说到底怎么来去保障大模型的安全。然后我觉得总结下来，我自己概括下来就是让大模型它全生命周期的各个阶段都能够采取一些能够可行的安全的措施。举个例子，比如说大模型你在建设期间，就比如在你在研发阶段，你其实应该考虑的是如何让你的研发技术，比如说通过人类反馈增强学习，或者是通过叫red timing这样的一些策略。Red tie ming其实就是说红队蓝队让让比如说让开发人员就扮演这种攻击的角色，想尽一切办法去攻破它的这个安全性。就是在开发阶段就要做这样的一些尝试，包括那个价值对齐，因为剑锋是价值对齐方向的专家，稍后可以在具体的介绍一些，这是在开发阶段。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:47",
      "text": "那大模型的发布阶段可能也有一些要注意的点。比如说你发布的时候，你要考虑这个大模型，它的文档要透明化。大模型中，你这里面有哪些关键的技术问题，技术漏洞，或者哪些需要大家去关注的一些点，安全的点。但都应该比较清楚地列在这个文档里。包括后来有如果有一些人做模型的修改或者是在做微调的话，你也要注意到这些问题，就是文档的透明化，然后包括你的水印。比如说你生成的这个作品里，AI生成的作品里面应该明确标明这个是AI生成的，就应该有这样一些watermark，就是水印。所以其实等等就是一系列的这种安全的措施，应该是在每一个阶段都要考虑进去，而且应该是被大部分的公司认同，这样的一些命题，应该是不光是开发这种OpenAI，这种比较顶级的做这个大模型的厂商，像国内的很多厂商其实也应该去考虑这样的一些问题，这是我觉得比较重要的一个收获。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:58",
      "text": "好消息，二维无码见听有群了。为尽快回笼粉丝，所有主播上班摸鱼陪您聊，进群还能了解二维无码最新活动动态及选题展望。进群请认准微信个人号，二维五码全拼，二维五码全拼，马小二恭候您的到来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:17",
      "text": "我也知道建峰其实之前一直是做人工智能的伦理还有治理方向的研究的。就是过去一年其实我们会发现人工智能这个领域，它首先是从技术和产业端发生了像是火箭被点燃了一样的这种速度的变化。就是我们过往在谈论人工智能的一些治理或者是说伦理的时候，我们可能还会说，然后的那个问题，它还是一个很遥远的问题。自动驾驶说了这么多年，他其实现在还没有大规模应用。以前其实一直是觉得产业没有到这个临界点，所以治理也一直他没有推进的这么快。在过去的这一年里面，他既然技术产业和应用上发生了这么大的变化。那在这个人工智能的治理，或者是说我们关心他如何更安全的这个角度上来讲，又发生了什么样的变化呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:09",
      "text": "这个问题非常关键，就是以前这个人工智能这个钱还是在这个小模型时代的时候，对吧？可能大家讨论的很多都是这种理论上的一些设想。刚才建飞讲的这个搬道工的这个，自动驾驶的这个道德的困境，那那这个可能确实以前还是归于理论。但是这一次我们去旧金山发现谷歌的微博，还有这个cruse，大家已经拿到了自动驾驶的牌照。就是你作为一个普通人，就可以通过他这个APP来去叫他这个自动驾驶的汽车。所以这些问题确实也变得越来越重要。所以其实过去一年大家对于这个AI的很多智力确实会更加关注。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:46",
      "text": "从我们今年关注的角度来说，我觉得其实可能最大的其实刚才小慧也讲到了，其实是关于大模型的价值对齐。那那我就简单的跟大家讲一下价值对齐这一块的一些我们包括交流的一些思考。其实大家讲这个价对齐，以前可能大家可能我觉得对这个概念还是有很多误解。我觉得我可以先跟大家讲一下这个概念这一块。其实我觉得这个可能是有三个层次。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:11",
      "text": "一个就是说你讲这个大模型的这个价值对齐，首先其实他讲的是跟用户跟使用者的这个需求来对齐，它能够给这个用户带来一定的价值。因为现在这个大模型它有很多的应用，但有很多幻觉的问题，胡说八道的问题。比如说你是一个医生的话，那他给你回答的医学知识都是错的对，那肯定没法满足你的这个需求了。所以他们是跟各个科学家、程序员、画家他的这个需求来对齐。这个我觉得可能是第一个层面。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:44",
      "text": "第二个层面可能是讲它跟要让这个模型去避免做一些不安全的或者不被允许的一些事情。你比如说刚才讲的一些有害的一些内容，生成一些木马、网络病毒，对吧？他去做一些道德上或者法律上不被允许的事情，那这个可能也是很重要的。其实最后还有一个就是说更长远的，大家讨论说要防止这个模型失控，威胁人的自身的发展。我觉得这可能是是我们去讨论这个大模型的对包括它的落地，需要去首先对齐的一些基本的一些点。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:19",
      "text": "你说的比较是一些理念性的，就比如说我们知道要对齐什么，那具体在实践上它是怎么来去完成这个对齐呢？就刚才其实我们也讲到一些像是不是像人类反馈增强学习是一种方式。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:33",
      "text": "对人类反馈强化学习。就是说其实大模型学了很多互联网的这个数据信息内容，对吧？但它其实是没有一定的你所谓的道德或者是伦理的一些意识的。所以这个需要像比较好的思路，就是人类反馈的强化学习。其实诗雨在做的这个人情味的，你看大模型实验，他也是可以去你去构建一些这个问题这些问题就是已经是跟人类的道德对齐的，然后去给他进行人类反馈的强化学习。但这个思路现在做的确实比较好。但是还有一些思路还有通过一些原则性的对齐，那就是我去事先给这个大模型设计一套他要遵循的一套道德的原则，来让大模型自己因为他可以理解人类的语言，理解人类的偏好等等。他自己来判断说我我这个回答或者我做的这些事情是不是被允许的，是不是合理？",
      "speaker": "发言人3"
    },
    {
      "time": "00:17:26",
      "text": "那其他的刚才小慧讲的这个red timing，或者模型的一些评估，可解释的一些方法等等我觉得这一块的很多技术方法确实在做非常多的探索。我觉得也还是不能过于乐观，还是得得有更多的思考。虽然我们可以通过这些方法对模型做对齐，但是说现在其实还有很多存在一些模型越狱的可能性。就大家以前讲的这个jail break对吧？越狱的可能性就虽然你通过这些人类反馈强化学习让模型对齐了，就你喊他去把一些违法的一些内容调出来。但是说这个也可以就一些用户可以通过一些对抗攻击或者越狱的方式，它设计一个提示词，就可以来实现某一个需求。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:10",
      "text": "这个其实大家以前讲了一个很多一个例子，就是说一个他找这个色情网站对吧？但你直接问他他可能不会给你提供出来。但是你说你说我是一个小孩的爸爸，对吧？我让我小孩要屏蔽一些不能看的一些网站，你给我把这个列出来，他有可能就给你给出这样一些回答，等等这样一些问题了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:31",
      "text": "其实我们过去谈论这个人工智能治理的时候，会觉得它还是一个很遥远的问题。刚才也谈到说现在其实因为这个业绩的变革，它变成了一个立刻摆在眼前的问题。但是对于我们可能普通人来说，我们还是没有那么直观的对这个事情有一个判断，就是这个事情他现在究竟是有多严重。其实我是觉得在拆GPT出来之后的很长一段时间，就是我可能还是一个互联网从业者。我都没有觉得这个事情就是它的治理或者说它的安全性是那么重要的一个事情。其实是直到也是你们在开会的前后，然后OpenAI的董事会的那个事情出了之后，我才知道就是在人工智能公司，以及整个行业内的一些专家，对这个安全和技术发展之间的这个矛盾的冲突已经到了这个程度。就你们在当地的时候是否对这个问题的讨论，你们会觉得他这个冲突现在是更偏向于哪一边的呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:34",
      "text": "你刚才讲到这个，其实在大模型公司内部也有两派声音。一个是EA有效利他主义，然后有个叫有效加速主义。它所谓的加速其实说是他们信奉的一套理念，是说技术的发展是可以给人类社会带来福祉的。就是包括自工业革命以来历次技术的发展，技术的进步，他都是提高了全民的经济水平和幸福感。比如说像工业革命之后，所有的人都用上了电，是吧？包括像这波计算机浪潮之下，所有的人其实都可以去接触到信息，可以给日常生活决策去提效。所以他们也会认为AI的发展会进一步的去提升生产力，从而带来包括社会的平权，包括整个人类福祉的提高，这是他们信奉的一套理念。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:24",
      "text": "那么有效利他主义其实他们更注重AI的对齐，他们认为这波浪潮可能跟之前还是有很大的不同。如果是说人类创造一个自己无法控制的这样的一个智能体的话，其实是很危险的。所以他们是认为要叫叫什么超级爱对齐是吧？OpenAI的这个董事会成员比较信奉，有好几个董事会成员都比较信奉这一些。所以就这两派，他对AI的理解应该是不太一样的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:55",
      "text": "我从我的角度来看当然这两派的声音他现在是势均力敌，应该说是在同步往前推进。你像一个大模型的团队里面，肯定就要有这种模型研发应用落地。然后也会有监管和治理，包括安全对齐等等这样方向的专家去共同努力去推进这件事情，朝着一个我们能控制的方向去走，所以我觉得这两派应该目前来说是都在整个AI浪潮中发挥巨大的作用。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:26",
      "text": "像我们交流的那个对齐研究中心的两位创始人，一个叫炮，一个叫bas对吧？那个base它其实就是一个。有效利他主义的铁定的支持者。他们两个之前也是在欧莱雅工作的，后来出去做第三方的研究。",
      "speaker": "发言人3"
    },
    {
      "time": "00:21:40",
      "text": "过去的工业革命两百多年的发展，其实大家也享受了很多便利，带来了很多福祉。但是说其实大家关注这个里面的一些环境问题的人其实特别少，尤其是在早期。所以其实现在导致现在这个环境的破坏，环境的污染。它直接去这种环境安全问题，可能就为了直接去威胁人类生存。所以现在做这个AI里面有效利他的，他其实就是希望避免这个人工智能领域的一些所谓的环境安全。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:08",
      "text": "其实其他的安全问题？提前有一些思考跟应对。现在其实这个anthropic跟因为他其实之前也是open I去独立出来，但它跟这个open I的一些理念可能会有一点点差距。就是说很多人担心说是不是说现在这个人工智能发展太快了。就是说因为你这个模型可以再不断去扩大，不断去迭代，那他能力也会不断增强。是不是说你得考虑一下我们现在已有的这些，包括做做的这些安全措施，能不能跟上这个模型进化的速度，如果说你这个跟不上的话，是不是就不要急于去扩大这个模型的规模，而是先用现在的这个AI技术先研究一下，说你未来的这个安全策略能不能有效。所以这一块其实是可能目前比较多的思考，就思考怎么去更加负责任的去训练迭代未来更加强大的这样一些模型。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:03",
      "text": "记得当时我们去访谈那个叫center for AI safety，这个机构它的一个核心成员叫。但我问他一个问题，因为我觉得你像互联网时代，大家对信息的这种获取已经都非常便利了。假设说你要去制造一些一个炸弹，或者是做一些什么对人类不好的事情，其实你去搜索的话，这些信息你也是可获取的那为什么AI出来了，大家就会非常关心这个问题？你是担心AI去制造，还是说担心其他人利用AI去制造一些什么东西？然后他的回答就是说，有了AI这样的工具之后，普通人可能以前他上网还是需要花很大力气去寻找相关的细节。但是AI出来了之后，他可能就需要一步一步的就可以指导你完成一些你的目标，然后你可能就会做出来一些所谓的生物武器，或者是有对别人产生巨大威胁的事情，这个成本就变得非常的低。而且也存在包括AI他自己是不是，如果他能够有在一些方面的特殊能力的话，比如说自主复制，或者是他有了一些自己的其他的想法的话，也会产生一些这样的风险。所以这次的风险跟我们以前遇到的风险是截然不同的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:24",
      "text": "而且他们交流下来，虽然觉得现在这些模型可能还是不具有自主复制，或者未来的一些强大的一些风险。但就现在也不好判断是如果这个模型继续迭代，继续能力更强，那是不是会有一些新的风险，所以需要有一定的预判。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:41",
      "text": "不知道能不能这么理解，其实这个有效加速主义和有效利他主义，你这两个派别之间的矛盾也好或者冲突也好，它其实是在现阶段资源有限的情况下的一个优先级的争论。其实大家的共同目标其实都是建立一个既要有用又很安全的能够服务全人类的AI只不过可能是说现在的显卡只有这么多，你是先做对齐还是先做模型迭代，是这样的一个问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:11",
      "text": "可以这样理解，其实他们这个目标是一致的，最后还是为了人类的福祉？就是我们能够利用AI帮助我们去提升生活的品质。只不过说这个路径是先加速还是先对齐，我觉得这个是本质问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:27",
      "text": "我觉得建飞讲的这个特别对，就是说你到底投多少资源对吧？这算这个算力显卡有限的情况下，你投入多少资源用于这个AI去往前发展，然后多少资源用于去研究这里面的一些安全跟控制的问题。其实那个open a做的那个super aligned对吧？他就承诺说他会把20%的算力资源用于对齐跟安全这一块的研究。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:52",
      "text": "其实这一轮AI的浪潮，我们会发现，其实他对这个技术的硬门槛其实非常的高。或者我们更直白说一点，就是对钱的要求似乎就非常高。在这个算力成为这个模型训练的基础这个前提下，就是高校在这一轮的AI生态中会扮演一个什么样的角色呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:15",
      "text": "我们这次其实去硅谷也访谈了一些高校，比如说像stanford berkeley，包括他们在做人工智能研究的一些博士。然后还有就是李飞飞老师的那个团队，专门在做以人为本的人工智能相关的工作。然后他们其实有几个角色，我觉得第一个就是他们其实是在学术的前沿上，就是在一些算法方面，或者是在一些大模型的可解释性等等一些方面在做一些研究工作。像计算机系的一些博士，我们这次也有去做交流。然后稍后建峰也可以再介绍一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:57",
      "text": "然后另外一块就是呃我觉得他们其实扮演了一个很重要的角色。就是说如何让政策制定者能够了解这个学术领域的进展。比如说像斯坦福的这个团队，他们就尝试去跟高校的各个实验室去建立一个比较密切的联系。一旦有他们有最新的跟AI相关的成果出来，他们都会第一时间把它翻译成这个政策制定者能够听懂的语言，就把它说简化，然后把它让他大家能够理解到底这个技术的进展是什么。我觉得这是也是一个非常重要的工作。然后另外就是在一些非常小的垂直领域的模型方面，我觉得高校应该还是会有很大的进展的。特别是跟叫AI for science。比如说这种人工智能的模型怎么跟这个学术的成果的发现，包括一些科学规律的发现结合起来，这肯定也是高校比较擅长的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:54",
      "text": "我觉得确实跟他们聊的话，大家觉得就这些高校，比如说你去直接研究这个大模型，跟这个open I去竞争，那其实高校肯定是没有这些方面的资源的对吧？这个资金或者人才，算算力都不够。但是说其实高校其实也是在这个生态里面，我觉得他们也扮演了一个很重要的一个角色。就是说对于这个里面的一些，就因为它是一个生态系统了，吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:18",
      "text": "里面的一些方法的创新。你像伯克利，其实他们在做的就是像这个很热的一个领域，叫做什么scalable oversight，可扩展的一些监督。他可以直接用这个open大模型去做一些研究，说他未来怎么跟人去更好的去协作。解决一起来解决这里面面临的一些社会的问题，就业的一些问题。这个我觉得其实是他们在方法这一块确实做了很多创新，包括对于这个里面的一些可解释性的一些问题，对吧？就是现在这个大模型虽然可以给你一个回答，他说你让他说你为什么给我这样回答，那他可能就不知道不知道怎么去回答你了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:54",
      "text": "但这个就是现在这一块的工作，可能还是要靠高校这些研究人员。因为他不需要那么多的芯片，也不要那么强的算力。更多是一些研究的一些方法或者一些思路的一些创新。",
      "speaker": "发言人3"
    },
    {
      "time": "00:29:09",
      "text": "我觉得这一块其实高校是有很大的优势可以在里面去发挥的对刚才还有其他的，刚才小辉讲的这些AF science等等我觉得这个也是高效。他不一定说需要那么大的大规模的模型，但是说它其实是可以贡献于。对我觉得还有一个就是说高校是可以参与这个开源生态的建设的对吧？高校里面因为开源生态它更多的有这种大模型，有小模型，可能有几十几几亿的参数或者几百亿的参数。大家可以用这种比较小的一些模型去在自己的店上做一些相应的探索，然后贡献于这个开源的社区。这个我觉得是高校，他们还是蛮活跃的一个方向。",
      "speaker": "发言人3"
    },
    {
      "time": "00:29:50",
      "text": "跳出这个人工智能治理之外，就你们有在硅谷那边或者是说在美国那边有见到什么，国内目前还没有或者是很少注意到没有被报道过的AI应用以及发展趋势。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:04",
      "text": "应用这块其实大家都在探索阶段。然后我们这次参会其实也交流了一些来自企业的代表，他们其实有聊到关于agent这块，就是中文叫代理。但是agent理解的话，你就可以把它理解为有自主执行的任务能力的这样的一些ai然后我们目前觉得agent的应用可能比较还比较早期，那可能就是完成一些特定的任务就行了。但这次我们聊到了一家企业叫cognition，也是做管理咨询和这种业务流程外包的这个供应商。然后他们其实是考虑再往前走一步，就是从agent再到一个决策系统，就比如说以前我们的一些决策可能都还是机器提供信息，然后我们人来去完成这个判断的过程。但是他们提了一种可能性，就是说直接让AI他去做AB test就去做测试。比如说两个路径是A好还是B好，他直接根据用户的反馈去看效果，然后效果评估完了之后，然后再去优化迭代。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:09",
      "text": "举个例子，比如说客服中心这样的场景。如果他们想去做一个什么东西的推广，那他是用优惠券更好，还是在特定的时间组织一些活动更好。那他可能就会根据这个call center，就是电话中心的这样访谈调研。然后让用户来打分，比如说给了优惠券的用户，他会跟踪一下他们的满意度怎么样，或者是参加了线下活动的这样用户，他的满意度会怎么样。然后他根据这个打分，他就直接去做这样的决策。下次再去根据你说，比如说你说优惠券更好，那我是给30%还是不给20%是吧？就是他这个折扣是给多少更合适？所以就以前是由人来去监督来完成机器去通过机器学习完成的一些任务。他现在可以用AI的能力完成整个流程，这个就是窖从这个代理到一个决策系统，决策叫决也都不叫决策支持系统了，就叫决策系统，就是AI辅助的决策系统对我觉得这个还是就会感觉又往前走了一步。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:12",
      "text": "其实他们现在已经推出产品，开始向自己的客户去提供服务。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:18",
      "text": "对，他们现在已经开始尝试跟这个客户去做POC。POC就是proof of concept，就是概念验证。如果完成了这个概念验证，可能就会采纳他们的服务，就开始落地。对，一般都会有一个POC的过程。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:33",
      "text": "但进展还是挺快的。你们还有看到就是类似像这样其实是已经在行业内落地，或者是说有看到其他的企业开始用AI去改变自己的业务流的这种。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:46",
      "text": "对，就具体的它落地的案例，这次我们其实没有太看到，就是没有直接说是啊他已经签了这个合同，这种还没有，但是他其实还是提供了挺多想法的。比如说刚才另外一个例子，就是开店选址，以前我们比如说要去开一个店，可能要去线下收集很多数据，然后去做评估，然后去做决策的比较。比如说是在这儿开还是在那儿开2个AB2个方案也是一样，就是他们利用AI的这个系统，就是自动帮你去收集很多相关的信息和数据，然后去做这个决策。然后让你告诉你，比如说你在这儿看你针对的用户群体应该是哪一波，你应该有什么样的销售策略？或者你在这儿开另外一个地方开的话，那那你的策略应该有什么样的不同？这些他其实都是用AI去可以辅助判断的。然后还有一个就是我们这次其实也去了像google、meta一些实验室。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:46",
      "text": "然后他们也讲到了一些落地的应用，比如说跟农业的结合，一些具体的行业场景的结合，这些也有聊到。比如农业机器人，就是也类似，都是利用各种各样的数据采集，通过AI的能力去提升这个产量销量，去给你提供建议。我觉得其实在大模型出来之前，叫机器学习在行业中的应用是非常广泛的。从推荐算法到具体的数字化的一些流程的优化上其实都有。只不过说这个大模型出来之后，可能是在外挂知识库，比如说每个企业都可以建立自己的这个对话机器人，然后可以有一些企业自己内部的知识库的问答，然后可以进行提效等等。这些其实我觉得跟国内的进展是比较一致的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:36",
      "text": "然后只是说你在国外的这个是不是to c端的这个应用会推的非常快，我自己感觉是不是会是这样。就是从从mid journey到现在的这个皮卡生成视频，然后包括那个hi jen，他们也是做这个字幕的翻译。这些公司都非常小，但是它的营收都非常的好啊。它其实资本这块，它自己就能产生大量的现金流，就是一个颠覆式的发展。大家这种C端的付费意愿，似乎在这个AI能提供高质量的工具方面，会再进一步的去去提升这个付费意愿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:17",
      "text": "对，就是C端的小切口的，它还是会更容易替代一些原本这个产业链中的环节。也许它可能已经有了在一些行业塑重新塑造整个业务流的能力，但是他需要把整个流程打通，可能还需要一段时间。你们两位可能是个人对AI未来发展的一些期待或者是展望。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:41",
      "text": "我觉得AI它现在的这个形态还是比较初级，就是刚刚开始，但这个过程会越来越快，我觉得我自己感觉就是在加速。从目前的一些大佬的反馈来看，可能AGI会在3到4年内出现，通用人工智能，它相当于超越我们大部分人类的一个智力水平，能够提供各种各样的服务，这是一方面。然后第二个就是说跟硬件的一些结合，包括像眼镜这种可穿戴设备，包括像我们这个也是才看到叫AIP这个东西加加在领夹上的这个东西。就是这些可穿戴设备会跟人日常的生活更多的融合在一起，相当于每个人都可以有一个助手，你可以随时语音去调用。以前我们用手机的时候，那个siri好像用的场景不是特别多。但是有了AI之后，可能你会经常询问他一些问题，或者是让他帮你安排一些事项等等，都会更多的跟我们的生活结合起来。这波浪潮下来，对普通人的影响和改变是非常大的。就从工作场景的对工具的使用，然后到提升自己的生产效率，再到可能很多职业带来新的冲击，影响会非常大对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:57",
      "text": "我也比较赞同小辉刚才讲的，我觉得还是我对未来可能还是保持审慎的乐观。首先肯定是乐观为主了，对吧？人工智能虽然说大家未来这个ATI什么实现还是有很多讨论，但是说未来肯定我觉得可能就是随着这个AI的发展，对我们的一些日常的一些工作，这个可以有AI去完成对吧？但是一些需要更多的一些复杂性的一些思考的工作，可能未来还是我觉得不一定是这个人工智能跟人类非此即彼。",
      "speaker": "发言人3"
    },
    {
      "time": "00:37:29",
      "text": "我记得之前有一本书叫讲这个人有人的用处，或者机器有机器的用处。可能未来确实是这个人工智能跟人怎么更好的去协作起来这样一个趋势。这可能确实会有一些短期的一些阵痛，确实也需要大家有一些新的一些技能的掌握，包括怎么去跟这个AI打交道对吧？包括对于教育的一些改革，确实确实也感受到技术发展加速。所以很多的一些人类的一些既有的一些制度，也得需要有一定的及时的去调整跟发展，包括对于就业，对于大家一些工作技能等等我觉得这可能就是首先还是对技术保持乐观。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:11",
      "text": "第二点的话可能就是还是要有一定对于技术发展的一种审慎的态度，不能去重蹈工业革命的覆辙了，对吧？就是很多环境问题也是等到一二百年之后，大家才开始去重视。这个互联网到今天，大家以前讲的是这种快速行动，打破常规。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:30",
      "text": "但很多的一些技术问题，可能我是通过事后的方式去解决的。但是说对于人工智能，它的这个能力现在变得越来越强，它的这个风险越来越不可预期的时候，那确实得有一个更加的负责任的创新这样一个态度。也是通过各个主体，各个企业，大家的一些努力，能够去保证这个技术，它是朝着造福于人类的方向去发展。所以我觉得可能就是对于负责任创新的这个观念的这落地，可能在人工智能这样一个背景之下会变得越来越重要。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:04",
      "text": "对我觉得可能目前还有一个挺重要的一个命题，就是中美竞争。虽然我们觉得这个命题其实还是有点敏感的，但是确实是横在中国的从业者面前的一个坎儿。当然也是让我们特别尤其关注这个科技创新，包括这个芯片的研发等等。一个比较好的一个开放式的，然后监管相对合理的这样的一个环境。这样对产业的发展其实是非常重要的。因为如果是一些国家掌握了先进生产力，但是一些国家没有掌握，其实你说这个竞争带来的差距是会越拉越大。所以就是如何让一个环境能够更有利于创新，然后能够让他能够持续的繁荣，其实是一个非常重要的命题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:54",
      "text": "就让每个国家在这个AI的浪潮里面都不不掉队。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:57",
      "text": "是吧？聊到最后我们发现其实我们两个嘉宾一个是有效加速主义，一个是有效利他主义。不过大家目标也像刚才说的，其实目标是一致的，就是做出一个既安全又有用的AI，就给全人类带来复制。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:13",
      "text": "你不说我还没有考虑过这个问题，就是到底把自己定位在哪一派里。就是今天听众朋友们也可以想一想，自己如果划分一个类别的话，是在哪个象限。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:24",
      "text": "对我觉得两派都很重要，就像这个世界他需要阴跟阳，对吧？只有两派他才有这种能够去维持这样一个平衡，是吧，避免都过于极端。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:35",
      "text": "感谢小辉和建峰今天和我们的分享，也感谢大家收听本期节目。您可以在小宇宙、QQ音乐、苹果podcast、蜻蜓FM、喜马拉雅等平台搜索并订阅二维码码。也欢迎通过留言评论等方式留下您的宝贵意见，我们下期再见。",
      "speaker": "发言人2"
    }
  ],
  "lab_info": {
    "summary": "",
    "qa_pairs": [
      {
        "question": "世界经济论坛在邀请不同国家和地区的组织及机构参加人工智能峰会方面，是否存在代表性不足的问题？",
        "answer": "确实存在这样的问题，世界经济论坛虽然在努力覆盖更广泛的国家和地区，但有些地区由于缺乏代表性参与，导致在讨论最新工具和议题时存在两极分化现象。",
        "time": "00:00:09"
      },
      {
        "question": "高校在当前AI生态中扮演的角色是什么？",
        "answer": "虽然高校在资金、人才和算力等方面相对于大模型公司有限，但他们依然在生态系统中发挥着重要作用，通过创新方法论（例如伯克利大学的可扩展监督学习）来探索如何与大模型协作解决社会问题。",
        "time": "00:01:07"
      },
      {
        "question": "这次世界经济论坛的AI治理峰会有哪些值得关注的议题？",
        "answer": "峰会关注了大模型的安全问题、治理问题、开源问题、AI技术的可持续发展以及全球范围内的可接入性等问题，并且邀请了来自技术、安全、治理领域以及政府、学术界、业界和第三方非盈利组织的多方参与者进行研讨。",
        "time": "00:03:08"
      },
      {
        "question": "对于全球发展不均衡，尤其是南半球国家在AI发展方面的挑战，有何讨论？",
        "answer": "参会者讨论了全球数据鸿沟问题，包括南半球国家因缺乏相应人才资源和云服务支持而难以参与大模型和人工智能发展的情况，以及如何缩小这种生产力差距。",
        "time": "00:04:14"
      },
      {
        "question": "中美两国和其他国家如何看待本轮AI浪潮？",
        "answer": "中美两国都高度重视AI及其治理，并且拥有繁荣的互联网行业基础。其他欧洲、亚洲和非洲国家的代表也参加了讨论，分享各自对该轮AI浪潮的看法和应对策略。",
        "time": "00:04:58"
      },
      {
        "question": "在AI产业生态中，南半球国家的角色以及所面临的问题是什么？",
        "answer": "南半球国家更多参与到产业链的低端环节，如廉价的数据标注等，而训练数据主要以发达国家的数据为主，导致这些国家的本地内容难以融入当前模型，进一步拉大了数字鸿沟。",
        "time": "00:06:56"
      },
      {
        "question": "在会议现场，外国与会人员对这一轮AI浪潮持何种心态和立场进行讨论？",
        "answer": "大部分与会人员对AI浪潮充满期待，认为这是人工智能领域的重要拐点，并积极参与讨论。他们不仅关注技术进步，更重视AI在社会应用中的影响及安全议题。",
        "time": "00:08:47"
      },
      {
        "question": "这次论坛的主要焦点是什么？对于AI安全问题，与会者提出了哪些解决方案？",
        "answer": "这次论坛主要关注的是AI的治理问题，包括AI的应用、对社会的影响以及安全议题的讨论，并非专注于具体的技术细节。与会者提出在大模型全生命周期各阶段采取可行的安全措施，如研发阶段使用人类反馈增强学习、红队蓝队策略、价值对齐等方法保障安全性；发布阶段确保文档透明化，清晰列出关键技术和安全问题；后期微调时也要注意水印等安全措施。",
        "time": "00:09:35"
      },
      {
        "question": "是否有大咖分享了关于AI治理的深刻见解？",
        "answer": "吴文达分享了他今年的一个意外经历，即花费大量时间说服政府不要关闭开源社区。这表明各国政府开始意识到AI的重要性及其安全问题，并在考虑采取管制措施。",
        "time": "00:09:56"
      },
      {
        "question": "在人工智能快速发展背景下，治理方面发生了什么样的变化？",
        "answer": "过去一年，随着人工智能技术和产业的快速发展，治理层面的关注点也随之增多。以前很多伦理和治理问题被认为较为遥远，但现在随着自动驾驶等领域的实际应用，这些问题变得日益紧迫和重要。",
        "time": "00:13:17"
      },
      {
        "question": "关于大模型的价值对齐，有哪些新的认识和讨论？",
        "answer": "大模型的价值对齐主要包括三个方面：一是与用户和使用者需求对齐，确保模型输出满足用户在各领域的需求；二是防止模型生成有害内容或从事道德法律不允许的行为；三是长远来看，防止模型失控，威胁人类自身发展。",
        "time": "00:15:11"
      },
      {
        "question": "在大模型学习过程中，如何解决其缺乏道德和伦理意识的问题？",
        "answer": "为了解决这个问题，采用的是人类反馈的强化学习方法。通过构建与人类道德对齐的问题，并让大模型进行人类反馈的强化学习，使其在理解人类语言和偏好基础上判断行为或回答是否合理、合法。",
        "time": "00:16:33"
      },
      {
        "question": "目前在模型评估和可解释性方面有哪些探索，以及是否存在“模型越狱”的可能性？",
        "answer": "当前有很多技术方法致力于模型评估和可解释性研究，但尽管如此，仍不能过于乐观，需要更多的思考。虽然可以通过这些方法让模型与人类意图对齐，但仍存在模型被越狱的风险，即用户可能通过对抗攻击设计提示词以实现非法需求。",
        "time": "00:17:26"
      },
      {
        "question": "普通人在面对人工智能治理问题时，对其严重性有何直观认知？",
        "answer": "普通人对于人工智能治理问题的严重性往往缺乏直观判断。直到OpenAI董事会事件后，人们才意识到行业内对于安全和技术发展矛盾冲突的程度已经相当严重。",
        "time": "00:18:31"
      },
      {
        "question": "这两种声音在AI浪潮中是如何平衡发展的？",
        "answer": "这两种声音在大模型公司中势均力敌，同步推进。团队中既有模型研发和应用落地的专家，也有负责监管、治理和安全对齐的专家，共同确保AI朝着可控方向发展。",
        "time": "00:20:55"
      },
      {
        "question": "有效利他主义者如何看待AI可能带来的环境安全问题？",
        "answer": "有效利他主义者借鉴过去工业革命的经验教训，强调在AI快速发展的同时，应当提前思考并应对可能出现的环境安全问题，确保人工智能领域的安全策略能够跟上模型进化的速度。",
        "time": "00:21:40"
      },
      {
        "question": "AI时代下，普通人获取信息和制造危险物品的成本有何变化？",
        "answer": "相较于互联网时代，AI工具使得普通人更容易获取并指导制造生物武器或其他对人类产生巨大威胁的物品，降低了制造危险品的成本和难度，带来了全新的风险。",
        "time": "00:23:03"
      },
      {
        "question": "高校在这一轮AI浪潮中扮演了什么样的角色？高校与大型AI企业（如openAI）在AI研究上的竞争关系如何？",
        "answer": "高校在AI领域的角色主要包括：1) 在学术前沿进行算法研究、大模型可解释性等方面的研究工作；2) 建立与政策制定者的联系，将最新的AI研究成果转化为政策制定者能理解的语言，提供技术进展的简明解读；3) 在小垂直领域的模型研究上发挥优势，尤其是将AI与科学发现结合的AI for science领域；4) 进行方法创新，例如伯克利大学在可扩展监督和模型解释性方面的研究；5) 参与开源生态建设，使用和贡献不同规模的模型，推动社区发展。高校由于资金、人才和算力等方面的限制，在与openAI等大型企业的直接竞争中并不占优势。但高校在生态系统中扮演重要角色，通过创新研究方法和思路，为AI技术的发展作出贡献，比如在可解释性、社会问题解决方案等方面。",
        "time": "00:26:57"
      },
      {
        "question": "有没有见到国内尚未关注或较少报道过的AI应用及发展趋势？",
        "answer": "在交流中了解到，企业开始探索将AI代理应用于业务流程中，如一家管理咨询和业务流程外包供应商正考虑从代理发展到决策系统。他们计划让AI直接根据用户反馈进行AB测试，优化决策过程，例如客服中心针对推广活动效果（优惠券还是线下活动）进行AI辅助的决策，从而实现从人工监督到AI自主决策的转变。",
        "time": "00:30:04"
      },
      {
        "question": "在POC阶段完成后，客户通常会怎么做？",
        "answer": "如果完成了概念验证（POC），客户可能会采纳该服务并开始落地实施。",
        "time": "00:32:18"
      },
      {
        "question": "是否有看到行业内企业正在使用AI改变业务流程的例子？",
        "answer": "是的，我们看到一些企业在利用AI技术进行业务流程的优化和决策支持，例如开店选址，通过AI自动收集相关信息和数据来辅助决策，并根据目标用户群体提供不同的销售策略建议。",
        "time": "00:32:46"
      },
      {
        "question": "是否有在农业或其他具体行业场景中看到AI的应用案例？",
        "answer": "是的，AI与农业的结合是一个例子，通过各种数据采集和AI能力提升产量销量，并给出种植建议。此外，AI还在推荐算法、数字化流程优化等领域有广泛应用。",
        "time": "00:33:46"
      },
      {
        "question": "对于C端市场，AI的发展趋势如何？",
        "answer": "C端市场中，AI应用会推得非常快，从文本生成视频到字幕翻译等小切口应用，这些公司虽然规模较小但营收良好，展现出颠覆式的发展和用户对高质量AI工具的高付费意愿。",
        "time": "00:34:36"
      },
      {
        "question": "对于AI未来发展的展望或期待是什么？",
        "answer": "认为AI目前形态初级但发展加速，预计3到4年内会出现通用人工智能（AGI），超越人类智力水平并提供多种服务。同时，AI将更深入地融入硬件设备，如可穿戴设备，成为人们日常生活中的助手，对工作场景、生产效率及职业带来深远影响。",
        "time": "00:35:41"
      },
      {
        "question": "如何看待AI对人类工作和生活的长期影响？",
        "answer": "对AI未来发展持审慎乐观态度，虽然会有一些短期阵痛和技能需求的变化，但AI将极大提升工作效率并带来新的职业机会，关键在于如何与AI协作以及教育改革和技术发展的适应调整。",
        "time": "00:36:57"
      },
      {
        "question": "在AI发展过程中，如何看待负责创新的重要性？",
        "answer": "技术发展过程中应保持审慎态度，尤其是在人工智能风险越来越不可预期时，需要有负责任的创新观念，确保技术造福于人类，而非重蹈覆辙。",
        "time": "00:38:30"
      },
      {
        "question": "中美竞争背景下，科技创新和芯片研发等命题有何重要性？",
        "answer": "在中美竞争中，科技创新和芯片研发至关重要，一个开放且监管合理的环境对产业发展极为重要，避免先进生产力差距过大。",
        "time": "00:39:04"
      },
      {
        "question": "在AI浪潮中，各国如何避免掉队并共同受益？",
        "answer": "每个国家都需要努力营造有利于创新的环境，让各国在AI浪潮中保持繁荣，不让任何一方掉队，最终实现全人类共同受益的安全且有用的AI发展。",
        "time": "00:39:54"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "全球AI生态中的挑战与治理",
        "summary": "讨论强调了人工智能作为一个全球生态的重要性，指出东南亚等国家在AI产业链中主要从事低端的数据标注工作，缺乏参与高阶工作，同时面临训练数据代表性不足的问题，导致南半球国家的本地信息难以融入AI模型。此外，会议关注了AI安全问题，强调了社会各界对于AI发展的期待与担忧，特别是AI对社会的影响和安全议题。吴文达的发言提到，意外地花费大量时间说服政府不要关闭开源社区，凸显了政府对AI安全和管制的重视。"
      },
      {
        "time": "00:10:42",
        "title": "大模型安全问题及研究方法探讨",
        "summary": "在最近的一次会议中，讨论了大模型的安全问题及其研究方法。强调了大模型在全生命周期各阶段应采取的安全措施，包括研发阶段的红队蓝队策略、价值对齐，以及发布阶段的文档透明化和标明AI生成作品的水印等。还提到，安全问题的重视不应仅限于顶级大模型厂商，国内的许多厂商也应考虑这些问题。同时，也提到了人工智能领域内伦理和治理研究的重要性，以及技术、产业和应用快速发展对治理提出的新挑战。"
      },
      {
        "time": "00:14:09",
        "title": "探索人工智能在决策系统和业务流程中的应用",
        "summary": "在硅谷和美国，人工智能（AI）在决策系统和业务流程优化方面的应用和发展趋势备受关注。讨论中提到，AI代理（agent）技术正处于早期阶段，主要完成特定任务。企业如cognition正在推进AI从代理到决策系统的应用，通过AB测试等方式直接让AI做出决策，优化流程，如在客服中心推广活动的决策。同时，AI在开店选址、农业机器人等方面的应用也被提及，显示了AI在数据采集、决策支持上的潜力。此外，国外AI在to C端的应用快速发展，如对话机器人、视频生成、字幕翻译等，体现了消费者对高质量AI工具的强烈需求和付费意愿。"
      }
    ],
    "mindmap": null
  }
}