{
  "pid": "62c6ae08c4eaa82b112b9c84",
  "eid": "66d70e575a91beebb38cda81",
  "title": "Vol.131 产业观察21｜热议大模型是否趋冷：对话清华大学教授陈文光",
  "task_id": "mloynmwm8go3qagp",
  "transcription": [
    {
      "time": "00:00:03",
      "text": "感谢大家，我是峰瑞资本的李峰，欢迎大家来到这一期的产业漫谈。其实这一期我们有幸邀请到了一位著名的行业专家，当然曾经是一位创业者。这是我们的清华大学的陈文光老师。我先特别简短的介绍一下陈老师大概的情况。他现在有身兼数个职务，在官方层面的职务是清华大学计算机系的教授，当然也是中国计算机学会的会士，还是副秘书长。除此之外，还是中国要杰出青年基金以及项目的授予者。另外相对偏商业化的是在整个蚂蚁集团。作为蚂蚁集团的副总裁，同时也是蚂蚁技术研究院的院长，然后负责在蚂蚁集团技术方面的很多相关事务。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:52",
      "text": "今天我们要找陈老师来讨论的话题内容，主要是过去一年比较火，我们已经谈过一两次的这个大模型相关。那为什么放在今天来谈呢？当然第一是因为今天从国外的资本市场表现看起来，大模型的最重要的这些参与者或者相关者们股价出现了一些波动。然后大家今天在大模型的这个问题上也相对出现了不同的声音。所以也许今天我们有幸邀请到陈老师，就来跟他探讨一下从现在看大模型和再往后看大模型大概的发展和今天出现的这些波动的情况，背后是不是有值得探讨的一些原因和过程。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:31",
      "text": "当然在此之前我们先有个简单的声明。我们在今天讨论问题的各自观点，陈老师既不代表清华大学，肯定也不代表蚂蚁集团，都代表他个人，或者说作为一个在计算机行业比较资深专业的从业人员来看待这个行业。我当然也不能代表机构，因为这里边并不代表了我们完全的投资观点，只是代表了我个人对这个方向的一些比较外行的思考。在此我们正式开展讨论之前，陈老师自己有没有什么对这个行业也好，或者对自己也好的背景介绍。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:05",
      "text": "我觉得我还是介绍一下我自己这个背景，聊这个话题，我的这个位置是什么？好，我是一个做高性能计算，就是大规模并行计算的人。然后当然在大模型里面，我也在几千块卡上去训练了一个几千亿参数的模型。包括之前在21年的时候，在咱们国家最大的超级计算机上，我们开发了一个系统叫八卦炉。其实也可以支持一个百万亿参数的稀疏模型。那个到现在为止还是世界上参数规模最大的一个模型。但是我并不是NLP领域或者说算法领域的专门研究这个领域的人。如果李峰说是从外行的角度来看这个事情，我可能更多的是一个半外行和半内行结合的角度来参与今天的这样一个讨论。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:55",
      "text": "我们先开始这个话题的时候，我们先追溯一下。因为大模型本质上还是个AI的某一种表现形态，或者某一种技术进步了。我不知道就是从您的角度来看，大模型所带起来的这一波，不管是投资创业，大家技术上的想象力，这一波的热潮从头到尾它有个只跟这个大模型有关的脉络或者发展进程吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:15",
      "text": "我觉得其实像bird和GPT，其实差的已经不是很多了。是的，对吧？包括GPT2出来大家也没有那么激动。是的，对，可能还是GPT3.5那个ChatGPT出来以后，大家觉得有一个飞跃的感觉。但他的技术其实抛开后面的基于人类反馈的增强学习部分，前面这个部分大家其实基本上知道他的能力了。但是我觉得后面是一个对话功能的上线，就让它整个拥有了一个爆发性的大家的关注。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:46",
      "text": "这个之后，其实又有几个里程碑式的事情，一个是GPT4对，我觉得其实还算是一个很重要的一个里程碑。因为它其实把3.5里面的很多的问题都解决了，就是包括对跟事实对不齐的问题。其实到GPT4里面很多和事实已经对的很齐了。当然我们并不知道它实际怎么达到的。比如说更大的训练数据的token数，然后更大的模型本身，包括它在真正服务的时候，可能也会有一些后续的rag一些方法来提升它的准确性，但是它的能力其实达到了一个相当的水平，我觉得这应该是一个很重要的里程碑。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:26",
      "text": "然后再后面就是今年春节期间的那个sora等于600GBT4。其实还有一个就是多模态的直线，就是我不只是可以读文字，对我还可以多多模态的，就是图片都可以加进来，对吧？一起来理解。然后到今年这个sora出来以后，就等于说在有了这个自然语言模型，就是我能够有它以后，我又用它和这个图片真正对齐以后，我又可以在视频空间可以达到一个很长时间。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:55",
      "text": "当然其实到后面它的发展好像并没有大家期待的。就是说从产业上，包括从它真正的那个服务的提供上，到目前为止还没有真正的开放服务，反而是国内的后续的一些像快手的这个工作，对是福军的这个生物科技的工作，其实都是能够真正拿出来给大家用的。这个我觉得是从自然语言的对话，到一个高准确度的和多模态的GPT4，再到一个长时间的多模态视频的一致性的生成，我觉得还是这样一个脉络。但是与此同时，可能还有一个线就是开源的线，开源的线也很多，但是我们其实就拿那个拉玛做一个例子，对吧？就是拉玛刚出来一个，然后后面拉玛二是用更多的token，更大的模型来做。但是拉玛三现在也是，它大概可以达到10T以上的token，包括模型的量也很大，最近新出的这个大规模的模型也还是有很好的效果。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:55",
      "text": "然后另一条线是国内的，国内一开始我们会比较担心说是跟不上。对对对，但其实从最近的角度讲，不管是千问、GLM，还有像01E就是这几个。我觉得他们其实不仅是在这些benchmark上面达到很好的，就是在LMC这个用人去评估的这个上面，其实也达到了一个很好的性能。好像大家慢慢的在自然语言的这个模型里面，已经可能至少是接近了GPT4的水平。如果不是说超过的话，就是在那个LMS上，好像最近是google的这个模型刚刚超过GPDGD。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:33",
      "text": "对对对，其他的可能还比他要低一点。但是我觉得能在那个榜上排进去，排进去能够去排，然后我觉得就达到了一定的水平。其实那个分数差的也不是非常多了，觉得可能近似在同一个级别可能还略有优劣。我觉得大概是这样的一个脉络。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:50",
      "text": "我不知道这块我本来应该提一个刁钻问题，比如说这里边您觉得谁比较好啊？",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:55",
      "text": "其实这个问题可能也不重要，我觉得因为我觉得现在在同一梯队的其实差不多比较多。对，就是你其实很难说谁一定比谁好，对吧？当然我们可以从各个角度说它的资源的拥有程度，它的持久性，它的商业模式，再去分析它未来的发展。但是我觉得在现现在大概在同一水平的其实还是有一批的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:17",
      "text": "并不是那么少。抛开这个谁好的问题，就是就作为我这样的外行，又跟这个有点相关性。作为投资人来看的话，有一个你刚才讲到比较重要的问题，就是拿中国的这些大模型本身和国外的相比。这个里边基于中文本身就是从语料的角度和语言的角度，就是基于中文来做和基于英文来做。当然这些国外的大模型也可以使用中文，但中英文的这个差别本身会给中国的这些大语言模型带来一些在语料也好，结果上也好，计算上也好，技术上也好的优势。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:55",
      "text": "我觉得可能不能说是一个长久的优势，但是确实就是高质量的中文语料其实是很少的，公开的其实更少。确实也看到像不包括这些拉玛这些开源的模型，它在中文的能力上其实相对于国内的这些模型来说还是有差距的。至少在国内的应用里面，其实国内的模型其实还是有相对来说比较明显的优势的。原因我认为也不是总的训练方法或者是技术结构上面的，可能更多的还是数据上。数据就是我们国内这些公司，它因为有更多的精力投在高质量的中文语料的收集上和处理上面，然后他把它也投入到这个模型的训练里面，所以达到了更好的中文质量。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:36",
      "text": "如果我从纯投资的角度来看，它有一个更长一些不同的可能轨迹。在美国更早一些了，是从移动互联网开始，大概就可能也许09年中国稍微晚一点，也许从10年左右开始有一波叫大数据的相关创业。那大数据这件事儿带来的好处，当然是使得大家经过了3四五年之后，对信息的数据化，或者叫数据本身的处理存储等等调用有了更好的基础设施，或者我们叫数据程度更高了。那接下来就到了AI的第一波，也许是CV就是四小龙，就是做这个图像识别，是旷视、商汤等等等等。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:15",
      "text": "对对对，第一波是计算机视觉相关的，这些创业的过程当中，计算机视觉处理的好。我当时的理解是他们处理脸的照片里面的特征提取的比较好。当然那个时候的方法我们从外行来看，简单来讲就是我能找到又准又好的特征，进行跟标准特征的比对。然后得到了说这件事儿到底是相似相同还是不相似不相同。或者我从无数的脸里面找出这个人来哈那这大概是当时的从外行来看的印象。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:46",
      "text": "在那一波的图像处理里面，但是在这个图像识别当中，刚才我们讲到了一个重要的词汇是特征提取，就是找到一个人面部照片的特征。事实上在这一波的这个大模型当中，在它的发展技术脉络延伸过程当中，有一个比较重要的小的节点，今天大家把它叫transforming。这对于。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:09",
      "text": "像陈老师或者像其他的从业者，这肯定不是个陌生的词儿。Transformers作为一种比较好的特征提取器，从技术的路线发展来看，它大概是什么时候发生的？从您的印象中。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:21",
      "text": "transformer那个论文应该是一二年12，对，差不多12。Google加attention is all you need那个论文里面提出来的对，最开始其实他主要做的还类似于翻译这样的任务，还不是对话这类的东西。所以它还是所谓的encoder decoder两个东西来配合的这样的一个模型。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:41",
      "text": "对我觉得transformer可能比较简单的说，它就是说我能够把两个序列之间所有的关联他都考虑到。当然它会不断的训练权重让它去优化，然后最后获得一个确定性的说，这两个sequence里面到底哪个和哪一个的关系可能更紧密。因为过去NLP里面就是说你像LSTM或RN它一长，它就那个状态就很容易丢掉。我觉得transformer就是说我干脆把你摊平了，就是你这么长，我也看你最后一个和前面一个可能已经是4000个投稿之前的了，我还要看你们俩之间有没有关联。而且它比较适合并行，这可能回到我那个老本行去了。因为它最后变成了一个类似于矩阵成这样的一个东西。这个东西大家很好的知道它怎么去并行，而且可以把GPU的这个计算效率发挥的非常高，而且可以在多机上都可以做很好的并行，大概是这样的对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:33",
      "text": "然后这是一个节点。然后那后面还有一个节点是所谓这个diffusion，就是这个diffusion我经常以我的外行身份给这个词起了个我自己容易记住的定义，就是瞎想。我说的瞎想就是说以我外行的理解，就是这个diffusion在原来我们的越来越收敛的抽象过程当中，起到了一个向外泛化一点，就是往合理的方向多向外延伸一些。我不知道diffusion这件事儿，从技术的发展脉络过程当中，对今天的大模型它是什么时候会起什么作用开始的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:08",
      "text": "其实diffusion tion和语言模型，其实它大概是平行的两条线。明白，就是他如果之前看的话，其实是干就是这种内容生成，其实过去是靠那个方式来做到，现在diffusion做。然后其实现在也有一些研究工作，就是说干的那个东西也许能提供一个更好的，比如真实感的一个结果。然后像它可能现在看上去它的那个丰富度可能会更好一些，但是它出来的那个图还是有点像那个卡通，真实感会弱一些。对对对，但是这也是一家之言，明白了。现在很主流的就是大家认为这是干之后的一个模型，就是可能在一些丰富度上好嘛，所以大家还是这方面做的更多一点。但也有它的好处是说，它算的可能会快一点，成本可能在你同样的分辨率的这个图，它的计算所需要的代价会低一些。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:00",
      "text": "其实这条线上还有另外一个技术的时间节点，就是模仿学习和强化学习。这两件事儿是在自动驾驶之后，就是大概在15年那波热潮之后。但是就肯定是在这一波大模型之前比较热的一个AI的技术方向。当然也包括陈老师刚才讲到的跟还有什么CNN、DNN之类的相关的技术发展方式。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:21",
      "text": "这里面还有一件事儿，就刚才其实您在最先开始的时候提到了，就是今天非常懂技术的人，他们经常会讨论到关于大概在1920样子有那个bert的时候，从bert那条技术路线到后来出现的GPT，大家采取了，当然之前的严格可能有一些相似性，但是之后大家在那个节点上发生了一些技术路线的不同。所以导致bert之后虽然按时间顺序出现了GPT，但是大家没有走同一条路，以至于GPT达到了一些在2022年底出现的这些超过预期的这些生成式的文本结果。这个大概之间的差别是怎么产生和啥样的？",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:00",
      "text": "GPT其实就是所谓的decode only。对，因为它的逻辑就是说你在说话的时候，其实你是看不到两边的东西。对，是的，所以你可能就看到前面，你就预测后面的，我觉得这些思想都非常朴素。但是其实你看唐杰的质朴的这个GLM，其实他有点看到两边的，因为晚上是学习，对吧？他早期的模型是看到两边轮椅填中间的，其实是和word的那个逻辑是会比较像的对对对对对，到目前自然语言上面确实都是decoder only的架构，因为它确实效果是不错的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:32",
      "text": "但是这个地方也有一些争论，比如说像一个多模态模型，多模态模型它其实不像是我们这个语言，它一维的sequence这么明确的。其实你更多的是说我可能在一个图片里面，我可能是不是挖掉一块儿。否则的话你如果把它做token nize一行一行的下去，对吧？其实你真的不知道下一行应该是什么。所以其实某种程度可能这种双向的或者是的模型可能也是有它的意义的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:00",
      "text": "明白了。提到今天大名鼎鼎的你们清华系的这个质朴或者唐杰老师，我们其实在20年的时候去看过，但是看的原因就是因为那个时候有个bert，所以我们就看看说这个语言模型的变化是不是会产生一些创业机会。去看了当时的质朴，但是当时的质朴做的跟今天应该讲完全不一样。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:21",
      "text": "不能说有什么不同，而是根本不一样，因为他当时主要还在做知识图谱。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:26",
      "text": "对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:26",
      "text": "是这个名字的角度讲。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:27",
      "text": "是的。然后那个时候做的其实更多的是跟我们叫工业情报检索也好，加一些些特定的舆情监控也好。所以当时犹豫了很久，结果就错失了一个大模型的机会哈那从投资上来讲肯定是遗憾的那我们回过头来讲，就是今天有一个大家其实我观察到的，就是在最近这段时间有两个现象比较特殊。我们先讲它的历史过程，就是因为这一波在AI里边热的主要原因，那个核是大模型。然后大模型在过去接近两年的发展过程当中，大家主要在拼那个就是把参数越做越多，越做越大。当然文本可以输入的越来越长哈那因为大家在拼大这件事儿，就产生出了第一对资源的消耗，这就是英伟达所带来的这个叫算力竞争。因为你要大了，就必须得后边那个机器越来越多，计算能力越来越强，计算资源越来越大，这是一件事儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:22",
      "text": "第二件事儿，大本身可能又带来了一些也许最少在阶段上超越预期的一些生成的结果。就是它生成的内容变成了好像更完整、更自然，或者甚至带有一些更符合逻辑的东西哈那这大概是大当中带来的两件事，当然这两件事各自给了人们的一些在投资上和创业上的想象力。左边那个是跟算力有关的，右边那个是跟智能化有关的，或者跟大家俗称想象中的AGI，就是通用生成式的智能有关的。今天OpenAI也出了很多各种各样的事儿，所以大家对GPT5始终不能发布，或者说能发布的时候是不是还能超预期，或者是不是因为暂时不能超预期了，所以OpenAI里边出现了这样那样的一些看起来的问题，或者叫看起来人员的变动。那我不知道一直拼大的这个过程，虽然持续了两年，看起来它有可能还会。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:18",
      "text": "再持续吗？因为我做超算的，其实我可以从超算的角度来说这件事儿。就是超算过去一直遵循着峰值性能十年1000倍的这个逻辑去增长。然后其中有100倍大概是由算法或者是优化这些方法，或者单芯片的扩展构成的。然后另外十倍基本上要靠你的规模增长OK。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:40",
      "text": "所以你就会发现这个机器就越来越贵。就是原来一台机器可能几千万，然后到几个亿，然后到几十亿。但是到几十亿以后基本上就很难再增长了。因为你要投一个几百亿的机器，那大家自然会问这几百亿能带来一个什么东西，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:58",
      "text": "那我觉得在AI的一个规模扩展上来讲，其实存在类似的问题。我觉得第一个大问题就是它的投入实在是太高了，就是在这个上面继续的去成倍的投入，就是大家现在在谈10万卡，就是10万块英伟达的卡。我觉得我其实不太能想象。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:16",
      "text": "一个100万卡首先投入太大，其次它在工程上也还是会有很多的挑战。比如说它的供电散热，然后它的可用性。其实万卡集群的可用性，我觉得应该基本上是在几个小时的这个范围。那你如果是10万卡那可能就是十分钟这个量级。十分钟这个量级你还要去做各种容错技术，那容错可能要花掉，比如说做的很好，比如说花掉五分钟，那实际上就是你只有一半的时间能用来训练。就是他在进一步大了以后，各种工程上成本上的限制也会让它训练效率也会极度的下降。包括10万卡的通信，其实也还是个很难的，对，是的，这里面有非常多的约束挑战了。但是我总体觉得再进一步扩大，可能对于它的性能和成本的编辑性能的提升，可能不一定有那么大的用处了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:07",
      "text": "从另一个线来看，其实是数据的问题。对，就是我们现在大概现在主流的好的模型，大概在用10万亿的token来训练这个量级的，也许是15T或者20T大概在这个量级。这个量级其实用万卡或者几万卡，我觉得应该基本上是可行的。但是你如果再进一步的扩大，那实际上可能带来的好处也没有那么大了。如果我们没有那么多的数据，实际上你也不需要那么大的机器来做这个计算。所以我的看法大概就是说万卡是肯定没问题，这已经是事实了。十万卡我认为是有可能的对，但是到百万卡我认为是。基本上从成本和各种收益上来讲，我觉得应该他就没有那么高的收益了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:52",
      "text": "所以除去大之外，大一停就有很多附加的问题就会产生了。比如说大一停GPT是不是还能如大家所愿干的超预期。就。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:01",
      "text": "OpenAI的上线这件事儿，我稍微有一点保守，就不太敢估计它。因为毕竟像ChatGPT这件事儿，对我们所有人来说都是个惊讶的事儿。就是他憋了八年，前面大家也不觉得这个公司怎么样，对吧？突然他有一个大招出来了。对他现在GPT5迟迟没有出来，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:20",
      "text": "没有出来我们因为没有在内部，我们不知道具的原因是什么？是说模型没有达到这种革命性的预期？还是说其实竞争对手现在我就拿GBD44，对吧？就是来用，我觉得在市场上也足够了，我要留着个大招明天再出，还是怎么样呢？没有一个特别好的判断。我觉得你可能想表达的一个意思是说，我们想象不出来这个大模型到这个阶段以后，你还能够往哪个方向去。是的，就是我不说你怎么做到，就是说你能干一件什么事儿，过去你就不能干或者干的很差，但是现在你一下就能干的很好了。这个想象我们没想象到，我不知道这是我们的局限，还是说这是这个领域的现实。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:04",
      "text": "这个问题我觉得就回到我一会儿要挑刺的另外两个问题了。我当然这个问题如果真的是大不能再进行的话，它就会引起我从投资角度作为一个第，因为我们不是利益相关方，是因为我们凑巧没有机会投到大模型所以我们就本着一点酸葡萄心理来讨论这个问题。因为一步大了之后，英伟达就会有一点点挑战了，因为大家不再激烈的算力竞争了。当然一步大之后，大家对大模型的想象力上限也会受一些拘束了，因为没有能不停地突破想象力的东西了。当然一不大之后大家就会回过头来，因为你暂时不涨了，大家就会回过头来算账。算账的概念就相当于您刚才讲到的最重要的问题。就是即便是我就大到现在这个样，我在什么类型的应用上，既能够突破使用者的预期，使用者且愿意为超预期付费。但是付的钱又能使得在这个规模上的大的消耗的资源，能得到在单人成本上的补偿，或者叫计算。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:03",
      "text": "对我觉得当然第三个是更大的挑战了。但是我们先回过头来讲，就是我的自己的个人观点是我觉得大这件事差不多就大到这儿了。因为我原来在内部，我们偶尔在大家讨论，我作为一个外行插话的这个态度。我就说很像一个小朋友学说话。就是因为我们在0到3和3到6是在不同的发展阶段。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:25",
      "text": "比如说我们在某一个特定的发展阶段，比如说两三岁的时候，一般来讲我们第一次能说爸爸妈妈，这都是激动人心的时刻。大家都觉得这个小朋友已经是终于不是任你玩弄躺在那儿没有办法表达的一个小朋友了。他可以开始有情感表达。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:42",
      "text": "当然他一般小朋友说的都是词儿，就是爸爸妈妈吃什么饼干药什么都是这种事儿。突然有一天他就说爸爸妈妈我要吃饼干。他说了一句话，你就觉得可能又是个小质变，你就觉得说他是不是已经长大成人了。但是再往下你说他能说出一个一百高考作文，可能还得再花一段时间了。但是基本上差不多。你在认为他是成人了，或者他有表达能力之后，他上了两个明显台阶的。从不会说到会说词儿，从只会说瓷到会说一句话，这是一个预期。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:13",
      "text": "另外两件事情，现在最近这大半年我经常问我们同事的问题，但是我的逻辑不一定能完全正确。我老说因为我们这一轮的大模型都是从自然语言的学习和处理当中出来的那这个就回到了某一个可能有道理的第一性问题，就是语言本身到底是代表了多少智能？就是语言本身到底是更多的代表了表达方式本身，还是更多的代表了思考方式本身。换句话来讲，一个从小没有经过语言训练的人，不管是因为哪些原因，他在大脑里是不是仍然有着比较精密的抽象思考。假定他有获取这些通用知识的方法的话，我也看过一些不同的讨论。但是其中有一个我自己比较认同的方向，就是语言本身主要还是个表达形式为主。然后他可以是，但是他可以不是比较重要是在我们大脑中思考问题当中进行抽象、组织归纳等等这些事情的。他可以是，但它也可以不是做这些我们大脑自己的模型思考的时候的一个能力，或者叫工具。这句话的反面就是说我们从语言中到底能学出多少智能。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:37",
      "text": "明白，我觉得这个里面可能有几层东西。首先如果我们指的是狭义的语言，它肯定不能表示所有的知识。因为我们最近也在探讨说，比如说一个化学方程式，你要拿自然语言来表达就很困难。我们把这个语言泛化一下，就是说它既可以包括自然语言这样的东西，对吧？也可以包括图片类的东西，然后也可以包括一个过程类的。比如一个过程其实叫一个程序，他其实也挺难用自然语言来表达的，很混乱对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:10",
      "text": "拿自然语言来表达，毫无疑问，实际上回到过去人工智能的研究的一个领域叫知识表示。对，知识表示里面其实有多种多样的知识表示的方式，就是自然语言。可能过去大家都不认为自然语言是知识表示的方式，对吧？所以其实某种程度现在的这个大模型，它相当于干了一件什么事儿呢？它相当于我读入了自然语言的大块的东西，对吧？然后我用一个神经元网络的方式，把中间的某些知识把它表达出来。是的，然后当然你还可以检索它，但你还可以用它来干一些事情，大概是这样的一个逻辑。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:45",
      "text": "所以回到您的问题上，我觉得你想表达的可能是自然语言的学习可能会是有局限性的。是有很多东西是没有学到的，或者在智能高度上，在智能的高度上，对它至少有一部分东西是没有通过这个语表达的这么清楚。或者你通过读这个文档可以把它学到。我觉得这个从一个一般的意义上来讲，我觉得是可能的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:09",
      "text": "其实我们最近在想一件事情，就是说我能让大语言模型读完一本物理的教材，然后他就能会做后面这个习题吗？对，能吗？现在不能。对，这不就是9.3和9.11之间的对，现在是不能的，现在是不能的。我觉得这个确实有一个gap，这个gap我认为是需要把像物理教材里面的某些知识，你还是要用其他的方式来表达，而不是说我只看了一眼这个东西。但是这个部分是什么？目前还在一个大家探讨和研究的过程中。对对对，大概是这样的一个状。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:42",
      "text": "对，这就是我老在最近大半年里问同事的问题，就是这一轮的热点的核心是大模型，但是今天我们把大模型这个词只说成大模型，但它本质上的出身是大语言模型，或者叫语言大模型。语言大模型我们原来一直讲说，就像他之前有辈一样，它其实是来自于在过去40年当中所积累的文本的数据化。就是各种各样字的信息把它变成了数据。这样计算机可以进行输入，可以进行计算。所以它经过了超过40年的文本的信息，变成了各种各样的文本数据之后，这个文本数据的多样性和复杂性已经代表了语言，或者叫文本本身的可能某一定比较高的比例了。因为太长时间太多东西了。在这个基础上假定我们能看到并且能把它计算到所有这些文本内容。这些所有的文本内容到底代表了多少智能，就是我只学语言能学到多少智能。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:45",
      "text": "所以这里面可能还是有一些智能的一些能力的具体的定义。现在他能干的事儿大概是从理解的角度来讲。你有个文章给他扔进去，然后他可以读这个东西，对吧？然后他可以帮你总结，是的，然后你还可以就这个东西跟大家提问，对吧？这个我觉得大概是目前是可以达到的。从生成的角度来讲，你说我来生成一个什么文档，根据这几个东西生成一个什么主题，我给你一个概要，你帮我生成一个文档，它也基本上是可以做到的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:18",
      "text": "回到刚才那个问题，就是说它其实从知识层面来看，因为你是从文本数据来的，它所涉及到的多样性、复杂性以及数据的质量高低也有评价，好坏也有评价，长短也有评价，多样性也有评价，组织形态也有评价。这种多样性。给了他之后，他就文本来对文本我觉得应该已经达到了一定的水平。但是就文本来进行文本之外的事情，比如说就像前两天有一个新闻说，原来最早最火的基于大模型的创业公司就是这个character ai就是所谓做人的个性化情感伴侣。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:55",
      "text": "我其实对这个方向的创业是有一点点不确定的怀疑。因为就像我们刚才讲的，就文本本身，对文本我觉得是问题不太大。但是其实从文本本身到情感，到共情，到所谓高情商的反馈，就是带有感情的文本组织到变成文本输出。就像人在这段叫情商高低的问题，我觉得这个过程就已经不是文本对文本了。这当然也算是一种智商，因为情商也是一种智商。在今天的大模型的能力上，他真的能做情感陪伴吗？这句话我一直是有点怀疑。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:38",
      "text": "可能这个方向我比您可能稍微乐观了一些。OK现在不说情商就是我模拟一个人说话的方式，这个可以来和你对话，这个没问题。但是这个情商可能定义相对比较复杂，我认为可以做到。就是你这个说话的风格，我觉得是可以学到的，这个没问题。用一定的情感模式来说话也是可以做。比如说我是以愤怒的、高兴的，就可能不是特别容易能做到的。就是说我要理解了你的这个状态，然后共情了以后，我要用一个什么路径去，我要让你心情变好，那我应该和你说什么？这个事情我觉得就以我目前对这个AI的理，你只要有足够多的例子给他，其实他能学个样子，就是给你一块对话，这个对话就是达到我刚才这个目的的这就是人和人之间的，比如说现在有一个心理医生。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:35",
      "text": "这个数据的获得可能是很难的，因为它涉及很多隐私这样的事情。我们假设说如果我们能够获得这类的数据，而且数据量达到一定程度的话，我觉得AI学到这样的一些路径。从我的角度来讲，我认为也不是完全不可能。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:52",
      "text": "的OK我一直有一点点怀疑，原因是因为就像刚才讲的，其实他从表达到表达背后的反映的情绪，到情绪背后那个共情，大概就是第一层抽象。也许从文字本身可以容易抽象的，当然如果把语音语调加进去更容易了一些。就是他是表达什么情绪的，但是这个情绪跟他真实意义上想表达的感受这个有意思。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:15",
      "text": "这个其实涉及到整个AI里面其实挺重要的一个争论，叫端到端还是一个分解功能。就是包括你在自动驾驶里也会有这个问题。其实现在大家对这个我们所谓语言模型的推理能力做了一些初步的探索。因为实际也没有完全搞清楚，他大概发现就是说他不是那一步一步的严格跳过去了，他可能就一下就跳到头了。但是他这条链就是你一步一步的推过去，他确实能到那儿。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:42",
      "text": "其实这个在刚才您说那个CNN就是识别的时候，它其实并不一定要那么明确的去把你的特征告诉你。它更多的是我有好几种卷积核，但是我卷积核弄完了，我就拿它来训练了。反正训练这边是训练集，这是图像，这边是分。我只要把这个东西不断的去迭代优化，我后面就能够把一个人脸识别的很好。它并没有显示的说我提的是你这个脸上的多少个特征点怎么样，它并不干这件事儿。从神经网络的端到端的特性上来讲，只要有足够多的数据集，你可能不知道它里面怎么弄的，但是他确实一定能学会你这个东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:23",
      "text": "如果一直在表达某一种情感的时候，用类似的pattern.",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:28",
      "text": "甚至就是包括你的策略，就是说我知道你不高兴，但是我试图从某个方向去缓解你的不高兴。这类的训练数据只要足够多，我觉得模型它一定程度上是可以学到的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:40",
      "text": "我需要就是它不是improvise，不是现场即兴发挥的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:44",
      "text": "我觉得模型这个东西就很神奇，对吧？其实你也不知道他们里面到底怎么学的对，反正我就给你看了这些例子，然后你下一个你就很符合这个例子给我的反馈。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:56",
      "text": "所以他回到我们的问题的起点。刚才我们提到这个问题的分支的原因是因为在讲模型会不会更大或者大，是不是模型竞争的方法。那大这件事在今天产生了两个大家对他讨论的疑点。第一个是今天已经有的大，即便是不再进步了，他能不能在某种意义上产生让大家愿意付钱且能覆盖成本的这些使用体验，这是最大的一件事情的影响。当然大家在大上另外一个想象力是通过一直不停的大，是不是我就可以走向通用人工智能了。当然我在这个里边稍微持保守观点的，就我就说他其实从语言这条路径上发展过来的大模型。大到极限，它也是个文本数据所发展出来的所代表的智能极限。这个里面没有多少智能含量，这个我觉得我肯定是没法去定义和定量的。但是我觉得他肯定是有一个比较确定的天花板的。就在这个单一路经常通过大的形态往下走。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:02",
      "text": "我觉得还是两个问题。首先大能够多少提高性能，如果在纯语言本身上面，还是取决于有没有一个新的方式能够获取一个大规模的语料。对，就是目前大家基本上就是十几万token这个东西，基本上把网上的东西清洗完，然后再买一些有什么书什么，其实那些都很少了。和这个量相比，就是所有的数据大概就是已经基本用完。用完以后再做，其实就变成合成语料。但合成语料在自然语言上，我目前来说大家做的比较少。因为可能十几万这个东西也已经达到一定的程度了。就跟您讲的那个小孩儿他已经达到了一个比如说15岁的水平。你再费那个劲儿，他达到一个16岁的水平，他不会再有大幅度的增长了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:51",
      "text": "但是另一块儿，当你的自然语言达到一定程度以后，可能这个多模态的数据，包括我们很多的视频、图片、图像这些东西。就这些东西现在有不同的用法。就比如说有一类的用法，就是说我要给每一个图片里面通过这个分割，再用很复杂的语言去描述它。就是现在大家做到了，比如用比较少的语言，对吧？比较多的语言像sora，它可能也用了很多的描述来生成。这类的东西目前还没有达到它的极致。因为视频东西还是非常多的。而且视频某种程度它达到了一个某种程度超过自然语言的一个范围，和我的视觉能够一定程度的结合起来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:32",
      "text": "可能未来还有一些触觉的东西，多模态的发展可能还会对模型本身的能力还会有一个比较大的提高。就是多模态的能力是不是还可以有一定程度的提升。这个多可以通过更多的数据和更大规模的模型来提升。因为你的机器规模还是要跟数据规模匹配的，如果数据规模不能够达到一个十倍的量级，那其实我的机器规模可能也不需要一个十倍量级的一个机器。从这个角度就是大到底能不能最后达到一个更好的性能？我觉得有可能还大一些，但是可能想象不出来说一定会大那么多大十倍再往上涨的事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:16",
      "text": "在这块我稍微插一下，可能听众不一定完全了解。这个行业里边大家经常讲来讲去叫规模定律，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:23",
      "text": "或者叫scaling law school law。我也不知道这个怎么翻译。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:28",
      "text": "有一点像当年大家总结说卷积芯片应该多少个月变成多少代了。用在数据计算资源和模型处理上线这些问题上大概是个怎么个规律？",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:39",
      "text": "其实没有严格定义scale LOW大致的意思就是说我用一个更大参数规模的模型，比如说到几千亿这样的一个参数。那你这时候需要和这个参数匹配的数据量可能是几万亿的token，然后和它对应的计算量可能就是说一个几千卡甚至上万卡，一个A100。在那个时候就是这样的一个集群，这三个是匹配的。大家会希望说我进一步的去扩展这个模型的大小，然后效果会更好。然后同时你又会需要更多的数据和更大的计算，基本上是这样的一个逻辑。我怀疑它不是个线性外推过程，应该理论上确实是。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:16",
      "text": "如果讲到狭义的skin loral，其实还有一些论文给定我一个数据规模，然后我怎么去选一个最合适的机器的时间，或者一个什么东西，我可以训练到一个什么样的loss。他基本上都是在小模型上做测试验证，然后推广到这个大模型。它更多的可以帮你去优化，对你的整个训练过程就变得可控了。就是我预测了你这个loss的下降曲线。这样的话你就知道我是不是中间训错了或者怎么样，就是用在skin in law，也经常被用在这种对训练过程的监控上。对我觉得往下收敛是可能可以线性往上外延，因为我自己也训了几个，从2B、7B到200B都训过。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:57",
      "text": "包括之前那个更大的一些，确实还是说模型规模大的时候，它那个loss下降是很明显的，是要加快的。我就没做过说从那个稠密模型看我不说MOE的模型，不说那个稀疏模型。就是说你从200亿到500亿，500亿再到1万亿，这个到底还有没有下降的空间？最后那个loss到底能多少？因为现在这个领域很大的程度会成为一个实验科学，大家也没有办法很好的去通过理论去做，包括skin law这些其实都是做一些前面几个点做曲线，做拟合。它不一定是线性的，它可能是一个非线性函数。但是非线性函数你还是可以拟合，你有几个点你还是可以去拟合，更多的还是个实验科学。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:36",
      "text": "确实是，我也觉得就这个比较合理。回到刚才我打断你了，你说我们把这个规模的事。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:41",
      "text": "规模能不能获得更大质量？我觉得可能还有一定的增长空间，但是不会像过去增长的那到10万卡以后到百万卡，你那个delta可能就没那么大，可能大家不会投。然后另一个我觉得从性价比的角度来讲，我觉得这个问题可能相对没有那么重要。因为计算这件事儿，就是这个定律到现在还没有完全失效。虽然就是说你那个线宽往下的这个速度变慢了，但是你同时你也多了什么3D堆叠，各种其他的一些，包括在那个精度上面，运算的位宽上，对吧？我从16位到八位到四位，还是有很多的其他的技术的一个组合来降低它的成本。是的，从一个长远的眼光上来，其实你只要能达到那个智能，那未来我相信一定会有便携的核聚变发动机在我们每个人身上。这个耗电也不是个事儿，就这些问题总能够在某个时候解决。只要你真正的能够提供那个智能的，一开始一定是个巨大的对吧？然后慢慢的把它缩小，然后变成经济上可行和经济上可盈利。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:44",
      "text": "当然这就跟47年的时候，计算机还是大方那么大。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:48",
      "text": "对对对，所以我觉得这个问题相对投资对短期，因为你要讲回报，这三年到底怎么？五年怎么样这个重要。但是从的角度来讲，可能相对就没有那么重要。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:59",
      "text": "这个问题不但是它从性价比的角度，是从投资上纯粹讲究。如果大模型不再拼大就大这件事儿，不管是因为OpenAI，还是因为其他的原因，还是因为资源的原因，大家不再往大了搞之后，因为要开始受到性价比的约束，就是在现在这个大的情况下，所以它就会往回收敛，变成去驱动应用。所以说应用落地和开始可能成型的时候，必须得等到它大家不再大了，不然所有的焦点却都在大上。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:29",
      "text": "这个确实目前我觉得已经有一些趋势，然后像刘志远他们做的那个mini CPM，也是从2B、3B这样的一些小的模型做起，包括千问也有，google也有，就是大家都做一些，微软也有，那个five系列的都是很小的模型。其实这些在一些特定的领域，它其实并不需要百科全书式的这个能力。能力它其实是一些相对比较通用的能力，加上那个领域特定的能力。所以在这些领域，其实我们看目前其实像7B13B的模型其实用的就相当不错。确实用一些更小的模型来获得原来更大模型的基本上相当的能力，然后用于应用，至少在性价比上肯定是有它的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:14",
      "text": "好处的对所以说我们总结一下我们前面这半段，因为一会儿我们要进一个另外一个更抽象和复杂的挑战问题。好的，在前面这半段就是说从大上来看，因为今天的大语言模型或者叫大模型是AI发展过程当中的另一次特点了。当然它也其实是PI的一部分。然后它的过程反正经历了刚才我们讲的这些技术演变，包括前面大数据的铺垫等等。同时在今天之前，大部分的大模型的热点都还是在模型的变大本身上越来越大。然后越来越大当然带来了算力竞争越来越大，也带来了AGI，就是通用人工智能的想象力等等。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:50",
      "text": "如果大这件事儿，不管是因为OpenAI的GPT5，还是因为性价比约束等等，假定大不再变大了，或者就像刚刚才陈老师讲的，就是变大了是不是还有必要？所以说是不是还会有人继续投入？如果不再变大了之后，反正第一个影响的就是算力竞争没那么激烈，也许这个是所有工作算力有关的人。然后不再变大了之后，也许多多少少大家在开始从做收敛型的垂直方向上的更好的性价比更高的应用，某种意义上也会开始。如果不再变大了之后，大家就会回过头来沿着这一条路的不停的虚线外延，就能通向通用人工智能。这句话是不是真的成立？换句话来讲，大家赋予大的想象力在这个时候是不是就受到了一些天花板或者叫挑战的问题。就刚才我们讲语言里面讨论半天到底代表多少智能的问题，这大概是大这一串我。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:43",
      "text": "可能表达两点。就是第一大能够通向通用人工智能，我觉得这本身就是一个没有太多依据的一个猜想。就是大家可能想表达的是大能力会更强强，但是真正走到那个通用人工智能，是不是靠大能得到？我觉得这个事情他本来就不是一个真正的共识，就是很多人同意，也有很多人不同意这样的一个想法。第二就是说大这个方向缓慢，我觉得可能不一定是终止，就它可能还会大对吧？比如从10万卡到15万卡，15万卡到20万卡也是有可能。现在的趋势是它这个训练是一波，其实推理还有一当然就是推理的应用其实还有一大，当然算力的需求。当然如果它的渗透率起来，就是等于那个增长率平了以后，推理的增长率其实还是会一定的上升的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:29",
      "text": "我们就是因为这件事，不是投了那个推理芯片，就是精华的那个这我们正好他也做了几步。我们在最早投的时候我还说过这个问题，我就说你变热的时候，就是大模型变大这件事儿要暂停一下。是的，然后大家就会回到怎么在硬件、软件、算法参数这些层面进行收敛和优化。然后你就会变得比较弱的，就是推理的成本优化。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:53",
      "text": "对，在讨论完大模型之后，我对大模型还有另外一个外行看法，它叫大语言模型。说我的一个纯粹在不懂技术情况下的理解，比如说我们看我们人类的语言是这么架构的。就是第一个问题，它有一个很粗的规则，就我们叫语法规则，就是关于什么是和不是之间的问题。然后剩下的问题，在我们遣词造句，或者说在我们做各种文本表达，包括我们现在在讨论说话也是文本表达了。在我们做其他的表达法的时候，当然你可以判断能不能听懂，以及能不能跟得上，或者说我说的话是不是中听，或者说我说的话是不是有问题。就是大概每个人都有一个自己的毫无疑问的语言大模型来判断我的表达本身。不管他是出于理解还是评价。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:39",
      "text": "其实某种意义上来看，我们来看自然语言表达这件事儿，它其实有如下几个特征。第一是他理论上可穷尽，但几乎他有我不可穷尽的搭配方法。因为我们比如说常用有6万个词或者5万个词，那他们怎么组织，怎么连接？理论上可以穷尽，那肯定道理。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:59",
      "text": "上这是个经典的组合爆炸的问题。对，是的，就是它肯定是个指数复杂度。所以你计算机再有能力也不可能穷尽。是的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:08",
      "text": "这是第一句话。但是它有个粗的规则来约束它。但其实我们脑子中就大家自己在处理，不管是自己表达还是听别人表达来看，理论上你也有一个评价和吸收理解的大模型，要不然他就没办法听懂或者评价这个人说话好坏，作文好坏分高低这些事儿了。大多数情况也是通过什么多看、多说、多学、多练这些事获得的能力。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:28",
      "text": "是的，那我把它处理为，其实理论上来讲，大家都表达同一个意思。就比如说我和别人都要想说同一个我们思考中的抽象的内容把它表达出来。但在这个遣词造句过程当中，我能够调用并且理解任意两个词之间的关系的这个能力。如果我的大模型上更好一点，听起来感受就别人觉得你表达能力强对吧？那大概这就是语言本身。当然语言和思考之间的差距，这个大家也都理解。就是每一种表达方式，你越具体和具象的表达方式，它丢掉的信息就会越多，就离我的抽象思考层面，就是你越具象就掉的越多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:10",
      "text": "我说这些特征，如果我们回到大语言模型的起点上来看，因为这些词理论上可以，但是事实上不能被穷尽的。但是计算机如果学到了看到了足够多的这些字，以各种形式或者叫各种长度不同搭配形式，还有客观的一些评价，他们表达好坏的这些数据输入。以至于在某种意义上，他把在表达上，我们脑子里每个人的那个表达模型，就刚才我们讲那个参数的问题是一样的。就是它把它变成了一个在某种意义上某两个词之间，在无穷高维度空间，这两个词的空间关系是可以某种意义上被计算的。但是它需要一些轴，就是需要你描述一些方式。在这个方式和下，这两个词就变成了他们绝对高维的距离有多少。在这种情况下它就能把语言组织起来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:07",
      "text": "就因为文本是个全毅维的，就是理论上它是个线性的，就是一个字一个字一个词一个词这么连起来的那这大概是我说我能想象到这个大语言模型是怎么作用和发生的。就是这个东西有个粗的评价规则，同时它有几乎无穷多的可能性。那个粗的规律只能定义行或不行的。但是语言模型形成的那个生成模型是它处理了足够多文本之间或者在单词之间的在某一个维度上。因为你的那个prompt就是你那个输入的东西，是给它约束了某几囗在那些维度上各种各样词之间的极其高维的绝对关系。然后它可以把他们再组织起来，变成是一个output，变成是一个输出。在这种情况下它就变成了生成。",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:57",
      "text": "当然中间有很多技术处理，就我们先扔一边。我说这大概是我能理解在这种文本的一维信息上大语言模型所经历的这些过程。我不知道从你的唇专业的角度来看。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:09",
      "text": "我也不能算纯专业。但是我的理解您刚才讲的应该没有什么大的问题，大面上我觉得应该就是这样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:16",
      "text": "好，如果我们把它变成是一个更不好的收敛的例子的话，就像曾经下围棋的那个阿尔法狗迭代一样。就是说那理论上也是个值得组织爆炸。对，是的，对，但理论上他其实可能有个组织的尽头或者绝对规模问题。但是从那个角度来看，就是每下一个对后边无穷多步到底有什么规律和规则。反正当然他开始也是学人的了，后来他不就自己能找这些好，那就变成阿尔法狗以后，李世石就打不过了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:45",
      "text": "我提出这个问题的是因为他是为了解释和努力找到一些方法，叫什么能适用大语言模型。就比如说你刚才讲的coding，我说也许coding可能可以，因为它跟这个有相似性。第一个，你的所有的字符串好有无穷多种组织，但是它有一些绝对规则，很粗的来约束他们。因为它是百分之百数字化的，就是因为你的写出的程序代码都是数字化。所以他如果经历了无数对错，高质量、低质量的这些数据输入和评价。他在完成一个逻辑或者一个指令的过程当中，在这个约束条件下，它就可以把两个命令行之间的绝对高维空间给它算出来。然后他就可以知道怎么连接，怎么输出。所以coding也许是其中一个。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:28",
      "text": "我觉得基本的逻辑是差不多的。可能coding这个事情还有一个比自然语言还要好的一个特点，就是说你其实可以编译它，然后去执行它。然后你如果编译不通过或者执行不通过，你就知道它不对。所以它其实有一个更多的一个反馈回来到你的生成里面来。这过程甚至不一定需要人人，所以它其实会有一个更好的自我反馈的机制。",
      "speaker": "发言人2"
    },
    {
      "time": "00:49:50",
      "text": "对齐比较容易。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:51",
      "text": "就跟围棋一样。对对对，围棋一样。所以我是说这个逻辑应该是基本上。",
      "speaker": "发言人2"
    },
    {
      "time": "00:49:55",
      "text": "是在这个基础上就产生了别的问题了。比如说第一个问题是，如果我们回到刚才讲的多模态数据。我说如果多模态数据就变成了今天的大模型，大到了今天这个程度去处理今天的一维里的就是文本上的。哪怕是在有输入，就是有这个prompt的输入的约束基础上，他去处理这些一维文本，字儿和字词和词儿之间的这些关系就已经大到这个程度了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:25",
      "text": "我说我可以理解文生图，因为文生图它本质上还是在说那句话，他还是在做一样的事儿。对对对，只不过是他把那句话里的话变成了一个它能得到对应关系的某一个图的元素而已。然后它本质上还是在说句话。所以我觉得文生图里边如果又是copilot，其实是可以的。因为你不要求它那个图片就变成是个真实性场景。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:47",
      "text": "但是图片分析本身as a input，就是图片作为它的一种输入，来解析这些事情和元素之间的关系。因为图片里面包含的最少是个二维关系了。因为他即便不到像素点，它最少也到非常多的，是一张照片里无数多的。我只是直觉上从刚才那个逻辑往后推到这一步，他会几乎很难可行。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:11",
      "text": "它现在是这样做的，就是主流的做法。在这个多模态大模型上，图片它是把它切成小块的，因为一个像素计算量太高了。但是最近也有一些工作，就是说我就用像素好像也可以。但是我们先不说那件事儿，我们就说把一个图片切成一个patch，sora就把它叫patch。其实就是一块片。然后它这个图片它还是把它做成一个一维的序列，就是这个patch的序列。因为我们整个语言模型，你其实可以把它看成token和token组成的序列。当然在自然语言里面，我们就是通过分词来形成token。然后在图片里面，它就会通过把它切成一片一片的作为token。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:52",
      "text": "刚才其实提到了这一点，就是说我一个图片其实上下是有关联的对吧？对，那你现在其实把它变成一维以后，你看上去好像丢了一些二维的信息，对吧？但其实这件事儿我们仔细来想，自然语言虽然说是一维的，但是通过transformer以后，其实把它变成了一个极高维的一个关系。你看上去它是一维的，它做了transformer以后，它其实是有后面的一个词和前面一个词的关系的关联的。是的，所以你把这个图片做成这样的一个一维的sequence以后，其实这两个token之间的关联它并没有完全丢OK，它只不过这个叫做空间的近邻性。要不要做成你的模型的一个鲜艳的假设，用这个假设来影响模型。只是这件事情我们把它做成一维的sequence化的时候，我们把这个信息丢掉了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:38",
      "text": "他在处理这个问题，就是我们从多模态数据作为input，比如图片作为输入input的时候，它切分的时候就最少。文字或者叫词是不管中英文，它本身在语言和语法规则上它已经是相对分开的。但是在图上它。",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:55",
      "text": "你可能切到了一个人的脸的两个部分，他会试图去理解说这个部分可能是这个人的脑门，对吧？比如这个是他的眼睛，他的embedding会和别的那个眼睛会比较像。因为我们切完以后，那个token本身它还是个自然表达的东西。就是你真正去训练的时候要把它转换成那个向量，就是这个embedding本身它也是有内容的。当然对对对，是的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:20",
      "text": "也许它可以作为一种训练数据回到人脑的问题了。我们虽然投了很多脑的，我也没有真的想过这个问题。就是我们处理视觉信息的过程。因为视觉的输入信息方法肯定是跟语言不一样的。但是我们在大脑中去提取图片信息的时候的抽象过程，跟我们听到语言或看到语言的表达法提取的过程。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:48",
      "text": "我不知道是一样的，有可能是不一样的。对，视觉其实人类理解的还是相对比较多的，这个过程肯定不会是这种sequence这种类型的。反正做机器学习的人一向有一个观点，就是说我们能达到大脑的功能，但是不一定要复制大脑的脑机制。就是说我也许有另外一条路对它在计算上更加的可行，然后它可以达到这样的一个效果。因为如果说从模仿大脑的角度来讲，我们的人工神经元网络肯定没有像脉冲神经元网络这么接近。就是这套机制目前它达到的效果其实还是比这个人工神经元网络还是有差距的。你说我更像人脑，大家同意，但是我要的是效果。所以我是说不像人脑的机制这件事儿，它可能是个事实。但是这对于它是不是就不能达到一定的智能程度这件事儿，这两个之间可能并不能够直接画等号。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:39",
      "text": "同意。好，我本来基于这个的想象是说，就像你刚才讲的，我们权限把另外选项中的一条路叫类脑计算。我们看过几个类脑计算，但今天确实是还不能讲能够效率更高。但我觉得这个里边主要的瓶颈是我们对脑了解的太少，对脑的复杂认知是的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:00",
      "text": "过程和机理了解的。是的，就是我说一个最基本的，因为我们要观察，人脑上面观察你都是一个很大的问题，你又不能做有创，就别说人脑猴子你都不能做很多的实验。视觉还好，视觉还是一个你在低等动物上还可以做的事。你可以在果蝇上做，可以在上面什么小鼠上面做。但是你要是上面这些语言机制什么的，你连猴子都不能做，你只能在人上做。所以这个大家也在想，就是你的观测的手段，包括一些实验伦理的问题，就是让这方面的研究其实都有很大的差距。是的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:31",
      "text": "所以最终就还是得靠脑电脑磁或者是马斯克那个叫什么。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:35",
      "text": "我觉得现在的大概的逻辑就是说人工智能本身它会有一条线去发展。脑启发的智能会作为一个alternative pass。大家也不能说这条路就一定不行，但是是不是一定行，大家也说不清楚。就是人工智能要自己发展，因为人也很多，然后做的人也很多，对吧？各种方法的突破，他总会往前走。然后类脑如果有一些好的结果能够用过来，那大家也喜闻乐见，就基本上处于我觉得在这样的一个状态。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:05",
      "text": "回到我们的一个命题里，就是文生图和图片作为输入在我心目中两件事了，如果我们再往上扩一层，我们到三维就加上这个时间维就变成了视频。当然我在图作为输入的时候已经比较有一点偏保守，但是我觉得生成图是因为本质上还是说句话，所以还稍微可接受一些，尤其是你后面有人的干预的话。那我不知道今天看起来这个再加一维下来，加到视频上作为输入，这个理论上是不是对今天的模型来讲过于复杂。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:42",
      "text": "我觉得也不一定。其实像sora，它那个文档基本上没写什么，就写的很少。但是你大概还是知道说他会把训练的视频它会有图片吗？然后这个图片有的是本身就有描述的，有那个caption，有一些它会通过一些些视觉模型对这个图片来做一些他描述，这样的话其实就变成一个序列。当然你后面讲的问题其实是说我如何去理解这个序列之间的关系。对的，以及到后面生成如何保持它的性。其实这两个部分其实在做视觉的社区里面，其实大家还是很活跃的在做这些相关方面的研究的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:57:20",
      "text": "我稍微说一点蚂蚁的有一个工作，就蚂蚁没有做这种直接生成一个很长视频的工作。但是蚂蚁做一个叫做可编辑的媒体，可以说你给我一个画，我在上面标一块东西，说这儿我要画个围脖，然后他会很逼真的去生成一个围脖在上面。明白就是能够靠自然语言和位置等等的画的这个交互，同时来指令图片的编辑。当然也有一项工作，就是说我怎么把一个视频里面的人的头发，比如都变成一个白的。然后这个其实就涉及到一些一致性，它其实还是首先在图片上面做变化，然后在这个时间一致性上再去做一些相关的约束，最后生成整个的视频。所以这些工作我觉得可能没有做到完美，但是其实大家也还是想了很多的方法，我觉得可能没有那种基本的技术的约束和鸿沟，就是说我一定跨不过去的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:17",
      "text": "如果我们又回到大语言模型本质上，在分析一句话或者词和词的绝对关系来看的话。今天的用来训练和输入的图片或者是视频数据，是大部分是没有标注过的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:32",
      "text": "还是是标注，有一些是有标注的，像facebook就是meta它开源一些数据集，但是肯定是更大量是没有标注的。没有标注的目前大家其实采用的方法是。用facebook还有一个很著名的工匠segment anything。就是这个图片里面有哪些东西，我都把它分割出来，分割出来它是什么？我再用视觉模型把它识别出来。然后所有的这些识别完了以后，我就可以生成一个非常复杂，达到long开始。然后这个东西以后再和这个图片联合的去做多模态的模型的训练，它就可以得到更多的数据。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:06",
      "text": "但它这个里面应该分析不出动词来，对不对？它可以把名词拿出来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:10",
      "text": "目前应该大家做的还是一个为，就是说这上面有什么东西，以及他们之间的一些相对位置。比如说这个瓶子是在这个上面，明白。但是如果你要有动作，那可能就是一个视频上面去做这个事情，对吧？我要去在图片之间再去做对比，看他那个delta的变化。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:27",
      "text": "明白了这个领域它的前世今生的今生里边其实由大模型还带来另外一个很热的赛道，就是这个叫具身智能机器人。是的，人形机器人的人形机器人我们确实投了好一些，但不是基于大模型来投的，是基于别的来投的。前一阵儿最热的创业公司在硅谷是李飞飞那个公司，对吧？他说这句话是肯定的。他说今天的大模型到了物理世界会有很多挑战，或者说他本来不是为物理世界设置的，所以他说他要解决在物理世界当中的大模型问题，或者叫智能机器人的foundation model这个基础模型的问题。但我对这句话非常赞同，我也觉得这个是肯定连不通的，就是从语言大模型连到今天的智能机器人所需要的基座模型。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:15",
      "text": "但是他今天的问题就来了。第一大家肯定在今天往后的智能机器人的热点赛道上要做新的模型，这是毫无疑问的。要考虑这些相互作用物理量力等等这些问题，以及形变什么这些物理量和物理上的变化。但是今天的挑战，我觉得在这个行业里边，第一暂时还不支持用所有的真正意义上的物理计算来解决。就是用这些模量的东西来解决，就真实意义上怎么算的的模拟。第二个问题，因为它没有任何信息更多的披露出来。但你想象说到这儿来，大家都会讲我们家很多多模态。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:56",
      "text": "比如说我们把机器人的视觉加上，也许将来还加触觉，当然还可以加一些别的什么三维的各种各样的东西。今天的挑战它比视频我觉得还不容易一些的原因是它被描述的这些多模态数据更少，就是说白了叫数据又少又缺标注。在机器人这个赛道的基座模型上，你觉得他会在可见的两三年内有一个真正的基座模型吗？",
      "speaker": "发言人1"
    },
    {
      "time": "01:01:26",
      "text": "我觉得取决于这个机动模型干什么，我认为可以干的事儿，其实还是视觉和场景理解这件事儿我认为基本是可做的。因为如果我们去看自动驾驶，对，自动驾驶基本上把这件事儿在户外他已经干了。是的，那么机器人实际上你无非是说我既有室内也有室外，我的观测的东西和你不太一样。但本质上这件事情我不认为它有一个本质的困难。就是我看到什么东西，我识别出来它的深度，然后我知道它是什么。然后这件事儿我认为在目前的这个视觉上，当然你可能说我要有没有毫米波，还是说我只有纯视觉，这都不是本质问题。是我觉得基本上如果我这个机器人看到一些东西，然后我理解这个东西是什么，我知道我跟它的相对位置是什么。我觉得这件事情基本上是目前的计算机视觉技术的一个很合理的一个扩展。这个应该是问题不是很大的对。",
      "speaker": "发言人2"
    },
    {
      "time": "01:02:16",
      "text": "这个是非常有意思的事情。就是自动驾驶有很多已经积累过的数据算法或经验，或者甚至标注过的数据和作用都可以平移过来。但它这里面跟机器人相比，尤其是跟操作型机器人相比，它有一个比较讨厌的地方是在自动驾驶的定义里，任何情况下都是以任何东西不碰撞作为前提。但是在操作型的机器人里的所有执行目的都是为了操作，对。",
      "speaker": "发言人1"
    },
    {
      "time": "01:02:46",
      "text": "就是为了物理接触。就我刚才说的，可能更多的是一个对环境的理解和移动。对我认为基本上可能这个技术还不成熟，但是我觉得没有根本的技术挑战的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "01:02:57",
      "text": "涉及到操作就是另一个故事。操作这件事儿最大的问题是它操作对象太多。目前大家基本上第一步肯定是攻克这种缸体的非精确操作，这个问题现在也还没有完全解决。因为现在采用的主流方法是模仿学习的方法。我先拿人干多少次，然后随着各家技术不一样，有的干几千次，我才能学会大家在这个层面上去做竞争。",
      "speaker": "发言人2"
    },
    {
      "time": "01:03:24",
      "text": "就这个部分我觉得因为是刚体，其实还不太涉及到触觉的问题。可能更多的还是你这个对操作臂的控制的这样的一些问题。当然未来你肯定是要往精确操作，然后非刚体的方向，比如说什么给人刮胡子、翻身，这你操作的可是个活生生的人，然后叠衣服都是非刚体的东西。然后精确操作，你可能对操作的这个准确性要求的更高一些。",
      "speaker": "发言人2"
    },
    {
      "time": "01:03:49",
      "text": "就是插电子元件。",
      "speaker": "发言人1"
    },
    {
      "time": "01:03:51",
      "text": "对对对，类似于这样。",
      "speaker": "发言人2"
    },
    {
      "time": "01:03:53",
      "text": "我们在大模型的应用当中投了一些不同的。比如说投了推理芯片，两个光芯片，一个risc应用上有游戏，一两个别的投的最多的其实机器人，我觉得机器人在操作就上肢这个问题上，最终在可见的两三年之内，很不容易有个叫基座模型，很不容易有个foundation model。因为数据太不够了，有标记的更少。我有点觉得他是会在专用场景里的泛化的模型是可以的这是规定好的某些东西。",
      "speaker": "发言人1"
    },
    {
      "time": "01:04:29",
      "text": "大家定义这个基座模型，我认为其实不好说它的含义是什么。对，就是假如说我是一个能识别这种室内物体的，然后能带着你移动的，它也某种程度可以叫自动物体。因为大家目前来讲，至少基本公认就是说操作这件事情。由于你的操作对象太多了，然后操作的交互的方式也非常不一样。所以大家其实更多的倾向于一个就事论事的方式。比如我要搬箱子就训练一个搬箱子，对吧？我要捡零件我就能捡零件的，对开门我就弄个开门的。就是大家很少说我能做一个各种操作的一个基座模型，我觉得目前可能还没有一套成熟的方法论来做这件事儿。",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:13",
      "text": "我也觉得是因为它太复杂，也许它会有一些模型，但肯定都是小的。",
      "speaker": "发言人1"
    },
    {
      "time": "01:05:18",
      "text": "未来因为技术都是从点状开始，然后慢慢的能够我觉得你很难说就一定不会出现这样一个东西，只不过目前可能大家都还没有到，我们知道怎么真正的去构建这种操作的计算模型的状态。肯定我觉得是从小的例子开始做，然后慢慢的能合并一类的东西，对吧？然后再去扩展到其他的。因为你很明显我搬东西和操作抓取一个东西，这两个不太一样。",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:45",
      "text": "我们回到机器人的最后一个小的部分是那个下肢，现在看起来可以稍微通用化一些了。就通过强化学习的这个影响，我不知道下肢或者叫运动这件事儿。我们讲的运动不是自动驾驶的这种轮子运动，我们叫不是平面运动，是跨平面运动。就是要上下台阶，上下楼梯什么之类的，或者是要爬坑什么过坎。这种类型的运动你觉得会单独出基座模型吗？",
      "speaker": "发言人1"
    },
    {
      "time": "01:06:13",
      "text": "这个我觉得还是有可能的，因为它本质就把视觉和下面的这个触觉，和整个它的运动控制把它合并起来。我觉得这个我认为是有可能泛化的对。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:25",
      "text": "好，所以我们总结一下我们刚才谈的这个话题。本来我以为会挺不容易谈的。因为我说了从外行理解上为什么会有语言大模型？是因为他把一套本身可能内在有一些相对规则，但很难清晰界定，但有一个比较好的粗的规则。同时大家各自形成了判断这些具体的词和词之间的这些在某一个约束条件下的绝对距离。这是我们脑子里对于表达方式的约束。大模型今天把它更好的学出来。因为文本数据提供的多样性和数据的种类好坏足够多了，这些事儿可以泛化到编程上。",
      "speaker": "发言人1"
    },
    {
      "time": "01:07:02",
      "text": "接下来的问题就是大模型再往下的延展。今天比较热的赛道是居身智能机器人，在这里边出现了另外一个挑战，就是大模型能不能直接挪得过来。现在看起来也许可能直接挪过来是有挑战的，但是也许上肢需要垂直场景下的一些中小模型，然后下肢看今天有没有机会有基座模型。",
      "speaker": "发言人1"
    },
    {
      "time": "01:07:25",
      "text": "另外就是现有的这个语言大模型，其实对于它任务理解和规划，这肯定有一定的作用。为什么语言模型之后这个机身智能又变得很火？我觉得这也是其中的一个原因。就是你过去很难告诉这个机器人你让他干啥，你拿鼠标操作还是拿手去操作？但现在你其实可以通过自然语言去跟他沟通了，就是让他干一个什么事儿。这个事儿在机器人的技术突破之前，其实是个很难的事情的。但是在这个突破之后，你变成你的假设了。所以我觉得这个其实也是一个为什么居然智能最近又火起来的一个原因之一。我觉得也是有关系。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:00",
      "text": "是的，而且它几乎可以复用很多。在自动驾驶今天在竞争了十年之后，因为自动驾驶是大概第二波AI热潮，就是在人脸识别之后的第二波那自动驾驶大家在里面折腾了10年，又介绍了这些算法的变化。里面非常多的东西可以平移过来到机器人上，这是也能对机器人有点帮助的那大概我们今天整个聊的这些话题是比较烧脑的，但是好在陈老师把它聊成了，听起来应该不管是外行还是内行都能听得懂的，只是希望内行不会觉得太科普而已。我觉得还可以哈那我不知道你觉得大模型整个这个话题里边，还有什么应该大家重视和补充的东西。",
      "speaker": "发言人1"
    },
    {
      "time": "01:08:43",
      "text": "我觉得可能基于OpenAI以前的表现，就是GPT5到底是什么，我还是有一点点小小的期待。就是说也许GPT5出来了，咱们今天聊的前面半截基本上就作废了。我觉得也不是完全没有可能性。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:58",
      "text": "但我比你保守语言上能表现和识别和证明的智能水平，我觉得今天已经还可以了。再往下可能就是那个9.3.",
      "speaker": "发言人1"
    },
    {
      "time": "01:09:13",
      "text": "9.11之类的问题了。对，其实前面也大概聊过，就是类似于一个通用的。它现在基本上是一个office的办公室文员的差不多工作，对吧？基本上不管是读还是写，我觉得他基本上都可以干了。然后其实大家现在比如想要用它来做一些这种复杂的交互，现在也在做agent这些东西，就是我让他来帮我去规划一个旅游，去订个票，这个事儿大概干的还没那么好。",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:40",
      "text": "另外其实我们刚才也讨论过，就是说当我们把它真的细化到一个专业的时候，当然现在的方法大概是专业数据在训练。但是这个它能够达到的深度，到底能够达到一个什么样的水平？像这个科学这个领域的应用，有像阿尔法fold，它持续的有改进的。然后这个模型在这个科学发现上，因为大家现在有人在讲，就是说它其实可以提assumption，他不只是可以说你提个东西，他帮你去学总结或者什么的，他甚至可以提出来他的创建。这个创建如果在和一些计算的方法去做闭环，和实验的方法去做闭环，甚至可以想象成一个自动的科学工厂。就这类的东西，当然它需要你的那个assumption的成功率相对高一点。就是我觉得可能还是有一定的想象空间，但是我确实不知道像GPT5的，它具体在哪个层面去做突破。GPT4在大部分的事实性的、文字性的，不管是理解还是生成都已经达到一定水平了。但是当我们进入到这种相对专业化的领域去工作的话，那么是不是还有更多的可能性去推进？我不确定GPT5的方向是这个，但是我至少从目前语言大模型使用的角度来讲，我觉得这个还是一些有想象空间的一些功能。",
      "speaker": "发言人2"
    },
    {
      "time": "01:11:01",
      "text": "对我去稍微照应一下你这句话，在历史上发生过的情况是在15至16年。那一波AI当然也包括自动驾驶和技术算法上的变化，就是强化学习，什么CNN这些事儿之后，再往下有一波热潮就是变成了叫AI加science。这次的大模型也是一次AI在算法和技术上的我们叫提升。这个阳光普照到只要大家不拼大对，马上他就会挨个的把各个重要行业对扫一遍，普照一遍。对，当然巨森智能机器人今天第一个得到阳光，就像那一轮有自动驾驶第一轮得到阳光一样。在后边就会把这些，也包括你刚才讲的这些AI for science这些事儿也普照一遍。感谢陈老师今天的时间，希望大家有耐心听到了结尾。这算是有点烧脑的一期，希望大家能继续支持，也欢迎大家有问题和意见能够提给我们或者提给陈老师，谢谢谢谢。",
      "speaker": "发言人1"
    },
    {
      "time": "01:12:05",
      "text": "好，谢谢大家，谢谢。",
      "speaker": "发言人2"
    }
  ],
  "lab_info": {
    "summary": "本次讨论集中于大模型的最新发展及其对产业界的影响，特别强调了GPT5在未知领域技术突破的乐观潜力，以及GPT4在处理事实性与文字性内容上的高水准，同时指出专业领域应用的潜力待发掘。讨论指出，AI进步推动了自动驾驶和强化学习等技术发展，并预示AI与科学结合的新热潮。大模型被视为AI算法与技术的重要提升，预计将广泛影响重要行业。此外，讨论覆盖了大模型定义、技术进步、未来趋势，包括扩大规模、特定应用潜力及实体操作应用等。还触及了类脑计算挑战、多模态数据处理复杂性及解决实际问题的现有技术。整体而言，讨论展望了大模型在不同场景下的应用前景及未来技术发展趋势和挑战，体现了对未来技术趋势的深入思考和乐观展望。",
    "qa_pairs": [
      {
        "question": "大模型这一波热潮，从头到尾是否有只跟大模型有关的脉络或发展进程？在这一系列发展过程中，您觉得哪个模型表现得最好？",
        "answer": "大模型热潮的发展脉络可以从GPT3.5（ChatGPT）的出现开始，其对话功能带来了爆发性关注。之后的重要里程碑包括GPT4的推出，它解决了许多之前的问题，并达到了一个相当高的能力水平。此外，还有多模态模型的发展，如能够处理文字和图片信息，再到视频空间的一致性生成。同时，开源项目如拉玛系列也在持续进步，而国内的一些工作如快手、福军生物科技等也在自然语言模型领域取得显著成果，接近甚至在某些基准上超过GPT4的水平。其实同一梯队的模型表现较为接近，很难说谁一定比谁好。更多需要从资源拥有程度、持久性和商业模式等方面分析未来的发展潜力。目前有一批模型性能相当，难以区分优劣。",
        "time": "00:04:55"
      },
      {
        "question": "diffusion模型在大模型发展中的作用和时间点是什么时候开始的？",
        "answer": "diffusion模型与语言模型是平行发展的两条线，它主要用于内容生成。虽然目前看来生成的图像可能不如其他方法真实，但扩散模型在计算成本上可能更低，所需代价更少。对于其在大模型发展中具体起作用的时间点，需要进一步研究和讨论。",
        "time": "00:02:55"
      },
      {
        "question": "中国的大型语言模型与国外相比，基于中文语料的优势能持续多久？",
        "answer": "高质量的中文语料在国内较国外有明显优势，这并非长久优势，但确实有助于国内模型在中文处理上取得更好的效果。国内公司投入更多精力收集和处理高质量中文语料，并将其应用于模型训练中，从而达到更好的中文质量。",
        "time": "00:07:55"
      },
      {
        "question": "transformer模型作为特征提取器的重要性及其出现时间是什么时候？",
        "answer": "transformer模型最初在2012年Google提出的“attention is all you need”论文中被提出，主要应用于翻译任务。transformer的优势在于能够考虑到两个序列之间的所有关联，通过训练优化权重以确定紧密关系，并且因其并行性特点，能高效利用GPU进行并行计算。",
        "time": "00:10:21"
      },
      {
        "question": "在1920年左右，从BERT技术路线发展到GPT时，为什么它们没有走同一条技术路线，以至于GPT在2022年底取得了超出预期的生成式文本结果？",
        "answer": "GPT采用了decoder-only架构，即在说话时只预测后面的部分，看不到两边的内容。而像GLM这样的模型则是看到两边信息的，但目前自然语言模型普遍采用decoder-only架构，因为效果不错。不过，在多模态模型中，由于其复杂性，双向模型也具有一定的意义。",
        "time": "00:14:00"
      },
      {
        "question": "当时清华系的质朴（应指唐杰老师的研究组）在20年时为何没有抓住大模型的机会？",
        "answer": "当时质朴主要还在做知识图谱相关工作，专注于工业情报检索和舆情监控等领域，因此错失了大模型的发展机遇。",
        "time": "00:15:21"
      },
      {
        "question": "最近AI领域有两个特殊现象，能否描述一下？",
        "answer": "最近的现象一是算力竞争加剧，为了追求更大规模的大模型，导致对计算资源的需求大幅增加；二是大模型生成的结果变得更加完整、自然且符合逻辑，引发了人们对智能化和AGI（通用生成式智能）的期待。",
        "time": "00:16:22"
      },
      {
        "question": "大模型停止增长后，是否还能保持超预期的表现？",
        "answer": "对于大模型未来的发展潜力，尤其是GPT5是否能如期超预期，目前无法准确判断，因为大模型的发展可能会带来意想不到的突破，但也会遇到新的挑战和瓶颈。",
        "time": "00:21:04"
      },
      {
        "question": "对于大模型的进一步扩大，是否存在物理和工程上的限制？",
        "answer": "随着规模的扩大，大模型面临投入成本极高、供电散热挑战、可用性降低、通信复杂度增加等问题。当扩展到百万卡级别时，其性能提升与成本投入之间的性价比可能不再划算。",
        "time": "00:18:16"
      },
      {
        "question": "大模型发展到一定程度后，是否意味着其对智能表达方式和思考方式的探索已达极限？",
        "answer": "虽然大模型在自然语言处理方面取得了显著进展，但它能否全面覆盖智能的所有方面仍有待探讨。语言本身更多代表的是表达方式，但在大脑中的思考方式可能并不仅仅依赖于语言训练，而是有更为深层的抽象思考能力。通过自然语言学习能获取的部分智能有限，大模型还有待解决知识表示和学习的局限性。",
        "time": "00:23:13"
      },
      {
        "question": "能让大语言模型通过阅读物理教材来完成习题吗？大模型的本质是什么？",
        "answer": "目前还不能，现在存在一个gap，需要其他方式来表达物理教材中的某些知识。大模型本质上是源自过去40年积累的文本数据化，通过计算机处理和学习大量文本信息后形成的。",
        "time": "00:26:09"
      },
      {
        "question": "当前大模型可以做到哪些事情？",
        "answer": "大模型目前可以理解文章、总结内容、与人对话并提问，以及基于给定信息生成文档概要或全文。",
        "time": "00:27:45"
      },
      {
        "question": "大模型能否做到情感陪伴，如具备高情商？",
        "answer": "对于模拟人的个性化情感伴侣方向，虽然对其存在一些怀疑，但认为模拟特定情感风格和模式进行对话是可能的，不过实现真正的高情商情感反馈可能较为复杂。",
        "time": "00:28:55"
      },
      {
        "question": "AI是否能学会在特定情境下以不同情感模式与用户交流？",
        "answer": "如果拥有足够多的训练例子，AI在一定程度上是可以学习到不同情感表达和交流策略的，例如识别并缓解用户负面情绪。",
        "time": "00:32:28"
      },
      {
        "question": "大模型的发展是否会带来性能提升和通用人工智能的突破？",
        "answer": "大模型在性能提升上可能受限于能否获取大规模语料，而在自然语言处理领域达到一定程度后，多模态数据（如图像、视频）的发展可能会带来较大的性能提升，但是否能实现通用人工智能仍待探讨。",
        "time": "00:35:32"
      },
      {
        "question": "是否可以预期随着大模型规模的增大，其性能会有大幅度增长？",
        "answer": "规模定律表明随着模型参数规模增大，需要匹配的数据量和计算资源也会增加，理论上模型效果会更好，但实际效果并非线性外推，更多依赖于实验科学和对训练过程的监控与优化。",
        "time": "00:36:39"
      },
      {
        "question": "规模能否带来更大的质量增长，以及性价比问题怎么看？",
        "answer": "规模可能有一定增长空间，但像过去那样从10万卡到百万卡的高速增长趋势会减缓。从性价比角度看，随着技术进步，如3D堆叠和其他技术组合，即使线宽变窄，也能通过降低成本实现长远发展。未来智能设备的便携性与耗电问题将逐步解决，只要能达到所需智能水平，经济上可行和盈利的可能性就会存在。",
        "time": "00:38:41"
      },
      {
        "question": "投资在短期内对回报的关注是否重要？",
        "answer": "对于短期投资回报而言，关注点可能不如长期重要，因为现在大模型的发展已经转向追求性价比而非单纯增大规模，这会导致算力竞争有所缓解，并开始驱动应用落地和垂直方向上的优化收敛。",
        "time": "00:39:59"
      },
      {
        "question": "大模型不再追求规模变大后，是否会转向应用落地并影响通用人工智能的发展？",
        "answer": "如果大模型不再追求大规模扩张，算力竞争会减轻，更多精力会投入到垂直方向上性价比更高的应用开发中。这并不意味着大模型无法通向通用人工智能，但目前对此并无定论，且大模型可能仍会缓慢增长。同时，推理方向上仍有增长空间，尤其是在模型参数优化和硬件、软件、算法层面的改进。",
        "time": "00:41:50"
      },
      {
        "question": "对于大语言模型的理解，它如何模仿人类语言表达的规律性和复杂性？",
        "answer": "大语言模型模仿人类语言表达时，理论上存在可穷尽但实际无法穷尽的搭配方法，类似人类语言表达有粗略语法规则约束，同时具有极大的表达可能性。大语言模型通过学习大量文本数据，形成一种基于高维空间中词与词之间关系的生成模型，能够在一定程度上模拟人类语言表达的能力。",
        "time": "00:46:10"
      },
      {
        "question": "在处理多模态数据时，比如图片作为输入时，是如何切分的？这种切分方法是否会影响模型对图片中信息的理解和关联性？",
        "answer": "现在的主流做法是将图片切成小块（patch），然后将这些patch转化为一维的序列，就像语言模型中的token序列一样。尽管这样做会丢失二维信息，但通过transformer模型后，一维序列中的token之间依然存在高维的关系。虽然切分后看似丢弃了二维信息，但实际上，transformer模型能够捕捉到token之间的空间近邻性关系。虽然模型无法直接看到整个图片的信息，但其内在机制仍能保持一定的关联性。",
        "time": "00:51:11"
      },
      {
        "question": "对于多模态数据输入（如图片和文字），它们的处理方式有何不同？",
        "answer": "图片在处理时需要切分，而文字或词在语言和语法规则下相对独立，无需额外切分。然而，在处理图片时，尽管切分为了便于处理，但仍然可能破坏一些原本二维空间上的信息联系。",
        "time": "00:52:38"
      },
      {
        "question": "是否可以将处理视觉信息的过程与人脑提取语言信息的过程相比较？",
        "answer": "虽然视觉输入信息的方式与语言不同，但在大脑中提取图片信息的过程可能与处理语言相似，不过目前的人工智能方法并未完全模仿大脑机制，而是追求计算上的可行性和智能效果。",
        "time": "00:53:20"
      },
      {
        "question": "类脑计算是否能够超越传统人工智能方法并实现更高效的智能？",
        "answer": "类脑计算虽有潜力，但目前受限于对脑复杂认知过程理解的不足，还不能确保效率更高。人工智能和类脑计算两条线各自发展，人工智能正积极寻求各种突破，类脑计算也不断尝试将有益结果应用于实践。",
        "time": "00:54:39"
      },
      {
        "question": "将视频作为输入的模型构建，理论上是否过于复杂？",
        "answer": "将视频作为输入理论上并不一定过于复杂，已有研究表明可以通过类似Sora的方法将视频中的图片通过描述或视觉模型转换为序列，再进行多模态模型训练。对于理解序列间的关系及保持生成视频的一致性，学术界还在活跃地研究相关方法。",
        "time": "00:56:42"
      },
      {
        "question": "当前训练大模型所使用的图片和视频数据是否标注充分？",
        "answer": "大部分用于训练的图片和视频数据并未标注，例如Facebook开源的数据集。目前采用的方法如Segment Anything等技术将图片分割并识别其中物体，以生成复杂标签用于训练多模态模型。",
        "time": "00:58:32"
      },
      {
        "question": "在机器人领域，是否有可能在短期内构建一个针对具身智能的基座模型？",
        "answer": "在视觉和场景理解方面，构建具身智能的基座模型是有可能实现的，因为自动驾驶领域已经在户外场景取得了显著进展。对于机器人而言，识别物体及其相对位置的技术挑战是可以被现有的计算机视觉技术合理解决的，但操作精确度和非刚体操作等方面仍面临较大挑战，尤其是在缺乏大量标注数据的情况下。",
        "time": "01:01:26"
      },
      {
        "question": "基座模型是否可以理解为能执行多种操作的通用模型？",
        "answer": "目前还没有成熟的方法论来构建一个能处理各种操作的基座模型，因为操作对象多样且交互方式各异。大家更倾向于针对特定任务进行训练，例如搬箱子、捡零件或开门等。",
        "time": "01:04:29"
      },
      {
        "question": "下肢运动是否会发展出单独的基座模型？",
        "answer": "下肢运动有可能发展出基座模型，因为它结合了视觉、触觉与运动控制，这种跨平面运动如上下台阶、楼梯或过坎，有可能实现泛化。",
        "time": "01:05:45"
      },
      {
        "question": "对于未来大模型的发展，您有何期待？",
        "answer": "期待OpenAI发布的GPT5可能带来新的突破，但保守来看，当前的语言大模型在表现和智能水平上已经相对成熟，而在专业领域的应用潜力仍有待发掘，例如科学领域的模型能否进一步提升其在假设提出和科学发现方面的能力。",
        "time": "01:09:40"
      },
      {
        "question": "语言大模型在机器人技术中起到什么作用？",
        "answer": "语言大模型通过学习大量文本数据，较好地理解和表达了表达方式中的规则，并能够将这些规则应用于编程上。此外，大模型对于机器人任务理解和规划也有一定的推动作用，使得通过自然语言与机器人沟通成为可能，这也是机身智能机器人赛道火热的原因之一。",
        "time": "01:07:25"
      },
      {
        "question": "自动驾驶领域的成果能否平移应用到机器人技术中？",
        "answer": "自动驾驶领域经过十年探索，许多算法和技术的变化对机器人领域有一定帮助，可以复用很多成果。",
        "time": "01:08:00"
      },
      {
        "question": "大模型的发展是否会引发类似AI加科学（AI4Science）的新一轮热潮？",
        "answer": "是的，随着大模型技术的提升，如同历史上AI技术进步推动自动驾驶等行业的发展一样，大模型将可能掀起AI与各行业深度融合的新一轮热潮，包括AI for science的应用也会因此受益。",
        "time": "01:11:01"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探讨大模型的发展与市场波动",
        "summary": "本次产业漫谈邀请到清华大学计算机系教授、蚂蚁集团副总裁陈文光，讨论大模型领域的最新发展及市场波动原因。陈教授从个人在高性能计算领域的经验出发，分享了对大模型训练的见解，并指出当前大模型研究的关注点。对话强调，讨论内容代表个人视角，不涉及所在机构立场。"
      },
      {
        "time": "00:02:54",
        "title": "大模型技术发展脉络与影响",
        "summary": "大模型技术，作为AI领域的一种进步形态，引发了投资创业热潮和技术想象力的飞跃。从GPT到GPT-3.5的ChatGPT，技术发展显示出了显著的飞跃，尤其是对话功能的上线引起了广泛关注。GPT-4的推出，解决了许多前代模型存在的问题，标志着一个重要的技术里程碑。此外，多模态的发展，如能够处理文字和图片的模型，以及长时间多模态视频的一致性生成，显示了技术的进一步进步。同时，开源模型的发展也表明了国内外在这一领域的活跃和进展。整体上，大模型技术的发展不仅推动了自然语言处理领域的进步，也对其他相关领域产生了深远影响。"
      },
      {
        "time": "00:06:50",
        "title": "中外大模型比较及投资视角分析",
        "summary": "讨论集中在比较中国的大型语言模型与国外模型的差异，特别强调了基于中文的模型在语料、技术上的优势。指出了高质量中文语料的稀缺性为国内模型带来的优势，以及这些模型在处理中文信息时的相对优势。从投资角度分析，讨论了中国在移动互联网、大数据和AI领域的进展，特别是计算机视觉的发展，并提及了transforming技术的重要性。"
      },
      {
        "time": "00:10:09",
        "title": "Transformer模型及其对NLP领域的影响",
        "summary": "Transformer模型于2017年在论文《Attention Is All You Need》中被提出，初期主要用于翻译任务，通过编码器-解码器架构处理序列间关系，改善了长期依赖问题并支持并行计算，从而提高了效率。随后，扩散模型(diffusion)和模仿学习、强化学习等技术进一步推动了人工智能技术的发展，特别是在自动驾驶领域。扩散模型提供了一种生成内容的新方法，尽管生成结果可能不够真实，但其计算成本较低。总体而言，Transformer及其后续技术的发展对自然语言处理和人工智能领域产生了深远的影响。"
      },
      {
        "time": "00:13:20",
        "title": "BERT与GPT技术路线的分叉及其影响",
        "summary": "对话中讨论了自1920年代起，从BERT技术路线到GPT的发展过程中，两者在技术路径上的分歧导致了不同的结果。BERT之后，虽然时间顺序上GPT出现，但两者并未沿同一路径发展，导致GPT在2022年底展现出超出预期的生成式文本结果。GPT采用了所谓的'解码器only'模式，意味着在预测时只能看到前面的信息，这一朴素的逻辑在自然语言处理上显示了显著的效果。同时，讨论也触及了多模态模型与双向模型的意义，以及清华系唐杰教授的工作方向从知识图谱的转变。"
      },
      {
        "time": "00:15:27",
        "title": "大模型发展面临的挑战与未来展望",
        "summary": "在过去的两年中，AI领域的研究和投资主要集中在增大模型的参数量，以实现更长文本输入和更自然、逻辑性更强的生成内容。这一追求导致了算力竞争的加剧，同时也带来了对资源消耗的显著增加。尽管增大模型参数在短期内推动了AI性能的提升，但也面临着成本和工程上的挑战，比如训练所需的大规模GPU集群的经济性和技术可行性。特别地，从万卡规模扩张到十万卡乃至百万卡，可能会因为成本和收益的不匹配而遭遇瓶颈。此外，数据的稀缺性也成为进一步扩大模型规模的限制因素。对于未来，虽然大模型可能继续发展，但其是否能超出预期、满足投资和创业的期望尚存疑问。"
      },
      {
        "time": "00:20:01",
        "title": "探讨人工智能模型的发展及其对社会的影响",
        "summary": "对话涉及了对OpenAI推出ChatGPT的惊讶反应，以及对GPT5延迟发布的猜测。讨论内容包括对大模型技术进步的期待、人工智能模型可能达到的极限、投资角度的关注以及对未来应用的想象。此外，还讨论了语言与智能的关系，以及语言模型在表达和思考中的角色。整体上，这段对话反映了对人工智能技术发展的关注和思考，以及对人工智能模型如何进一步突破和应用的探索。"
      },
      {
        "time": "00:24:37",
        "title": "探讨语言模型的局限性与知识表示",
        "summary": "讨论重点在于语言模型，尤其是大语言模型，在知识表示上的局限性。首先指出，狭义上的自然语言无法完全覆盖所有知识，如化学方程式和复杂过程难以用自然语言准确表达。通过将语言泛化，包括图片和程序等，可以拓展知识表示的范围。过去人工智能领域的研究较少将自然语言视为知识表示方式，而当前的大模型通过神经网络处理大量自然语言数据，尝试捕捉并表达其中的某些知识。尽管如此，这种模式在理解和生成文本方面取得进展，但对于处理文本之外的知识，如物理习题，仍然存在明显局限。讨论也涉及到，即使大模型基于过去40年积累的文本数据训练，它们在智能的全面理解上仍有不足，特别是在处理超出文本范畴的问题时。"
      },
      {
        "time": "00:28:55",
        "title": "探讨AI在情感陪伴和高情商反馈中的应用潜力",
        "summary": "讨论集中在AI技术能否实现真正的情感陪伴和高情商反馈上。虽然对AI模拟人类说话方式的能力表示乐观，但对AI能否达到共情和提供高情商反馈持怀疑态度。讨论指出，虽然通过足够的训练数据，AI可能学习到特定的情感表达和应对策略，但涉及到深层次的情绪理解和共情时，AI的能力受到质疑。同时，探讨了大模型在提供高质量使用体验和推进向通用人工智能道路上的可能性和限制，认为即便模型持续扩大，其智能的上限仍然是一个确定值，受限于基于文本数据的发展路径。"
      },
      {
        "time": "00:34:02",
        "title": "探讨模型规模对性能的影响及多模态数据的潜力",
        "summary": "讨论集中在两个主要议题上：一是模型的规模如何进一步提升性能，二是多模态数据的潜在价值。首先，关于模型规模的讨论指出，模型的大小需要与数据规模相匹配，以达到最佳性能。尽管增大模型规模可能带来性能提升，但这种提升可能不是线性的，而且存在边际效益递减的现象。其次，探讨了多模态数据的潜力，强调了利用视频、图片等多模态数据对于提高模型性能的重要性。认为目前在这方面还未达到极致，特别是在自然语言处理与多模态结合上，还有很大的发展空间。讨论也触及了计算资源的成本和效率问题，以及对未来技术进步的乐观预期，尽管短期内的经济效益可能是次要考虑因素。"
      },
      {
        "time": "00:39:59",
        "title": "大模型发展与应用落地的策略转变",
        "summary": "随着大模型的发展，关注焦点开始从单纯追求模型的规模转向考虑性价比和应用落地，标志着AI领域的一大转变。这种转变促进了专注于特定领域的小模型（如2B、3B大小的模型）的开发，这些小模型在某些领域展现了与大模型相当的能力，从而在性价比上展现出优势。讨论还指出，如果大模型不再无限扩大，可能会影响算力竞争的激烈程度，并促使研究者和开发者更多地关注于垂直方向上性价比更高的应用。同时，提出了对通用人工智能（AGI）实现途径的质疑，强调大模型通往AGI的路径可能并不是共识，并且即便模型规模扩大，其在特定领域的应用价值和成本效益仍需细致考量。"
      },
      {
        "time": "00:43:53",
        "title": "大语言模型的理解与应用",
        "summary": "讨论了大语言模型的基本概念、结构和应用。首先，指出人类语言表达具有复杂性和多样性，由粗略的语法规则约束，但仍存在几乎无穷尽的组合方式。然后，通过讨论语言模型如何学习和模拟人类语言的生成过程，阐述了大语言模型通过分析大量文本数据，学习词与词之间的高维空间关系，进而生成新的语言输出的机制。此外，强调了理解和应用大语言模型对于提升自然语言处理技术的重要性。"
      },
      {
        "time": "00:48:16",
        "title": "探讨大模型在多模态数据处理及应用中的挑战与机遇",
        "summary": "对话围绕如何应用大语言模型处理多模态数据，特别是图片和文本的结合，展开了深入讨论。首先，通过阿尔法狗在围棋中的表现，提出了模型在无穷多步预测中寻找规律和规则的能力。接着，将这一思路应用于编程中，强调了编程与大模型之间的相似性，尤其是编程的反馈机制对于模型训练的重要性。随后，讨论转向了如何处理多模态数据，特别是将图片转换为一维序列（patch序列）的方法，以及这种方法对模型空间近邻性假设的影响。最后，讨论了人脑处理视觉信息的方式与机器学习模型的不同，强调了即便不完全模仿人脑机制，通过计算上更可行的方法也可能达到智能程度的提升。整个对话突出了在多模态数据处理和应用中，模型面临的挑战、机遇以及未来研究的方向。"
      },
      {
        "time": "00:54:39",
        "title": "类脑计算与人工智能的发展挑战与机遇",
        "summary": "讨论集中在类脑计算的挑战和潜力，以及与人工智能发展的相互关系上。一个关键点是当前对人脑理解的限制影响了类脑计算的效率和应用，特别是在不损伤生物体的情况下研究复杂认知过程的技术限制。此外，讨论也触及到人工智能领域的两大发展方向：传统AI方法的进步和脑启发智能的探索，后者被认为是可能的替代路径但效果尚未可知。在视觉和语言处理方面，技术如可编辑媒体和视频内容生成展示了深度学习在理解和生成复杂视觉信息上的进展。尽管存在挑战，但通过技术如大语言模型和视觉识别的进步，可以看出在理解未标注的视觉数据方面取得了进展，尽管对于动作等更复杂概念的理解仍处于初步阶段。"
      },
      {
        "time": "00:59:27",
        "title": "智能机器人领域的挑战与发展方向",
        "summary": "讨论集中在智能机器人，特别是操作型机器人面临的挑战和发展方向。当前，机器人领域依赖于视觉和场景理解技术，这些技术在自动驾驶中已有应用，但对于操作型机器人而言，存在物理交互、多模态数据缺乏以及标注数据不足等挑战。尽管机器人技术在某些特定任务上取得进展，如识别和移动，但在复杂操作和非刚体对象处理方面，仍需克服数据和算法上的限制。讨论还指出，未来机器人技术的发展可能从特定任务模型开始，逐渐向更通用的模型过渡，但目前尚缺乏成熟的解决方法。"
      },
      {
        "time": "01:05:45",
        "title": "大模型对未来机器人技术的影响与展望",
        "summary": "讨论集中在如何通过强化学习使机器人的下肢运动更加通用化，探讨了大模型在机器人技术，特别是机身智能领域的应用潜力。指出目前的挑战在于大模型直接应用于机器人可能存在的困难，以及对特定场景下中小模型的需求。同时，强调了语言大模型在任务理解和规划中的作用，以及自动驾驶技术对机器人技术的潜在帮助。最后，对未来大模型，如GPT5的期待以及其可能带来的技术突破进行了展望，同时讨论了大模型在专业领域应用的潜力和挑战。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "基于AI的一种技术表现形态"
                },
                {
                  "children": [],
                  "content": "特点：参数量巨大，训练数据庞大"
                }
              ],
              "content": "大模型概述"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "从Transformer到GPT系列的突破"
                },
                {
                  "children": [],
                  "content": "大模型的技术挑战与优化"
                }
              ],
              "content": "技术发展脉络"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "大模型的资源消耗与算力需求"
                },
                {
                  "children": [],
                  "content": "大模型在不同领域的应用与挑战"
                }
              ],
              "content": "现状分析"
            }
          ],
          "content": "大模型的演进与现状"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "改变了NLP领域的处理方式"
                },
                {
                  "children": [],
                  "content": "提高了模型的并行计算能力"
                }
              ],
              "content": "Transformer的重要性"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "数据质量与量的影响"
                },
                {
                  "children": [],
                  "content": "算法与架构的优化"
                }
              ],
              "content": "大模型的训练与优化"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "是否会继续扩大参数量"
                },
                {
                  "children": [],
                  "content": "大模型的性价比与应用落地"
                }
              ],
              "content": "大模型的未来方向"
            }
          ],
          "content": "大模型的技术讨论"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "图像、视频等数据的处理"
                },
                {
                  "children": [],
                  "content": "跨模态数据的融合与理解"
                }
              ],
              "content": "多模态的挑战与机会"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "机器人技术的现状与挑战"
                },
                {
                  "children": [],
                  "content": "大模型在机器人控制与决策中的应用"
                }
              ],
              "content": "机器人与大模型"
            }
          ],
          "content": "多模态与机器人"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "从理论到应用的跨越"
                },
                {
                  "children": [],
                  "content": "潜在的行业革新与颠覆"
                }
              ],
              "content": "大模型对AI领域的影响"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "投资大模型背后的逻辑与风险"
                },
                {
                  "children": [],
                  "content": "AI技术在不同行业应用的投资机会"
                }
              ],
              "content": "投资视角"
            }
          ],
          "content": "未来展望与投资机会"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "从语言理解到生成的能力"
                },
                {
                  "children": [],
                  "content": "对智能的边界与限制的探讨"
                }
              ],
              "content": "语言大模型的智能表现"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "大模型与AGI的关系"
                },
                {
                  "children": [],
                  "content": "大模型技术在实现通用智能中的角色"
                }
              ],
              "content": "大模型与通用人工智能"
            }
          ],
          "content": "语言大模型与智能"
        },
        {
          "children": [
            {
              "children": [],
              "content": "大模型是当前AI领域的关键技术之一，其发展对多个行业产生了深远影响。"
            },
            {
              "children": [],
              "content": "随着技术的不断进步，大模型在实现更复杂的任务和应用场景中展现出巨大潜力。"
            },
            {
              "children": [],
              "content": "未来大模型的发展需要解决资源消耗、模型优化以及多模态数据处理等挑战。"
            },
            {
              "children": [],
              "content": "大模型的广泛应用和优化为投资提供了广阔空间，同时也对AI领域的未来方向和可能性提出了新的思考。"
            }
          ],
          "content": "总结"
        }
      ],
      "content": "大模型与AI发展脑图摘要"
    }
  }
}