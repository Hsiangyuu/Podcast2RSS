{
  "pid": "5e5c52c9418a84a04625e6cc",
  "eid": "66a6e059f8b95bef7ca8dc82",
  "title": "E161｜聊聊大模型如何思考与深度学习科学家Yann LeCun",
  "task_id": "82xz94v67p5o9m6v",
  "transcription": [
    {
      "time": "00:00:03",
      "text": "欢迎收听硅谷101，我是红军。从ChatGPT到特斯拉V12，自动驾驶神秘的大模型一次又一次的在工程界给人们带来惊喜。当人们输入一个数据，大模型就能直接输出一个答案。但整个中间过程是怎么样的，没有人知道，我们把这个过程称为黑盒。也正是因为黑盒的不可解释性，所以AI的安全问题在当下受到了很多大佬的质疑。有一群科学家他们在尝试去解开这些秘密，业内称之为白盒研究。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:44",
      "text": "今天我们邀请到了加州大学戴维斯分校的助理教授陈渝北。他博士师从加州大学伯克利分校计算机神经科学家bruno oth。Housing博士后是从纽约大学的深度学习专家杨乐坤教授，央视2018年的图灵奖得主，被业内称为卷积网络之父，同时他也是meta的首席科学家。今天我们就来和渝北聊一下黑盒模型的拆箱进展，以及与之相对的白盒模型。也许不用所有的人都了解黑盒的秘密，但是总要有人打开它。Hello, 渝北你好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:23",
      "text": "你好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:24",
      "text": "然后今天跟你聊这个话题，其实我主要是想聊一聊白盒模型，所以你现在是在研究这一块儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:31",
      "text": "对这个方向，其实它的一个比较大的目标，就是把我们现在看到的这种深度学习，从一门纯经验性学科向一个科学学科来推动。或者说工程变成科学。其实主要的一个动力是来自于这种工程上的一些进展，而它的科学发展相对来讲又缓慢。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:51",
      "text": "那在你自己做这个白盒模型研究的过程中，你有没有发现一些我们怎么去解释GPT它的输入输出，它到底是怎么推动已经出来的一些研究成果。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:03",
      "text": "我自己的工作早期做过一些，以前有一个模型叫做词的嵌入embedding，他可以学到一些语言的一些表征。大家当时其实就有一个疑问说，我们做任务的这些性能变好了，可是是什么导致这个性能变好了？所以我们当时做过了一个非常早期的一个工作，就尝试打开词汇的这些表示。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:25",
      "text": "当你把它打开的时候，你会发现一些很有意思的现象。比如说苹果，苹果这个词，苹果的这个词，它有一个机器学习出来的一个表示。当你把它打开的时候，你会发现你可以找到里面的一些原意思。比如其中的一个意思可能就是代表一个水果的一个意思，然后另外一个意思，它代表甜点的一个意思。然后你再往下挖下去，你会找到有一个是技术和产品，当然它就指的是现在苹果公司的这些iphone这些产品。所以你就会发现在所有的这些意思里边，你能找到这些原意思。顺着这条路，你就可以去把这样的方法延伸到大语言模型里边。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:02",
      "text": "当我们学完一个大语言模型以后，我们也可以尝试在这种大语言模型里面去寻找它里边所带有的一些原意思，然后尝试去打开。当你做这些事情的时候，你会发现，一个大语言模型它有很多层。在初级的这些层里面，它会出现一个现象是说词语的消息。比如说像在英文里面有个词叫做left。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:21",
      "text": "Left这个词它既有可以当做是向左转的这个意思，也可以说我离开的一个过去式。那么具体它是什么意思呢？在当前这个语境下，要取决于前后的这种上下文。所以它的语言模型你会发现它在初期的几层里面，它就把这个词语的消歧就做了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:39",
      "text": "在中期你会发现有一些新的意思也可以产生。当时我们觉得一个很好玩的一个意思是他就做一件事情，他就做单位转换。一旦你说多少的公里变成英里这个转换，然后一旦你说多少的温度从F就是华氏变成摄氏度的时候，它就会被激活，就是这个意思，会被打开。所以当时我们觉得这就很有意思，你可以顺着这个路找到很多相似级别的这种原意思，然后你可以再往上走。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:06",
      "text": "再往上走的时候，你甚至会发现有一些原因，它只检测一种规律。这种规律就是说当你的这个上下文里面出现了一个重复的一句话的时候，或者重复的一个意思的时候，它就会被激活。比如说在星空联盟的这个广播里面，当你说广播播放了两遍，你就发现这个意思它被激活了。然后或者说你说在歌词里面，我重复了一句歌词，它也会被激活。所以就是说你会用这样的方式可以去打开大语言模型以及小语言模型，对吧？当然这些思路也并不完全是新的，它在视觉的模型里面其实已经有相当的历史了。就比如说从马苏zala开始就是有一些这样的探索。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:45",
      "text": "那顺着这个思路是不是如果我们知道了它部分是怎么运作的，我们可以从工程上对它有很多的优化。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:52",
      "text": "对这个是一个非常好的问题。我其实觉得理解的比较高的标准，或者是说做任何的理论，它的一个比较高的要求是可以指导实践。所以在我们当时做这种语言模型，还有词汇的表征的时候，其实当时也有一个目标。就是说当我们理解以后，我们能不能反过来优化这些模型，其实是可以的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:14",
      "text": "就比如说举一个例子，如果你在这种大语言模型里面，你找到的一个原意思。这个原意思他可能当他看到某一种原意思的时候，他就会激活。那这个东西它这一个神经元它就可以被作为一个判别器，你就可以用这个东西来做一些任务。当你找到了这么多原意思以后，你可以通过对这些原意思的改变。改变之后，你就会说我这个模型以前它有一些这样的一个bias，或者说这样的一个偏见。然后你可以通过对这些偏见的一些调整，如果我能发现它的话，那我可以调整它。最近anchor rope c他们做了一个工作，他们能找到这种语言模型里面的一些可能存在的一些偏见，然后对它进行一些改变。可能是可以使这个模型变得更加的公平。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:59",
      "text": "更加的安全。然后我看到去年OpenAI它还有一项研究，它的那项研究就是用GPT four去解释GPT two，看GPT two到底是怎么工作的。比如说GPT two的神经元在回答所有跟美国历史1800年前后的事情的时候，是第五行的第12个神经元会被激活。在回答中文的时候是第十二行的第13个神经元会被激活。如果说我们把它回答中文的这个神经元关闭的话，它对中文的理解能力就会大幅的下降。包括我们去看他说到跟加拿大有关的信息的时候，就是第二十一排的这个神经元。但是我们就看他越往后的这个神经元，比如说它的神经元到了2000排左右的时候，那它整个的可信度就已经下降了很多。你有没有观察到这样一篇论文。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:51",
      "text": "具体这些数字我好像没有读到这篇文章。不过这个方法，我觉得其实你如果要仔细想这件事情的话，它非常像是给大脑的神经元做手术。就是相当于我现在如果有了一个神经的网络。如果这些网络的它的意思从某种意义上它能找到一个局部的一个存在的话，它不是完全分散的，然后它是相对能够找到的这个意思的话，那么我就可以相对来讲对它进行一些操作。比如说我把这个神经元切掉了，那你就可以认为他这一块的能力相对来讲就损失掉了。就是人其实也是一样的，就比如说我在人如果是有癫痫，然后有的时候做完手术了以后，可能会出现某一些语言的一些障碍，对吧？但是其他的功能不受损是多少？我觉得是从原理上看起来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:33",
      "text": "是相似的。OK，那你觉得你的研究跟OpenAI，包括anthropic他们大家都在研究这个大模型的可解释性，它们之间有什么区别呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:45",
      "text": "就是说白合模型的研究是否我们将来能成功这件事情我不知道。因为在这件事情上，实际上我也跟我的导师我们也都讨论过。大家一致的看法是说这件事值得尝试，但是是否会成功我们都不知道。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:00",
      "text": "如果我们回到这块儿的话，我们其实是想理解这个人工智能，并且通过我们的理解重构它？构建出来一些从根本上不一样的东西。观测就是说从解释性这个我觉得只是一种手段。就是说打开这种模型也好，我做这些实验也好，我尝试去根据我打开的这些东西来对我的这些模型进行一些调整也好。我认为这个都是我们在理解过程中所谓的一些尝试的一些手段。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:25",
      "text": "但是我觉得真正重要的一个白盒模型的它的本质，实际上要回到这个信号的本身。因为我不管是人脑也好，还是机器也好，他们学习的本质是因为这种信号。我们这个世界中存在一些结构性，他们也要通过这些结构来进行学习，学的也正是这些结构。那么我们是否可以找到这些结构背后的规律，以及表示他们的一些数学工具，然后把这些东西进行重组，构建出来一个不一样模型。如果这件事儿可以完成的话，我想可能可以带来的一个希望是说，我们可能会提我们的系统的鲁棒性也好，安全性也好，可信度也好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:04",
      "text": "但是还有一点，其实我觉得是如果我们看历史的话，最重要的一点，可能它的efficiency，也就是说它的效率会提高。这个例子多少有点像是一个以前我们一开始是这种蒸汽机先出来的，后来才有了这些热力学这种理论出来了，才能支撑把它从一门完全的工匠的学科变成了一门科学。同理到今天来讲的话，我们现在就好像我们第一次在数据上有了我们的蒸汽机一样。我们从以前不理解我们的数据，终于可以开始做出来一些AI的这些算法，把数据中的规律给抓出来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:37",
      "text": "所以它会更节能。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:39",
      "text": "你要是说到节能的话，我可以给你几个有意思的例子。第一个数是说肯定是节能，因为大脑它相当于一个基本是20瓦的功耗的一个灯泡。我们现在的超级计算机，它可能要超过百万瓦。它这样的一个功耗，首先这是节能，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:54",
      "text": "第二点是说，如果我们看自然界的各种各样的这种生物，大自然进行演化的时候，它演化出来的这个生物，它其实效率非常的高。比如说我们举个例子，像有一种生物叫做jumping spider，它是一种特殊的蜘蛛。这个蜘蛛它只有几百万个神经元。但是你如果看它的在世界中的这些行走的话，它其实是可以做出非常复杂的三维的裙线去捕捉它的猎物。比如你在一个很复杂的一个草丛，然后这边是它的猎物，他可能要分析整个的结构，然后他发现我应该先从这儿下去，然后再从这边走过来再上去，对吧？他要能理解这种三维的结构的，然后达到它的猎物。他有这么强的能力，还要控制自己的话，他只有几百万个神经元。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:36",
      "text": "我其实觉得最有意思的一件事儿，实际上是人对于数据使用的效率。我觉得这个很有意思。你看我们现在AI在过去其实不长的时间，对吧？就是大概也就12年这个样子。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:50",
      "text": "一二年是从哪一年开始的？",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:52",
      "text": "14年我们我觉得从image net我觉得可以作为一个分水岭。因为image多少可以认为是一次对数据大范围的一次尝试。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:01",
      "text": "就是竖的那个项目。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:03",
      "text": "对对对，是的。很多人说就是把AI的发展的这个年，它断到叫alex net，就是alex net出来那一年，也就是说在一美之战上它的性能提高上去了。但是我其实更倾向于看到的是说，在这之前2010年的时候，这个数据其实从原来的小数据变成大数据了。这个是一个分水岭。在这短短的十几年里面，它取得的进展其实是巨大的。到今天来讲，我们的这种大语言模型，比如说lama three，我印象中他现在可能也变得数据量更大了。那应该是13个trAiling的这个token。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:36",
      "text": "但是如果你想人在自己的一生当中，就是在你的成年之前，你到底能接受多少的数据呢？不管是图片也好还是文字也好，我认为这个magical的比较神奇的数字是十个building。就是你假想这样我每秒钟都可以获得30帧图像，那么这30帧图像的话，你1个小时有3600秒。你每天假设那你这样做12个小时，然后你做20年，那你得到的大概就是十个病例。同样的话，我可以不间断的在做阅读，对吧？我每秒钟我可以阅读30个token，大概十个词这个样子。我阅读也是像刚才那样，阅读20年的话，我得到的也是十个病例。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:18",
      "text": "那问题来了，就是说人是如何通过如此少量的一个数据，看似少量的数据跟大模型比是已经很少了对吧？一样这样的一个数据获得如此强的一个泛化的能力？我觉得这个是又是一个efficiency里面最让我觉得神奇的一点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:37",
      "text": "那你觉得我们去揭开大模型到底是怎么运作的，跟揭开人脑是怎么运作的哪个更难？我听起来都很难。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:45",
      "text": "这两者它各有各的难法，我觉得他的方法上是相似的对吧？就是不管是人脑也好，大语言模型也好，我都是我尝试去观测他，看他对什么产生了响应。这个方法我其实觉得从hobo and vessel，就是当时他们得诺贝尔生理学奖。他们是研究在视觉皮层里边的这种叫做simple cell。就是人的这种视觉皮层大概就是在后脑的时候这个地方，然后从眼睛过来经过中间，然后再传到后边的这个诊业。他们找到了这样的这种simple cell，并且尝试研究人看到什么东西的时候，这些神经元它会产生冲动。然后他就可以分析，我让你看不同的东西，看你有的时候完全不响应，有的时候他非常的高兴这个神经元。我就想知道你看到什么东西能最佳的让他兴奋。他们就找到了这个神经元的receptive field。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:36",
      "text": "我们今天来研究这种大语言模型的话，其实也是相似的。我们就来找这种不同的输入，让我们的大语言模型，我们尝试理解它内部的哪些神经元是对哪些输入感兴趣，对吧？其实是相似，只不过它有个区别。第一个区别我认为是对于大语言模型，我们的优势是我们其实所有东西我们都可以观测，并不是受限于我们的观测手段。对于人脑，你就有很多的受限手段。你以前是可以插一个电极，然后后来你可以插一个电极上面比如12个电极.",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:08",
      "text": "再后来就脑机接口的那。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:09",
      "text": "一套是对对对，是的。然后现在你可以比如插上几百个这样的上千个的这种，但是你毕竟你的观测手段是受限的。不管你是用FMI还是用不同的这种neo pixel，这种侵入式的非侵入式的，他们各有各的局限。所以它语言模型给你一个天然的好处，就是说你的观测手段不再受限了。如果你有更好的方法，你就可以尝试去分析。甚至你还可以整个的模型还是可微的对吧？你可以通过一些微分的方法来进一步的分析。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:38",
      "text": "但是它的缺点是大语言模型的能力，我认为还远远不及大脑，尤其是这种大语言模型。如果我们给他一个例子的话，它只从这种语言里面来学习这个世界，他的对世界是理解是不完整的。就觉得好像是说一个人他没有了其他的感官，只有语言。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:54",
      "text": "大脑处理的是更多维的信号，对不对？他除了语言还有嗅觉非常多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:01",
      "text": "对对对，听觉对，就是说他的这种感官的丰富的程度，他对世界的理解，很多的时候甚至有的时候我们可能会想一个问题，就是说语言是否是完备的。如果没有其他感官的支撑的话，语言里边是不是所有的概念都可以独立的存在？还是说它一定需要其他感官作为支撑，你才有可能说来最终的理解那一部分的意思。就比如说我举个例子，我说在语言里边我可以说冰箱这个东西，你如果不和现实的这种世界构成一个这种冷热等等的。当然你可以通过冷热的这种方法，它有门的这个东西来描述这个冰箱这种通过它这种统计特征。但也许这种描述永远是不完备的，但具体是不是完备的我也不知道，我感觉是不完备，但是我也没有办法去把它完全的用数学证明。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:46",
      "text": "或者所以说其实现在整个大模型跟大脑相比，它还是欠缺非常多层的。但是因为我们可以看见的更多，可以把它拆开来研究。所以我综合你的观点，就你觉得他还是会比揭开大脑的秘密的这个野心稍微更进一步的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:04",
      "text": "理解大语言模型它的难度当然就在于你观测的手段多，你可能能对他理解的更加多一点。我的感觉是这样的对吧？有两台机器，一台机器你完全可观测，一台机器部分可观测。我从直觉上来讲是一些完全可观测的这台机器更容易被理解。当然他有一些能力是这台机器没有，所以不能取代对人脑的一些理解。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:28",
      "text": "对我跟听众简单介绍一下，渝北之前是学neuroscience的，所以也是懂非常多神经科学相关的知识。其实我挺好奇，就是你觉得之前你学的这个学科背景，包括我们对整个神经科学的研究，对现在你来做AI方向的研究会有什么帮助吗？或者说他会不会有一些跨学科可以相互借鉴的研究方法在里面。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:53",
      "text": "对我我学过一些计算神经科学，但是我是个半吊子。我其实一直也不是专业学计算神经科学的。因为本科的时候在清华是电子系，在伯克利的时候其实是在伯克利a research也是电子工程计算机系。然后还有一些纯数学的一些背景。我当时我所在的那个研究的研究所，他是一个理论神经科学的一个研究所，所以我导师自己是计算神经科学的专家。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:20",
      "text": "刚才的这个问题说计算神经科学也好，神经科学也好，对于我们研究AI有什么不一样的帮助？我的感觉是说，对于我来讲的话，这种帮助通常来讲是一种启发。因为当你知道自然界的这些系统，有的时候你知道它可以做到什么的时候，或者它面临的一些情况是什么样的时候，你可能会有不一样的想法，会重新看待我们眼前的这个问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:45",
      "text": "我可以举几个例子，这几个例子很好玩，就是说我们现在习以为常的一张图片。这张图片的话它是一个像二维的一个输入信号，它有很多的pixel像素。这个像素它会分有横向的，有纵向的，然后它形成一个网格。但如果我们看人眼的话，你看人眼的视网膜的话，它不是长这样的。首先它的这种不同的感知的这种接受器感受器，它是可以非常密集，但又不是非常规则的方式排布的。而且它中间非常的细密，向两边的时候会变得稀疏。当时你面对这样的一个输入信号的时候，你会想首先一个问题说我们习以为常的这些卷积神经网络什么的这些东西所有的这些东西都失效了。因为连卷积在这里都没有定义，所以当你看到生物系统它所面临的这样的一种情况的话，你会重新去想我们所谓的这些卷积到底从何而来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:39",
      "text": "所以你会重新去想你的方法是不是对的，是不是一定要以这种方式来实现。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:45",
      "text": "对，假设你第二天你醒来的时候，所有的神经元都打乱了，然后你还能再去理解这个世界吗？就是你因为你已经不看到的已经不再是一张图片了，你也不能再用卷积神经网络来做这件事情了。那你怎么去理解这个世界呢？你需要什么样的。方法其实还是可以的，我们没有完全解决这个问题。但是我觉得做了一步，还挺有意思的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:06",
      "text": "这个是怎么做的呢？你就可以说，虽然我的所有的神经元都打乱了，就是我们的感受器图像里面的这些像素打乱了。可是相邻的这些像素他们有一些关系。比如说我们看图像里边的话，我会发现如果一个像素是红的那周围的像素也更可能是红的这是他们统计上的一些关系。那么通过这种关系，你就可以去让这些像素他们重新去找朋友。然后你就可以把相似的这种像素让自己自组织成一些关系这样东西。然后这个时候你再加上我们的大语言模型的这个里面的这种transformer这样的结构，你就可以重新的对这种图像做出一个表示，而且这个表示的最后的它的性能还不错。这个就是一个具体的一个例子，就是说完全就是从一个自然的一个启发。我们重新去审视我们现在一些工程上的一些做法，然后提出来一些不同的方法。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:56",
      "text": "对感觉整个研究AI大模型跟看人脑跟神经科学是怎么运作的，还是有很多相似之处的。我好奇会有神经科学家从他们的这个角度来研究，跟你们产生这种跨领域的合作的吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:12",
      "text": "其实有很多的神经科学家以及统计学家，然后数学家他们想要理解自然信号中的一些结构，同时也会关注大脑中的神经元它们是如何运作的。然后把这两者结合在一起，尝试去提出一些极简的对于信号的一些表示。举一个例子，就是说在大脑里面你会发现有一个现象，就是说这个神经元虽然很多，但是同一时间在工作的这些神经元，就是兴奋的这些神经元，它其实是非常的稀疏。也就是说比如我给你100万个神经元，可能几千个他们在工作。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:45",
      "text": "这里面的问题是说，他们到底学了一个什么东西？其实早年的时候，神经科学这边就提出来一个方法，就是我当时导师他们的参与研究这个工作叫做稀疏编码。稀疏编码当然它不仅仅是一个神经学方面的一些看法，同时它在统经济学家也在同期在提相似的一些思路。也就是说在这种高位信号中，我们能不能找出一些稀疏的低维的一些表示。从这样的思路出发，你就构建出来的一个算法，它也会学出一个神经元它的表示。然后你会惊奇的发现，你学出来的这个表示，它和你在大脑里面观测到的这些神经元的这些表示非常的相近。所以这个是当时计算神经科学的一个早期的算是无监督的一个成功。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:28",
      "text": "我觉得到今天来讲的话，我们的整个的这一只，我管它一个名字叫做自然统计信号的研究，叫做natural signal statistic。它的目标就是揭示信号背后的一些基本结构。它的发展其实相对来讲挺慢的。你会和这种大模型它的进展来看的话，你会发现大模型的进展非常的快。但相比之下，这种白盒模型这类的神经科学的结合，它相对来讲走的慢一些。我其实觉得一方面可能是因为问题复杂，但另一方面也是因为投入这个方向的人比较少。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:01",
      "text": "简单来说就是研究白盒模型的人太少了。但是像我们之前研究的，比如说传统的机器学习的这种算法，线性回归、决策树等，我们都可以理解它是白盒模型。简单来说，在大模型出现以前，我可不可以理解成整个传统的机器学习，它可能就是属于白盒模型的范畴。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:20",
      "text": "我觉得这个说法可以认为是对的。就是说以前的这些机器学习的模型相对简单，你都相对来讲可以理解。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:29",
      "text": "他们类似于现在我们看到的这些大模型，包括扩散模型，他们其实是可以算作属于是黑盒模型的。为什么说现在整个的黑盒模型看起来它在研究跟进展，甚至在表现跟大家的观感上，对白盒模型它是实现了一个弯道超车。就为什么它打击？对对对，为什么他的速度可以快这么多？",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:51",
      "text": "这个问题你问出来，我们就先是紧张一下，对吧？然后再回答我为什么紧张这个问题，就是因为它很尖锐。其实这个问题就是说是不是白盒模型或者说可以理解的这条路径我们应该放弃了呢？就是说我们是不是在AI的研究上，从我们这个时代开始，我们已经不再研究科学了。就是说它从以后全都变成一个经验性学科呢？我觉得还不是。",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:20",
      "text": "但如果回到你刚才的这个问题是说到底发生了什么？在这个过程中，为什么现在这种黑盒模型往前跑得快，而白盒模型跑的不够快？我认为首先一点就是说黑盒模型的包袱少。你既要这个方法可以工作，可以work，然后你同时又要这个方法可以解释你有两条要求。",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:41",
      "text": "那他放弃了一条。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:42",
      "text": "放弃了一条我可以让他工作，这一条是一个非常重要的一条。第21个我认为一个很大的一个被大家所忽视，相对来讲甚至被很多科学家所忽视的一个东西。我认为是数据的逆势增长或者说规模扩大。我认为这个在过去的十几年来讲，甚至有一个我记得Richard sutton写了一篇博客文章，他就讲叫做bitter lesson，一个痛苦的教训。它里边提到了一个事情，就是说在过去的20年里面，有一个一直没有被打破的一个东西。就是说当我们有更多的数据，当我们有更多的计算，你总是应该找一些比较能够真正扩张的一些算法。它能够把所有的数据的这规律找进来。我认为这个是黑盒模型里边，或者说我们现在的经验性的这种进展里面很大的一条。就是说我们有更大的数据更好的数据，更多的计算，更大的模型，然后我就能学的更多。但是我们回到这个问题的话，你可以想白盒模型。你说这个里面大家有一个追求是说我想要做出来这个模型，它要简洁性，然后他要这个模型本身要简洁。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:46",
      "text": "为什么白盒模型要简洁性？我是不是可以理解成如果它过于复杂，你们要在中间加的东西会更多，然后它就很难被设计。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:56",
      "text": "对我其实觉得做理论，你可以只有简洁的东西才可以被理解，对吧？你肯定是要做一次一次的简化。但是如果你考虑到这种skilling law这件事情的话，你会有一个问题，就是说当我们在追求模型的简洁性的时候，可能会做了一次又一次的，在英文里面叫做over simplification过度简化。就是一旦你出现这种过度简化的话，你的模型就无法完全的刻画数据的形态。那么数据更多的时候，你的模型就更无法刻画它的形态。那你就会出现将来这个模型就走不下去了，它的能力会被被限制住。所以我认为这是以前大家在研究白盒模型，在研究简单模型相对来讲面临的一个困难。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:38",
      "text": "我不仅仅要带着那个包袱，我这个模型需要工作，同时我还需要它可解释，同时我还需要它简协。当你把所有的这些东西带上，你会发现这个包袱太重，有点走不动。然后它你会引入错误，对吧？当你做过度简化的时候，你就引入了错误，错误会积累，再后来就走不动了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:57",
      "text": "但是现在黑盒模型发展的很快，然后我们又开始尝试去解决它。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:03",
      "text": "对这次如果我们在解决它的时候，你可能就会重新来审视这个问题。就是说我们不一定需要让这个模型完全的简化到那个程度，它还是能够表示这个世界比较复杂的一面，但是你还是要知道，我们的包袱还是很重要。希望他工作同时希望他还是比较可以理解的，还是希望它有相对来讲简化。所以我认为如果有一天我们可以做到白盒模型的话，在此之前，我认为每一次的尝试都是一次过度的简化。但是我们希望每一次简化，每走一步都能往前走，我们甚至不需要完全做出一个白盒的模型。也许我们可以做出一个白盒的，但是没有大模型那么强的模型，但是也很强做到一个相对来讲不错的模型，但同时它又相对来讲非常简也非常简化。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:51",
      "text": "同时还要保证功能，对部分功能是部分功能部分功能。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:55",
      "text": "它对于我们理解的学习背后的本质是有帮助的。同时这种理解可能能反过来又让我们对大模型的训练什么的，它的效率也会上去。因为我们要回到这个效率这个问题，这个也是我跟一样之前讨论过几次的事情。就是说如果我们发展这个背后的理论，最后我们就可能可以让我们的工程的这种实践，它以数量级的方式效率上升。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:19",
      "text": "所以杨乐坤他的观点是什么？他是更希望发展白盒模型还是黑盒模型？",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:25",
      "text": "如果是在我看来的话，我跟漾聊过这个事情。我认为Young他是一个科学家，但同时他是一个以工程方面所著称的一个科学家。所以他的很多的尝试还是要走第一步，要让这个东西工作起来。但是作为白盒模型的话，我认为这件事情是一样支持，但是他也不知道能不能走通的一个方向。比如说我跟他讨论完，他会觉得这条路值得探索，但是是否能实现呢？他也不知道。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:52",
      "text": "就一个过于有野心的目标。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:55",
      "text": "总要有人做的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:57",
      "text": "是的，而且感觉白盒模型就像你说的黑盒模型，它是一个类似于工程问题。白盒模型它是一个科学，你必须用科学解释它，感觉它对商业化或者应用，它在你真正能出成果以前，他看投入产出比不是那么高。但是如果你最终能做出来这个东西，我觉得对AI的安全性，包括我们说最终对应到它的商业化还是很有价值的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:25",
      "text": "商业化这件事情，其实我认为所有做基础AI研究的人，首先他工作的初衷不是以任何的应用为初中。它是一个对于智能这个问题一个比较纯粹的一个好奇心来驱动的。紧接着你可能会发现它有一些应用在这上面。比如说这个中间的一些过程，你所发现的一些规律，它反过来可能能帮到你在工程的实践。但是你由于这个研究本身它并不是为某一种应用所设计的，所以它并不是一个那种直接的关系。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:57",
      "text": "举一个例子，那你正常来讲做无监督学习的话，你可能会需要训练很多个e poc就是它训练一遍。我们现在就可以问一个比较疯狂的问题，就是说我们能不能所有的数据只看一遍，能学多少是多少？这个时候你会怎么办？如果你这个时候不知道学习的背后的它的一些基本的一个原理的话，那你可能就不容易达到一个比较高的效率。我们当时也做过一些这样的尝试，你会发现其实当你知道背后他在学什么的时候，你是有可能数据只看一遍，然后也学得非常好的。虽然他没有完全把这个区别消除，但是它其实可以比你正常不了解这个原理的话，它的效率高了很多很多，它的区别是很大的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:38",
      "text": "还有一点的话，我认为说当我们在追求这种白盒模型这个过程中，还是极致的这种效率的过程中的话，你会回来追问这个问题。就是说我们现在做的这个大语言模型，是不是只通过这种规模化或者skin law这一条路走下去就可以了。我认为其实还是不是的，因为人他其实是做不到接受这么大量的数据。那如何用少量的数据还能获得比较高的泛化能力，这个也是我们在研究的一个重要的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:04",
      "text": "我觉得这个也是黑盒模型的学者在研究的一个问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:08",
      "text": "对对对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:09",
      "text": "大家都在研究是是是，那现在白盒模型它有哪些学者跟流派在研究这个事情呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:16",
      "text": "白盒模型的话我其实觉得就是看AI的3股力量。第一股力量的话就是说我们在研究大语言模型，研究这些工程模型的过程中，我们可以会产生的一些经验，然后我们可以对它进行一些可视化，这个我认为就是一种流派。Anthropic最近OpenAI他们也参与在做的这些事情，然后对它进行可视化之前就做了一些，然后现在又做的更多，这是其一。其二的话就是计算神经科学这边，神经科学这边我们要尝试对人脑进行理解。然后在人脑里面比如找到了视觉和语言的他们交叉的一些区域，找到了一些记忆可能的存在的一些方式，找到一些层次化表示的一些迹象，这是一种流派。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:57",
      "text": "还有一种流派是从比较数学的角度来出发，比较统计的角度出发。我们问的一个问题就是信号的基本的结构是什么？大家研究的甚至我们会追问，比如3乘3的1个像素空间，它长什么样子？它的形状是什么样的？然后去追问这个信号本身背后的这个结构，这是三种。然后在这个之间还会产生很多的交叉。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:21",
      "text": "你属于哪一派？",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:23",
      "text": "其实这三派我都或多或少的有受到一点影响。因为之前在伯克利的时候，跟我的导师以及马毅老师他们都属于多少有点像计算神经科学和数学统计的这个流派。然后在一样这边是工程这边受的训练多一点，所以这三种方法我也觉得都可以接受。因为它最终都会让我们往同样的一个方向前进。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:47",
      "text": "同样的方向是哪个方向？现在有阶段性结果吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:50",
      "text": "最终就是理解这个模型，之前有一些阶段性成果，就比如说我们能不能做出一些哪怕是两三层的一个网络，然后它还能表示把这些比较高层的这些概念学出来。那每一层我们都可以看他学的是什么东西，最后你发现真的可以做到一个数字，你要想表示它它你会把它一个一个的笔画全都学出来。笔画之间就这些相似的笔画，它们可以把它联系在一起。在这个之上你就可以构建出来下一个层次的一个表示，就像这样的一层一层的，最后找到了数字的这样的一个概念。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:23",
      "text": "有意思。那你现在的这些研究会继续有真正的对黑盒模型产生优化吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:30",
      "text": "黑盒模型优化的话也会有一个是就是说当你对它的理解加深了以后，你可能会比如优化这些黑盒模型，让它的效率变高。第二个是说可以让不同的黑盒模型，你可以把它们统一起来，这样的话你就是减少了很多不必要的浪费。同时我觉得还有一个涉及到我这个实验室的另外一个支柱性的工作，就是要给研究不仅仅是感知，但是还有控制。就是当你给了这些大语言模型也好，给这些不同的model它能够和世界交互的这个能力的时候，这个过程能不能让他的整个的学习的效率变高。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:06",
      "text": "然后之前我们做过一些很好玩的一些尝试，就是比如说在控制系统里边，你能否获得同样的泛化能力。但是这个是什么意思呢？就是说在感知系统里面你会发现，我学了苹果，我学了离，然后来一个桃子。由于我之前学了一个相似的苹果和梨的概念，你可以很快就学会桃子的这个概念。那么在控制的领域的话，你能不能达到相似的性能？比如说我现在这个机器人，它学会了向前走，然后我学会了原地跳跃。那我能不能很快一变，就把它变成了一个向前一边跳一边走的一个机器人。就是有这样的一种控制的泛化能力，这是我们之前做的一个比较好玩的一个工作。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:44",
      "text": "综合来说，如果让你给一个结论的话，你觉得白盒模型的研究到我们现在去解开这个大模型它是怎么运作的，这个秘密。它大概是一个什么样的进度条？它的进度条到哪里了？",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:57",
      "text": "它的进度条我都不知道这个进度条有多长。我感觉我们距离这个目标其实很远。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:03",
      "text": "就可能是还在one percent。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:06",
      "text": "它其实有的时候发展它不一定。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:08",
      "text": "是一个线性的对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:09",
      "text": "然后它可能是一个这种比较像量子的这种跳跃。当你有一个什么东西，你一个新的一个认知出来以后，你可能会马上往前走一大步。我倒是觉得我们有可能能够做出一个比较强的这种模型，完全可理解的。但是他复现当时的像比如alex NET这样的performance或者说理解。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:30",
      "text": "就还是要看你的阶段性目标是什么。对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:33",
      "text": "看你的阶段性目标是什么。如果你想做一个白盒的ChatGPT，我认为这个还挺远的。但是你如果说我们要是想做出来一个还不错的这种模型，我觉得这个还是非常有可能的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:44",
      "text": "就是根据我们还不错。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:46",
      "text": "的白盒模型。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:47",
      "text": "比如说它可以用来干嘛。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:49",
      "text": "它可以就做这种image net的这种识别。然后我们可以理解它里边的每一步它是怎么做的，然后它是如何一步一步的变成了一个猫和狗。然后这个猫和狗它的这个结构是怎么产生的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:01",
      "text": "就image net的识别它算是白盒还是黑盒，就是我们还没有发现它的工作原理。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:06",
      "text": "是什么过我们还没有完全发现它的工作原理。但是我们之前比如从methow ZE eller和rob focus他们做的一些早期的ization，后期的又有很多的研究者，他们做的这些visualization就是观测可视化还是有一定理解。但是没有人能够创造出来这样的一个模型，然后每一步我们都可以理解，然后他且还能工作的不错。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:29",
      "text": "所以我觉得可能目标就分阶段。第一步我们先解释这个imagine net是怎么工作的。这个谜底揭开以后，我们可以再来解释，比如说一些小模型是怎么工作的，就像用GPT four去解释GPT two是怎么工作的，然后再慢慢的来解释这个大模型是怎么。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:46",
      "text": "工作的对对。所以这个过程我觉得还是有相当的一个过程的，而且也需要更多的人来投入到这个方向上。因为毕竟工程上面的话现在主要是进展，所以导致大部分的工作也就集中在这儿。如果我们放到学校来做的话，那你其实需要有一些原创性的一些想法，而不是说你去scale我也去scale，大家都是skill。最后其实是没有区分度，就看谁的机器最好了和谁的数据最多了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:15",
      "text": "那倒也是对，接下来我想跟你讨论一下你博士后的导师Young了抗。虽然在开头的部分其实我没有介绍过样，但是我还是想给不太了解的听众来去介绍一下样的背景，让他的中文名字叫做杨丽坤，是一名法国计算机科学家。因为他在深度神经网络概念和工程上的突破，他和gel free hinton以及yoh a bengel一起获得了2 0188年的计算机学界最高奖项图灵奖。他们三个人就被称为是深度学习三巨头，可以理解成现在我们在人工智能上的巨大突破，跟他们的科学研究成果，跟他们的推动是有很大的关系的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:00",
      "text": "Young在2013年，它是成为了facebook人工智能研究院的第一任主任。当时facebook是专门为了他在纽约成立了一个研究院，现在他还是meta AI的首席科学家。可不可以给我们不懂技术的朋友稍微解释一下，让主要的科学研究成果跟他为什么这么知名度。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:21",
      "text": "杨子坤他相当于从80年代的时候就开始研究神经网络AI这个领域。它经过了很多次的高峰和低谷，高峰低谷也有不同的学派出现。衰落样的话，他从早年他就选定了这样的一个方向。他坚持深度学习网络，他相信这个一定能做成。不管他的高峰低谷，他走过黑暗的人。所以也就是说他们经过了当年2000年的时候，他因为那种不同的学派起来，然后摔落在2000年的时候。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:50",
      "text": "曾经有一个非常有意思的一个小故事。他们发文章的时候，你会发现非常的困难，困难到什么程度呢？如果你的文章里面存在neural这个词，就神经或者是你存在network这个词之一的话，你的被拒稿的概率就很大了。但是如果你存在neural network的话，基本就一定会被拒告。所以当时对于他们来讲，这是一个至暗时刻，对吧？但是他们那个时候可能经费也受影响，但是他们能在这种黑暗当中，他们能坚持不放弃，最后能走出这个黑暗，一直坚持他们所相信的这条道路。到今天神经深度网络也确实改变了世界，对吧？我觉得这个其实也是他们得图灵奖，对他们当年早期作为前期的先锋的一种记忆。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:35",
      "text": "对我对你的个人经历也挺感兴趣的。就比如说我知道其实你在博士后的时候，你是选了两了困的组。你当时是为什么会选他的组？",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:45",
      "text": "这是一个比较有意思的奇遇。我当时其实挺迷茫的，我甚至没有想过那个学期去毕业。因为我当时觉得我在博士的工作其实没有做好。当时是我博士当时的决心是说我在博士期间就要做出一个白盒的模型，而且要和alex NET它的性能要可比。当时我觉得就差一点，我就想好，那我再拖一拖再毕业。但是我那年去开new rips，反正也在温哥华。然后同学们就说你做博士后反正也是做做博士也是做，你也不用说非得说博士把所有东西都做完。他们说你不如这个学期毕业。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:22",
      "text": "我同学他们说的对吧？就是那一年很有意思，很多事情都不是我自己决定的。我以前事情都是我自己决定，那一年我感觉我是在被推了很多。对对对，基本上就是他们说什么，我想一想有也有道理，然后我就好，我就那时候决定毕业了，然后决定毕业十天基本就把毕业论文写完。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:39",
      "text": "当时我就想，那你要毕业的话，我要找博士后，那要找博士后的话我去找谁呢？然后我本来想的是给别人发邮件，同学他们就说你都在neuropace在开会，大家都在这开会，你为什么不当面聊呢？我觉得很有道理，然后我就当时去当面去聊，当时我想到的其实第一个想到的人是chelly。如果你这么看的话，他有点像是一个东海岸的我的导师。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:03",
      "text": "这个风格我们在西海岸也是sim chelly，也是计算神经科学领域的一个领军人物。他在东海岸那边，所以我一开始想到的是他。但是他那一年，刚好他要去有个Simons foundation，就是James Simons开创了一个simple foundation，是一个研究机构。他要去那个地方去筹建他们的一个计算神经科学的研究所，他就非常忙。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:26",
      "text": "然后我其实跟他聊也没有聊出来一个说要约meeting约一些会，然后我们也聊一聊聊得挺好，但是也没有得到一个结论吧？是不是要一起工作等等的。然后在会场上就碰到了。我当时想的话是说大家肯定都想找样去做博后。我不想是王兆芬，我其实不是特别投机的一个人。所以当时碰到他的时候，我其实主要想的是聊一下他对我工作的一些看法，以及对未来的方向上的一些。大家可以谈一谈这个观点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:56",
      "text": "比较有意思的时候，当时在会上聊聊的就非常好。当时也觉得非常的，至少我们相信的这种方向以及我想的一些问题，他曾经也都想过，只不过是从neural network，就是从这种神经网络的这个角度来想这个问题，以及最终追求的一些方向的话，我觉得也很切合。所以当时他就问我，joppa sock你有没有兴趣申请一下？我说我当然申请了。所以当时就是这样一拍即合，有意思。所以我最后博士后也就只申请了他的博士。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:28",
      "text": "要是一个什么样风格的导师，他是属于非常多的给学生自由空间探索的，还是属于他其实就是实际上来跟大家一起讨论帮忙很多的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:42",
      "text": "首先是后者的话，他现在这个情况下已经不可能了，他现在太忙了，我觉得这个事情比较多。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:49",
      "text": "你指的他太忙了是比如说meta那边的事情很多，研究的事情也很多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:54",
      "text": "当你变得很有名的时候，你自然就变忙了，很多人都需要他的时间，从这个角度来讲，它能够分给每一个人的时间也相对来讲就没有那么多。我觉得一样，相对来讲，我认为是相当放羊的。他其实和我的博士的导师相似，就是说在一些大面上是非常放羊的。但是我认为他们有另外一点相似的事情，就是说对于他们所相信的事情，他们会有坚持。就是他可能会给你说往这个方向走，那么具体怎么走，你走哪条小路，你是乘船还是乘车，这都没有关系。但是这个大的方向，我认为他会有自己的一些品味。我会觉得另一方面我认为她对不同问题的直觉还是非常不错的。其实他会给你指一个大方向，他不会去控制这些细节。然后我们会有一个比较大的一个愿景或者说一个目标mission在这个mission下面，我们就会要坚持的沿这个方向走。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:53",
      "text": "他的大方向是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:55",
      "text": "其实很多年也没有变过。让他想什么实际上是非常透明的。因为他会出去给不同的地方给演讲，然后他讲的这些东西基本上都是他坚持的这个大方向。在过去的这些年里面，我觉得他坚持的这个方向一直是自监督学习。然后自监督学习的话其实分两部分。一个部分是我做感知，感知上面的话我可以做自监督。但是更重要的一点的话是当有最深的时候，我如何用最深的方式来做自监督。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:24",
      "text": "或者我们现在给他一个名字叫做世界模型word model，我认为这个是他believe in的一个方向。这个名字其实还是我安利给他，但是因为我当时读了David和史miss uber的那篇文章，然后他们起了一个名名字叫word model。然后我觉得这个名字挺酷的。虽然是一个传统的想法，就是以前也有这种model，predictive control, 然后forward model，就是有各种各样的名字，对吧？但是这个world的model我感觉挺酷的，所以我们当时强烈的安利了一波。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:53",
      "text": "你觉得让他的研究方向跟脉络，跟OpenAI的这一套，antha rapist的这一套好会有什么不一样吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:02",
      "text": "如果说真要说什么不一样的话，我觉得一样可能想要的是模型它需要有几件事情。第一件事情它要有自身的能力。我觉得他要是可以在这个世界里不是只是堆数据，而是说这个模型最终他可能会可以自己去探索这个世界。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:19",
      "text": "这个有什么不一样呢？大家都希望最终达到这样的一个结果。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:24",
      "text": "但是你如果说看他的执行的方式的话，我觉得每一个地方他执行的时候，他的最坚持的我其实觉得是比如说在OpenAI，我认为它是scaling law，对对对吧？就是我认为这个其实是OpenAI一直做的比较，相对来讲是他们做的很对的一个东西。那我要更多的数据，更好的数据，然后更多的计算，更大的模型，更general模型对吧？基本上坚持这个对于硬来讲的话，它其实还是比较科学化的。他会说如果我们想真正通向比较像人艺这种level的智能的话，那你到底需要什么？而不是说我就把数据给你堆上去，只是做这样的事情。那我可能会觉得只是堆数据是不够的这是它的不同点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:03",
      "text": "所以它其实也是相当于你说的黑盒白盒一起研究。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:07",
      "text": "就是它对于样子来讲的话，甚至我认为它没有那么在意这个是否它发展成一门科学。目前我认为他的观点是他还停留在经验性和工程上面，然后让这个系统可以工作得更好。我认为这个话在短期之内是会走的比较快的对吧？也是他其实一直非常擅长的一个东西。因为当年其实在开会的时候，在会场上他就会带着他当年做的卷积神经网络去做给别人看。你看这个我可以做数字的识别等等的。他其实很擅长这个工程的这种让这个。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:41",
      "text": "系统可以工作起来。对我好奇的是在OpenAI证明了skin law可以达到很好的效果的时候，你觉得让他在科研方法跟他的思维上他会有转变吗？还是他非常坚持的，还是原路线。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:54",
      "text": "我其实觉得他并不反对skin law。对对对，就是更多的数据，更好的数据和更多的计算。我觉得大家在这件事上并没有冲突。但真正的可能分歧就是说比如说在OpenAI很多工作其实还是要以产品为导向的，对不对？一样的研究组来讲，我其实觉得OPI的很多东西，一个是工程上执行的极致，另外一方面也是产品上的一些突破。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:21",
      "text": "比如说对话的形式的最新的引入。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:24",
      "text": "这个还是需要一点商业上的天才来做这样的事情。然后我觉得对于央行自己的组，它其实更是一个科学形式的一个组。他想这些问题的时候，想的就是里面不太涉及到产品的这些问题。他想的只有一个问题，就是说我怎么能实现这样的智能，那到底是需要什么？因为他在这个领域已经太久了，已经不像是我们我们进入这个领域其实也有一段时间了，对吧？但是他8几年的时候就在这个领域在深耕了。所以他可能看这些问题的时候，他还是坚持自己的理想。说我怎么能获得更强的像他看到的这种方式，来让这个智能的能力提升。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:59",
      "text": "对你刚刚一个说的是让这个智能自主的学习，这是第一个观点。就是让它的一些大方向，其他的还有一些方向是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:08",
      "text": "还有一个方向的话一样一直相信的一个东西，我其实觉得这个是一个有意思的问题。这个问题就是说他一直在谈的是japan joint embedding predictive architecture这个结构，它其实表示一个观点，就是说我当然要有自身能力，对吧？我当然要有自主学习的能力。但是比这个更重要的一点是说，它其实不仅仅是一个压缩的一个问题。它是当你在学习数据的时候，你是希望把数据中的一些比较高层次的一些规律学习出来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:37",
      "text": "那就是两派。一派是说好，我学到的这些东西，我要能够对数据进行完全的重建。你可以认为是一个挺压缩的一个思路。但是要说的这个东西，他认为说他说数据中它所具有一些高层次的规律，你不希望它完全的去回到这个图像当中。因为你如果要是还能重建这个图像的话，你就带有了太多的细节。而这些细节并不是对你的这个系统做判断的时候最重要的一些信息。所以在这点上的话，我认为是他也一直在坚持的一个东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:10",
      "text": "这点他跟你伯克利的导师马毅老师的观点是不一样的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:14",
      "text": "我其实觉得严格来讲，他们是很好的朋友OK。所以我其实觉得这个观点上并没有本质的冲突，只不过是表述的方式。我自己看这个问题的话，比如马老师觉得这个世界的规律是简洁的，让觉得说这些细节其实对你做下游的这个任务或者做一些很多的判断是不利的。所以你要把那些高层次的规律找到。但如果你仔细想，这两个东西实际上是一样的，对吧？因为高层次的规律它是简洁的，但只是说当我们想这个问题的时候，我们可以把这个完全看成一个压缩问题，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:48",
      "text": "马老师经常说所有的东西都是压缩。如果你拿一样的这个观点来看的话，你会发现，没错，所有的东西都是压缩。但是这个数据的它的这种层次的结构有不同，对吧？因为是现实世界是复杂的。那么现实世界如果你你深入到这些细节里边，你会发现有大量的东西，它其实是低层次的一些结构。不是说这些规律不存在，只是说这些规律并不像我们人类，比如说咱们人类知识的高峰就像万有引力，对吧？我们找到了这样万有引力的几个公式，可以基本上在我们可观测的范围内都是对的，或者说在我们常规的物理的可观测范围都是对的那这个可能只是很小的一段信息，但是如果我们去看外面的这个森林的树叶的样子的话，那它这里面很多的结构是局部的那这些局部的这是什么意思呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:49:35",
      "text": "当我们在谈压缩的时候，数据中有结构。任何存在结构的东西都是从噪声偏离的一个反应。就是说完全没有结构的东西就是噪声，任何离开噪声你就是有结构了，对吧？然后我们要学习的本质要学习这些结构，但结构有不同的层次，低层次的话，比如地毯它的样式，当你上升这个层次，在更大的一个尺度的时候，你会发现这个东西这个结构其实已经不重要了。它甚至已经没有更高级的结构了。那它在那个层次来看的话，这些东西就已经变成相对来讲像噪声一样的东西了。所以这样的一个观点是说，我们需要有这样一个层次化的学习，能学习出来越来越高的这个结果。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:16",
      "text": "所以我如果我们做压缩的话，这对我们做的出了一个挑战。我们要压缩是没错，我们要学习信号中所有的结构，不同层次的结构。但是最高级的结构，它往往对于压缩的整个的所占的这个比，它不大，在优化的过程中可能会丢失，对吧？就是因为你大量的东西都是在低层次的，这些像噪声一样的这个信息量是最大的。越往上走就越难发现这样的结果，为什么呢？因为在你的优化的loss function，就是你的目标函数里边，你找到这个规律和找不到这个规律可能对你的loss影响不大。我觉得主要就是这么几点，它一个是对于这种世界模型，一个是对于这种层次化的表示。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:58",
      "text": "你觉得他们身上有哪些特质是特别打动你的？",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:03",
      "text": "我觉得他们身上特别打动我的特质，可能就是他们做事情的那种专注和纯粹。对，因为我跟Young有一次吃午饭，然后我觉得我们聊一个事情，我觉得他说的一句话很有意思。他说你们在年轻时候想要的所有的东西我都有了，但是我已经没有太多时间了。所以他只能用自己剩下的时间做自己真正相信的事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:33",
      "text": "我觉得当你跟这样的一些科学家工作的时候，你可能会被他们身上的这种气质所影响。以至于你即便你还没有达到他们现在所在的这个地位，以及他们所拥有的这些东西之前，你也能以他们的视角来看待这个世界一点。所以你在做选择和做事情的时候，你可能会超出你现在完全你所在的这个位置。可能会想一些，我如果我有每天也都像他一样全都拥有了以后我会做什么，对吧？那你这样的话，你在选择一些研究的问题的时候，以及事业的这种方向的时候，你可能会被他们的这种气质经过长时间的这种气质所影响。我觉得这个可能是我觉得收获挺大的一个东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:16",
      "text": "所以他有改变你的哪些决定吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:18",
      "text": "有啊，他会让我做很多的选择的时候会想到这个事情。其实这点的话，我在读PHD的时候，读博士的时候，也会被我的导师影响。本身他们几个人都是朋友。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:30",
      "text": "对，所以就是学术圈子很小。",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:32",
      "text": "对，学术圈子很小，他们以前也是有合作。我读PHG的时候，第一天其实我的导师他讲了两件事情，他说希望你不用发很多的文章，后来他不承认这件事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:47",
      "text": "对的，就是出不来结果还是要说对他后来我跟。",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:50",
      "text": "别人讲的时候他也在场，我说他说不需要我发很多的文章，他说他没说过这个，但是他有一个他承认，他说过他就是说他希望你能发出来的这种文章能够穿越时间，就是说在20年以后看到这篇文章依然不救。我后来觉得这个很难，因为很多的工作它带有鲜明的时代感。但是真正一些深邃的思想，他可能穿越了100年，穿越了几十年，它依然看起来还不是很老。这样是高质量的工作。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:16",
      "text": "那你那个20年还不旧的工作，那至少是能推动人类往前前进20年的一年不就就推动人类前进一年。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:24",
      "text": "对，这个是一个很高的目标，而且短期无法被验证。只有在你退休的时候，它可能才能被验证。等你快要退休的时候，我们才能重新审视这个人。但是他至少他提出了一个灵魂的拷问，对吧？就是你能否坚持去做一些能够与时间共存的工作，我觉得这个要求很高。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:40",
      "text": "第二个是他希望说一个学者应该具有自己的一种态度。如果你觉得一件事情是A可以做，B可以做，C可以做，你也可以做，你就不要做。就是说当你做这件事情的时候，你会发现并不是这个工作需要你，而是你需要这个工作，这是一种投机的心态。就是我其实觉得他们身上有相似的这种气质，可能就是说他希望你做一点，不要随大流，能有自己的态度，寻找到自己的一些voice的一些东西。所以在你在选这些研究的方向的时候，你也会自己时不时的判断一下我现在做的这个工作到底是一个投机的，还是一个真正的中流砥柱的工作，有的时候你还是会做一些投机的工作，但是你自己心里要有一个判断。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:21",
      "text": "对我觉得这个就是独立思考且坚持自己的热爱。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:26",
      "text": "对，而且我觉得他们，尤其是像一样，他们比较伟大的一点就是说你可以穿越了这种几乎是绝望的过程中，然后迎来曙光。因为我觉得没有经历过低谷的人，沉淀的可能还是不够。当你经过至暗时刻，你还能走出。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:42",
      "text": "在至暗时刻没有改变方向。对，走出来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:45",
      "text": "对，当然你不是说不撞南墙不回头就是完全错了。而是说你你的眼光可以穿越短期的这个时间，你可能真正有一些坚持的东西，而且你是证明他是对的。我觉得这个是挺有意思的一种气质。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:58",
      "text": "有哪些样在科学上的看法是你不同意的吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:01",
      "text": "比如说样的观点会有点挺鲜明的一些特点，它有的时候会铁口直断。比如说最近他有可能说如果你是PHD的话，那你就不应该研究large language model。",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:13",
      "text": "那他认为什么阶段应该研究？",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:16",
      "text": "不他就是说你如果作为一个研究者的话，你在读博士的话就不应该研究这个东西。这他有很多种理解，从他字面上意思的理解的话，你就会很多人就会不同意，对吧？包括我可能会觉得大语言模型，可能它里面有一些结构是值得被理解的，去研究一下的。但是他可能他真正想说的，也许我有的时候听他的这个话，他背后想说的可能是你不要去做，就像刚才说的这种A可以做，B可以做，C也可以做这种投机性的工作。而是说你真正有自己的一点坚持，找到一些比较原创性的贡献。如果是这样的说的话，我其实觉得我会更同意一些。但是我其实觉得有的时候他表达的是这种意思。可是由于他是大V，他他说如果说所以。",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:57",
      "text": "认同他的理念，不认同他的表达话术。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:00",
      "text": "他有的时候这个话讲出来会吓你一跳。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:03",
      "text": "什么意思对吧？很可爱。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:06",
      "text": "对我觉得这他比较有意思的地方，但是他有话题性。这样的好处是说大家看完了这个以后，大家觉得你就瞎说，然后这我觉得挺好玩的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:16",
      "text": "对，因为你也在meta工作过，你觉得一样对meta最大的贡献在哪几块儿？",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:24",
      "text": "一样对meta最大的贡献，我觉得首先它应该算是帮助筹建了meta ai当时他筹建meta AI的时候，首先是mark找到他，第二个是说他自己也有一个理想。因为他早年是贝尔实验室的，他很向往当年的贝尔实验室的那个状态。所以他其实想在meta.",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:43",
      "text": "在工艺复制这样的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:44",
      "text": "一个贝尔实验室。他秉承了这样的一个理念做了meta ai也招了一批非常不错的人。结果，其实也是给这个领域做了很大的贡献。我认为这个可能是他真正比较大的一个贡献在meta。然后借助这样的一个平台，把这样的一个理念给贯彻出去。这也是他现在推动整个领域发展的一个方式。如果你只是自己一个人研究的话，可能不如能搭一个摊子。然后让大家这些聪明的人一起在这样的一个框架下一起推动，一起玩。",
      "speaker": "发言人2"
    },
    {
      "time": "00:57:15",
      "text": "OK对我觉得开源应该也算是他的很重要的一个贡献。比如说麦塔拉玛之所以走了开源的路线，跟整个样的思想应该也是非常。",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:26",
      "text": "一致的对对，这个说开源的话，我认为这是样所坚持的。至于将来在商业上，因为商业上它总是有一些竞争，这条理想主义的道路到底还能走多远，我也不知道。将来meta是不是会一直开源下去，就是所有的东西都开源。还是说因为毕竟meta也会面临竞争。它作为一个公司来讲，它要发展的话，它会面临他什么样的竞争，比如OpenAI，google什么这些公司的竞争。那在这样的一个竞争情况下，你是否还能以一个比较现实的方式，一直坚持这种开源的这种理念？我其实不知道，但是我觉得这是一样的一个理念，最终能执行到多好，能走多远，其实也要看整个的这个群体community它的发展。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:10",
      "text": "那你觉得现在整个大模型的研究，它是一个必须是一个科学家驱动的吗？还是它会慢慢变成一个工程驱动的事情？",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:19",
      "text": "我觉得它已经变成一个工程驱动的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:21",
      "text": "早期是科学家驱动的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:23",
      "text": "就是当东西它不太work的时候，就是它还不太好用的时候。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:28",
      "text": "这个就它没有做出来的时候。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:29",
      "text": "它是科学家驱动。对你需要有一些belief，就是说你要有一些坚持。但是在过去的这些年里面，我感觉这一两年里面，我觉得主要的这个进展都来自于工程的执行，执行的极致程度？数据的质量是不是变高了，数据是不是变多了，它的distribution是不是变丰富了，计算是不是能够并行？这一个一个的这种工程的非常重要的细节导致的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:54",
      "text": "就感觉现在大家都是在做忧患早期从0到1的时候，是科学家在带着大家从无到有去创造这件事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:02",
      "text": "对它的发展，它前期是从0到1，它需要这种突破性。然后从1到100，它其实需要工程的严格性和执行能力。他也是不同人在不同阶段，他的角色的变化，反正要让他发展的话，可能需要不同角色的人一起来推动。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:18",
      "text": "大家现在都在期待GPT5，你觉得如果GPT5就是下一个这样非常大规模的大模型出来了，它更多是一个科学问题，还是一个工程问题呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:29",
      "text": "我觉得工程上面可走的路是很远的，还是有相当的一段路可走的。甚至我们可以认为skin law他还有相当的路可走，他完全没有到尽头。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:40",
      "text": "就是数据还有很多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:42",
      "text": "数据还有很多算力，还有算力可以扩展。你的数据的质量，以前大家光说量，其实质也很重要。这些我觉得都能走相当的一段时间，但是我认为不够的，你skin law肯定不是not enough。就我们这很多现在大家喜欢说或者是什么什么什么is all you need，我觉得更好的一个方式，我们都觉得是什么什么东西is not enough。即便我们现在找到了最robust最鲁棒的一条路，就像是skin law这样的东西，我认为is not enough。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:13",
      "text": "那么我们还需要什么呢？我其实觉得需要的就是类人的这样的efficiency，就是这样的高效效率。那这个效率如何实现这样的一个效率？有可能是数据触发的，有可能是data追问的对吧？完全是数据驱动的，但也可能是还有其他的一些东西。所以我觉得如果我们说要通向AGI的过程中，应该还会有这种完全从0到1的一些比较大的一些。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:37",
      "text": "就是既要有科学上的进展，然后工程上我们还有很大的空间可以去提高。对这个总结非常好好，谢谢渝北。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:47",
      "text": "感谢。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:50",
      "text": "好了，这就是我们今天的节目。如果大家喜欢我们的节目，欢迎在你所收听的音频渠道来订阅。我们中国的听众可以通过小宇宙、喜马拉雅、苹果播客、蜻蜓FM、网易云音乐、荔枝播客和QQ音乐来关注我们。海外的听众可以通过苹果播客和spot f来关注我们。另外大家也可以在youtube上搜索硅谷101播客来关注到我们。我们的搜索词是硅谷101播客。如果大家在搜索的时候出现了我们硅谷101的视频，大家也可以一起关注。好，感谢大家的收听，谢谢。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "在探讨AI领域的进展与未来趋势的对话中，一位加州大学戴维斯分校的助理教授强调了理解AI模型运作机制的重要性，指出当前AI研究正从经验性学科向科学学科转变。尽管黑盒模型占主导地位，但解码这些模型的内部工作原理对于提升AI系统的鲁棒性、安全性和可信度至关重要。他提到，跨学科合作，特别是计算神经科学与AI的融合，能促进AI理论与实践的进步。同时，对话还涉及了AI未来发展的几个关键点，包括模型效率的提升、数据的重要性以及实现类人智能所面临的挑战。整体而言，讨论透露出对AI技术未来潜力的乐观态度，同时强调了探索AI更深层次理解过程中的未解之谜的重要性。",
    "qa_pairs": [
      {
        "question": "在白盒模型研究中，你是否发现了一些可以帮助解释GPT等大模型输入输出的工作成果？",
        "answer": "我早期做了一些相关工作，例如通过词的嵌入（embedding）模型学习语言表征时，探索了模型性能提升背后的原因。我们尝试打开词汇表示，发现其中蕴含的各种含义，如“苹果”这个词在不同层中的不同意义。这些方法可以类比应用到大语言模型中，去寻找并理解其内部的原意思和消歧现象。",
        "time": "00:02:03"
      },
      {
        "question": "如果知道大模型部分运作原理，是否可以在工程上对其进行优化？",
        "answer": "这是一个非常好的问题。理解高深的标准或者说做任何理论的一个较高要求是可以指导实践。当我们对语言模型和词汇表征有深入理解后，确实可以反过来优化这些模型。例如，通过识别模型中特定原意思的激活情况，可以将其作为判别器用于不同任务，并通过调整这些原意思来消除模型的偏见或增强其公平性和安全性。",
        "time": "00:04:52"
      },
      {
        "question": "你们的研究与OpenAI、Anthropic等机构在研究大模型可解释性方面有何区别？",
        "answer": "虽然大家都在研究大模型的可解释性，但具体目标和方法有所不同。我们致力于从本质上理解人工智能，并通过理解重构出全新的、更高效的模型。我们希望通过白盒模型研究揭示信号本身的结构及其规律，构建出鲁棒性更强、安全性更高且可信度更好的系统。",
        "time": "00:08:00"
      },
      {
        "question": "大模型与人脑的学习效率相比，哪个更难揭示？",
        "answer": "揭示大模型是如何运作的和揭示人脑是如何运作的，两者都极具挑战性。但有趣的是，人类通过相对少量的数据就能获得强大的泛化能力，这同样是一个非常神奇且值得深入研究的“高效率”现象。",
        "time": "00:12:18"
      },
      {
        "question": "在研究人脑和大语言模型时，你们的方法有何相似之处？",
        "answer": "我们在研究人脑和大语言模型时，都是通过观察它们对不同输入产生的响应来了解其内在机制。比如在人脑研究中，科学家会观察简单细胞对不同视觉刺激的反应；而在研究大语言模型时，我们会尝试找出哪些输入会让模型内部的神经元产生最大响应。虽然人脑的研究受限于观测手段，而大语言模型的优势在于我们能够更全面地对其进行观测和分析。",
        "time": "00:13:36"
      },
      {
        "question": "大语言模型与人脑相比有哪些局限性？",
        "answer": "大语言模型的能力目前还远不及人脑，它主要从语言中学习世界，这种单维度的理解相较于人脑处理多维信号的能力是有限的。此外，语言模型无法像人脑那样利用多种感官信息来全面理解世界，这使得它在理解和解释复杂现象时可能存在不完整性。",
        "time": "00:14:38"
      },
      {
        "question": "神经科学背景对您研究AI有何帮助？",
        "answer": "我的神经科学背景为我提供了跨学科的启发，了解到自然系统如何实现某种功能后，我会反思并重新审视眼前的问题，这有助于创新思考和提出新的解决方案。例如，在研究图像处理时，借鉴人眼视网膜的结构特点，提出了不同于传统卷积神经网络的新方法。",
        "time": "00:17:20"
      },
      {
        "question": "是否有神经科学家从他们的角度来研究AI领域并与你们产生跨领域的合作？",
        "answer": "是的，很多神经科学家、统计学家和数学家都在关注自然信号中的结构以及大脑神经元的工作机制，并尝试结合两者提出关于信号简洁表示的新思路。比如稀疏编码就是早期的一个成功例子，它揭示了神经元活动的稀疏性和高位信号中的低维表示之间的联系。然而，目前白盒模型的研究进展相对较慢，可能是因为问题复杂度较高和投入该领域的科学家较少。",
        "time": "00:20:12"
      },
      {
        "question": "在追求模型简洁性时，为何会出现过度简化的现象，它会带来什么问题？当前研究白盒模型面临的主要困难是什么？",
        "answer": "过度简化的现象是指在追求模型简洁性时，可能对模型进行了一次又一次的简化，导致模型无法完全刻画数据的复杂形态。一旦出现这种过度简化，模型的能力会被限制住，无法进一步提升其表现力，限制了模型的发展潜力。主要困难在于需要平衡模型的可解释性、简洁性和工作能力。当带上这些包袱后，研究者会发现很难前行并可能引入错误。而黑盒模型虽然发展迅速，但目前尝试解决该问题的方法是让模型保持一定程度的复杂性以表示世界复杂的一面，同时力求保持相对简化和可理解。",
        "time": "00:24:56"
      },
      {
        "question": "杨乐坤（Young）对于白盒模型和黑盒模型的发展持何种观点？",
        "answer": "杨乐坤是一个以工程著称的科学家，他首先关注的是让模型能工作起来，对于白盒模型的看法则是既希望它能工作，又希望它是可解释且相对简化的。尽管他支持探索白盒模型的可能性，但也意识到这是一条尚未走通的道路，但值得探索。",
        "time": "00:27:25"
      },
      {
        "question": "白盒模型研究与黑盒模型研究之间有何关联？目前有哪些学者或流派在研究白盒模型？",
        "answer": "白盒模型研究与黑盒模型研究是相互关联且共同推进的。白盒模型有助于理解学习背后的本质，提高大模型训练效率，并可能对AI安全性及商业化产生深远影响。而黑盒模型也在寻求如何用少量数据获得高泛化能力，两者都在研究如何优化和理解AI模型的工作原理。研究白盒模型的学者主要有三大流派：一是从大语言模型和工程模型经验出发进行可视化的研究；二是计算神经科学方向，通过理解人脑来借鉴其结构和功能；三是数学和统计角度出发，探究信号的基本结构。杨乐坤本人则受到这三派的影响，并在不同场合有所侧重。",
        "time": "00:32:30"
      },
      {
        "question": "当前白盒模型研究进展如何，能否对黑盒模型产生优化作用？",
        "answer": "当前白盒模型研究还在发展阶段，距离完全理解并解释大模型运作的秘密还很远。不过，已经取得了一些阶段性成果，例如能够逐层解析模型学习的内容，并有望通过加深理解来优化黑盒模型的效率、减少不必要的浪费，以及在感知与控制领域提高学习效率和泛化能力。",
        "time": "00:32:30"
      },
      {
        "question": "在神经深度网络领域，早期存在一个让研究者感到困扰的情况，能具体描述一下吗？",
        "answer": "当时如果文章中出现“neural”或“network”这样的词汇，尤其是连用为“neural network”，被拒稿的概率非常高。这个时期对研究者来说非常艰难，但他们在经费受影响的情况下仍坚持下来，最终通过不断努力和探索，走出困境，坚持自己的信念，最终神经深度网络的发展改变了世界。",
        "time": "00:37:50"
      },
      {
        "question": "您在博士后阶段为何会选择特定的研究组？",
        "answer": "当时我在博士期间的工作进展不顺，决心在博士阶段做出一个性能可比于alex NET的白盒模型。受到同学们建议，在迷茫之际决定毕业并开始写论文。在寻找博士后机会时，我原本打算通过邮件联系潜在导师，但同学建议我去现场与chelly进行面对面交流，所以最终我选择了去他的组里做博士后。",
        "time": "00:38:45"
      },
      {
        "question": "您与chelly的合作是如何开始的？",
        "answer": "在一次学术会议上，我与chelly进行了交谈，虽然一开始没有达成明确的合作结论，但在另一个场合我们再次相遇，并深入讨论了科研方向和观点。这次交谈让我发现我们在自监督学习、世界模型等研究方向上有共同的兴趣和深入的理解，因此我决定申请加入他的博士后团队。",
        "time": "00:40:56"
      },
      {
        "question": "chelly作为导师，他的风格是给予学生很多自由空间还是更倾向于共同讨论和指导？",
        "answer": "chelly现在虽然因为工作繁忙而不能像以前那样投入大量时间给每个人，但他依然会在大方向上给予指导，鼓励我们追求自己认为的方向，同时他的直觉和对问题的看法都相当不错，会在宏观方向上有自己的坚持，并让我们在大方向下自主探索。",
        "time": "00:41:54"
      },
      {
        "question": "chelly的研究方向与OpenAI等机构相比有何不同之处？",
        "answer": "chelly的研究方向同样重视模型的自我能力，但他更关注如何实现模型在真实世界中的探索和自我提升。相较于OpenAI强调的scaling law（即更多的数据、更好的数据、更多的计算等），chelly更看重实现智能本质的技术路径，而非单纯依赖数据堆砌。",
        "time": "00:44:24"
      },
      {
        "question": "chelly是否支持OpenAI提出的skin law（经验性原则）？",
        "answer": "chelly并不反对skin law（更多数据、更好数据、更多计算），但他更倾向于从科学原理出发研究如何增强智能能力，而不像一些研究组那样更多地以产品为导向。chelly坚信找到高层次的规律并自主学习的重要性，这也是他与其他一些学者观点上的异同点。",
        "time": "00:45:54"
      },
      {
        "question": "在数据压缩方面，为什么需要层次化学习？",
        "answer": "因为数据中的结构在不同层次上存在，低层次的结构可能像噪声一样不重要，而更高级的结构在整体中占比不大且容易在优化过程中丢失。层次化学习能够识别并提取不同层次的结构，从而实现有效的压缩。",
        "time": "00:49:35"
      },
      {
        "question": "科学家身上的哪些特质特别打动您？",
        "answer": "科学家们专注且纯粹的工作态度特别打动我，他们追求真正相信的事情，这种气质会影响和启发我在做选择和事业方向时以更高视角看待问题。",
        "time": "00:51:33"
      },
      {
        "question": "这些科学家是否改变了您的决定？",
        "answer": "是的，他们的态度让我在很多选择时会考虑到长远影响，例如在读博士期间，导师希望我追求高质量而非大量发表文章，强调作品应经得起时间考验，这一理念对我有很大影响。",
        "time": "00:52:18"
      },
      {
        "question": "您是否认同某位科学家关于研究大语言模型的观点？",
        "answer": "我部分认同他的理念，即不应盲目跟风投机性工作，而应坚持原创性和寻找具有持久价值的研究方向，尽管他表达方式有时引人惊讶。",
        "time": "00:53:40"
      },
      {
        "question": "对于Meta的最大贡献，您怎么看？",
        "answer": "Meta的最大贡献之一是帮助建立了Meta AI，并借鉴贝尔实验室的理念打造了一个优秀的研究平台，吸引了众多人才，推动了整个领域的发展，开源也是其重要贡献之一。",
        "time": "00:56:44"
      },
      {
        "question": "当前大模型研究是一个科学家驱动还是工程驱动的过程？",
        "answer": "初期大模型研究主要是科学家驱动，从0到1的突破性进展由科学家引领，但近一两年来，工程执行能力和细节优化（如数据质量、算力利用等）成为推动研究进展的关键因素，表明大模型研究正在向工程驱动转变。",
        "time": "00:58:10"
      },
      {
        "question": "如果GPT5这样的大规模模型出现，它主要解决的是科学问题还是工程问题？",
        "answer": "GPT5等大规模模型的后续发展更多是一个工程问题，尽管科学上的进步也很重要，但在数据量、算力扩展和模型效率等方面仍有许多发展空间。",
        "time": "00:59:18"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探索黑盒模型之谜：从ChatGPT到深度学习的白盒研究",
        "summary": "硅谷101的红军主持与加州大学戴维斯分校助理教授陈渝北就黑盒模型的拆箱进展及其对AI领域的影响进行了深入讨论。陈教授指出，深度学习正从一门经验性学科向科学学科转变，主要动力来自于工程进展与科学发展之间的不匹配。通过研究白盒模型，科学家尝试揭示黑盒模型内部的工作原理，如通过词嵌入模型解释GPT的输入输出过程。早期的研究显示，词嵌入能学到语言的表征，揭示词汇的多重含义，为理解大语言模型提供了基础。"
      },
      {
        "time": "00:03:01",
        "title": "大语言模型的内部探索与应用优化",
        "summary": "讨论重点在于如何在大语言模型中寻找并利用其内部的原意思进行模型优化。通过探索模型的多层结构，可以发现模型对于词语消歧、单位转换、重复规律检测等功能的实现方式。进一步地，通过理解这些模型的运作机制，可以针对性地进行优化，比如调整模型的偏见，以实现更公平、安全的模型表现。此外，还提到了通过研究特定神经元的激活情况来解释和改进模型的案例，如OpenAI的研究，展示了解释和优化大语言模型的潜力和方法。"
      },
      {
        "time": "00:06:51",
        "title": "探讨人工智能模型的可解释性与未来发展方向",
        "summary": "对话内容主要探讨了人工智能模型的可解释性研究，特别是如何通过理解和重构提升模型的鲁棒性、安全性和效率。类比于对人脑的研究，指出当前人工智能研究需要找到数据背后的结构和规律，以及表示这些结构的数学工具。此外，还提及了历史上的技术进步，如蒸汽机的发展，以及通过更高效能的方法来提升人工智能的效率和节能性。"
      },
      {
        "time": "00:09:54",
        "title": "自然界生物与AI的数据使用效率比较",
        "summary": "讨论集中在自然界生物，特别是跳蛛，如何以较少的神经元实现高效的复杂行为，与AI在大数据时代的发展进行对比。AI近年来通过增加数据量实现巨大进步，如大语言模型的发展，但人类凭借少量数据就能获得强大的泛化能力，这一点令人惊奇。"
      },
      {
        "time": "00:12:35",
        "title": "大模型与人脑运作机制的探索",
        "summary": "探讨了理解大语言模型和人脑运作机制的相似性与差异。两者均通过观察对不同输入的响应来理解其内部运作，但存在观测手段的差异：大模型的观测手段相对不受限，而人脑研究受限于技术手段。此外，大模型对世界的理解不如人脑全面，缺乏多感官信息，但其可完全观测性使得对其的理解可能更为深入。"
      },
      {
        "time": "00:16:28",
        "title": "神经科学对AI研究的影响与跨学科合作",
        "summary": "神经科学背景对AI方向研究具有显著帮助，主要体现在提供灵感和启发上。通过对自然界系统，如人眼视网膜的观察，能激发对AI问题的新思考，例如重新评估卷积神经网络的适用性。具体案例说明，通过模仿自然界的方法，如像素间的统计关系，可以提出创新的解决方案，如通过自组织来重新表示图像，从而提高AI模型的性能。此外，神经科学和AI研究之间的跨领域合作展现了巨大的潜力，表明了从不同学科角度结合研究的必要性和重要性。"
      },
      {
        "time": "00:20:11",
        "title": "探索自然信号统计与神经科学的结合",
        "summary": "神经科学家和统计学家致力于理解自然信号的结构与大脑中神经元的工作机制，通过稀疏编码等方法寻找信号的低维表示，成功揭示了信号背后的基本结构。然而，相较于快速发展的黑盒模型，如大模型和扩散模型，白盒模型的研究进展缓慢，这部分原因在于问题的复杂性和研究人力的不足。尽管如此，过去的机器学习模型，如线性回归和决策树，仍属于白盒模型范畴，强调了理解和可解释性。当前黑盒模型的快速发展得益于其对于数据和计算资源的有效利用，以及不追求模型的解释性，这一点启示我们在AI研究上应继续探索和平衡白盒模型与黑盒模型的发展。"
      },
      {
        "time": "00:24:46",
        "title": "探讨白盒模型的简洁性与复杂性平衡",
        "summary": "对话中强调了白盒模型简洁性的重要性，指出过度简化可能导致模型无法充分表达数据的复杂性，从而限制模型的能力。同时，指出了追求模型简洁性与保证模型的有效性、可解释性之间的平衡挑战。此外，还提到了黑盒模型的发展对重新审视白盒模型设计的影响，以及通过理论发展提升模型训练效率的可能性。"
      },
      {
        "time": "00:27:18",
        "title": "探讨AI模型的发展方向：白盒与黑盒",
        "summary": "对话中讨论了杨乐坤对AI模型发展的看法，他作为一名科学家，重视工程实践的同时，也对白盒模型持开放态度，认为虽然其商业化和应用的直接价值不高，但对AI安全性和商业化具有长远价值。讨论强调了基础AI研究的初衷并非直接应用，而是出于对智能问题的好奇心。通过无监督学习的例子说明了解原理对于提高学习效率的重要性，同时也提出了利用少量数据获得高泛化能力的研究问题。此外，还询问了目前白盒模型研究的学者和流派。"
      },
      {
        "time": "00:30:15",
        "title": "探讨人工智能模型理解与优化的方向",
        "summary": "对话内容涉及了对人工智能（AI）模型理解的不同方法，包括通过研究大语言模型获得的经验、计算神经科学在理解人脑方面的应用，以及从数学和统计角度对信号结构的研究。这些方法都在努力理解AI模型，尽管研究者可能来自不同的流派，但他们都朝着理解并优化这些模型的共同目标前进。此外，通过这些理解，有可能优化黑盒模型，提高其效率，统一不同模型，减少资源浪费，并扩展模型的能力至感知与控制，进一步提高学习效率。"
      },
      {
        "time": "00:33:05",
        "title": "探索白盒模型及控制系统的泛化能力",
        "summary": "对话集中在探讨是否能在控制系统中实现与感知系统类似的泛化能力，例如通过学习苹果和梨的概念快速掌握桃子的概念，从而推测机器人能否在学会基本动作后快速适应复杂动作。此外，讨论了当前白盒模型的研究进展，认为尽管已经取得一些成果，如对ImageNet识别的理解，但距离完全理解复杂模型如GPT的工作原理还有很大距离。强调了阶段性的研究目标和需要更多原创性思想的重要性。"
      },
      {
        "time": "00:36:14",
        "title": "杨丽坤与深度学习的革命",
        "summary": "杨丽坤，一名法国计算机科学家，因其在深度神经网络领域的突破，与两位同事一同获得2018年图灵奖，被誉为深度学习领域的三巨头。他的工作对人工智能的进步有着重大影响。自80年代起，杨丽坤开始研究神经网络AI，尽管经历了研究领域的多次起伏和学派的更迭，他仍坚定地推进深度学习网络的研究。他在2000年左右遭遇了研究生涯的低谷，文章难以发表，经费也受到影响，但最终坚持走出困境。他的故事体现了科学家面对挑战时不放弃的坚韧精神。目前，杨丽坤担任Meta AI的首席科学家，继续在人工智能领域作出贡献。"
      },
      {
        "time": "00:38:34",
        "title": "选择博士后导师的奇妙旅程",
        "summary": "对话者分享了他在博士后选导师的经历。原本对自己的博士研究不满意，计划延迟毕业，但在同学的建议下决定正常毕业。在一次会议上，他原本打算寻找一位在计算神经科学领域有领导地位的导师，但因该导师太忙未能成行。意外地，他在会上与另一位导师（以下简称“他”）进行了深入交流，发现两人在研究方向和兴趣上非常契合。这位导师最终邀请他申请自己的博士后职位，对话者欣然接受，从而确定了自己的博士后研究方向。"
      },
      {
        "time": "00:41:28",
        "title": "自监督学习方向坚持与导师指导风格",
        "summary": "导师因事务繁忙而给予学生较大自由探索空间，与博士导师相似，对大方向有坚持，不控制细节，强调自监督学习，特别是深度学习中的自监督和世界模型概念。"
      },
      {
        "time": "00:43:53",
        "title": "探讨人工智能研究方向与OpenAI的差异",
        "summary": "讨论重点在于人工智能模型的发展方向，特别是与OpenAI研究路径的比较。主要观点认为，无论是哪一种研究路径，最终都希望能够开发出能够自主探索世界的模型。OpenAI的研究方法强调了'scaling law'，即通过增加数据量、计算力和模型大小来实现更通用的模型，这种方法被认为是一种科学化的尝试，目的是探索达到人类水平智能的必要条件。不同之处在于，仅仅堆积数据被认为是不够的，需要有更深入的探索和创新。"
      },
      {
        "time": "00:45:02",
        "title": "探讨人工智能研究方向与方法论的演变",
        "summary": "讨论集中在如何在人工智能领域内融合黑盒和白盒研究方法，以及这种方法对提升系统性能的重要性。一方面，通过经验性和工程手段让系统更好地运作是当前的主流；另一方面，OpenAI通过引入skin law证明了更多数据和计算能力对于提高效果的重要性。此外，讨论还触及了在科研方法和思维上可能的转变，特别是在产品导向的研究与纯粹科学探索之间的平衡。一种观点认为，虽然技术实现和产品突破非常重要，但对于智能实现的本质探索也不应被忽视，这需要对人工智能领域有深刻理解和长期投入的研究人员去深入思考。"
      },
      {
        "time": "00:46:58",
        "title": "探讨智能学习的未来方向与Japan Joint Embedding Predictive Architecture",
        "summary": "讨论了智能学习的两个重要方向：一是智能体的自主学习能力，二是Japan Joint Embedding Predictive Architecture结构，强调在学习过程中不仅要关注数据的压缩，更要注重从数据中学习高层次规律。观点认为，仅仅能够重建数据细节并不足以支撑系统的有效判断，重要的是抓住数据中对判断最具价值的信息。"
      },
      {
        "time": "00:48:09",
        "title": "探讨简洁性与层次化学习的统一性",
        "summary": "对话集中在讨论如何从不同角度理解和应用世界的简洁性和复杂性。一方面，强调寻找高层次简洁规律的重要性，认为这些规律对于解决实际问题至关重要。另一方面，提出即使是在简洁性追求中，也需要考虑到数据的层次化结构，因为现实世界是复杂的，包含多个层次的结构和细节。强调了学习这些不同层次结构的重要性，尤其是对于压缩技术而言，不仅要关注高级结构，也必须顾及低层次的细节，因为它们在优化过程中容易被忽略。最后，指出理解这些层次化结构对于实现更有效的学习和压缩至关重要。"
      },
      {
        "time": "00:50:57",
        "title": "科学家的专注与纯粹：对年轻人的启示",
        "summary": "对话者分享了与一位科学家共进午餐的经历，以及这位科学家对生活和工作的深刻见解如何触动了他。科学家的话语让他深刻体会到，当人拥有了一切物质条件后，更重要的其实是用剩下的时间做自己真正相信的事情。这种专注和纯粹的态度，以及对未来工作的深度思考，影响了对话者对研究方向和人生选择的看法。他从导师和这位科学家身上学到了追求高质量、能够经受时间考验的工作的重要性，以及在学术和生活中坚持自我、独立思考的重要性。这种对工作和生活态度的启发，使他在面对选择时，能够超越当前的处境，以更广阔的视角来看待问题。"
      },
      {
        "time": "00:54:57",
        "title": "对科学界某些观点的个人看法",
        "summary": "对话中表达了对科学界内某些观点的不同意见，特别是针对一种观点，即认为PHD学生不应研究大型语言模型。发言人认为这种观点可能基于希望研究者能做出更多原创性贡献的想法，但同时也指出这种表达方式可能导致误解和争议。虽然发言人认同追求原创性研究的重要性，但也认为大型语言模型等领域的研究有其价值。此外，发言人还提到了公众对于此类观点的反应，认为这种争议性话题能激发讨论，有一定的趣味性。"
      },
      {
        "time": "00:56:16",
        "title": "Meta AI的成立及其对领域发展的贡献",
        "summary": "Meta AI的成立被看作是对Meta最大的贡献之一，这背后是Mark对重现贝尔实验室辉煌的渴望。通过建立Meta AI，他不仅实现个人理想，还吸引了众多优秀人才，推动了AI领域的整体发展。此外，开源成为其另一大贡献，与他的理念一致，尽管未来在商业竞争中开源的理想主义道路面临挑战，但这一理念的实施效果及影响力值得期待。"
      },
      {
        "time": "00:58:09",
        "title": "大模型研究的发展趋势：从科学驱动到工程驱动",
        "summary": "大模型研究初期由科学家驱动，强调创新和突破。近年来，进展转向工程执行的极致，注重数据质量、数量、分布丰富性以及计算并行能力的提升，表明了从科学探索到工程实践的转变。尽管算力和数据仍有发展空间，但仅靠这些不足以满足未来需求，需追求类人的高效性。大模型向AGI迈进的过程中，既要科学上的进展也需要工程上的提升。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "黑盒模型的不可解释性"
                },
                {
                  "children": [],
                  "content": "白盒模型的研究进展"
                },
                {
                  "children": [],
                  "content": "试图解开黑盒模型的内部运作"
                }
              ],
              "content": "黑盒与白盒模型"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "ChatGPT、特斯拉V12等模型带来的惊喜"
                },
                {
                  "children": [],
                  "content": "AI安全问题与黑盒模型的可解释性挑战"
                },
                {
                  "children": [],
                  "content": "从工程向科学的转变"
                }
              ],
              "content": "大模型的发展与挑战"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "通过白盒模型深入理解大模型"
                },
                {
                  "children": [],
                  "content": "尝试通过实验和理论研究揭示模型内部机制"
                }
              ],
              "content": "AI的可解释性研究"
            }
          ],
          "content": "主要议题"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "助理教授，加州大学戴维斯分校"
                },
                {
                  "children": [],
                  "content": "博士师从加州大学伯克利分校计算机神经科学家"
                },
                {
                  "children": [],
                  "content": "研究方向：深度学习、神经科学"
                }
              ],
              "content": "渝北（陈渝北）"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "2018年图灵奖得主"
                },
                {
                  "children": [],
                  "content": "Meta的首席科学家"
                },
                {
                  "children": [],
                  "content": "被誉为卷积神经网络之父"
                }
              ],
              "content": "杨乐坤"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "计算机神经科学家"
                },
                {
                  "children": [],
                  "content": "渝北的博士导师"
                }
              ],
              "content": "Bruno Oth"
            }
          ],
          "content": "人物介绍"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "揭示词汇的多维度含义"
                },
                {
                  "children": [],
                  "content": "词汇表征的理解与应用"
                }
              ],
              "content": "词嵌入（Embedding）"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "神经元的激活与功能分析"
                },
                {
                  "children": [],
                  "content": "大模型层次结构与语义理解"
                }
              ],
              "content": "大模型内部结构解析"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "通过实验理解模型内部机制"
                },
                {
                  "children": [],
                  "content": "优化模型以提升解释性和安全性"
                }
              ],
              "content": "语言模型的可解释性"
            }
          ],
          "content": "技术讨论"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "对AI安全与理解的重要性"
                },
                {
                  "children": [],
                  "content": "理论与实践的结合促进科学发展"
                }
              ],
              "content": "白盒模型的潜力"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "科学与工程的平衡发展"
                },
                {
                  "children": [],
                  "content": "对人类认知与智能的深层次探索"
                }
              ],
              "content": "深度学习的未来"
            }
          ],
          "content": "行业展望"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "理解智能的本质"
                },
                {
                  "children": [],
                  "content": "通过神经科学启发的模型探索"
                }
              ],
              "content": "人工智能的科学研究"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "大模型的效率与应用"
                },
                {
                  "children": [],
                  "content": "数据与计算能力的持续提升"
                }
              ],
              "content": "AI工程实践"
            }
          ],
          "content": "技术与研究方向"
        }
      ],
      "content": "硅谷101播客总结脑图"
    }
  }
}