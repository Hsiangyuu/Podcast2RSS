{
  "pid": "5e5c52c9418a84a04625e6cc",
  "eid": "65d93a79c50b123481a2c696",
  "title": "E141｜我们用了10款AI工具，最后又回到了版权库",
  "task_id": "g34dn8ewp828nwjz",
  "transcription": [
    {
      "time": "00:00:02",
      "text": "欢迎收听硅谷101，我是红军，大家过年好。之前我在节目里面说要拆解一下咱们硅谷一零一的工作流，是怎么样运用这些生成式AI的工具的。没错，这期节目就是来填坑的，正好也给大家梳理一下你们平时看到的博客，还有视频产品，我们是怎么做出来的。大家如果在听这期节目的时候，觉得我们还是一个有趣的团队。那我们同时也正在开放我们新一轮的招聘。硅谷101正在招聘运营、播客、监制、视频后期文案策划总监。具体的信息我会放在播客的show notes当中。如果你对加入我们感兴趣，欢迎把你的简历还有代表作品发送到HR at SZ101点NETHR at SZ101点NE。下面我们就一起来认识一下硅谷一零一幕后这些超酷的小伙伴们。首先邀请我们硅谷101的视频后期Jacob，hello jab, 你好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:12",
      "text": "hello红军，你好，硅谷101的听众朋友们大家好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:16",
      "text": "对，大家之前在我们硅谷101的视频中看到一些非常漂亮这样的视频画面，包括动画特效都是Jacob来做的。Jab应该也算是我们今天所有人中尝试AI功能最多的人是我们今天的主力。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:31",
      "text": "对，过去一年确实用了很多AI的各种工具在不断探索，希望能够提高工作效率。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:39",
      "text": "还有一位是张君武，君武之前在给我们写代唐的稿子的时候，其实是用了非常多的AI的工具的。待会儿可以跟我们分享一段这个小故事。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:51",
      "text": "好的，hello大家好。",
      "speaker": "发言人3"
    },
    {
      "time": "00:01:52",
      "text": "我是君武。还有一位是大家非常熟悉的，就是我们视频的主理人陈倩。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:58",
      "text": "Hello, 谢谢红军的请hello hello硅谷101的听众朋友们，大家好，我是陈倩。",
      "speaker": "发言人4"
    },
    {
      "time": "00:02:03",
      "text": "不然先j up给大家分享一下AI是怎么运用到视频的后期中的。因为我觉得其实它跟剪辑的这些软件是结合的最紧密的。而且今天我们在录播课的时间是在2024年的2月15号，也是今天OpenAI刚刚发布了sora。因为j up你之前其实也用过runway跟皮卡做生成式视频。我不知道你今天有没有看sora她的视频发布，你自己是一个什么样的感觉？就对比这几款软件。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:35",
      "text": "对，确实今天早上起来就看到各种群有各种朋友同行在发open I的新的sa它的一些效果视频看了之后确实是很惊艳。我觉得在此之前的所有的，甚至是AI在视频方面的应用，都比不上现在就看出来的这个效果视频我觉得待会可以详细的聊一下。我因为我今天也是花了一些时间去去看了一下他的一个介绍页面，然后我觉得是挺兴奋的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:04",
      "text": "我看现在皮卡它生成视频大概是3秒runway，是4秒sora，它今天已经是可以生成60秒的视频了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:12",
      "text": "对吧？对，runway跟皮卡一开始生成的那段视频是3秒到4秒。当然你可以不断的往后延长到十几秒。痛点就是你在不断往后延长的时候，它后面的视频会出现变形，那就会导致你前后视频的画面不一致了，那这张素材就用不了了。我是有发现pick labs在这方面的表现会比runway好一点位，基本上你十段延长有九段的画面是用不了的。两个工具目前来说的话，在这方面表现还是比较弱一点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:51",
      "text": "现在在我们硅谷101上线的视频里面，你有用到过PKA或者runway的这些画面吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:00",
      "text": "老实说还没有大量的在使用，但是有一些动画的设计上面有一些画面我其实是有在用runway在进行动画的生成的。但是也只是仅限于那几秒的时间，但没有太大的使用。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:15",
      "text": "基本上对你来说仅仅是在你做特效的过程中。其实现在runway他们的产品还是很难用到我们现在硅谷101的视频到后期的工作流中。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:27",
      "text": "对的，因为我们在处理的视频信息密度很高的，所以更多的是我们怎么把信息更好的带给我们的观众。所以很多的时候信息的准确度，还有整个动画的设计，它是一个高度精细化的过程。但现在生成式AI能做到的只是给你一个很general的一个画面。它现在的作用对我来说更像是一个无论是平面还是视频了，就是更像是一个插画师或者是一个AR artist这样的一个角色。但是真正说到design，就是从设计的层面上去看的话，其实对我目前的工作流没有什么太大的改进。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:07",
      "text": "你刚刚其实有提到像皮卡还有runway，它在视频生成的在extend。比如说它原本是3秒或者4秒，你要把它延长到10秒，他后面是非常容易丢帧的。你能举一个例子吗？就给大家一个比较形象化的描述。",
      "speaker": "发言人1"
    },
    {
      "time": "00:05:22",
      "text": "就比如说我现在画面里面生成了一个人物，他的背景是一座山。我可能需要整个画面有背景上的一些云，他的一些动态的画面，然后加上这个人可能是有一些小小的一些运镜，就会经常出现的一个状况，就是他身体的结构也在发生着变化。比如说身体上面的衣服的细节，它可能随着你的秒数不断增高，就是你视频越来越长，他到了后面它整个衣服就变形，跟你一开始的那个图像就不吻合了，会出现有这种前后不一致的现象出现。所以这个对于我来说挺头大的。因为视频的一致性不够的话，其实那个素材是用不了的，就很出戏。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:07",
      "text": "不过讲到这个，我这边正好有个小问题，因为对于我们这些一般用rain位或者皮卡比较少的朋友来讲，能不能大概介绍一下什么叫一开始从三四秒然后extend到七八秒。就是因为它是一个输入是视频，输出也是视频的工具。还是说它输入是你一般会看text，然后输出不是视频这样子。",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:29",
      "text": "它有两个，一个是je one，一个是je two。Je one是video to video，就是你输入一段视频，它可以通过那个视频在上面给你做一些变形。Text to video就是输入一段话，然后他出一个视频这样。",
      "speaker": "发言人4"
    },
    {
      "time": "00:06:43",
      "text": "我目前用的比较多的其实更多是图片，其实是image to video。就是我会给他一个我提前修好的，或者我从me journey生成好的一个图上传上去，让他把这个静止的图像动起来。那这个时候我可能就会需要它精确到你身体的这个部分把它动起来，或者是你的背景的一些部分能够动起来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:06",
      "text": "其实上次我们准备把硅谷101的博客做成视频，你是有做一张背景图的。我就假设你生成了一个人，他正在看书，但是你extend就想让他的手去翻书，其实他是在精准控制的方向，现在不能做的非常的好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:23",
      "text": "对runway现在有一个新的功能，就是你可以把其中的一个物体的部分拍卖出来，然后让他去精确的动那一部分的画面。但是其实具体使用起来，它其实一致性不是很高。当你的视频变得越来越长的时候，它就越来越跑偏了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:42",
      "text": "其实这个还是对我们真实世界的模拟的这一部分出了问题。它会让这个视频看起来不像是一个真实世界的，就是他对物理世界的逻辑理解的不是很清晰。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:55",
      "text": "对，是这样的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:57",
      "text": "今天sora刚刚出来的时候，因为现在他还没有开放给公众测试，我是看见twitter上一共是放出来了48个sora生成的视频，最长是一分钟，短一点的也有10秒，就不是每一个都是有60秒这么长。然后有一个视频的画面，大概是一个人在睡觉，他旁边蹲着一只猫。我们仔细看那个猫的时候，那个猫它的光影都生成的非常好看。它真的是一个窗子照过去，早上你能看到那个猫，它还有一个倒影在床上，它的动作也很连贯。但是就有人注意到了躺在床上的那个人，他的手的位置非常奇怪。正常的人手你不知道他的手在哪哪儿。比如说他被子的一个脚在那儿动，但是他的人手是在另一个地方的。大家就会觉得可能这个就跟物理世界就能感觉到有一个明显的不一样。其实如果说当我们真的要把这种画面用到我们的生成式视频里面，好像就很难了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:55",
      "text": "还有一个对我来说印象挺深刻的就是这个soa它其中有一个视频是一个女孩走在东京的街头的那个视频。那个是真的让我觉得，真的直接秒了之前全部的智能视频的AI模型了。因为他一边走你会发现他背后的那些广告牌上面的信息是不怎么变化的，这个让我觉得很厉害。很多时候其他的一些视频生成，它并不能让一个天空、大自然这样的一些场景，它都未必能够保持到你视频第一秒跟最后一秒有一个一致性在里面。但是我发现这次的solo它是全程那个广告牌这么细节的一些画面都能够保持着连贯性。对我来说这个是很厉害的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:45",
      "text": "针对画面上我补充一下，因为其实我们硅谷101做的是这种前沿科技的深度内容，我们做很多的explain，就是解释性的内容。其实我们用的素材分为三个部分。第一个就是有一些纪录片，有些documentary在历史上真实用的这些画面。其实我们就可以直接引用这些documentary，然后在上面说这个素材来源是哪里，这些是真正的素材。我觉得这些东西可能是AI不管它runway或者是sora做的再好，可能以后也不会改变的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:10:16",
      "text": "第二就是我们的动画。如果大家看我们的视频的话，就会发现中间有很多的比如说骨架、数字，很多的bar cher或者是这种pitcher这种的数据图在里面。这一块其实现在也是AI动画没有办法做的，或者是非常难以做的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:10:32",
      "text": "第三块就是可能现在是有一些可以改变的，就是我们用的一些比较general，比较通俗的一些素材。比如说我们在在最近的一期视频当中，我们讲钻石，我们可能表现这个钻石非常闪亮的部分。这些图其实是我们平时有买图库的，我们有买大概2到3个图库。然后中间有很多的他们已经拍好的一些video一些视频，可以给我免费的使用这些图库。",
      "speaker": "发言人4"
    },
    {
      "time": "00:10:59",
      "text": "我觉得是现在AI生成视频将要去直接竞争的商业模式。但是现在对于我们的一个产品或者挑战就是说如果AI它生成出来的这些视频有各种各样的小问题，但是我们现在已经买的图库其实已经可以满足我们日常的剪辑的用途。我们其实也还会持续的用图库，暂时也不会用AI身上的东西。但是如果sora真的是效果非常的好，而且现在有60秒，可以让我们更加的customize，更加的定制化的去生成一些。根据我们的视频的节奏，根据内容更match更加匹配的视频内容的话，我想以后是很能够代替我们对于素材库这方面的需求。",
      "speaker": "发言人4"
    },
    {
      "time": "00:11:41",
      "text": "其实我对倩姐前面提的第二点，我还有个小好奇，你说第二点是做一些岔子，可能是一些数据的可视化。那你为什么说这一点现在AI很难去做？",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:53",
      "text": "目前来说其实没有从剪辑软件里面能够去把一个图表精确的把它用动画形式表现出来的。之前我觉得这个过程由AI来完成，我觉得是不可能的事情。因为你看到现在的一些视频宣传，他连个完整的字都没办法生成出来，无论是平面还是视频。那这样的情况下，你怎么expect它以后会能够精确到什么程度呢？但今天看了这波骚A的更新，我其实也在想，可能说不定还真的能够出现这样的一种状况。就是AI已经完全能够帮你去做一些精确的信息上面的处理。但目前来说的话，还没有出现类似产品。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:40",
      "text": "你今天看了sora的更新，你觉得他能够在我们动画解释的那个环节帮到你吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:46",
      "text": "这个具体我不知道，因为现在还没有开放。大家不知道它整个interface是怎样的。但是如果还是通过文字去生成的话，我觉得本身文字去生成这样的一些图像，它还是有它的限制的。很多时候你在做设计的过程当中，往往不是你能够用言语去把它描述出来的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:09",
      "text": "对我能get到jack up的意思就是说很多时候我们想要表现出来的东西，比如说我想要这个图是这样的，我想要动画是这样的。就有的时候因为我跟jack a不是他在广州，然后我在硅谷这边。有的时候我们打电话或者zoom的时候，我都觉得非常的难以用语言去给他形容我想要什么东西。所以有的时候我能够感觉到他其实我表达完了之后，他还是非常的疑惑，非常的confused。所以很多时候我需要真的是用手给他画出来，说我这个东西要放在这里，然后他下一秒移动到这里。对，要非常的用这种图形的方式跟他解释清楚，他才能get到。",
      "speaker": "发言人4"
    },
    {
      "time": "00:13:45",
      "text": "那我们怎么去跟AI做这个沟通呢？是不是我还是要用一样的这种手法给AI说我这幅图要长这样，但是你要把它变得更加漂亮一点或者怎么样。所以我觉得跟AI沟通其实是一个非常难的东西，包括音乐也一样。对我今天也在玩谷歌，之前的那个音乐生成的东西，待会儿我们可以详说。但是我就觉得非常的难以articular，就是很难表达我想要它的一个感觉。",
      "speaker": "发言人4"
    },
    {
      "time": "00:14:12",
      "text": "是的，我觉得特别有意思。可能正是因为人和人交流的时候，可能本来我如果要是表达怎么样做一个视频，本来就是需要画画的，本来就是需要去把一个视频这样子的可以做出来的。所以可能对于AI来讲，就是分析他AI是怎么样能够生成这些内容的？可能他学习的是人脑，他学习的是怎么样去学习各种位置。跟AI交流的方式从本质上来讲，或许应该就跟人和人之间交流的方式是差不多的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:39",
      "text": "这个问题我们其实有问过runway的创始人跟CEO Chris，他当时到硅谷这边来参加一个活动，我们有问过他说你们觉得之后怎么去跟AI更好的交流，能够创造出来视频类的这样的一个表达。他说text就是言语交流的方式，不是最好的方是因为我们人创造视频的时候就不是用语言的方式。我们是看到了一个什么东西，我们说我们有摄像机把它给capture下来，或者我们看到了这个河应该这样流。所以我们觉得说他动画或者也好，3D怎么也好，应该是一样的东西。就是我们的逻辑就不是说用语言去描述所有的事情。",
      "speaker": "发言人4"
    },
    {
      "time": "00:15:20",
      "text": "对我非常赞同。但是换个角度看，结合我最近在用多模态GPT，还有谷歌新出的german line这样的交互的体验来看的话，他现在是可以就我画个图然后让他去理解的，他是已经能够做到这个地步。那如果进一步的话，到时候把text to view这个整合进去的话，那是不是到最终它就不再单单只是一个text to video这样的一个工具，而是更多的以一个agent的角色去帮你实现一些任务？我最近是有在思考这个事情的。如果能更好的结合多模态的话。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:57",
      "text": "你就是说可以同时继输入文字，让它去生成视频。同时我还可以辅助的，比如说我把图片也给他，让他最终去delivery一个结果。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:10",
      "text": "所以我觉得感觉随着我们的用户不断的去探索的话，可能最终这些功能在可行度上是可以做出来的。就是看它每一个单一模块的能力做的怎样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:21",
      "text": "前面那个问题的意思是不是就是说AI它到底是视频剪辑师的工具，还是说他自己可以作为视频剪辑师本身？大概是这样的一个在思考这样的一个问题是吗？对这个问题我也觉得特别有意思。这么一讲起来就让我想到之前是在哪个报道上看的，还是怎么就是说为什么这一波的AI大家会觉得这么的impressive并且frightening。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:47",
      "text": "At the same time就是之前的几次工业革命，科学技术的革命，这个技术本身还是要被人去使用的，人永远都是把它们作为工具来用。但是这一次的AI甚至有从工具本身蜕变成自己就知道该怎么去使用这个工具这样的这种感觉。就是他自己可以完全独立于人，脱离人去完成一些事情。但是我在好奇的是在整个视频剪辑里面，人的作用是什么？有哪些东西是只有人知道，但是AI是没有办法自己去思考到的一些事情。是不是一些宏观的这种理念，还是说需要我们人去灌输给AI这样来做。",
      "speaker": "发言人3"
    },
    {
      "time": "00:17:27",
      "text": "我觉得分视频的类型，如果你是一个纯的讲述历史的东西，这些东西是很好被还原的。但是如果你是一个纯科普的东西，比如说我在解释自然钻石是怎么生成的，人造钻石是怎么生成的。人造钻石它有两个不同的方式，一个是CVD，一个是高温高压，它分别是怎么生成的？这个东西我觉得如果以后视频生成非常的成熟了之后，我觉得他应该很好的被做出来。但是我总觉得好的作品当中是有很多东西应该是做不出来的，或者是需要一些创造力在里面的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:18:02",
      "text": "大家会看我们的视频的话，会发现有些时候会有些梗，然后有一些时候会有一些那种贴纸的东西表现出来有一点讽刺，或者是有点性格的东西。其实我觉得那是我们视频里面最有意思的东西。我相信也是jack up在工作的时候，他觉得最有意思的一个部分。",
      "speaker": "发言人4"
    },
    {
      "time": "00:18:19",
      "text": "比如说我印象非常的深刻，我们讲英伟达的时候，老黄他不是有一幕是举着那个英伟达。然后当时jack就把那荧幕跟在狮子王里面，然后辛巴被举起来的那一幕剪辑在了一起。然后当时那个背景音乐也是狮子王的那个音乐。然后当时我看第一刚出稿的时候，姐就觉得说oh my god，this is so brilliant, 就笑喷了。对我觉得那一段是非常好。然后他是首先人理解的内容，然后他懂那个梗，然后他觉得情绪到了那里。",
      "speaker": "发言人4"
    },
    {
      "time": "00:18:49",
      "text": "然后我有这样的一个idea一个点子出来，我通过我的这个尝试把它给放在那，就是有一个非常好的点位，一个moment在那个地方。但我不觉得AI可以有这样的一个创造力。现在来说的话，艺术创作也好，还是我们做内容也好，做视频也好，这些永远最juicy的地方，最有创造力的地方，最值得我们去尝试新的东西，新的思考的地方。我觉得永远都是我们最自豪、最骄傲，也是我们最喜欢去做的东西。",
      "speaker": "发言人4"
    },
    {
      "time": "00:19:19",
      "text": "对，还有我觉得你那个问题也可以把它分为，我们是想要更加科幻的，天马行空的生成。我经常会觉得，比如说我让它生成一个博客封面，它的构图会比我想象中要好很多倍。但是你要是看细节的话，它的什么字儿、图案，可能都是会多多少少有一点问题的。所以它不是非常的可控性的生成。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:40",
      "text": "最难的就可能是我们刚刚前面提到了对现实世界的精准还原。就比如说jack up说到在你前面生成一个东西，你后面他的衣服上风吹过去，他还是有褶皱的时候，他这个动作能不能是连续的、持续的。当一个天鹅在湖上，如果他有影子的话，你能理解湖是一个面，镜子是一个镜面，玻璃能不能反光？墙能不能反光？就是我觉得这些可能都是涉及到整个AI对物理世界的理解。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:10",
      "text": "我觉得还挺难的。我自己在看视频的时候会觉得好的视频跟一般的视频差距真的非常的大。一般的视频可能不难做，而且随着生成式视频以及生成式文案的越来越好，我觉得我们的市面上马上会涌现出一大批用AI生成的视频的内容出来。但是我目前没有看到一个精心被设计的或者是构思的非常好的顶级的视频能够被AI打败。因为好的视频里面，它不管是段子还是思考，还是文案都是顶级的。现在AI我觉得出来的都是最多是average，最多是平均的东西，就是顶级的作品是不会被打败的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:20:51",
      "text": "确实我觉得前几个红军说的都很有意思，而且怎么说呢？在这个各种AI工具满天飞的时代，我感觉这个回答让我又觉得或者说找为了，或者说提炼出来了，人们做这么多事情到底是为什么？就是这些精彩的地方，很多东西确实是只有人才能创造的。我再去思考为什么？如果要从machine learning的最基本的道理去讲的话，这些生成的视频都是由数据去来的。但是好的一个视频就像倩姐讲的，可能它里面每一个东西都是人已经帮她精心筛选过的那AI生成的这个模型，除非他的训练集也是一个公司精心筛选的，否则他如果从网上大量的爬虫抓取下来的信息，总归会有一些良莠不齐或者说质量参差不齐的一些东西。所以我在猜想这可能是为什么倩姐前面讲的这个现象的原因。",
      "speaker": "发言人3"
    },
    {
      "time": "00:21:39",
      "text": "其实本来这一趴我没有打算在我们讲视频的这个环节讲。有一个非常有意思的现象，就是之前不是有很多人说我能不能用chat BT写小说，或者做编剧，或者做编剧创业。但是就有人就试了，其实是之前那个牛油果烤面包的主播，我们两个前几天在聊，他就说ChatGPT写的东西非常的落入俗套，因为他想要的所有的东西都是概率最大化，这可能跟他的算法是有关系的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:09",
      "text": "就比如说你说如何把老师小朋友跟外星人结合起来，那他就会编写一个故事怎么样外星人入侵，老师带领着小朋友最后打败了外星人，取得了胜利。对这对这这是一个大家非常意想中的故事。但是比如说你去看刘慈欣的乡村教师，你就会发现他怎么把外星人跟一个老师跟小朋友结合起来，那个构思就太妙了。我也在想，这可能是ChatGPT很难去出非常顶级的文字作品。所以后来有人说编剧怎么工作，那就是跟ChatGPT反着写，他往这个方向写，我就往那个方向写。但其实我是听到他的这样的一个故事模板，他就是很难给大家灵感的，因为他一切都落入了那个最大概率中。但是好的作品是要情理之中，但一定要在你的意料之外，按照意料之外的这个线去发展的对讲。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:02",
      "text": "到这个我觉得天马行空的想一想，因为我自己是机器人出身，其实我对于比如说AI的准确性，AI它不能去胡思乱想。这个在我平时的工作之中是有很多的要求的。但是这么回过头来一想，AI如果再乱想的话，甚至可能这正是她所谓的创造性的来源。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:21",
      "text": "当然我对AI是不是会很lust，我没有专业的研究，但是因为我也在思考，红军前面讲的现在很多generate AI本质是一个预测性模型。他只有看到之前的东西跟他的training set，然后他才能预测下一个是什么。但他不会自己像人一样有创造性东西的能力。所以我很好奇在比如说接下来的几十年，科学家能不能够发现，就是人们为什么有创造新东西的能力？生物学上的这种机理是什么？如果万一哪一天真的发现了这样的机理，就像AI是神经网络一样，说不定特别的会有。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:55",
      "text": "就AGI到了吗？",
      "speaker": "发言人4"
    },
    {
      "time": "00:23:57",
      "text": "我们还没结束，又已经哲学问题了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:00",
      "text": "下一代会真正去思考的这种AI但这可能扯得有点远了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:03",
      "text": "对，到时候我们全都失业了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:24:05",
      "text": "但我觉得至少现在来讲的话，确实人的创造性还是非常强的那。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:09",
      "text": "我稍稍再把话题拉回来一点，j up你要不要跟大家分享一下，现在你在用哪些的后期软件，你觉得它加入了AI的功能？",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:19",
      "text": "好，我现在目前的工作内容除了视频后期之外，其实还包括一些平面的设计。我们回到me journey，虽然是提供了我们更多素材选择，但其实还是有一些限制的。实际上它并没有很好的提高你的效率了。因为你现在需要一个图，你还是得写一个提示词让它去生成。但这个过程可能你还得想一下，这个提示词我要怎么写才能够有一个更好的结果。我们现在可以通过GPT的辅助帮你写这个提示词。可能说你只是简单的描述一下你大概需要一个什么东西。然后GPT就可以通过my journey提示词的一个特性，去帮你生成一个专门给每journey去用的一个提示词，而且是尽可能具体的，可能出来最终结果是一大段的文字。然后让没准你去生成这个可以提高你需要的最终生成的那个效果。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:16",
      "text": "但是这个过程当中也会耗费你很多时间。可能有些时候我在做设计的时候，可能这张图我需要很快的把它生成出来，是我直接去素材库把它找出来。这个过程可能花了五分钟、十分钟。但现在你要我耗半个小时到1个小时去专门做一个图，其实很多时候我是不愿意去这么做的，我宁愿去买这个素材，更省一个时间的成本。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:39",
      "text": "所以现在AI还没有颠覆素材库，还没有，但是快了可能对。",
      "speaker": "发言人4"
    },
    {
      "time": "00:25:44",
      "text": "但是我有发现现在反倒是很多素材库在整和AI就是之前比如说我需要一个单一的素材，比如说我需要一个杯子的图，它是一个PNG图，就是后面是没有背景透明的这样一个图，我是大量用到的。我就发现现在素材库就很多是杯子，它可能是生成的，只是它多了一步，就是把它抠出来这个过程，所以现在的素材库也就变得很多选择了。然后还有一点就是我自己在做的时候，就是现在的一些adobe的软件。比如说像PS follow shop，它是已经整合了。比如说像AI智能填充这样的一个功能，那这个用起来就很好用了。比如之前可能我一个背景，它可能是一个横向排版的一个图，那现在我需要把它变成一个竖向的图。那这样的话原来的那张素材可能就不能用了。那现在的话其实可以通过像generate view这样的一些功能，就可以把一张本来横向的图填充成一张数值的图。这个实际操作起来就很方便，你不用因此去花大量的时间去找另一个图来代替它，而是可以在原有的图上面更多的customization。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:56",
      "text": "这点我举个例子，它这个类似的像AI扩图，就是因为我记得去年的时候，我们桂101在成都，然后跟世界科幻大会有一场合作的线下论坛。当时现场的那个屏幕特别长，一般我们其实出的图都是16比9的，或者是4比3的那其实我们之前出的那些图，PPT，其实是放不到那个上面的。那么我们可能就要左边放一个白的，右边放一个白的，中间再放一个深色的就很难看。当时杰克不就做了一个AI扩图的这样的一个效果图，就是把非常长，杰克不那个是多少尺寸来的，你还记得吗？我记得非常长，但是整个出来效果就非常好，非常的统一，而且是那么大的屏幕，对吧？非常大的屏幕。",
      "speaker": "发言人4"
    },
    {
      "time": "00:27:41",
      "text": "对，AI扩图一方面是他帮你扩展了，第二方面是现在有很多工具是可以让你把比如说原来像素不是那么高的一个图像，让它变得扩大好几倍。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:55",
      "text": "美图秀秀就有。我这个春节整个就在玩美图秀秀，玩上瘾了，是因为就我们另一位成员杰瑞米，他是自己在家搞了一个影棚，然后就给大家拍新年照片。我当时的那张图其实也是我女儿的一个图，然后我想把它变成一个横版。但是它其实拍那个照片的时候，他那个AI扩图还不仅仅只是说它扩那个红色的背景，因为那个其实相对比较简单。当时他拍到我女儿那个芭蕾舞裙，它是有一点点的小角落没有拍进去的。但是AI扩图的时候，她把那一块的裙子给补上了，我就觉得效果还蛮好的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:34",
      "text": "我用的比较多P图软件，就是PS感觉上就像是你之前是在用铅笔在作画，但现在你的这支笔变成了一支神笔，就是它有超能力的一支笔。然后他就可以比如说一些局部的细节，你需要把这个人拿着的这个手机或者这个杯子，把它换成一些别的东西。那现在就可能几秒钟的时间，你已经能够达到能够精细的去把那个物体把它换掉。这个对很多做律师来说是能够大大提高你的效率的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:05",
      "text": "当然我现在分享的只是photoshop里面的一些应用。像有一些插画师的话，他们在用那个illustrator，就是另一个adobe的软件做插图的。他现在是可以一键把整个配色都换掉。他做图的时候，比如说我现在是这个配色，那现在我可能就多了很多其他配色的选择。这个过程就不需要你一点一点的去把它那个色换掉，而是能够一键把这个色直接就把它换掉了。感受起来还是有很大的一个效率上面的改进的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:37",
      "text": "我现在比较期待的就是像photoshop这样的一些生成效果，它可以达到me journey这样的一个水准。因为现在你通过general，可能你还没办法做到一步到位，因为生出来的那个效果往往不是那么理想。但如果能够有me journey这样的一个水准的话，那可能使用起来就会更加的方便了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:00",
      "text": "应该很快了，就是把这些工具都整合进去。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:04",
      "text": "杰克不你要不要说一下在音乐方面、音频方面，我们在后期做的一些应用AI的软件。",
      "speaker": "发言人4"
    },
    {
      "time": "00:30:11",
      "text": "音乐方面其实我现在在这部分用的还比较少了。但是我们之前是用过eleven labs去把一些比如说倩姐平时的旁白可能录少了一两句话。我是试过用eleven labs去把那句文案去用见解的声音把它还原出来的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:29",
      "text": "但我发现有的时候他是补的还可以，但有的时候就是怪怪的。因为我不知道他是因为中文，他现在还听的不太好还是不行。对，因为我爆个料，就是我们最新的钻石的那一个片子，最开始的时候就是那个C杠C键，我读成了CC键，是一个文科生的错误。然后后来我们有一个后期的小朋友说，倩姐这个应该叫碳键。对，然后我当时就跟jack说，你能不能用eleven lips就直接帮我补了，我就不用重录了。但是要不后来给我的那个版本，他的那个音调就是有点怪怪的，他就变成了什么弹弹键。我说你这个还不如我说CC键。对，后来还是我自己重新补了一下。",
      "speaker": "发言人4"
    },
    {
      "time": "00:31:11",
      "text": "对，其实它是叫eleven labs的声音克隆功能，我们在播客里面也用的蛮多的。比如说我们跟嘉宾录制的时候，嘉宾他可能有一些口误，但是他自己没有意识到。或者说有一些数字。因为我们在录制的时候都是现场即兴发挥，他就说错了，所以就后期要补录像。这种情况的话，通常情况下他会后期我觉得哪句话说错了，我会跟他说，你用手机在后期录一个给我。但是因为他的录制环境跟第一次的录制环境不一样，所以他手机的白噪音跟生产环境是不一样的。就你能明显听到，比如说上一个是这个音调跟这个声场说的，下面一个整个环境就变了，它这种进入跟进出的这种感觉会非常的明显。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:56",
      "text": "后来有一次我在录的时候，就嘉宾补录了一个给我，我把点进去了。同时我把它的声音放在eleven labs声音克隆里面，大概就是选十几秒的样子，让eleven labs克隆一段他的声音，然后再把这个声音放到我们的音频里面。其实证明是比真人补录要更好的，因为它的生产还原的环境是更加一致的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:18",
      "text": "但他有一个非常大的问题，其实就是你刚刚说的，现在他对中文的优化并没有很好。我发现你只能做一个非常短的补录。比如说你说巴拉巴，这是一个重要的事情。当他念完一段大概有30个字的时候，他的音调绝对你能听出来这是一个外国人的音调。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:37",
      "text": "因为他会把比如说像重要的事情，他会说成重要的事情。对你一听就是觉得就是一个外国人在说中文的感觉。但是它能还原那个人的音色跟声场，他很难去还原这个中文的语调。后来我也找到了一些让他尽可能还原的像普通话的方法，就是给他的字越少越好。因为大家通常在生成式AI的时候，比如说我第一遍生成不好，我就再让它生成一遍，我就不停的重试。我就发现这个eleven labs你越让他重试，他的语调偏离的越厉害，就会有这样不管是什么地儿？对对对，然后其实如果你把字稍微控制的少一点，只要他说最短的话就是几个字的话。他通常在第一次你找准demo，或者如果你觉得他还原的不好，你就换demo的音频，它是最后是可以还原的比较好的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:34",
      "text": "但是我发现就是现在虽然他说的非常像外国人说中文，但是他有一个特别好的应用场景，就是在我们的视频里面，我们当时带糖的那个片子。然后有两个地方其实是很长的一段。",
      "speaker": "发言人4"
    },
    {
      "time": "00:33:46",
      "text": "对其中一个角色要说怎么说。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:47",
      "text": "就是角色他当时引用的一很长的一段quote，他当时的一个采访原话。当时我们就说要不然就是我念出来就是挺无聊的，就是没有什么惊喜。然后当时我们后期处理一个方式，那就是j up用eleven lips，用当事人的声音去train了整个历史的人物，他们自己来复述这段话。但是说的是中文了，可能就是更好的理解一点。但是用的是他们自己的历史上原型的人物的那种声音声调来说，一个外国人说中文还挺有意思的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:34:19",
      "text": "对我当时看到戴堂那期稿件讲那几个科学家的故事，然后还原他们的声音的时候，我觉得还蛮有趣的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:27",
      "text": "其中一段就是罗斯福总统，他可能讲了一段话，然后我就去油管上面找了一段他很久之前的一段录像，然后我就把那段的声音就拿进去劝eleven labs，然后就出来了这个克隆声音。我觉得从声音的还原度上面是做的很棒的。但是就是在中文上面它会有一些语调的一些不一样，但是我觉得反而出来那个效果就很像一个外国人在讲中文，挺有意外的。然后就直接用了也不用想那么多了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:56",
      "text": "对我觉得在那个情节当中，大家是能够容忍你这个中文说的有点奇奇怪怪的，因为大家知道是一个外国人在说中文。",
      "speaker": "发言人4"
    },
    {
      "time": "00:35:04",
      "text": "对，但是讲到中文还原了，我今天又发现了一个神器，我发现它能够更好的还原中文文字的生成，这个神器叫做open voice，你们其实可以去用一下，或者说现在要不要现场演示一下这个东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:19",
      "text": "可以。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:20",
      "text": "视频其中一期里面选的是吗？",
      "speaker": "发言人3"
    },
    {
      "time": "00:35:22",
      "text": "对我今天截了一段前近期视频的一个十秒钟左右的一段sample。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:27",
      "text": "这个是my shell做的就是open voice。他的创始人刚上了我们外部3101的节目。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:34",
      "text": "好，现在这个是倩姐sample的声音。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:37",
      "text": "在2月14号情人节购物销售额在美国能够超过250亿美元。而在情人节礼物当中，超过5分之1的人选择了首饰OK。",
      "speaker": "发言人4"
    },
    {
      "time": "00:35:48",
      "text": "我们现在就用这段声音去生成这段字。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:52",
      "text": "jackup给我们打的字是红军，今天天气不错，我们去吃个饭。我们来看看倩姐的生成是AI声音。对，AI倩姐的声音。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:03",
      "text": "好，准备好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:04",
      "text": "红军，今天天气不错，我们去吃个饭。",
      "speaker": "发言人4"
    },
    {
      "time": "00:36:08",
      "text": "我觉得这个确实比eleven labs做的要他的音调是准的。但后面那句话我能感觉到，不是你说的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:17",
      "text": "我会说，亲爱的，今天天气真好，我们赶紧出去吃个饭。",
      "speaker": "发言人4"
    },
    {
      "time": "00:36:23",
      "text": "我觉得一部分应该是我们给的sample太少了，所以他不能完全capture到倩姐平时讲话的整个的感觉。但是我觉得从音调来说，它是接近我们国人的发音的对对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:36",
      "text": "它的音调它比那个弹弹键要好多。",
      "speaker": "发言人4"
    },
    {
      "time": "00:36:40",
      "text": "那这个公司是一个什么来头？红军前面也提了一下，它叫open voice。它是个open source的项目吗？",
      "speaker": "发言人3"
    },
    {
      "time": "00:36:46",
      "text": "还是说它是一个开源项目，然后是MIT跟牛津的一群人来做的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:53",
      "text": "其实我觉得现在好像声音生成其实不是一个特别难的技术了。我看见好多国内其实有些视频其实都是AI生成的语音。包括我觉得有的时候大家会分不清楚什么时候是AI生成的，什么时候真的是有主持人在的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:37:09",
      "text": "前段时间我们有个视频，中间有一段voice over。因为当时的场地的原因，还有时间的原因，我不是在现场直接录的。我可能就是拿这个稿子用手机来录音的。可能因为我之前是电视主持人，所以我一旦进入这种拿着稿子手机录音的那个阶段，我就会读的非常的字正腔圆。然后读的非常像电视台的这种机构化的这种感觉。",
      "speaker": "发言人4"
    },
    {
      "time": "00:37:32",
      "text": "当时视频下面好多的观众就说，你们这个是不是用AI生成的？你们这个voice玩录音，你们现在已经开始AI已经用起来了。你们团队知识，你的真实的团队好先进。我当时就觉得说，我到底要不要clarify澄清一下，这是我自己的声音。结果你真的用AI配音的，大家都没有听出来。对，所以我觉得这个界限好像越来越难以区分了。所以我是觉得有些时候，比如说我们稿子里面有一些有情绪的，或者是有的时候有一点小段子、有梗，然后稍微的调皮一下，这种地方的处理有特性的、有特色的，可能AI还是很难去表现出来。但是非常的标准的电视台化的这种东西，这种配音，我觉得现在其实做的已经非常好了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:38:18",
      "text": "对我觉得刚刚j up给我们分享了声音克隆，因为我知道其实硅谷101的很多配乐都是你自己来配的。你要不要跟大家分享一下AI作曲？",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:29",
      "text": "我先稍微说一下我的感受，然后jack来补充。目前其实我们很多的作曲还是用素材库，有素材库里面其实有非常多可以去选择的乐曲，而且我觉得挺好选的。就是一般你输入一些关键词，比如说我们表现一个商业故事非常的紧张，他要破产了对吧？我们比如说打一些intense，或者是bankrupcy，或者是比较negative消极的词进去。然后它大概的你听十首音乐的感觉，就是你大概听前面的5到10秒，你就知道这个音乐是不是much，是不是能够配合你当时的那个文字。所以一般2到3分钟之间，我就能够找到1到2首还可以用的一个配乐。所以我觉得这样的的一个方式对我来说效率已经是挺高的了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:39:17",
      "text": "你说素材库的效率，已经素材库的相同素材挺高的了。而且因为它非常多的资源，所以你选择起来还是挺好用的。就是我其实有试过之前大家觉得还蛮火的一个软件，叫做music FX，它是谷歌出的。今天现场可以给大家演示一段哈那比如说我们在前段时间讲拉斯维加斯sphere那个网红大圆球的那个片子。如果大家有看那个片子的话，你会发现其实我们讲的是一个纽约富二代，非常的像继承之战，secession里面的那种感觉。因为它也是一个含着金汤匙出来的，也没有特别的有天赋。在经商上面到30多岁的时候还吸毒，脾气也特别的不好。",
      "speaker": "发言人4"
    },
    {
      "time": "00:39:58",
      "text": "然后我当时就跟说，我们是不是可以去尝试一点纽约90年代那种纸醉金迷一点的，上层社会一点的，有点luxury的这种感觉。对，有点jas在里面的这种感觉。其实素材库里面已经能够有一点像机神之战的片头曲的那种感觉了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:40:16",
      "text": "然后我其实也用music FX试了一下，可以先给大家听一下。我的提示词其实很简单，就是produce a documentary background music to demonstrate manhattans in nineties。翻译过来就是说给我创作一首纪录片的背景音乐，来展现90年代的曼哈顿。我可以可能加更多的一些东西在里面。比如说funny一点，jax一点的东西，但是我没有加。然后我觉得其实效果还可以，先给大家听一下。",
      "speaker": "发言人4"
    },
    {
      "time": "00:41:18",
      "text": "好听是不是有点这个感觉？",
      "speaker": "发言人4"
    },
    {
      "time": "00:41:20",
      "text": "就有点繁花。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:21",
      "text": "就有点繁花，然后有一点继承之战，然后它有古典背景，有钢琴，感觉是这么一个感觉了。然后他大概会有30秒，你用了吗？没用，因为我觉得我们的素材库里面的那个音乐我更喜欢一点。在music FX里面，然后你输入这个提示词，它会给你有几版。比如说刚才是一版，然后它可能有稍微的变形。",
      "speaker": "发言人4"
    },
    {
      "time": "00:41:56",
      "text": "对，然后还有最后我们那个纽约富二代这个sphere网红球，我们用的是这个音乐，稍微给大家听一下。",
      "speaker": "发言人4"
    },
    {
      "time": "00:43:10",
      "text": "对，用的这个音乐非常好，我觉得比刚刚生成的那。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:14",
      "text": "几个都要好。对，所以我觉得生成的它是有一点有这个意思，但是又差点味道。对对对，差点味道。因为我觉得但还是有点太general，因为素材库里面它有成百上千的intense funny luxury，就是各种各样关键词的这种主题的音乐。我一般晚上11点钟，就是在我办公室里面没事儿就放着听。你真的是听到了非常对味的那个音乐，你会一下就觉得说就是他了这种感觉。其实是你要听到了它，你才会觉得说这是你想要的。对我觉得跟一个你主动去输出，然后用一些比较general的一些prompt的词去生成一个AI音乐，我觉得这两者之间可能还是是有点差距的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:44:00",
      "text": "所以音乐制作人现在听到这个还不用慌，还没能替代。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:07",
      "text": "有一点慌，但是还不用太慌。对。",
      "speaker": "发言人4"
    },
    {
      "time": "00:44:10",
      "text": "但说回来，其实这样的工具有一个优势，就是很多时候你找到一首曲子，其实比较大的问题就是你要用它的话得有版权。这种情况下，我现在不知道AI的这个版权是怎么算的。但是如果说它生成的一些音乐都是我们可以用的话，那其实这个也算是是提升了我们不少的效率。你不用去花钱去买这首歌的版权，但是你又能得到一条比较类似的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:36",
      "text": "但我觉得我们要花钱去买AI软件，如果比较AI软件跟现在版权库的价格，我觉得可能版权库对也差不多。但是版权库的效率更高。对，目前是效率更高的对对我。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:52",
      "text": "觉得一个功能可以更好的。它能否像生成图像的me journey那些那样，我可以给他一个reference。因为很多时候你其实很难描述一首歌的感觉也好，还有他的一些风格，可能对一些对音乐制作比较陌生的，像我这样的制作者来说，其实我是很难去描述一首歌是什么品类的，然后它的BPM是多少，它的节奏是怎样的。如果说我能给他一个reference，那是不是我在做出我想要的那个音乐会简单很多呢？这个是我比较想期待看到的对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:29",
      "text": "这个reference我感觉是必须的，就比如说刚刚像欠你加入的一些关键词，就比如说funk还有什么这次的感觉，然后还有90年代的曼哈顿。我其实是觉得如果大家是专业处理视频，或者像我们处理播客跟音频的，大家在版权库里面可能对这些词都非常的熟悉。就是他到底是要一个什么样的情绪，它是哪种音乐风格更细一点。像我们的音频后期他还会分什么快版、中版、慢版这一类的。他其实是本来大家已经是知道很多的这个音乐标签的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:06",
      "text": "我好奇这样的工具以后如果给更多的普罗大众去使用，会不会有某种功能，就是说我们可以哼一些调子，就比如说如果是suspend就是大大大大这样子。我不知道这样是不是可以做一个reference，因为我想到比如说谷歌它有这个听歌识曲这样的一些功能。对，就是这前面顺着你的思路往下想，就是这个reference。因为如果我们已经有了一个很棒的一个sample，我们可能就当然了也有可能是要去做一些variation这样子。但是可能如果已经听到了一个很完美的，我们可能也不一定需要再去生成了。但很多时候是不是就是心里有某种想法，但是很难用言语表达出来。但是如果能哼出来AI能够。",
      "speaker": "发言人3"
    },
    {
      "time": "00:46:51",
      "text": "给你在每个人都能音乐创作，听起来挺美好的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:54",
      "text": "对我觉得那个很好。而且还有一种可能就是因为其实现在我们很多的画面也好，还是文案也好，其实是要跟着音乐去剪画面的那比如说它的一个beat是怎么样的，然后是长是短，是四排是三排，我们是要通过那个画面去跟着那个节拍去剪的。但有可能有的时候画面不太适合，或者这个画面就没那么长，或者是他的稿子或者我念的VO voice over，他就好像不那么配。但是如果以后能够反过来的话，我们用音乐来适配我们的稿子，适配我们的画面，配着我们的画面来做一个适合他的音乐，我觉得这个可能会更好一些。比如说有的时候我们会为了音乐去延长我们的开头，就看有的时候跟我说，倩姐这个音乐真的非常好听。因为比如说大家如果看我们视频的话，会发现我们可能在一分钟左右会有一个片头的文字特效出来。然后经常就是说音乐的最后3秒钟，经常就是一个落尾的很强的收尾的这种音乐。那我们就会用3到5秒钟的时间，就把我们的这个片头特效的图片，配合着那个音乐给有很强烈那种情感的给它贴上去，然后就是一个很强的这样的一个开头。",
      "speaker": "发言人4"
    },
    {
      "time": "00:48:07",
      "text": "我再把这个话题拉回到素材库，就是我觉得很多素材库它的功能已经非常强大了。就比如说同一个曲子你可以跟他选，你是要三秒、6秒、9秒还是要十秒的这个版本我感觉这些素材库其实也在加入这些AI功能。然后我们其实要比如说我们就要3秒或者9秒，我们就是为了要他那个片尾对吧？就是他可以告诉你这个章节终结了，我们马上要开始下一个章节了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:33",
      "text": "是有的，但是我觉得可能还是不够做的精细。因为它可能有10秒的版本、20秒的版本、30秒的版本。但是它不会有16秒的版本或者是25秒的版本，就是刚刚好卡在那个秒上。比如说我们现在开头我的主持出来是36秒，然后那个音乐是50秒。有的时候我们现在会出现的方法就是为了配合那个音乐。",
      "speaker": "发言人4"
    },
    {
      "time": "00:48:55",
      "text": "有两种减法了。第一种就是我们在中间去加一些其他的素材，或者其他人的采访，或者是历史人物的一些说的话，一些采访，一些伤害在里面去。把时间撑到50秒，但是这样的话就会拉慢开头的那个节奏。可能大家会觉得开头慢了，可能很多人就不会看下去。开头的完播率它其实就会降低，那它的算法可能就滚不动了。所以就是现在可能我们用了一个方法，就是说在那30秒或者40秒的开头的时候，我们还是保证他最后的那个落点的几秒钟能够配合我们非常strong的一个画面。但是中间我们可能把音乐给掐断，就是他可能不会那么连贯，但是可能开头的时候大家也不太听得出来。",
      "speaker": "发言人4"
    },
    {
      "time": "00:49:39",
      "text": "或者说我们放一点点的外面的natural sound，或者放一点点的sound back在里面，然后有一点点的卡，有一点点的炖，不太放得出来。但是它不是一个完整的曲子，它中间其实还是有断层的对，我们经常用这种方法。对，所以我就说是不是AI可以把它弄得更加smooth一点，还是可以把它换成一个非常完整的一段音乐，它中间不会有jump .",
      "speaker": "发言人4"
    },
    {
      "time": "00:50:01",
      "text": "cut的这种衔接稍微好一点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:03",
      "text": "其实现在的剪辑软件上是可以实现这一点的。就是它可以把一条1分50秒的音乐变成一个50秒的音乐。它会自动帮你剪，让你觉得它的衔接会变得更加流畅。哪个软件？我平时用来剪视频的软件就是PR，premiere pro它是可以实现的，把音频缩短或者拉长都可以。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:24",
      "text": "就是你只用在那个时间轴里面去拉它或者缩减它就可以了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:28",
      "text": "对它有个功能让你可以延长。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:32",
      "text": "它是调整速度吗？还是把它的整个曲调都变了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:50:36",
      "text": "没有变去掉它就是在该剪的时候把你剪掉，然后把它缝合在一起，就是你讲的第二个办法。但是它是通过机器去实现的，不用我们人工去找那个该剪的地方。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:48",
      "text": "OKOKAI融合。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:50",
      "text": "对他可能就是找了一个，如果你把它剪了，听上去也不会那么突兀的那个点，他就是帮你把那个点给找了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:50:57",
      "text": "我觉得放大看应该也有这样的功能，但是我不清楚，没用过。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:02",
      "text": "我去找一下audition有这个功能吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:04",
      "text": "应该有吧，PR都有了，audition应该有。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:07",
      "text": "我为什么没有发现？我每次还把它剪断，然后中间衔接一下就想办法。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:12",
      "text": "我觉得他们对，他们应该多多做一下广告这些新的功能。",
      "speaker": "发言人4"
    },
    {
      "time": "00:51:17",
      "text": "我这里有一个可以说商业上的问题，因为我听下来感觉从剪辑上AI非常重要的一点就是它需要很多的个性化和定制化。我们以前传统上所谓说大公司做了很多比较通用的东西，startup的机会就是做这些比较小个性化的东西。但是现在看来AI模型什么职业都是被大公司所去，有很多大公司大模型做得非常好。我想问一下倩姐，红军就是你们用下来，感觉在以后在未来是小公司可能把这些比较细节的feature做的比较好，你们会真的去用呢？还是你们现在会觉得你们以后还是会使用大公司的产品。因为他们已经有了一个很成熟的产品体系，只是往里面去微调一些细节会更加容易一些。",
      "speaker": "发言人3"
    },
    {
      "time": "00:52:02",
      "text": "我觉得他只要做得够好，小公司、大公司我都愿意去试。",
      "speaker": "发言人4"
    },
    {
      "time": "00:52:06",
      "text": "但是你们觉得是小公司更有可能做得好，还是大公司更有可能做得好？",
      "speaker": "发言人3"
    },
    {
      "time": "00:52:12",
      "text": "从我的角度的话，我是期待现有的这些用的比较常用的一些制作软件，它能更多的去整合现在小公司在做的这些功能的。因为从用户的角度，我已经熟悉了一个软件，一个系统。那这个时候你其实看到的是它能因此变得更高效。你不可能因为某些小的功能，然后去学习陌生的另一套系统。这个对我们做设计的，做制作的来说，其实是会造成很大的不便。就好像你用惯了一个软件，你是很难去跳到另一个软件上面去工作的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:48",
      "text": "对我觉得包括现在像final cut pro。上面有一些基本它的就是原来的一些功能，这些东西其实它也是都在upgrade，就是在更新了。但是我觉得有一些小公司它会有一些插件，通过卖插件的这种方式来实现它的商业化。比如说我其实两年前买了一个99美元的AI消噪的这样的一个插件，其实不便宜。但是它在两年前出的，我觉得它效果非常的好。它比之前final cut pro它自带的一些消噪的功能会处理的自然很多。把它买下来之后，把它import到final cut里面去之后，其实也很好用了。它直接就到你的插件栏里面，直接把它拖过去就可以进行一个香皂了。而且有很多很多的小公司，还有自己的工作室在出这样的一个插件，然后就直接适配到adobe premium或者是final cut pro或者是其他的一些剪辑软件上的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:53:44",
      "text": "可能跟公司的性质规模也有关系。比如说很多个人创作者，他们也拍视频，做出来的视频可能他也不输专业级，他可能用剪映就可以了。像我们如果就是一个做播客跟视频的工作室，我们还是会用像adobe的各种软件。那如果再专业一点，像线上自采的三体的特效导演，其实后面他还给我们推荐了很多声音的处理软件，那个真的是已经到非常专业级别的了。他也可能是插件，也可能是一整套软件。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:15",
      "text": "其实对他们来说，他们那个规模的制作，就是市场上所有的AI类的产品。你只要对我们的创作有帮助，我们全部要用。基本上其实我们今天聊这期节目也是，只要对我们的节目有帮助，我们全部会去试。你的效果好，能用上，我们就留下来继续付费。如果它的效果不那么好的话，其实我自己也订阅了很多软件，我可能就一个一个的又慢慢退订掉了。它可能是有一个市场分级的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:44",
      "text": "刚刚我们分别有讨论过视频的环节是怎么跟AI相结合的。播客的环节，比如说声音替换，声音克隆，还有背景音乐的生成。其实还有一部分我觉得也是大家用的最多的一部分，跟我们真正相关的内容创作的环节。就比如说在我们的写稿能不能帮我们整理采访提纲，然后能不能帮我们整理内容框架，还有我自己生成锈note的部分。先请君武给我们分享一段，我知道你写代唐的那篇稿子，你其实是有用ChatGPT去找一本特定的书的问题的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:19",
      "text": "你是怎么用的具体当时的use case，就是说用ChatGPT去总结一本书里面的一些我想找到的具体的例子。但讲到这个，我觉得可能有必要给大家稍微分享一下这个背景。代唐这篇稿子讲到最早的第一代代唐在1910年代。那个时候人们一开始为什么会对代糖的安全性慢慢开始产生质疑？那是因为他们读了一本当时出版的叫做图昶的小说。但是这个小说有四百多页，非常长，里面具体有哪些细节描述了代糖可能在安全方面的隐患。我不太可能每一页都去把这个小说去读下来。所以当时我就找了四百多页的P也直接把它一整个一股脑全都上传到了当时ChatGPT最新出的那个GPT s制作插件的这个小工具的网页里面。那我当时就说，你这个插件能不能帮我做一个小说的总结，告诉我这本书里面具体哪些地方，具体哪一些的描绘，让读者读了之后可能会产生对于食品安全的质疑。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:21",
      "text": "那ChatGPT s它很快的，我记得当时是10秒20秒之内就把这400页整理完了。跟我说OK这本书里面有一些比如说对于香肠，它的香薰料，包括像香肠外面包裹的这些东西，这些食品添加剂的安全，这些问题大家会比较关注的。所以说这个是一个我具体的use case。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:41",
      "text": "我觉得总的来说，在创作和写作的过程当中，需不需要去用工具分为两大类。一类是可能我们对事实的准确率要求很高的，比如说代堂里面的一些可能使人产生疾病的这些机理，包括甚至像我猜，有可能比如说讲钻石背后的化学的这些性质，包括像怎么样这些准确率要求高的，我可能还是会自己作为人去读论文，或者怎么样，然后把它总结出来。另一类相对来说是对准确率要求没有那么高的那比如就是说在一个四百多页的小说里，把它的核心的概念去总结出来。也不是说让他拼point到哪一页，讲了什么东西，具体是什么，但是把这个意思提炼出来，包括像我会把我的提纲跟ChatGPT分享一下，看他觉得是不是能够很清晰的整理出来一个逻辑。如果我的东西跟他说，他都不知道我在说啥，那可能就说明我的思路非常混乱。但他如果能够大概的get我想表达是什么意思，这可能说明我的这个框架相对来说就是比较清晰的。总的来说用AI工具会从对准确率的要求是否高这个方面去把它分为两大块的这样的内容。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:51",
      "text": "那欠你会用ChatGPT帮你去写内容框架吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:55",
      "text": "其实我现在其实用的不算多了。X GPT刚出来的时候，我有非常actively的想要去积极的拥抱它。但是出了两个很大的错误，最后没有到成片里面了。就是我自己在做一些调研的时候，发现两个很大的错误，然后就是让我有点阴影了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:58:12",
      "text": "第一个是可以跟大家分享一下，就是当时我正在写OpenAI成长史那篇稿子。最开始的时候我就问他说OpenAI最早的投资人都有哪些？最开始比如说有elon mask，有sam autem等等等等这些人，然后出现了一个腾讯，然后我当时就非常的震惊，我说这怎么可能就是一本正经的，我一本正经的就是腾讯夹杂在很多的外国人的名字里面。然后我当时就是非常的有八分怀疑，1点9分的震惊，还有0点1分的兴奋。然后那个0点1分的兴奋就说如果这是真的，那这不是震惊全球的大新闻吗？我们硅谷101是不是要搞个大新闻？但是我当时就是99%，nineteen nine percent, 他肯定9.9999，他肯定是出错了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:58:58",
      "text": "那我就很好奇说他是怎么会出现这个错误的，然后我当时就问他说你说腾讯是投资人，那你的source，你的来源是哪里？然后你把link发给我，然后他当时还可以给发link，就是说他的信息来源是哪里。然后我发现说他的link是腾讯投资的一个公司新闻的下面一个新闻是open I接受了可能马斯克什么什么的投资。所以他把这两篇一结合，就变成了腾讯投资OpenAI太会联想了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:59:26",
      "text": "对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:26",
      "text": "然后我当时就觉得说这个东西太扯了，然后就完全不能用它去做很多basic的一些research。所以我现在其实在做一些准确度非常高的一些调研的时候，我可能自己还是比较谨慎了。就是我现在大概的写稿步骤，可以跟大家break down一下，跟大家分享一下。我觉得对于硅谷101，因为我们做还是做比较深度的内容。我觉得一篇稿子对我来说就是了解这个选题的求知欲有没有被满足。我们说写稿子做新闻，就是5个W1个h what，where, why, when, who and how.",
      "speaker": "发言人4"
    },
    {
      "time": "01:00:02",
      "text": "然后我们把这些问题要是解释好了，那它就是一篇好稿子。其实每个步骤都是说，慢慢的把这个细节掰开去求证的这样的一个过程。就包括第一就是前期的内容准备。如果你抛给我一个选题，或者我们决定做一个选题，我起码要对它有一个大概的理解，才能够确定它这个稿子的框架跟选题的思路。但是我觉得这个部分是可以用叉GBT的。",
      "speaker": "发言人4"
    },
    {
      "time": "01:00:28",
      "text": "如果在ChatGPT之前，比如说红军我们写稿子的时候，可能之前的职业训练都会跟我们说，你就去google上面去找关键词，然后把google的前十页里面的新闻报道全都读一遍。你其实对一个事件就有大概的一个认知了。但是我觉得现在这一部分，其实是可以通过跟叉CBT或者冰川，或者是其他的一些大模型聊天，来完成这一部分对这个事件的一个基本的认知。也许以前要看google的前十页的每篇报道，你要用2到3个小时，可能现在会更快一些。你跟他聊天的话，半个小时或者1个小时，可能你对这个事件有一个稍微基本的一个认知。所以我觉得它的优点是可以很快的帮你节省时间，然后你大概对这个事情有一个来龙去脉的一个了解。",
      "speaker": "发言人4"
    },
    {
      "time": "01:01:16",
      "text": "但是它缺点就是它非常的笼统。就是我们读新闻的时候，特别是读一些非常权威的机构出来的东西的时候，它里面其实有非常多证据，非常多细节的东西。那些东西是ChatGPT完全给不了你的。比如说具体的数据，具体的细节，具体的它的故事来龙去脉是什么样子的。XGBT, 你会发现它非常的笼统。",
      "speaker": "发言人4"
    },
    {
      "time": "01:01:38",
      "text": "又拿最新的正式的报道来举个例子。比如说我跟x gbt聊的时候，我问他的问题是人造钻石是如何颠覆钻石行业的。他就会很笼统的跟你说，通过人造钻石技术的发展巴拉巴拉。然后现在导致了钻石行业的一个价格的下跌。人工钻石它的技术发展也能也导致人工钻石价格的下跌。但是没有具体的数字，也没有具体跟你说他技术是怎么发展的。如果你不知道具体的中间应该怎么去问他的问题，或者你不知道什么对，你不知道怎么去问他对应的细节问题。",
      "speaker": "发言人4"
    },
    {
      "time": "01:02:14",
      "text": "但是如果我看一篇比如说纽约时报，或者是其他的非常权威的媒体写的比较好的一些长篇深度的报道出来。他们很大可能会跟你说，技术发展是通过两个不同的技术派别的。是有化学气相沉积法CVD，还有高温高压法HPHT，以及这两个技术发展是什么样的。然后哪一年发生了什么样的事情。然后你可以再去通过具体的问题就问XGBT说，给我解释一下什么叫做化学气象沉积法，什么叫做高温高压法。如果你问对了这个细节的问题，他就会跟你说列举出来12345他是怎么去work的。我觉得这部分他其实还是挺有用途的。但是是说你要去找到问他那个具体的问题的那部分，我觉得可能还是现在搜索大量的去阅读新闻的报道，可能我觉得目前是一个更好的方式。",
      "speaker": "发言人4"
    },
    {
      "time": "01:03:04",
      "text": "刚刚听你的那个描述，我觉得前半部分你说我们是不是可以在通过跟ChatGPT的聊天中取代我们直接在谷戈上去读取网页，它的效率是更高的。其实我现在反而觉得，如果你对信息的效率利用的足够高的话，人写的东西一定是会比机器写的东西。它的结构逻辑完整度，包括它的故事是更加能够促进理解的。我就举一个例子，你想了解AXTZ这家投资机构，你可以去chat GP上问很多问题。如果我的大脑是一个数据库，我知道纽约客写过一篇还原这家机构的mark and的非常好的报道，那可能我的优先级是先去读那一篇深度报道。我如果还知道哪些媒体，我可能知道一些非常好的顶级的杂志，写过他们的，我会去搜这些杂志的名字，看他们有没有去写。我觉得这种方法可能是我读三篇报道胜过我跟ChatGPT聊俩小时。但这种前提条件是我们知道怎么去搜索更加精准的信息。",
      "speaker": "发言人1"
    },
    {
      "time": "01:04:13",
      "text": "对，你知道nuka写过那篇报道。对对对，或者是你知道什么样的媒体是什么样调性。",
      "speaker": "发言人4"
    },
    {
      "time": "01:04:20",
      "text": "或者什么样的媒体能够让我知道这个事情它的前因后果是什么样的。所以我基本上是在采访前，我是不太会让他去帮我做任何的采访准备工作的。因为他刚出来的时候，其实我试过说你要不要给我列一些提纲什么的。就是我觉得他列的那个提纲大概就是每个人都能问出来的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "01:04:41",
      "text": "我也不会让他列提纲。所以我刚刚说的只是非常前期的一个内容准备。就比如说你把人造钻石它的技术是怎么去实现的？我这个have like zero knowledge的东西给我，然后我可能觉得说稍微跟他聊聊天，然后稍微知道一个非常广泛，非常不get .",
      "speaker": "发言人4"
    },
    {
      "time": "01:05:00",
      "text": "started。",
      "speaker": "发言人3"
    },
    {
      "time": "01:05:01",
      "text": "对我觉得那个是一个开始。但是我觉得后来我大概知道这个东西是怎么回事了，我也知道我想问什么了，我要去探索什么了。我觉得大纲的一个初步确定，然后接下来是我会做的。但是这一步我可能自己脑子里面就已经成型了，我也不会通过x GPT来给我写提纲。",
      "speaker": "发言人4"
    },
    {
      "time": "01:05:18",
      "text": "接下来就是说一个信息采集的一个过程，我觉得这一部分我也不会用它。第一个原因，也是我刚才说了，我觉得它有很多不准确的地方，我也不太敢用。第二，我是觉得如果要写出最好的故事，就像洪军说的，就是你不能去读average写的东西，不能去做每个人都能写出来的东西。所以我觉得很多时候就一手采访是最重要的。然后我觉得这也是我们硅谷101其实是我们最看重的东西。然后你要去跟行业里面真正做这个事情的，并且做的最好的人去聊他们观察到的东西，他们解释出来的东西永远都是最有价值的东西。这肯定就是比XGBT它通过涌现或者它生成的average的这种解释要好很多很多，或者是要准确很多很多。",
      "speaker": "发言人4"
    },
    {
      "time": "01:06:03",
      "text": "刚刚你有提到在制作钻石的时候，这个化学气象沉积法他是一个什么样的东西？你问ChatGPT，其实我觉得这个是非常好的，就是他写出来的水平肯定是超过我的。因为我记得当时我做了一期跟生物医药相关的博客，然后那个播客里面其实是有非常多的专业名词，比如说冷冻电竞是什么？就是我可以在谷歌上搜索，然后我也确实搜了维基百科也用了。但是我觉得他们都解释的不够好。包括有很多的医药公司，像什么limbers薛定谔公司，他其实都是通过新闻里面来的。然后我让ChatGPT来做，他就真的是这个名词解释做的非常的好。他把每一家公司他的疾病的治疗范围都写了，我就直接用了，我把它放在修nose里面了，我让听众来挑错。到现在为止，还没有人来挑这个错。但我现在想一想，我们都不知道他是不是在一本正经的胡说八道，但是让他初步去解释一下一些概念还是好的。",
      "speaker": "发言人1"
    },
    {
      "time": "01:07:05",
      "text": "我记得有一次也是君武写的一篇稿子，是不是可能那个时候军武刚加入我们写稿子，然后不知道这个语言应该要怎么去解释的，high level一点，还是技术性一点，还是怎么着？当时我们跟军武说，你要把这个东西写的，就是你奶奶都能够读懂它是一个什么意思。当时君武说，那我让GPT给我解释一下，就是一个什么three year old child的都能够解释的清楚，或者my grandma都能够了解的了的这种技术解释什么样子的，我觉得那个还蛮有帮助的。",
      "speaker": "发言人4"
    },
    {
      "time": "01:07:35",
      "text": "是的，我觉得这也是可能是有原因的。像洪军说的谷歌我们搜索的时候，他的可能算法就是比较客观，比较事实。但是ChatGPT因为它有各种不同的数据去训练，所以它可能更会像讲故事一样讲出来。所以我觉得真的就是说这种具体的解释用它还是可以降维的比较好。你们之前讲的有一个我就觉得特别有共鸣，就是说一开始的时候是不是用ChatGPT写提纲，我也是肯定不会用它去写提纲的。我的感受是提纲可能这个文章的框架是真的。我们作为人，作为写手对于这个文章的贡献之一，或者说比较核心的一个决定权。我希望这个决定权是我自己通过阅读之后，我自己脑子里去编织的一张知识网去总结出来的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:08:20",
      "text": "它其实就是你的好奇心。",
      "speaker": "发言人1"
    },
    {
      "time": "01:08:22",
      "text": "exactly就是我的好奇心的体现。但如果我一开始就上来让ChatGPT给我一个提纲，可能我个人至少是会比较容易被他带偏。我就说他已经给我一个，那我可能就让他这么去，可能会有点掰。就是说我会按照他那个提纲去找新闻。这样子的话可能就不一定能够特别全面的完全从白纸一张开始去进行自己的一些思考和总结。所以这一点是跟很有共鸣的一点。",
      "speaker": "发言人3"
    },
    {
      "time": "01:08:46",
      "text": "对我总是觉得用整个XGBT的感觉就是我在被给东西，我在被喂东西，而不是一个主动去寻找、主动去search，主动去求知的一个过程。我觉得这两者还是挺不一样的一个感受的。就是在整个search的过程中，你很快的去阅读很多的书也好，新闻也好，文章也好。其实你会发现很多东西你是不知道的，你根本就不知道它存在的。然后你再去对那些新的东西展开去深挖，其实那个过程是非常美好的。但是chac BT就是给你一个很笼统的东西，就直接给你结论。你也不知道那个结论怎么得来的，你也不知道它到底是不是one hundred percent准确的。是的，那个感觉还是完全不一样。",
      "speaker": "发言人4"
    },
    {
      "time": "01:09:28",
      "text": "满足我们好奇心的写作的这个原动力还是要抓在我们自己的手里，动力还是。",
      "speaker": "发言人3"
    },
    {
      "time": "01:09:33",
      "text": "要有的对大模型还是能帮助助我们去节省工作效率的。说实话我其实用ChatGPT蛮少的，是因为我非常不喜欢他对中文的语言表述习惯。我不知道是不是因为他的训练语料的问题，我会让chat BT跟cloud点AI就anthropic旗下的一款也是大模型文字生成式的AI产品来帮我们去写修note。我发现我更喜还cloud点AI写的修容词，我是觉得它的整个的语言结构跟语言表述，可能我更喜欢他的文字风格一点。这个就是一个纯个人喜好的事情。但是在大模型生成修notes的时候，我生成完了，我在即刻上发了一条状态。",
      "speaker": "发言人1"
    },
    {
      "time": "01:10:16",
      "text": "我说这个大模型生成的修notes比我实习生好比我快。但其实也是磨合了蛮久的，取决于我会给他什么样的一些我的demo的样板。就比如说如果我说你每两分钟生成一条总结，它会非常整。02.000、4.000、6.00它会这样抓。然后他生成的东西也非常的随机。但是在我给他一些好的模板以后，他会越来越按照我的方向写。因为可能你让大模型帮你生成，他可能就跟一个实习生一样。",
      "speaker": "发言人1"
    },
    {
      "time": "01:10:51",
      "text": "他最开始大家生成修nos都喜欢去把主持人的问题生成出来。比如说人工钻石是什么，都是类似于这样子的。但是其实我们知道是nos更吸引人的写法。它可能有几种，一种是你要写问题的结论，人工钻石是什么中间最吸引你的那个点，而不是问题。你要去回答你的问题，或者说你要去总结嘉宾的观点。还有一种是有的时候嘉宾会有很多的金句，大家可能会想知道这个京剧的前因后果是什么。",
      "speaker": "发言人1"
    },
    {
      "time": "01:11:22",
      "text": "第三点，可以去挖掘播客中一些有意思的细节点。比如说像我们上一期聊到脑机接口的问题，嘉宾就说到了有3到4家视网膜公司都是因为封装问题而倒闭的。就把这个观点直接总结出来，就会比说脑机接口现在的风险点有哪些会更吸引人。这个就是抓住播客中采访到的关键的细节点，把它呈现出来。",
      "speaker": "发言人1"
    },
    {
      "time": "01:11:48",
      "text": "最后一步，如果说以上三个部分既没有观点又没有进去总结，还没有有意思的细节点，那我们就直接说问题了。但是大家可以想象，如果前三个部分都总结不出来的话，那这一部分的博客基本上听起来是非常的无聊。就是我觉得它是有非常多的层次，但是大模型通常只写到了第一个层次。总体来说就是我觉得他的写作水平可以用，但是离好还是有差距。",
      "speaker": "发言人1"
    },
    {
      "time": "01:12:17",
      "text": "还差很远。因为我觉得它在细节上面还是完全不行。讲故事细节，然后把一个故事讲的非常的生动，我觉得还差一点点。",
      "speaker": "发言人4"
    },
    {
      "time": "01:12:29",
      "text": "对我觉得其实我们对他能不能用的标准，可能就全看自己对内容的标准。",
      "speaker": "发言人1"
    },
    {
      "time": "01:12:34",
      "text": "没错。",
      "speaker": "发言人4"
    },
    {
      "time": "01:12:35",
      "text": "好，谢谢陈倩，谢谢君武。",
      "speaker": "发言人1"
    },
    {
      "time": "01:12:38",
      "text": "谢谢jack up。好的，我们在这里给大家拜个晚年，真的是拜晚年了。对对对，祝大家龙年大吉。",
      "speaker": "发言人4"
    },
    {
      "time": "01:12:46",
      "text": "龙年快乐。",
      "speaker": "发言人3"
    },
    {
      "time": "01:12:47",
      "text": "祝大家新春快乐。这期节目我们谈到的所有的产品，都是我们自己的试用体验，以及硅谷101自己的内容偏好。它并不能代表我们对生成式AI的整体意见。我们在这里也发一个我们自己的招聘信息，就是硅谷101现在正在招聘播客的监制视频，后期我们节目的运营，还有视频的内容策划总监。如果大家想知道我们招聘的详细信息，可以在我们博客的show note中点击我们的链接，或者在硅谷101的微信公众号上搜索我们的招聘信息。欢迎大家给我们积极的投放简历，我们的简历投放的截止时间是在3月1号，截止之后我们会开始进入到面试环节。",
      "speaker": "发言人1"
    },
    {
      "time": "01:13:39",
      "text": "欢迎对内容创作感兴趣的小伙伴来加入我们的大家庭。这就是我们今天的节目。如果大家喜欢我们的节目，欢迎大家在小宇宙、喜马拉雅、苹果播客网、易云音乐听听FM、荔枝播客、QQ音乐来收听。我们海外的听众可以通过苹果播客25还有youtube music来收听我们。因为谷歌今年会关闭他们的google podcast的产品，所以我们的播客会转移到youtube还有youtube music上。大家也可以在youtube上搜索硅谷101播客来找到我们。感谢大家的收听，谢谢。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "本期《硅谷101》深入探讨了生成式AI在播客摘要撰写、内容创作、视频制作和音频编辑等领域的应用及其对工作效率的提升。讨论强调，尽管AI能有效搜集信息、生成文章大纲并促进团队协作，最终的创意和深度思考仍需人类完成。对话中也展现了对AI工具带来效率提升和创新机会的乐观态度，同时强调保持人类创作者的角色和价值，指出AI无法完全替代人类在创意、情感表达和深度理解方面的能力。节目最后，邀请听众参与AI工具的应用和开发，以推动媒体行业向前发展，并提醒对新技术保持开放性的同时，也要清醒认识到AI的局限性。",
    "qa_pairs": [
      {
        "question": "在硅谷101的视频制作中，AI是如何被运用的，特别是视频后期制作方面？",
        "answer": "在硅谷101的视频后期制作中，AI工具如runway和皮卡等被广泛应用。过去一年我们不断尝试各种AI工具以提高工作效率，尤其是在动画特效设计上。例如，Jacob就使用了这些工具进行动画生成，尽管目前生成视频存在变形、画面不一致等问题，但在延长视频时，pick labs的表现相比runway略好一些。",
        "time": "00:03:12"
      },
      {
        "question": "runway和皮卡等工具的工作原理是什么？",
        "answer": "runway和皮卡等工具可以通过video to video的方式对视频进行变形处理，也可以通过text to video的方式将文本转为视频。其中，更多时候是使用image to video功能，将静止图像动起来，精确控制图像的部分运动。",
        "time": "00:06:29"
      },
      {
        "question": "AI生成视频时，如果延长视频时长，画面会出现什么问题？",
        "answer": "当AI生成视频从三四秒延长到七八秒或更长时间时，画面容易出现丢帧现象，导致前后画面不一致，如人物的身体结构、衣物细节等随着秒数增加而变形，无法保持画面的连贯性和一致性，这对追求高质量视觉效果的团队来说是一个挑战。",
        "time": "00:05:07"
      },
      {
        "question": "是否在硅谷101上线的视频中使用了runway或皮卡生成的画面？",
        "answer": "目前还没有大量使用runway或皮卡进行后期工作，但在一些动画设计中有所应用，但仅限于几秒的时间，并未深入到整个视频后期工作流中。",
        "time": "00:04:00"
      },
      {
        "question": "对于AI生成视频与真实世界的模拟是否存在物理逻辑理解不足的问题？",
        "answer": "是的，AI生成视频在模拟真实世界方面存在问题，尤其在物理逻辑的理解上不够清晰，比如生成的人物手部动作位置不自然，与背景环境的一致性难以保持，这限制了AI模型在真实世界模拟方面的表现力。",
        "time": "00:07:42"
      },
      {
        "question": "AI生成视频对于硅谷101现有的内容制作需求能否构成威胁或替代？",
        "answer": "AI生成视频目前还不能完全满足硅谷101的需求，特别是在动画解释和数据可视化方面，由于AI尚无法精确地将图表以动画形式表现出来。不过，随着技术的发展，如果AI能够实现更高级别的定制化和信息精确处理，未来有可能替代部分素材库的需求。而对于解释性内容中的动画制作，目前仍需依赖专业团队进行创作。",
        "time": "00:11:53"
      },
      {
        "question": "AI与人交流的方式是否与人类之间的交流方式相似？",
        "answer": "是的，AI通过学习人脑和各种位置信息来生成内容的方式，从本质上讲，它与人与人之间交流的方式是类似的。",
        "time": "00:14:12"
      },
      {
        "question": "AI是否能通过多模态交互（如文本、图片）创建视频内容，并以agent角色帮助完成任务？",
        "answer": "现在AI已经能够接受文字和图片输入并生成视频，未来整合text to view功能后，它可能会成为一个更强大的工具，不仅限于工具角色，而是能以agent的角色协助完成一些任务。",
        "time": "00:15:20"
      },
      {
        "question": "AI在视频剪辑中扮演的是工具还是独立完成视频制作的角色？",
        "answer": "这个问题探讨的是AI是否能从工具转变为能独立思考并使用自身完成视频制作的实体。目前来看，AI在某些类型视频如历史叙述方面表现出色，但对于需要创造力和宏观理念指导的科普类或复杂场景视频，人的作用不可或缺。",
        "time": "00:16:47"
      },
      {
        "question": "AI在现实世界精准还原方面的挑战是什么？",
        "answer": "AI在精准还原现实世界中存在困难，如物体动作连续性、物理属性如风对衣物的影响、光线反射等，这涉及到AI对物理世界的理解和模拟能力。",
        "time": "00:19:40"
      },
      {
        "question": "AI能否具备人类的创造力，例如在视频中插入幽默、讽刺等元素？AI生成的视频与精心设计的人类创作相比，有何差别？",
        "answer": "目前AI还无法像人类那样具有创造性和洞察力，无法理解并融入深层次的文化内涵和情感表达，例如视频中的梗或贴纸表现，这些往往源于人类的独到见解和情绪把握。AI生成的视频往往缺乏精心筛选的内容和顶级的创意构思，多呈现出平均质量。好的视频背后蕴含着精心设计和构思，AI目前难以取代高质量的手工创作。",
        "time": "00:20:10"
      },
      {
        "question": "AI是否能通过类似ChatGPT的模型创作出顶级的文字作品或剧本？",
        "answer": "ChatGPT等AI模型在创作文字作品时，受限于其基于概率最大化的算法，往往倾向于落入俗套的故事模板，难以产生真正意义上的创新和灵感，而优秀的作品需要情理之中但又在意料之外的独特构思。",
        "time": "00:22:09"
      },
      {
        "question": "AI扩图技术如何帮助改善图像尺寸不匹配的问题？",
        "answer": "AI扩图技术不仅可以扩展图像尺寸，还能将原本像素较低的图像放大几倍，保持整体效果统一。例如，在去年成都世界科幻大会合作活动中，我们使用AI扩图技术将原本不适合大屏幕展示的PPT图片进行完美适配，不仅尺寸变大，而且画面细节得到了补充和优化。",
        "time": "00:27:41"
      },
      {
        "question": "AI扩图功能在其他应用场景中表现如何？",
        "answer": "美图秀秀等软件中也具备AI扩图功能，可以用来调整照片尺寸，甚至补全缺失部分，比如拍摄影棚照片时由于拍摄角度问题而未能完全捕捉到的背景或物体边缘。通过AI扩图，能够快速、自然地修复这些缺陷，大大提高了编辑效率。",
        "time": "00:27:55"
      },
      {
        "question": "AI技术在P图软件中是如何提高工作效率的？",
        "answer": "在Photoshop等P图软件中，AI技术能够实现诸如替换图像中物体的功能，只需几秒钟就能精细地替换人物手中的手机、杯子等物品，极大提升了设计师的工作效率。同时，对于插画师来说，可以通过AI一键更换配色，极大地简化了色彩调整过程。",
        "time": "00:28:34"
      },
      {
        "question": "AI生成效果在哪些领域有所突破？",
        "answer": "在后期制作方面，AI生成效果已能在一定程度上达到专业水准，如Adobe Photoshop中的一些功能，能够更方便地处理图像和音频。音乐方面，Eleven Labs等工具可以利用声音克隆技术还原缺失或错误的录音片段，虽然中文优化尚不理想，但在英文文本上的表现较好，尤其适用于语音内容的修复和补录。",
        "time": "00:29:37"
      },
      {
        "question": "Open Voice项目在中文语音生成方面的表现如何？AI音乐生成技术目前的发展状况如何？",
        "answer": "Open Voice是一个开源项目，由MIT和牛津大学等机构联合开发，能够较好地生成接近国人发音的中文语音。相较于Eleven Labs，Open Voice在音调上的准确性更高，但对样例输入的要求更多，如果提供足够的样例，AI可以更好地捕捉到个体语音特征。目前，AI音乐生成技术已能够根据关键词从素材库中选取或创作出符合情绪和氛围的配乐，尽管对于某些具有独特风格或个性化的音乐创作，AI仍存在局限性，但在标准化、电视台化的配音场景中，AI音乐生成技术已经展现出了高效且高质量的一面。",
        "time": "00:36:53"
      },
      {
        "question": "AI音乐生成工具是否能替代音乐制作人？对于AI音乐生成工具能否接受reference以更准确地描述所需音乐风格？",
        "answer": "目前还不至于完全替代音乐制作人，但确实提升了工作效率，尤其是在版权音乐查找方面。不过，AI生成的音乐可能还较general，缺乏特定项目所需的精准味道。这是一个非常期待的功能，如果能通过提供一首歌曲作为参考来描述音乐的感觉、风格和BPM等详细信息，将大大简化创作过程。",
        "time": "00:43:14"
      },
      {
        "question": "AI音乐生成工具在处理版权问题上的优势是什么？",
        "answer": "如果AI生成的音乐可以合法使用，那么无需购买版权，这将大大节省成本，但目前对于AI音乐版权的计算规则还不清楚。",
        "time": "00:44:36"
      },
      {
        "question": "剪辑软件是否具备剪辑音乐时实现无缝衔接的功能？",
        "answer": "现有的剪辑软件如PR（Premiere Pro）确实有延长或缩短音频并保持连贯性的功能，能够自动找到合适的剪辑点，使得音乐剪辑更为流畅自然。",
        "time": "00:50:03"
      },
      {
        "question": "在未来，小公司开发的个性化功能是否有机会与大公司成熟的产品体系竞争？",
        "answer": "只要功能做得足够好，无论大小公司，用户都愿意尝试。对于用户而言，希望现有常用制作软件能整合小公司开发的实用功能，以提高工作效率，而不是被迫学习新的系统。同时，市场上已有许多小公司通过销售插件等方式实现商业化，并与大公司产品形成互补。",
        "time": "00:52:12"
      },
      {
        "question": "在写作过程中，你具体是如何使用ChatGPT来帮助整理书籍内容的？",
        "answer": "当时我在写关于代唐的稿子，需要找到一本四百多页的小说中与代糖安全性相关的问题。我将这400页小说上传至ChatGPT s制作插件的网页工具中，让其做一个小说总结，找出书中哪些地方可能引发读者对食品安全的质疑。结果ChatGPT在大约10到20秒内就完成了整理，并指出了书中关于香肠香薰料、食品添加剂等问题的描述。",
        "time": "00:55:19"
      },
      {
        "question": "在创作和写作过程中，你会如何区分哪些部分适合使用AI工具如ChatGPT，哪些部分则需要人工处理？使用ChatGPT存在的缺点是什么？",
        "answer": "我会根据对事实准确率的要求来区分。对于准确率要求高的部分，比如医学机理或化学性质等内容，我会亲自阅读论文并总结；而对于准确率要求相对较低的部分，比如在一本小说中提炼核心概念或整理提纲，可以借助ChatGPT。如果ChatGPT能够清晰理解并整理出逻辑，说明我的思路较为清晰；反之则可能意味着我的框架不够清晰。ChatGPT存在的主要缺点是提供的信息较为笼统，缺乏具体数据、细节和故事来龙去脉。对于需要深入探究和精准信息的内容创作来说，直接阅读权威媒体的深度报道仍然更为重要。",
        "time": "00:56:41"
      },
      {
        "question": "你会用ChatGPT帮你去写内容框架吗？ChatGPT在内容准备阶段能起到什么作用？",
        "answer": "目前我使用ChatGPT帮写内容框架的次数并不多。在ChatGPT刚推出时，我积极尝试，但遇到两个重大错误，导致我对它在基本研究中的准确性产生质疑。例如，在写OpenAI投资人的文章时，ChatGPT错误地将腾讯视为投资人，这源于它结合了两个不同来源的信息而产生的误解。ChatGPT可以在前期内容准备阶段帮助快速获取对选题的基本认知，节省时间。通过与ChatGPT或其他大模型聊天，可以在较短时间内了解一个事件的基本情况，而以往可能需要阅读google前十页的相关报道才能达到同样的效果。",
        "time": "00:57:55"
      },
      {
        "question": "对于通过ChatGPT获取信息与自己直接搜索信息，你认为哪种方式更好？",
        "answer": "我认为在某些情况下，直接通过搜索引擎搜索精准信息并阅读深度报道，如纽约时报等顶级媒体的文章，其结构逻辑完整度、故事叙述和理解深度会优于ChatGPT生成的内容。不过，ChatGPT对于一些复杂概念的解释和专业名词的转化能力较强，可以在一定程度上辅助写作。",
        "time": "01:03:04"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "硅谷101团队分享利用AI工具的工作流程",
        "summary": "硅谷101的红军介绍了团队如何利用生成式AI工具提高内容创作效率，包括视频制作、文案策划等方面。Jacob分享了负责视频后期和动画特效的经验；张君武谈及使用AI工具撰写稿件的经历；陈倩作为视频主理人，也参与了讨论。同时，红军宣布了硅谷101的招聘计划，包括运营、播客监制、视频后期文案策划总监等职位。"
      },
      {
        "time": "00:02:03",
        "title": "探讨AI在视频后期制作中的应用与发展",
        "summary": "对话集中于讨论AI技术，特别是OpenAI新发布的Sora，在视频后期制作中的应用及其与现有技术的比较。讨论者分享了自己使用Runway和皮卡等工具生成视频的经验，指出这些工具在视频延长时存在的问题，如视频变形和画面不一致。他们还提到了Sora能够生成更长视频的能力及其带来的影响，尽管目前这些AI生成工具在专业视频制作中应用有限，主要用于动画设计和特效生成，但对于信息密度高的视频内容制作贡献有限。讨论者认为，AI生成视频目前更适合作为辅助工具，而非主要的制作手段。"
      },
      {
        "time": "00:06:07",
        "title": "探讨生成式视频技术的进展与挑战",
        "summary": "讨论重点在于生成式视频技术的最新进展，特别是如何通过AI将文本、图片转化为视频内容，以及在这一过程中遇到的挑战。一方面，技术能够实现将静态图像动起来，甚至精准控制视频中特定部分的运动，如让画面中的人物翻书。然而，随着视频长度的增加，维持画面真实性和逻辑性的一致性成为一大难题。技术在物理世界逻辑理解上的不足，导致生成的视频在某些细节上与现实存在差异。另一方面，新出现的技术如Sora能够生成细节丰富、连贯性高的视频内容，例如精细地呈现光影效果和背景广告牌的信息一致性，这些进步标志着生成式视频技术正在向更加真实、细腻的方向发展。"
      },
      {
        "time": "00:09:45",
        "title": "硅谷101在前沿科技内容创作中的挑战与AI的未来潜力",
        "summary": "硅谷101专注于制作关于前沿科技的深度内容，其素材主要包括纪录片片段、动画和通用图库视频。虽然AI技术在视频生成领域展现出巨大潜力，如sora更新可能预示着未来在动画解释环节的助力，但目前仍面临精准信息处理和数据可视化挑战。创作团队在表达具体动画设计要求时经常遇到语言描述的限制，凸显了当前AI技术在理解和生成复杂视觉内容方面的局限。尽管如此，硅谷101对未来AI能够克服这些挑战并改进内容创作流程持开放态度。"
      },
      {
        "time": "00:13:45",
        "title": "探讨与AI的有效沟通及创意内容生成",
        "summary": "讨论重点在于如何与AI进行有效沟通以生成创意内容，特别是视频和音乐等领域。一方面，存在挑战，如精确表达个人对作品的期望和感觉给AI，使其理解并生成满足要求的内容。另一方面，技术进步使得AI能够理解并基于人类提供的多模态信息（如文本、图像）生成更为复杂和具体的内容。此外，探讨了AI在未来是否能够不仅仅是人类的辅助工具，而是能够独立完成一些创意工作。最后，指出即使AI技术高度发展，仍有一些人类独有的创意和理念是AI难以完全复制的。"
      },
      {
        "time": "00:18:02",
        "title": "探讨人工智能在视频创作中的局限与挑战",
        "summary": "讨论集中于人工智能（AI）在视频制作中的应用及其局限性。指出虽然AI在生成视频内容方面展现出一定的能力，如构图设计，但仍然难以达到人类创作者的创造力和精准度。特别强调了人类在视频创作中对细节的处理、情感的表达以及对物理世界理解的深度，是目前AI技术难以超越的。同时，通过举例说明，如对英伟达演讲的创意剪辑，强调了人类创作的独到之处。最后，讨论了AI生成内容的普遍性及其面临的挑战，比如精准还原现实世界、避免落入俗套等问题。"
      },
      {
        "time": "00:22:09",
        "title": "探讨人工智能与创造性思维的界限",
        "summary": "对话内容涉及如何将老师、小朋友和外星人结合创作故事的讨论，以及刘慈欣的《乡村教师》中对这一主题的巧妙处理。进一步讨论了AI在创造性工作中的应用限制，提出了AI无法像人类一样进行创造性思维的观点。对话中也表达了对将来科学可能揭示人类创造力生物学机制的期待，以及这可能对AI发展带来的影响。"
      },
      {
        "time": "00:24:09",
        "title": "探讨AI在设计和后期制作中的应用及挑战",
        "summary": "对话中讨论了AI技术在视频后期和图形设计领域的应用情况，特别是AI生成内容如何帮助设计师提高工作效率。尽管AI技术如MeJourney和GPT可以辅助生成特定提示词来创造图像，但这种方法也存在局限，如耗时较长，有时不如直接购买素材来得高效。同时，讨论也指出，AI技术在素材库整合、图像扩展和质量提升等方面已经取得进展，比如Adobe软件中的AI智能填充和扩图功能极大便利了设计师的工作。然而，目前AI生成效果尚不能完全满足专业需求，期待未来AI技术能进一步发展，达到更高的应用水准。"
      },
      {
        "time": "00:30:04",
        "title": "应用AI技术在音频后期制作中的实践与挑战",
        "summary": "对话中讨论了使用Eleven Labs软件在音乐和音频制作中进行声音克隆的应用，特别是在修复录音错误、复原特定声音以及创作具有创意效果的音频内容方面的实践。尽管AI技术在模拟声音上展现出了强大的能力，能够有效补录缺失的旁白和纠正口误，但对于中文的处理存在明显的挑战，表现为语调的不自然，尤其是在处理长句子时更为明显。参与者分享了通过控制输入文本的长度和选择合适的音频示范来优化输出的经验，同时指出这种技术在特定场景下，如模拟历史人物声音时，能产生有趣的效果，即便中文发音带有外国口音。"
      },
      {
        "time": "00:35:04",
        "title": "探讨Open Voice在中文语音生成中的应用及效果",
        "summary": "对话中讨论了Open Voice作为一种能有效还原中文语音的工具，其在语音生成方面优于其他同类产品。通过比较不同技术生成的语音样本，发现Open Voice的音调更为准确，更接近国人发音习惯。尽管如此，仍存在一些挑战，比如对于特定情感表达和个性化语调的捕捉不够准确。此外，讨论还触及了声音生成技术在实际应用中的模糊界限，以及如何区分真人声音与AI生成声音的难度，特别是在标准化语言输出方面，AI技术已经达到了较高的水平。"
      },
      {
        "time": "00:38:18",
        "title": "探讨AI作曲与音乐素材库的优劣",
        "summary": "对话中讨论了使用AI作曲和音乐素材库来为项目配乐的体验。一方面，AI作曲能够快速根据提示生成音乐，为内容创作者提供便利，但生成的音乐可能缺乏特定的个性和情感深度，使得其在表达复杂情感时略显不足。另一方面，音乐素材库提供了大量的现成音乐选择，通过关键词搜索可以快速找到符合需求的配乐，尽管存在版权问题，但使用起来更加直接和高效。讨论者认为，虽然AI作曲技术有其优势，如版权问题的潜在解决方案，但目前看来，它还未完全达到能够完全替代专业音乐制作人的水平，特别是对于要求高情感表达和个性化的项目来说。"
      },
      {
        "time": "00:44:52",
        "title": "音乐创作中的AI技术应用期待与挑战",
        "summary": "讨论者提出了在音乐创作过程中利用AI技术的几个期望点。首先，期望AI能根据提供的参考音乐生成新的音乐作品，以解决音乐制作人难以用语言准确描述音乐风格和感觉的问题。其次，讨论者希望AI能根据视频画面或文案自动生成配乐，以实现音乐与视频内容的更紧密匹配。此外，还提出了对于音乐素材库中AI功能的需求，希望AI能提供更加精确的音乐剪辑和调整服务，解决音乐与视频长度不匹配的问题。讨论者最后提到，现有的剪辑软件如Premiere Pro和Audition已经具备一定的音频编辑功能，但仍然期待AI技术能够进一步提高音乐制作的效率和质量。"
      },
      {
        "time": "00:51:16",
        "title": "探讨AI技术在视频制作中的应用及未来趋势",
        "summary": "对话中讨论了AI技术在视频制作领域的应用，特别是个性化和定制化功能的重要性。虽然大公司拥有成熟的产品体系，但小公司和独立工作室通过开发高度专业化的插件和软件，提供了更加细节化和定制化的解决方案。这些小公司能够满足专业人士对视频编辑和处理的高要求，如声音处理和特效制作。同时，讨论也触及了AI技术在内容创作、采访提纲整理和创意写作方面的潜力，强调了AI工具对提高创作效率和质量的贡献。"
      },
      {
        "time": "00:55:19",
        "title": "利用ChatGPT总结文学作品与科学写作",
        "summary": "发言者分享了使用ChatGPT帮助总结一本400页小说《图昶》的经验，目的是找出书中关于代糖可能的安全隐患的描述。通过上传整本小说到ChatGPT的工具网页，该工具在短时间内成功提取了关于食品添加剂安全性的关键信息。此外，发言者讨论了在创作和写作过程中使用AI工具的两种不同情况：一种是对准确率要求极高的科学性质内容，倾向于通过阅读论文或专业资料后亲自总结；另一种是对准确率要求不那么高的文学作品等，利用AI工具提取核心概念和框架。通过与ChatGPT的互动，可以帮助作者检验自己的思路是否清晰，以及是否能够有效地传达给读者。"
      },
      {
        "time": "00:57:50",
        "title": "ChatGPT在内容创作中的应用与局限",
        "summary": "对话者分享了使用ChatGPT进行内容创作的经验，特别是撰写关于OpenAI成长史的稿件过程中发现的错误。起初对ChatGPT抱有期待，但在实际使用中遭遇了误导性信息，如将腾讯误列为OpenAI的早期投资者之一，这反映出ChatGPT在处理具体、细节性信息时的局限。尽管如此，ChatGPT在提供基本信息和节省前期研究时间方面仍有其价值，但对话者强调，在进行精确度要求高的研究时仍需保持谨慎，依赖传统的研究方法以确保内容的准确性和深度。"
      },
      {
        "time": "01:03:04",
        "title": "探讨人工智能辅助内容创作的利弊",
        "summary": "在讨论中，一位内容创作者分享了他对使用ChatGPT等人工智能工具辅助内容创作的看法。他认为，尽管AI在提高信息检索效率和提供初步概念解释方面有其优势，但就深度报道和故事讲述而言，人类作者凭借其对结构逻辑的把握和故事叙述能力，仍然优于AI。此外，他强调了一手采访的重要性以及对于内容创作而言，保持个人的好奇心和自主思考的必要性，担心依赖AI生成的提纲可能限制创作者的创造性思考。"
      },
      {
        "time": "01:08:46",
        "title": "探讨ChatGPT与云AI在内容创作中的应用及个人偏好",
        "summary": "对话中提到了使用ChatGPT和云AI进行内容创作的不同体验，指出ChatGPT虽然能提高工作效率，但存在对中文表述习惯的不满，以及生成内容在细节和故事讲述方面的不足。相比之下，云AI的文本风格更符合个人喜好。同时，强调了主动探索和求知的重要性，以及对生成式AI的使用标准应根据个人对内容质量的要求来定。此外，还提及了硅谷101的招聘信息，包括招聘职位和简历投递截止时间。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "使用AI工具提高工作效率"
                },
                {
                  "children": [],
                  "content": "Jacob使用AI进行视频画面优化和动画特效制作"
                }
              ],
              "content": "视频后期处理"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "张君武运用AI工具编写稿件，探索效率提升"
                },
                {
                  "children": [],
                  "content": "AI工具帮助整理采访提纲和内容框架"
                }
              ],
              "content": "文本内容创作"
            }
          ],
          "content": "AI技术在内容创作中的应用"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "运营"
                },
                {
                  "children": [],
                  "content": "播客监制"
                },
                {
                  "children": [],
                  "content": "视频后期文案策划总监"
                }
              ],
              "content": "正在招聘"
            },
            {
              "children": [],
              "content": "投递简历至HR@SZ101.NET"
            }
          ],
          "content": "招聘信息"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "使用生成式AI进行视频画面的生成和优化"
                },
                {
                  "children": [],
                  "content": "探索不同AI工具如Sora在视频制作中的应用"
                }
              ],
              "content": "后期技术应用"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "素材库与AI生成视频之间的选择"
                },
                {
                  "children": [],
                  "content": "AI在视频剪辑和动画制作中的局限性"
                }
              ],
              "content": "视频素材获取"
            }
          ],
          "content": "视频制作流程"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "使用ElevenLabs和OpenVoice进行声音克隆"
                },
                {
                  "children": [],
                  "content": "探索音乐生成软件如MusicFX在背景音乐创作中的应用"
                }
              ],
              "content": "声音克隆和音乐生成"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI在还原音调和语调方面存在局限"
                },
                {
                  "children": [],
                  "content": "对中文语音处理的特殊挑战"
                }
              ],
              "content": "对AI音频制作的评价"
            }
          ],
          "content": "音频内容制作"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "在特定任务中提高效率，如关键词提取和内容概要生成"
                },
                {
                  "children": [],
                  "content": "需要根据内容创作标准进行选择和评估"
                }
              ],
              "content": "AI工具的实用性"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI工具在创造性和准确性方面的局限性"
                },
                {
                  "children": [],
                  "content": "人类创作者的不可替代性"
                }
              ],
              "content": "AI的创造性和准确性"
            }
          ],
          "content": "对AI工具的看法"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "AI作为辅助工具的角色"
                },
                {
                  "children": [],
                  "content": "人类创作者在内容创造中的核心价值"
                }
              ],
              "content": "人类与AI在内容创作中的角色"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI技术在提高内容创作效率方面的潜力"
                },
                {
                  "children": [],
                  "content": "人类创作者与AI工具的互补性"
                }
              ],
              "content": "对AI未来发展的思考"
            }
          ],
          "content": "内容创作的哲学讨论"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "探索AI在内容创作中的应用"
                },
                {
                  "children": [],
                  "content": "分享内容创作经验与见解"
                }
              ],
              "content": "硅谷101的节目愿景"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "邀请听众分享对AI应用的看法"
                },
                {
                  "children": [],
                  "content": "期待听众对节目内容的反馈和建议"
                }
              ],
              "content": "鼓励听众参与"
            }
          ],
          "content": "结语"
        }
      ],
      "content": "硅谷101播客节目总结"
    }
  }
}