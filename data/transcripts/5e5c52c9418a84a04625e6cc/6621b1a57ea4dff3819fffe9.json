{
  "pid": "5e5c52c9418a84a04625e6cc",
  "eid": "6621b1a57ea4dff3819fffe9",
  "title": "E147｜Suno引爆音乐圈，与音乐人聊聊AI生成音乐与艺术的随机数",
  "task_id": "mloynmwmbgy4qagp",
  "transcription": [
    {
      "time": "00:00:09",
      "text": "Still, the common value to the brightest st. Mind is creating technology. That's one of a kind.",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:15",
      "text": "We live in a digital age where AI is so fur. Now can you see this building easier? And let's come with me. Show the log.",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:44",
      "text": "欢迎收听硅谷101，我是红军。大家刚刚在片头听到的这首曲子，是我们要求AI根据硅谷101的主题来创作的一首爵士乐。他的歌词旋律还有演唱会都是AI自己生成的。你们觉得怎么样？",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:03",
      "text": "这期我们来聊最近在生成音乐方面非常有名的一个音乐模型，就是sono。它可以大家只输入一段非常简单的提示，就生成一段非常好听的音乐。最近在我身边的圈子里也是很火，因为大家都在测试，然后感觉这个测试的效果还不错。但是我们都是非专业的专业的人士。是怎么看待zu NO生成音乐的效果的那今天我们有请到了冯建鹏，他是youtube上非常有名的音乐分享的youtube r他的账号叫做刀刀。他同时也是美国音乐学院打击乐讲师和美国百老汇的打击乐演奏者。欢迎冯老师，hello冯老师，你好你好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:46",
      "text": "感谢。",
      "speaker": "发言人3"
    },
    {
      "time": "00:01:47",
      "text": "还有一位也是专业的这是meta music的tech lid，他是Roger陈。Hello rogier你好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:54",
      "text": "你好，谢谢邀请。",
      "speaker": "发言人4"
    },
    {
      "time": "00:01:56",
      "text": "我知道其实除了苏宁以外，还有其他的几款生成音乐的软件。最近大家还有用其他的什么软件吗？你们用过哪些，我们要不要先总体的聊一下？",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:06",
      "text": "我听说过几家，比如说audio stable audio，还有一些开源的。比如像refused meta之前出的music jam，还有google的muc LM OpenAI以前做的一个joke box。但是其实他们感觉效果都差不多，可能都是互相借鉴出来的那为什么。",
      "speaker": "发言人4"
    },
    {
      "time": "00:02:26",
      "text": "最近感觉是苏宁是最火的呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:29",
      "text": "我的推断第一点，酥糯他是最胆大的，他首先敢发布他们的AI生成音乐的模型，像其他大公司，比如说facebook、google，其实我们的技术肯定是遥遥领先的。但是我们有很多的考虑，除了说把这个技术把它给发布出去，还要考虑它可能会对社会造成的影响。尤其音乐，它是一个不像文字或图像，它的版权问题其实是一个非常敏感的一个话题。如果你有海量的数据，假如说你把世界上所有的歌都用来训练一个模型，那它肯定是能够做出一个很好的效果。但是他就会可能面临很多的法律问题，甚至说你把这整个音乐产业的格局改变了，蛋糕就这么大。最后怎么去分跟唱片公司、出版商去分钱。这些问题如果没有想清楚的话，后果可能不堪设想。所以我就认为苏诺他胆子是最大的，所以他先把这个模型先公诸于众，我们就静观其变，看一下他们会怎么发展。",
      "speaker": "发言人4"
    },
    {
      "time": "00:03:35",
      "text": "听起来很危险，其实不是技术问题是版权问题，大家还没有把全部的劲儿给使上。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:42",
      "text": "对对对，是的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:03:43",
      "text": "对。接下来我们听一听测试的效果，大家先有一个直观的感受，然后我们看看现阶段这些文字生成音乐的模型发展到了一个什么样的阶段了。因为冯老师我知道你在自己的youtube上其实已经发过了两次，可以说是sono的一些测试的分享。今天你给硅谷101的听众们也做一个现场的测试。我其实自己也玩过一下，就是让它生成一些什么求职的音乐、失恋的音乐、悲伤的音乐、说唱乐摇滚乐。但是因为我们就是小白，就是图个一乐，所以今天您的生成我希望是尽可能专业的，有难度的，然后我们来挑战一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:23",
      "text": "好的，没问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:04:25",
      "text": "好，那我们开始我也可以帮你出一些题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:29",
      "text": "可以，没问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:04:30",
      "text": "因为我现在发现它的生成音乐都是非常欢快的，然后它的调度非常的普通。我今天试了几次让他生成摇滚乐，但是我失败了。他最后生成的那个音乐不是特别的摇滚，所以我想要生成比如说比较悲伤的摇滚乐，你可以在一些专业方面再加一些限定。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:51",
      "text": "OK，那我试一试OK，然后歌词就让他自己写。因为实话说他歌词就是OpenAI的那个东西，所以让自己写就行了。好的，然后比如说sad story.",
      "speaker": "发言人3"
    },
    {
      "time": "00:05:04",
      "text": "对。",
      "speaker": "发言人4"
    },
    {
      "time": "00:05:05",
      "text": "style of music，那就rock就可以了。还需要有其他更具体的吗？",
      "speaker": "发言人3"
    },
    {
      "time": "00:05:11",
      "text": "我们再给他限定一下主题。比如说限定找不着工作，或者就是工作没有收到面试OK对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:17",
      "text": "看能不能再限定一下他用的乐器，或者说什么年代的摇滚，80年代还是90年代，OK OKOKOK classic rock之类的。比如说BPM什么，看能不能他能不能理解，多几个角度。",
      "speaker": "发言人4"
    },
    {
      "time": "00:05:30",
      "text": "BPM因为悲伤一点，可以给它显得慢一点，比如说80，然后乐器的话我们规定一下有吉他、贝joong keyboard，然后rock classic rock OK。好，现在这个歌出来了，我们来尝试一下。先看看第一版。",
      "speaker": "发言人3"
    },
    {
      "time": "00:05:53",
      "text": "这个生成速度真是很快。",
      "speaker": "发言人4"
    },
    {
      "time": "00:05:55",
      "text": "对，是的，我来试一下。",
      "speaker": "发言人3"
    },
    {
      "time": "00:05:57",
      "text": "struggling the shadows.",
      "speaker": "发言人4"
    },
    {
      "time": "00:05:59",
      "text": "他取了一个名字。是的，这个名字取的还比较有艺术感。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:19",
      "text": "Welcome back to the world making.",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:34",
      "text": "But all I see is done this.",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:44",
      "text": "I send out right to me.",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:05",
      "text": "Can find my way.",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:30",
      "text": "OK大概是这么一个感觉，我觉得从它生成词来说，它的词肯定跟我的主题是符合的。但是从音乐的角度来说，首先比如说它这个词，咱们当时输入指令的时候需要有一个set story。但是他的音乐当中，实话说我没有听出太多的态度，就是他音乐本身所以就是在一个average level的一个曲子，他可以符合我们的要求。它有一个rock，至少说是这个意思。80BPM没有测，但是我感觉可能应该是比他快，肯定是要比80要快。所以我估计他的BPM不知道是不是因为我们写在这儿了，但是他应该不是很能理解这个问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:08:09",
      "text": "作为曲子本身，因为我之前测试了很多中文的歌曲，我觉得英文歌曲和中文歌曲比，可能英文歌曲还是稍微的更成熟一点，就是它对文字的理解转换成音乐要更成熟一点。但是就音乐本身而言，从摇滚乐的结构上来说，比如说它两个verse，咱们就中文叫主歌，然后后面course是副歌，感觉他从主歌到副歌之间是缺少一个递进的，缺少一个推进的。我们可以听他的主歌，然后直接就进了副歌。无论是从器乐上向上的一个英文管的叫build up对吧？就是中文没有一个完全相关的词儿，就是缺少一个往上推，就是我到了高潮之前我总得有一个攒，然后爆发的这个过程，它缺少最后这一推。",
      "speaker": "发言人3"
    },
    {
      "time": "00:08:52",
      "text": "相反他倒是在两个主歌之间进行了一个小小的区分，它有比较好的一个间奏。所以我觉得相较而言，如果是人类来做这个歌的话，可能主歌和主歌之间的情绪上的变化不会那么大。但是主歌和副歌上的情绪一定是变化会更大一些。",
      "speaker": "发言人3"
    },
    {
      "time": "00:09:09",
      "text": "然后同时稍微说的玄学一点，我自己其实在做音乐上不是一个特别玄学的人我认为一切东西其实都是可以在某些程度上被解释的，或者可以我们抓取特征然后来去阐述它。但是在这儿咱直观的说一些稍微的玄学的，就是我觉得这个歌和真人作曲比，最大的问题是它缺少一个态度。或者换句话来说，更深一层的意思就是我缺乏一个写作的动机。比如说我要是一个真人，我想写这一首歌，那么我一定是有一些我具体的原因在里面的。比如说我找不着这个工作，所以我很沮丧，那么可能你这个歌听起来就会更丧一点。或者我可能因为找不到工作，然后我觉得是因为什么原因，所以我很愤怒。可能这个歌本身无论演唱的方式还是他的音乐本身就要更愤怒一些。",
      "speaker": "发言人3"
    },
    {
      "time": "00:09:58",
      "text": "这个生成的音乐，包括我之前测试给我的感觉，就是它可以满足我的基本需求。我的所有文字描述可以有，但是具体把它在音乐作曲和编曲当中，怎么能体现人类的那种情感。目前我的测试结果表明，他音乐暂时还没有做到。为什么？我觉得这个很重要。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:17",
      "text": "我们可能听到的很多流行歌也好，或者这些摇滚其实已经不完全是流行音乐了，他的音乐分类会更加的特殊一点，它是一个专门的一个音乐分类了。但是很多音乐或者说之所以经典的音乐它可以流传下来，其实更多的是因为它承载的人文和它体现的态度，所带给的所有人的共鸣。我们觉得我们可以带入到这个歌的情绪里面。所以有一万首摇滚的歌，可能有那三首就成了传世的佳作，大概是这么一个意思。但是目前AI的这个至少咱们测试出来的这个结果，它缺乏的是最终的那个让我们能感觉到共鸣的态度。所以他可能能够写出来，但是很难在行业里面出类拔萃。因此在这个程度上来说，他还没有完全的能够代替人类作曲家的这种情感。",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:08",
      "text": "讲的非常好，但是你觉得他到达了人类的一个平均水平吗？我问这个问题是因为我觉得你刚刚提到了有一万首摇滚，然后有三首是特别出类拔萃的那其实我们看人类作曲，他要表达一个情绪，一个共鸣，包括像我们创作者要去做一个爆款，他其实是首先是需要积淀的，其次它也有一点玄学跟运气的成分在里面，就他能不能红？如果我们去对比现在在整个音乐圈作曲的一个平均水平，你觉得他达到了吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:42",
      "text": "我觉得可以说差不多，但是问题在音乐界，平均水平这个事儿看你怎么来看待。比如说我有一万首歌，然后咱大概做个排名，那么我抽他第4000首到6000首，这个中间的这个水平跟他去比可能差不多。这个我觉得他是可以达到的。因为人类我们写歌的时候有很多比如初学者在写歌，或者他可能刚开始的技术没有那么精进，所以也有很多水平不是很好的作品，这个都很正常。每个人都有成长的过程，AI其实也是。但是问题就在于在音乐这个产业当中，你的平均水平可能不足以在音乐当中出挑。也就是说你说人类的我们能够想到的经典的，咱就说摇滚乐。",
      "speaker": "发言人3"
    },
    {
      "time": "00:12:27",
      "text": "从历史到今天，我们每个人脑子里能有印象的，连主题带歌曲名带，能唱出来的，说每个人咱能说出100首吗？我觉得未必。真的那些能靠它吃饭的，能靠它成为一个专业的，说我是靠演乐队这个曲子，我能活且能活得很好的，对吧？咱能迅速说出100首或者两百首歌吗？我觉得顶多200首普通人也就这样了，就是我愿意去买票，我花钱去听我有这个level的也就这样了。可能剩下那999或者什么几九万手、9000万手，可能它是也高于平均水平。但是它不足以成为这个工业当中出类拔萃，能养活自己的一个专业的一个水准。我觉得公平的说它可以达到平均。",
      "speaker": "发言人3"
    },
    {
      "time": "00:13:10",
      "text": "但是在实际应用当中，它真的投产到这个音乐产业里，他能不能作为好的摇滚乐生存下去，这个是一个疑问。但是我在有很多方面我对这个音乐的要求没那么高。比如说我现在可能做一个短视频，然后我就需要有一个摇滚类的风格的音乐，然后来给我作为一个铺垫。它就是一个背景音乐，我也不需要它出类拔萃，我不需要所有人都记住它。在这种情况下，我认为现在的AI已经可以达到这个作用了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:13:38",
      "text": "我对他的观感是这样的，它有一个优势就在于现在其实很多小制作的，主要是影视这方面，它其实是可以从很多的棉半卷的音乐当中去做的。就是现在已经有这些很大量的免版权的音乐库。那么AI和免版权的音乐库相较而言，它的定制的性能会更好一些，或者可能会好很多。因为比如说我想生产一个，比如我今天晚饭相关的这么一首歌，你要在免版权库里面找到一个类似主题的，说我就要说今天的晚饭，或者我今天就想说我是北京人，就爱想说今天我吃了一碗炸酱面。就这个事儿的话，你很难在免版权的这个库里面找到这么贴合，这么实际跟它直接相关的音乐。目前的AI可以解决这个问题，但是也仅限于此。而且还是说我们目前它投入成产品，然后出来以后，本身免版权的音乐它能挣多少钱？它在这个工业当中它的经济利益有多大，这个是一个问题。AI取代的这部分OK确实是好一些。但是从不同的要求，不同的层级来看。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:39",
      "text": "还是有不同的需求的。讲的非常好。刚刚其实我们还有一些细节的问题，你说你写了80BPM，它是没有办法理解的。这个指标是什么？",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:50",
      "text": "他就是八十拍每分钟，就是我们取的这一个速度就是1234。这我们数拍子，80拍每分钟是我们对他一个要求。而速度这个东西，其实在音乐当中可能是最重要的。我同样一首歌，你把它速度放慢2到3倍，本来是很欢快的歌。你把它放慢2倍到2倍半，可能它就变成了一首悲伤的歌。本来是一个悲伤的歌，你把它加快个两三倍，它就会变成一个很快乐的歌。这个其实之前是有一个电影，我印象中大万里中间好像有这么一个桥段，就是他本来是个哀乐，然后就是说我们现在这太矮了，我们得弄快一点，然后再把哀乐两变成了两倍，然后就发现跟我们听的什么金蛇狂舞这大个的这个节日的歌就差不多了。有很多这些具体的细节，我觉得AI可能暂时还没法，至少从目前我测试的结果来看，暂时还没法控。我相信他可能有这个方式能控，但是我不知道是他的，这可能Roger可能可以帮我更好的适宜一点，为什么他暂时没有在细节上能够有更多的把控？",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:48",
      "text": "对这个问题我也非常想问Roger，首先为什么他没有办法去理解80BPM？其次为什么我们觉得他还不够悲伤？他是不能理解悲伤的意思，还是说现在他的生成的方式是做到的？",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:00",
      "text": "OK我就接着冯老师刚刚讲的，从技术角度再解读一下。其实冯老师刚才说了好几个点，一个点就是说这个音乐它能够加一万首歌，可能排到后7800千这样。它达不到头部的这种音乐小姐。这音乐产业它就是一个head heavy的一个产业，它有个非常long tail，它这个只能在尾部当炮灰的音乐。",
      "speaker": "发言人4"
    },
    {
      "time": "00:16:25",
      "text": "那这个音乐为什么它会产生这样的效果？其实跟它大模型它的训练数据是有关系的。就是你就想，你要训练这样一个模型，你需要收集什么样的数据，你需要有文字跟音频的这种配对。你要告诉这个模型，这首歌它是一个悲伤的classic rock，另外一首歌是一个史诗的弦乐。看你需要有这样的标记，把它扔到这模型里面去，他才能去学到现在业界的这些数据库其实是什么呢？",
      "speaker": "发言人4"
    },
    {
      "time": "00:16:57",
      "text": "其实就是我们刚刚说的这些免版权的音乐库。这些realty free music，比如说shutter stock music，还叫什么ponder five，他们那种你可以交个年费，然后你就可以用他们音乐了。或者说每首歌花个30块钱，可以用在一个视频广用的这种场景。他们的音乐库就不只是说把音频文件放上去，还有很多mad data，每一首音乐它都有一个简单的描述。我们可以打开那个网站，你就简单看一下就可以知道。就是说每首歌它都有一个大概二十几个字的一个描述。",
      "speaker": "发言人4"
    },
    {
      "time": "00:17:30",
      "text": "在我们刚才我们去输入，比如说我们叫一个悲伤的音乐，从统计学来讲，它就会从它的训练数据中学到一些悲伤音乐大概对应的是怎么样的音频。就是悲伤这个词sad或者是其他的什么描述悲伤的词，都可以对应到某一些音频的一些抽象出来的一些表达。它肯定不是把音频直接copy出来，它是会进行一些自我的location或什么。总之它会排列组合出一些跟原来不一样的东西。这些就是我们刚听到的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:18:01",
      "text": "所以他从本质上来讲，他的训练数据就不是头部的音乐。所以他也不指望说自己能够生成Taylor swift级别的那种很高品质的。他觉得我说说这个跟shat stock的这种免版权音乐效果好像差不多。那么从模型的学习角度讲，他就达到任务了。所以他们会认为这个模型的训练是成功的，这个就是为什么这个音乐它不是很出彩。",
      "speaker": "发言人4"
    },
    {
      "time": "00:18:27",
      "text": "第二点是说我们听着音乐感觉它这个build up，比如说有个worse 1 corus，感觉worse 1到worse one。好像有一个很明显的transition到verse two到cos中间的过渡就很突然，这个是为什么呢？我们人类在作曲的时候，通常是一个从top down，从高到低的一个逻辑。就是说你先去想，我这首歌是个AABA form对吧？或者是交响乐几个movement。",
      "speaker": "发言人4"
    },
    {
      "time": "00:18:59",
      "text": "先从一个很大的框架去界定我要做一个什么样的流派，就是什么样的大的框架。再在每个框架里面去定这个verse我要一个什么样的和弦进行，cos要一个什么样的和弦进行。然后再去想这个worse的配器可能要稍微安静一点，covers要稍微吵一点，这是一个从高到低的一个逻辑顺序。但是我们这个大元模型它是什么顺序？其实我们大家都用过拆gdpr，他在回答问题的时候都是一个从左到右的顺序。",
      "speaker": "发言人4"
    },
    {
      "time": "00:19:31",
      "text": "你让他去做一个悲伤的摇滚，他就是先把第一秒做出来，然后做第二秒，做第三秒，他没有一个全局观。所以就导致什么呢？他在做的时候OK我们现在在worse 1，他可能这个worse一它有一个限定，我们在worse一的这个状态里面做着做着，突然这个歌词你的输入数据有一个方括号worse two，他不行了，下一秒我得赶紧进worse two了。那就怎么办？",
      "speaker": "发言人4"
    },
    {
      "time": "00:19:57",
      "text": "那就赶紧看一下有没有什么办法，在这个拍子上就进去好了，就是选一个从统计意义上来讲，一个最自然的方式就进去了。然后他就是走一步算一步走一步算一步，所以就是有一种什么感觉呢？就是没有大局观，有的时候就会很突然的去变。甚至有时候比如说我们生成了八句的歌词，我们会期待说每个小节唱一句，他可能有时候一个小节唱了两句就少了一句怎么办？那就只好就强行的就一句没了，直接加点鼓就进下一个再审了。这些就是build up的一些问题。",
      "speaker": "发言人4"
    },
    {
      "time": "00:20:31",
      "text": "然后一个问题就是说这个歌词它的灵魂，这个其实怎么说呢？也不能怪苏努的模型，因为毕竟他们也是用别人的文字生成的模型。假如说你让PPT去写一个关于找不到工作的歌词，他可能也就写成这个样子。他至少能够表达出我主题是对的，押韵这些东西是可以达到的。但是你具体说灵魂什么的，其实它就是根据互联网上的这么千万篇文章把它给抽象出来的。大部分东西都是没有灵魂的，所以这个就是一个AI的一个问题。我觉得这也是人类可以打败AI的一个关键的一个突破点。",
      "speaker": "发言人4"
    },
    {
      "time": "00:21:13",
      "text": "至于BPM为什么理解不了，其实这一点我是很诧异的。因为在训练书里面，我也看过他们的训练书里面确实是每一首歌BBM都标记好的。但是至于他有没有用到这个信息，可能他没有用到，我只能说他觉得这个信息至少在目前不易碎的版本里面不重要。可能以后他们会逐渐的加速更多的这种限制性的条件。我只能说技术上这是一个很好解决的问题，只是为什么没有解决，是一个让我诧异的点。",
      "speaker": "发言人4"
    },
    {
      "time": "00:21:42",
      "text": "可能就是说BPM这个事情，他现在没有把它放在他的优先级里面。如果放在优先级里面，他们在算法上去做一些调整，或者给他加权重，这个事情最终是可以被解决的。是的，刚刚你说的，其实我还有几个部分的疑问，冯老师其实提到了，现在整个音乐最大的问题是他没有表现出歌曲的情绪，没有表达出大家的共鸣。其实你的答案，我想你的一部分是想说，是因为我们交给他的训练数据都是版权库的音乐，这个是非常的平均水平的那我假设它不是说技术上不允许，他只是说版权上跟伦理上可能不允许我们把像Taylor swift还有历史上经典的这些摇滚乐，什么queens、cold play这些非常经典的歌曲拿过去训练。是不是说AI也能做出类似于这些经典歌曲的歌曲？",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:35",
      "text": "是的，确实就是只要训练数据足够优秀就可以。但是训练数据不只是音频本身。假如说你把spotify的歌全部都下载下来，如果你没有对他进行适当的描述的话，他也不知道去学什么。你必须要告诉他这个扣play的这个yellow是一首什么样的歌。下次他看到同样的描述的时候，他就知道要是那个跟yellow类似的歌出来。",
      "speaker": "发言人4"
    },
    {
      "time": "00:22:58",
      "text": "但是如果他生成了一个跟yellow非常类似的歌，声音还是用cosplay唱的，这个就是侵权了，对不对？",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:07",
      "text": "对，除非可能以后跟音乐人达到一种和解，音乐人可能发现这个已经没办法再控制，潘多拉的魔盒已经打开了，没办法收回去了。那他们就只能你生存就生存，只要给我钱就好了，可能以后就会是一个这种情况。",
      "speaker": "发言人4"
    },
    {
      "time": "00:23:21",
      "text": "对，但至少我们现在来看，音乐人的版权库，仅仅是用他的这个训练数据都是不行的。现在这个在业界里面还是被禁止的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:31",
      "text": "是的，现在专门有一个组织叫做fairly trained。凡是一个民间组织，他反正也盯上苏诺了，他们会不断的去看，他们prop出来跟版权音乐很相像的东西。如果做出来，那可能就可以去告他。",
      "speaker": "发言人4"
    },
    {
      "time": "00:23:47",
      "text": "关于历史上一些非常经典的交响曲，他们的版权保护是怎么样的。我印象中有一个public domain好像是有一些曲子，它的版权是50年.",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:00",
      "text": "应该是作曲家去世后70年.",
      "speaker": "发言人4"
    },
    {
      "time": "00:24:03",
      "text": "对吧？70年。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:04",
      "text": "对，但是他是那个谱子本身是免版权的，可是你那个谱子最终还要找人录。比如说纽约爱乐录了以后，那它纽约爱乐对于他这个录音本身还是有版权的，只不过就这个谱子你谁都能演，就是这个区别。所以如果你最终训练的话，除非他可以做到用图像来训练声音，那么这个是有可能的。这样的话他版权可能更那什么一点。如果他还是用声音训练声音的话，那些录这些曲子的将乐团就这些组织，他们依然还是拥有这个版权。所以它其实还是属于版权性质的东西。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:39",
      "text": "理解就是说这个软件可以用一些合成数据。我们先把这些曲谱让电脑自己录成声音，然后再用这个合成的录制的声音去训练这个大模型，这样子做是可以的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:54",
      "text": "从版权上说是可以的。但是这样做我的一个忧虑就是他可能在作曲上，我感觉可能出来的效果未必特别好。原因是现在哪怕在我们音乐行业，我的作曲软件的模拟声音的程度都不是特别的令大家满意。我们最好的这些什么电影音乐那个的还是需要找真人去录。是因为你本身对于这个音色，各个方面的演奏的具体的方法。比如说一个小提琴，它可能能发出什么拨弦，什么揉弦，它可能发出很多种十几种的这种不同的声音。那么在演奏当中这些细节，目前为止音乐软件，就我们作曲的这些软件还达不到。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:34",
      "text": "如果你要花大量时间去调每一首曲子的这个东西的话，我觉得可能某些方面来讲更费时间，对吧？你每一个乐器都要调的，你小军鼓滚奏怎么打？然后什么什么定音鼓，什么长号怎么吹，怎么出气，那个它都是有很多问题的。因为你最后目前来看，它这个软件目前都是端到端的。就是我给它输入一个指令，他最后给我生成的是音乐，而不是说他给我生成乐谱。如果他要生成乐谱的话，可能这方面的劣势是可能没有那么明显。但是如果你要直接给我生成音乐的话，你音色本身和演奏方法就是非常重要的。你同样一个音乐水平高的和水平低的演出来，我们本身观众听着就已经不一样了。那么你AI这方面如果要是是个大的劣势的话，那么对他来说困难其实也。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:15",
      "text": "蛮大的那刚刚我们提到的这一部分非常经典的乐曲，就是在作者本人去世以后的70年，这一部分乐曲是可以用的。这样的一个数据库大吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:26",
      "text": "从古典音乐来说还可以。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:28",
      "text": "对唱片行业应该是50年代才发展起来的。所以你这么算下来的话，也就是2020年的时候，最早的时候像猫王，再早一点的一些爵士乐的。先驱一点的可能会有一些录音，但是他们首先音质很差，你用那些录出来的也不符合现在的我们的审美标准。所以可能再等个70年，等到我现在应该可以用了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:26:53",
      "text": "古典乐古典。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:54",
      "text": "乐曲的是足够多的对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:56",
      "text": "曲子足够多，但是录音不够。对。",
      "speaker": "发言人4"
    },
    {
      "time": "00:26:59",
      "text": "那我们接下来测试一下古典乐，我们刚刚测试的是一个歌曲。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:03",
      "text": "摇滚乐可以没问题。然后我们这回用instrumental，我尝试着规定一下它的乐器。因为咱们都用器乐了，看看它可不可以有好的写的，是希望它生成一个交响乐团英雄为主题的。大家如果交响乐爱好者的话，可以猜一下我这是从哪儿来的。乐曲规定的是弦乐木管铜管打雀里有定音鼓，然后还有其他的打觉，这个应该还是比较常见的一些配置，大概是这种感觉。然后我们生成一下试一试。好，我们来试一试第一首曲子。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:42",
      "text": "OK, 我觉得其实这差不多了。我们来听一听第二首。因为它有的时候两首可能生成完了以后差别还挺大的，听听他第二首生出来啥样。",
      "speaker": "发言人3"
    },
    {
      "time": "00:29:27",
      "text": "OK, 我觉得可以了，我觉得相较而言，第二首比第一首听起来更加像英雄一些，同时第二首比第一首听起来稍微的更像交响乐一点。但是大家可能第一个观感可能和我差不多，就是我听到他们都觉得像电影配乐，比如说任何的描写英雄的电影，然后给他们做这个配乐，气氛上是差不多的，和真正的这个交响乐可能还差一点。要不我再尝试一下，咱再生成一下，我把这个写一下classical，我稍微标一下时间，然后我再写一下18世纪，写19，18有点太早了，因为这个可能会更详细一些。OK然后咱们再来生成一下试一试OK好，确实速度很快，速度惊人。然后我们来看一看它这个19世纪的降雨。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:54",
      "text": "OK这个要规定了时间以后，确实比之前那个要好很多。但是这个手里面，我反正目前肯定是没有听到任何的跟打击相关的或者什么定音鼓这些的。主要还是低音的弦乐，它主要是弦乐为主，木管和铜管至少他要用的话也是混在一起的感觉。音色上也不是特别听得出来，它比之前相对来说更接近于古典音乐。是因为它音乐的旋律的写作上面以及它的律动上面，整体的不像之前那个重复性那么高，之前是律动一直是重复的，然后它的旋律大部分的形式也是重复的，只不过有一点高低，所以更像电影音乐。然后19世纪的这个生成以后，稍微有一点动机慢慢发展，就是有点这个感觉了。但是距离真正交响乐的形式可能还差的会多一些。当然我相信如果我给他写的更加详细的提示词的话，可能它生产效果会稍微更好一点。但是从写作水平上来说，目前大概是这个状态。",
      "speaker": "发言人3"
    },
    {
      "time": "00:32:49",
      "text": "我印象中这个写作水平比你最开始就是你在你的视频demo里面测试的那个写作水平好像已经提高很多了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:57",
      "text": "对，但是他有这个问题，就是我生成的那这个里面也有一些还可以的，它就有点类似于抓彩票。比如说像这个里面它的音乐写作的水平要好一些。但是我期间对它比较重要的这些乐器的要求，它其实反而没有达到。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:12",
      "text": "理解。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:13",
      "text": "对，所以如果我是一个甲方，那么我给他要求乙方做这个工作的话，我会认为乙方没有达到我的要求。因为有一些硬性的规定他暂时还没有做到。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:23",
      "text": "你有可能把这个曲子拿出来分声部，然后你自己再添加一些乐器进去，把它改成一个按照你的提示词，甲方能接受的一个音乐水准吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:34",
      "text": "有可能，但是那个工作量其实也蛮大的这是有可能的。所以现在大家经常会开玩笑说，拿他给自己找灵感比较合适。就是AI写了一段音乐，我抓住这四五个小节或者什么，我拿它作为一个我写作主要的音乐里叫动机。我们可能叫一个小的主题，还是英文叫motive。然后我拿它拓展成一个很大的交响乐，这个是可以的。但是如果靠它直接生成作品的话，反正目前这个测试的结果和交响乐的差距还是蛮大的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:03",
      "text": "总体上你给他打多少分？",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:05",
      "text": "总体上十分的话，我觉得看从哪个方向来说。他因为毕竟没有达到我的对他乐器上的要求，所以我可能给他五分。他的写作听感上来说，我觉得可以有七分6到7分左右，这个状况就至少听起来很像了。但是如果我要是做一个要求到要求来说的话，那我可能觉得他不到6分就是不及格。因为硬性的一些标准他没有达到。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:28",
      "text": "那Roger你怎么看？他可能miss掉了我们一些要求他使用的乐器。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:34",
      "text": "对我可以从我角度来评判一下。首先第一点，为什么第一次我们生成的特别像电影配乐。第二是好像我们加了eighteen century还是什么的，好像效果会好很多。",
      "speaker": "发言人4"
    },
    {
      "time": "00:34:46",
      "text": "这个其实又回归到训练数据这个问题。我看了一下他们训练书一集，刚才他们有两类弦乐的流派，它其实有两种不同的标签。像对这种古代的古典音乐，就是那种大师级别，它专门有一个流派叫做master works，它都不叫什么orchestra或者叫什么strings。可能他在理解上，你必须得给他一个他能理解的这个词，他才能对应到。他知道我要从那个角度去推理出这个音乐出来。如果你给的是像orchestra或者procuration，其实这些经常出现在他们因为这个训练续集有一些巨大的给电影配乐的音乐，他就很容易去匹配到那块儿上去。所以可能这有一个提示，就是说如果我们想生成好的音乐，需要去研究一下它的数据集是怎么标的，可以从里面找到一些灵感。",
      "speaker": "发言人4"
    },
    {
      "time": "00:35:41",
      "text": "第二点就是说为什么我们要求的乐器它没有办法完全的重复出来。比如说我们要求的这个木管和铜管乐。但他好像混在一起也听不出来到底是个什么鬼。",
      "speaker": "发言人4"
    },
    {
      "time": "00:35:54",
      "text": "其实原因就是什么呢？就是他在生存的过程中，他并不是一个乐器，一个乐生成的这个大模型。他听了很多的录音之后，他大概抽象出来，音乐是有很多的很小段的音频的基本元素，把它给拼凑出来的。他的一些排列组合可以排列出一个人类称为音乐的东西。所以他就去学了做这样一件事情，他并不知道什么叫铜管，什么叫木管。他就知道，你告诉我这个首歌features would wind and brass。他就是听起来是这个样子的那我就去学，只要大概听起来这样子的东西，那我就是满足我的要求的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:36:35",
      "text": "所以我觉得可能以后的发展方向是一方面在声源分离这个技术上也越来越成熟。就是说人们可以把这些现有的录音，把它给一轨的stem，把它全部分离出来，然后再单独的去训练。这样可能会对每一种乐器理解会更深入一些。至少现在他们毕竟很赶着上线，所以不能指望太多。",
      "speaker": "发言人4"
    },
    {
      "time": "00:36:56",
      "text": "然后说到刚才最后一点，就是给音乐人找灵感，这个还是可以。但是现在怎么说呢？现在它只支持一种输入方式，就是文字的输入。其实同样一套架构可以也去支持这种音频书。",
      "speaker": "发言人4"
    },
    {
      "time": "00:37:10",
      "text": "假如你可以去输入一首classical music，找一个莫扎特的音乐输进去，然后你说我要加点电子鼓进去，然后让他看他生成成什么样子。可能这就是一种对音乐人来讲可能更有用的一种东西。但现在它是一个非常大众化的。它假设你的用户是完全不懂音乐的，只知道文字输入。那么现在它可能是一个从商业化角度讲是一个比较成功的一条路。再往后我会相信会有很多的别的公司去尝试这种精分市场，针对音乐人能够发布一些更好的产品。",
      "speaker": "发言人4"
    },
    {
      "time": "00:37:43",
      "text": "对，那冯老师从你自己来看，你看到sono这个产品你是兴奋还是恐慌，还是觉得测试一下就那样。其实我是想知道音乐人他的心里是欢迎这类产品的，还是说是有一点点抵触情绪在里面的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:59",
      "text": "首先说我肯定不能代表所有音乐人，所以我只能代表我自己。所以音乐人这个群体他到底怎么一个想法，我是知道前些日子纽约那边好像有二百多个艺术家联名要抵制AI这个事儿其实已经出来了，是个新所以可以看到它确实对我们行业是有一定的冲击的。我自己整体的态度是谨慎乐观。就是我觉得第一就是我们没法抗拒这个洪流，就是历史发展就是必然。它的工业化的程度是一定能够解放人类的生产力的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:31",
      "text": "说的有点玄乎了，但是细节上就是说我现在写一首曲子，我可能需要有一个很好的一个主意，一个idea。然后我需要花很长的时间把它写成一首曲子谱出来，然后再花很长的时间去录出来，然后这个project这个项目才能完成。现在有了这个AI以后，可能可以迅速的提高我这个速度。作曲家能有更多的时间真的去想这个曲子，而不用担心那些细枝末节的东西等等。就包括一些低成本的这些音乐制作，然后我觉得他真的是可以的，非常好的，很有发展前景。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:03",
      "text": "但是同时我对这个事儿也不是特别的恐慌，是在于像之前rather咱们聊的时候也是这个原因，就是人类还是有一些自己独特的一些特性。目前AI至少说它的模型这个算法可能暂时做不到。当然它未来你有可能是几个模型一起混。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:19",
      "text": "比如说我知道的就是小样本，它怎么能够提高他学习的效率，这个是一个很大的问题。包括它的逻辑推导性，就至少目前这个AI我知道程序员以前符号主义他们可能逻辑更那什么一点。但是现在的这个AI就是它不是以一个逻辑推导为思考方式的这么一个东西。但是很多的音乐其实它是有很严谨的明确的逻辑在里面的。如果我不能从这个方式去思考的话，那我只能是去他模仿一个形式。但是人类的真正的思考的能力，以及我们2000年来攒下来的有迹可循的这些文化上的积淀。人类也不是说我就出生以后，我从零开始就自己研究所有的事儿。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:00",
      "text": "人类的这个发展？音乐领域上来说至少也得有2000年左右，至少说1000年肯定没问题。所以我也是有之前1000年技术积累的，人类也是在这个程度上持续在发展的，还是有一定的优势的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:12",
      "text": "我觉得目前就我的视角来看，除非AI可以跨越它现在基于统计学的这么一个壁垒。因为现在咱说统计学这个事儿，我感觉还不是一个纯纯粹粹的智能，它更多的是一个统计。比如有很多人说阿尔法狗像这种东西，它可以很快取代人类。是的，因为他目的明确，他就是算自己那个棋，他只要有足够多的演算，他能算到最终我一个目的要赢就可以了。他用大量的数据算出最佳路径，算概率可以，但是音乐产生没有一个说我唯一的路径或者我要赢要怎么样，它太分散了。所以除非人工智能真的发展出了智能，他有自己的意识，他有创作的原因，他有这个情绪，有创作的动力，那么人类可能才会真正的受到威胁。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:59",
      "text": "就作为一个整个行业，当然个人可能已经有人会受到威胁了，这个我认为是的。但是整个这个行业所取代人类的话，我觉得我不担心。因为当它出现智能的时候，且不关我们学音乐的事儿，其他行业的危险性更大，或者整个人类的危险性，它真的有自主意识的话，那是整个人类的危险，那就不是我们音乐行业自己孤军奋战的问题了。而且我相信在出现这个事儿以前，人类一定会用自己的法律和我们的道德等等去规范它，去约束他。我们是在一个框架下去相对安全的去发展的。所以我对他是保持谨慎的乐观，我觉得他是一定会对我们是有帮助的，我们没法抗拒，但是距离对我们有足够的威胁。完全取代我们那个路非常的长。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:44",
      "text": "然后我注意到现在我们用苏诺他的生成，它的英文就是你刚刚生成的几个。我觉得他的英文的生成效果是要明显好于中文的。今天听众们听到冯老师生成的这两首歌，我觉得还是属于水准非常高。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:00",
      "text": "好的，如果去听一下我自己生成的歌曲，如果大家需要的话，我也可以放一下非常的口水歌，感觉非常的普通。所以开始为什么？就是我在出题目的时候，我说我希望能够加上悲伤的。就是因为我发现我即使给他一个非常失恋的场景，要写的非常的自嘲难受，他都会给我整的非常的欢快。还有一部分就是我不知道为什么中文他的歌曲的生成会比英文整体听起来更加的口水歌一点。这个是因为训练数据集的问题吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:32",
      "text": "对我觉得具体的生成质量肯定是用训练数据集来解释是比较好的。因为理论上从模型角度来讲，英文和中文并没有本质的区别。高兴和悲伤也不会导致你用两套不同的模型去胜任。可能免版权音乐他们就是偏向于欢快的。因为你要用在广告里面，很少人会用很悲伤的音乐，可能他就会有一个buyers在这里面。",
      "speaker": "发言人4"
    },
    {
      "time": "00:42:57",
      "text": "理解，刚刚其实冯老师因也提到了，有一个是非常有逻辑的，比较难的那种音乐。我看之前您在那个视频里面有尝试做赋格的生成，现在有生成成功吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:10",
      "text": "有的听起来比较像。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:11",
      "text": "我们听一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:12",
      "text": "可以，我们想试一下吗？用这个生成一下。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:15",
      "text": "好，试一下。可以，你要不要再试？以前先跟大家讲一下什么是副歌，然后给大家播放一个历史上比较标准的这种副歌的音乐作品。然后我们再对比一下，听一下AI生成的副歌。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:27",
      "text": "可以副歌其实它是一种作曲的形式，更确切的说它其实是用对位法的方式来作曲。我们现在大部分流行歌曲是这么一个规则，就是我上面生成一旋律，然后底下我再给它配和弦，是这么一个对比。但是副歌它其实不是考虑的副格，它是考虑的比如每两个音之间的关系，这两个音如果要是和谐的话，下面怎么发展到不和谐，然后怎么从不和谐怎么再解决到和谐。所以它在副歌的写作当中会有很多非常严格的条条框框。比如说什么平行的三度不能超过三组，不能用平行的纯5纯8，就很理论化的一些东西。所以我觉得这个其实用逻辑的方式去写会更容易一些。如果你要是听这个副格的话，本身它可能只是听着比较的像一些，这是其中之一。",
      "speaker": "发言人3"
    },
    {
      "time": "00:44:15",
      "text": "另外就是在副歌写作当中，它有一个刚上来有一个主题，我们管这个英文叫subject主题。然后同时另外一个声部会对它有一个回应，英文你们管它叫answer，有主题有回应，然后再用到我刚才说的对乐法，就是两个音之间关系的方式再去写这个音乐。然后中间还有其他一些变化的方式，从这就是它是一个很复杂很系统的创作的一个条条框框。说一句题外话，就是因为它的条条框框太严格了，所以副歌发展到一定阶段，这个音乐就被取代了，对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:44:48",
      "text": "所以为什么后来我们出了古典音乐，不是一直副格，从副格这么厉害这么好，为什么没从文艺复兴时期一直写到20世纪呢？为什么后来出了古典音乐？就是因为它对人的限制太严格了。那么你限制越严格，你可以创新的点就越少。所以写着写着大家就觉得这个音乐我需要再突破这个框框。所以大概是这么一个状况，我感觉russia应该很理解。",
      "speaker": "发言人3"
    },
    {
      "time": "00:45:09",
      "text": "刚刚我给你发了一个prompt托卡塔的那个，对，那个就是巴赫的东西。这个prom是训练数据集里面的prompt，就是长这样的。我想看一下，如果你就把这个输进去，它能不能就一个听起来很像巴赫的音，或者说跟原曲一模一样，会不会有这种效果出来？",
      "speaker": "发言人4"
    },
    {
      "time": "00:45:27",
      "text": "好，我们试一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:28",
      "text": "好，我们可以试一下。",
      "speaker": "发言人3"
    },
    {
      "time": "00:45:29",
      "text": "我们给听众念一下这个prompt.",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:32",
      "text": "我翻译成中文来念，因为大家可以看英文了，就是拖开。它和副格是D小调托卡塔与赋格，需要有阴暗一些，然后有戏剧性dramatic。它中间feature solo organ，是说的是用到的是管风琴的独奏，然后用到一个系列的很严肃的，而且很有力量感的这样一种感觉，是这个音乐的形式。好，来试一下。这个题目本身是巴赫的一个非常著名的曲子，他的可能是大家最熟悉的曲子。好，底下这个已经出来了。好，我们来试一试，给的是一个教堂的这个图片，教堂还是非常贴切。",
      "speaker": "发言人3"
    },
    {
      "time": "00:46:17",
      "text": "快放城出来了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:46:52",
      "text": "OK, 可以，我对他的感觉就是还是我之前的评价，他写的很像。如果你要是去听他这个感觉的话，可能会觉得跟原曲差不多。但是实际上它和原曲的差距其实还是非常明显的，尤其是听了原曲的话，大家会觉得首先巴赫在写这个的时候，刚上来有一我们听一耳朵。",
      "speaker": "发言人3"
    },
    {
      "time": "00:47:14",
      "text": "稍微听一耳朵。好，我们放一下原曲。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:29",
      "text": "OK我们就只说这几句。像刚上来的这种给人的这种震撼感，尤其是当你在教堂或者在一个比较广阔的空间听到这个的时候，就刚上来他这两句可能对我们来说是最震撼的。像这种东西它就不是一个平均数，它如果要是做成数集的话，它一定是在那个数集的范围之外的。像这种东西就是AI目前为止在这个训练的方式很难直接达到的。我其实最想说的就是这一点，就是你从刚上来的这个曲子的质量，就是说给人的第一个震撼其实差别就比较大的。然后再到后来，就是巴赫的曲子，它的各个声部之间我随便叨叨一个地方，咱们听一下，相对来说会比较清楚。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:44",
      "text": "OK, 所以你看我们这里面有几个比较明显的感觉，它其实是有两个声部互相呼应。第一个声部我先说一句话，第二个声部再重复他说一句话，这是副格写作非常明显的一个特征。同样一段旋律在不同的2到3个声部之间进行重复以及变奏。但是在重复变奏的过程当中，需要能让人听出来，它是同样的一句话产生出来的。这个在我们刚才生成的AI的音乐里面，声部之间的呼应和同样的这个主题它就不是很明显，应该说很不明显。所以如果我们要是去形容它的话，对我来说听起来就比较的糊，比较的年，所有的东西全在一起。你说它是不是管风琴的这个声音，是不是两个声部？是，但是它的主题性和严谨的逻辑之间，它是目前还没有的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:49:30",
      "text": "而且我觉得很有意思的是，你看其实你在youtube上搜巴赫的音乐，第一首出现的它是一个教堂的封面。刚刚在苏诺里面它也是一个教堂的封面。某种程度上它可能还是有在这个封面上去做一些借鉴的。应该是的，对我觉得这部分特别好。其实问这个问题，我更想了解的是我们做赋格的这种音乐类型的时候，因为你讲到了它的逻辑性非常的严谨，就是我在想他是不是反而是更适合ai因为你给AI一个公式，我不知道他现在的逻辑推理是怎么样的，它是更适合AI的，还是更不适合AI的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:04",
      "text": "其实对副歌研究在AI音乐领域还是有好多年历史了，哪怕是20年前、30年前，那个时候大部分人都拿着medi data，因为巴赫的这些乐谱在网上都很丰富，而且大家也知道这是一个逻辑性很强的音乐，他的两个声部之间的对位法这些东西都是在AI领域是很容易获得的数据，然后也很好建模。它其实就是一个比如说从左到右进行推理，再简单说这样，就在符号层面，它其实已经可以模拟的很好的。我相信肯定是有一些软件它可以生成这种midi的数据。就在复合这个领域，它可以生成的非常的逼真。包括把前面的这些motive，后面这些variation都给做得很好。",
      "speaker": "发言人4"
    },
    {
      "time": "00:50:51",
      "text": "但是在现在这个m to m的生成系统里面，suno这一套他肯定不是干这个用的。可能他在训练期只听过一首，所以你不能指望他能学到这里面的东西。如果你给他听了20首，可能他就能够学到点东西了。而且他能把这些里面的不同声部的不清晰的部分，它也能够把它搞得清晰一些。像这个领域是不同的AI可以做的更好的一个地方，就是更偏向于逻辑推理的AI会更好。",
      "speaker": "发言人4"
    },
    {
      "time": "00:51:21",
      "text": "Roger，其实我们刚刚在录播客前闲聊了一会儿，然后你之前也是学的跟音乐相关的音乐家ai音乐技术。对，音乐技术可以解释一下这个具体是学什么的吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:34",
      "text": "我们学的东西其实它是在double e computer science。音乐包括一些music production的这种东西，还有一些心理学、认知科学。因为我们认为音乐这一块，它毕竟是人类情感的语言，它就是一个文化传承的东西，它又是一个数学性很强的东西。所以我们认为把各种学科的知识都融在这些交叉的学科，可能它可以去产生出一些有趣的东西。所以我们当时像我同学有的是乐理出身的，有的是学心理学的，有的是像我是WE出身的，有的是编程特别好，有的可能做过AI方面的research。所以就是各方面的想法都能够融在一起。但现在发展最好当然是AI这一块，因为这个心理学。",
      "speaker": "发言人4"
    },
    {
      "time": "00:52:22",
      "text": "怎么跟音乐融合在一起。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:26",
      "text": "OK一方面是所谓的心理声学，就是当你听音乐的时候，就比如说音乐的声音越大，你未必听到的就越响。就是它响度跟信号的这个幅度不是线性关系，或者说像你耳朵听到的声音有个叫做掩蔽效应。中文应该叫做比如说像MP three，为什么它能够对原始音频进行压缩？就是说他发现了这个音频中某些频率。当这个音存在的时候，旁边的有些音它有没有对你的听觉感受是没有影响的。所以它能够对数据进行压缩，其实就是心理学最主要是从这个角度。另外一方面就是说你在做很多跟音乐相关的实验的时候，你是需要去有人来界定他好坏的那这时候就需要一些心理学的统计方法。",
      "speaker": "发言人4"
    },
    {
      "time": "00:53:15",
      "text": "然后你觉得你的这一段学习经历对你现在研究跟音乐相关的大模型，它的帮助是什么？",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:22",
      "text": "最大的帮助一方面是我学习了音乐在数学上的本质。包括我们当时也学了很多20世纪的先锋音乐，就是像什么。",
      "speaker": "发言人4"
    },
    {
      "time": "00:53:33",
      "text": "巴托克bartok或什么约翰凯奇荀伯格。",
      "speaker": "发言人3"
    },
    {
      "time": "00:53:37",
      "text": "对，约翰凯奇杰勋伯格这种无调性的这种东西当然学了很多，包括后期的像什么Steve right什么，他们都不是用正常的乐器，就挑战你对音乐的理解，很多这种方面的东西。当时我就学到一个很重要的概念，就是说音乐的本质就是organized the sound。它跟声音的区别就是它是有组织的。这个组织它其实就是一个很不同级别的组织。就是从一个很大尺度上，你要对音乐去进行乐段的分段。在短时间你有和弦，在更短时间你有每个乐器怎么去onset，怎么去release，包括每一个音声音的细节，就是它是一个多尺度的一种东西，所以这套思想就被融入了。现在我们开发大模型就是用的是这一套思想。",
      "speaker": "发言人4"
    },
    {
      "time": "00:54:25",
      "text": "你刚刚其实开始也提到了，现在有非常多的音频生成软件。你自己又有哪些软件？你觉得有其他的软件会比苏宁生成的更好吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:35",
      "text": "现在如果我们说的是这种to c的软件的话，那可能苏诺肯定是最好的。就是说我们看着用户体验什么这个角度的话，肯定是有的最好的。但是如果你站在我的角度的话，我看的都代码，如果我把所有的源代码都抠出来，那我肯定可以组合出一个最适合我。假如说你是音乐人，你是希望用AI达到什么目的，那我肯定可以帮你实现这样一个东西。就比如说你想找灵感，或者说你想给一个死去的你的乐队主唱johana再延续他的生命力，再唱个十首歌，那这个我们也可以做。或者说你有一首摇滚歌曲，我想把它转换成另外一个快，转换成一个歌剧，我们也可以做。这一套大语言模型，它能做的事情非常的丰富，就看有没有训练数据版权能不能通过，看有没有市场。我们预计接下来的两年，就是在音乐这块会有各种各样的不同的应用，速度只是其中一点。",
      "speaker": "发言人4"
    },
    {
      "time": "00:55:33",
      "text": "根据刚刚的的分享，因为冯老师你是专业做音乐的，我不知道你有没有什么特别的关于音乐方向的小问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:42",
      "text": "我倒不是有问题，但我会觉得这个东西特别的好是在于至少从我自己的兴趣点上，包括我自己做节目分析音乐。其实我特别想把音乐当中的一些特点给提出来。我们现在聊音乐，从音乐文化上来说，我们都说的太玄学了，对吧？就是我们都认为很多最厉害的作曲家就是坐那儿夸天打雷劈，上来一雷，然后他来了个灵感，然后写出一部特别伟大的作品。但是对于我来说，我认为不是的。音乐最终怎么能它可能是认知领域的科学，就是人这个东西最终要不就是电信号，要不就是化学物质，对吧？就是包括我们所有的情绪也好，我们的思维也好，对我来说你最终我们现在解释不了，但是他肯定是一个方向，就是早晚可能在某种程度上是可以尝试对它进行描述的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:28",
      "text": "那么说到音乐，就是说为什么我们大家听到这个音乐，绝大多数人都觉得他是个欢乐的？为什么听到那个绝大多数人都觉得他是悲哀的？我觉得我们其实从音乐人的角度来说，我自己是很对这个东西感兴趣的。但是在这方面，其实AI这个东西能够帮助我们提高效率，而且可能会给我们带来很多更多的研究的思路。就是我们不一定说一定要让AI一步到位，达到他最终的那个完美的力度，然后它才能够帮助人类。它其实在本身这个研究的过程当中，就是和音乐这个学科有很多的交叉。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:03",
      "text": "我们是可以做很多很有意思的研究的。所以我自己本身对这个也是特别的感兴趣。所以我觉得如果要有任何AI这方面的朋友，如果感兴趣想做相关的研究的，也欢迎他来找我就是我对这个特别感兴趣，愿意一起来做。所以我觉得他可能给我们的启示就是很多其实历史上也是很多发明也好，或者很多什么也好。他在达到最终目的之前，他的一些旁枝所达到的效果，可能已经能对我们其他的行业有一个很大的推动力了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:31",
      "text": "所以我觉得AI就是它整个研究的这个过程，对于我们音乐人来说，这也是我不抗拒的一个很大的原因。就是他对我们本身的日常工作是可以有很有帮助的。无论他最终的产品做出来是什么样，它本身研究对我们来说就很有用。所以我通过rugger的讲解，我觉得我对这方面的会更感兴趣，而且对他的感受可能也会更深。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:53",
      "text": "因为你最终也是一因，我总说你甭管什么情绪，你甭管什么样的人，你有什么想法，你最终那个因也是一个一个音生成出来的。AI也是如此。那么你怎么能把你的情绪最终一个一个还原成一个一个的音，然后还能让广大的听众听了以后和你产生共鸣，这个本身就是一个非常有意思的事儿。所以我对这个其实挺有感触。",
      "speaker": "发言人3"
    },
    {
      "time": "00:58:14",
      "text": "应该说对其实你提到音乐，它是有一定的写作的手法，包括你刚刚其实有反复的提到。比如说我把一个节奏变快，它可以从一个悲伤的音乐到欢快的音乐，包括副歌。他有很多很多写作的手法。我想到了我自己是学新闻的，新闻也有很多固定的写法。同时我也在看很多编剧的书。其实好莱坞他在怎么去编一个剧本的时候，虽然这是一个非常creative的工作，但是同时它也是一个有非常多的模板跟各种写作手法的工作。那一个初级的编剧，我们说肯定不是随意发挥，而是先去套模板，然后你再看你的发挥，怎么样去跳出那个模板。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:52",
      "text": "但其实我现在特别感兴趣的一个问题就是冯老师你之前有在视频中提到，你说音乐最怕无聊。我不知道未来AI它能不能克服这个问题，它怎么样写的更加有创意，更加情理之中。但是在你的意料之外。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:09",
      "text": "对，这个其实就是所谓的AI可不可以无中生有。AI可以从1到2做得很好，就是它已经有这个东西，然后他迅速提高这个AI速度是人类没法比的。但是这也是我另外一个不担心人类的问题，就是人类的音乐之所以一直存在，是因为它一直在发展。那么发展的时候是很多，比如说我从爵士乐里面就生产出了摇滚乐，但是在有摇滚乐以前，这个领域是空白的。我就是因为老玩爵士乐，玩着玩着然后我需要给他进行一定的突破，一定的变化，然后出了摇滚乐。然后摇滚乐又从这个rocket bei，就是这种摇滚和爵士之间的这个东西，又发展成了摇滚，然后又到硬摇，然后又到金属。咱只说这一一条路，但是它的发展其实是一个线性发展很远的一个东西。",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:53",
      "text": "所以我觉得还是AI这个东西，它可不可以无中生有，因为它需要在模型以外。因为你现在是统计学，就是你所有AI生成的东西都是人类已有的东西，然后再进行总结出来的。但是整个艺术它其实需要的是在人类总结的范围之外，你哪怕有一点点突破，它的这个艺术是有意思的。但是AI目前的作用机理，至少我听完了以后，他毕竟还是这个方式，所以它可能暂时没法达到。说到我最早说的，就是当他有一天达到了，那就被威胁的就不是我们了。那个真的很可怕的对，我是愿意看到它。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:27",
      "text": "计算机演算就相当于现在有一个程序可以演算到，比如说到地球爆炸，然后人类怎么能？就是它其实是完全的是一样的事情。我可不可以让音乐来演算，音乐一直演算我现在固有的音乐，然后能发展出什么新的形式，然后能发展什么新的style，新的风格。我觉得这个肯定路很长的真出这一天我会非常高兴的，我实话说死了都愿意，真的是当然会有很多的道德上约束，但是我就是说作为一个有好奇心的人来说，我的好奇心是对这方面很有期许的那。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:57",
      "text": "Roger你觉得从技术的角度，就是你看到的AI到底能不能克服这种生成式音乐的无聊？",
      "speaker": "发言人2"
    },
    {
      "time": "01:01:04",
      "text": "我觉得某些程度上是可以的。就是我刚刚说的音乐是organized sound，其实有些音乐的流派就是对已有的元素进行重新的排列组合。比如说不同的single page可以让你听起来。比如说像这个爵士，很多人就觉得这个节拍是这种swing的，跟摇滚就是那种44拍不一样，但乐器上可能是很类似的。那这种重新的排列组合，包括现在很多流派，像黑pop的一些支流，它都是在节奏上做文章。节奏其实就是一种音乐元素的组合方式。",
      "speaker": "发言人4"
    },
    {
      "time": "01:01:39",
      "text": "我觉得如果你给这个AI足够多的时间来不断去演算，但他总能生成一出一个能够符合人类审美的，而又从来没有人类去尝试过的一种组合方式，他一定能够做到这样的一件事情。但是你指望算法它自动的把这一个演算把它给摘取出来，那可能做不到，还需要有人类的审美去约束，去做选择。所以长期来看，可能会有很多人去尝试做一些各种各样的fusion。拿非洲的元素跟拉丁什么的这些民族的元素跟电子东西去混搭，肯定能做一些很猎奇的新奇的音乐流派出来，就看有没有人能够把这个东西抓取出来，然后在人类社会中去把它给发扬光大。然后再产生巨大的人类制作的训练数据。喂给AI就会成为一个feedback loop，就是人类和AI共同发展，AI慢慢的去raise the bar for human being。",
      "speaker": "发言人4"
    },
    {
      "time": "01:02:40",
      "text": "就是人类的音乐人需要创建更优秀的作品来击败AI的这些平庸的作品。然后AI接受更多的优秀的作品，自己就不断的进步。最终我觉得可能20年之后我们再看音乐，可能人类的音乐会更加优秀，BI也会更加优秀，大家共同进步，我觉得是挺好的。共存。",
      "speaker": "发言人4"
    },
    {
      "time": "01:03:02",
      "text": "有一点点类似于AGI的状态。",
      "speaker": "发言人2"
    },
    {
      "time": "01:03:05",
      "text": "我想稍微补充一点，我提出一个非常无知的一个suggestion。我自己只是异想天开的想这个事儿有没有可能在现在的AI当中产生一个随机数机制。因为我觉得其实AI或者是说人类的音乐的发展，其实并不完全是一个新的排列组合的问题。",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:25",
      "text": "现在所有的AI就我的理解而言，它是在一定程度上就是我们给它贴标签什么的。在一定程度上它是有自己的逻辑，或者它是有一定的道理，规矩可循。但是能不能产生一些人为的就是要求它产生一些随机数。就是我要求你不在我已有的模型里边做组合，加入一些随机的程序。这个随机的程序可能是任何的状况，有可能是新的音色，有可能是新的节奏型。我觉得可能这个对我来说会更新奇一些，而不光是说我们已有的元素对它进行排列组合。因为其实现在大量的作曲家一直以来一直在尝试这些东西。非洲的音乐和古典音乐和什么流行音乐和rock和这些各种组合，人类能想到的已有的东西组合，其实是总会有人尝试的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:04:07",
      "text": "但是增加一个随机数的这么一个东西，让他真的里面就是上帝要不要会不会掷骰子，对吧？我真的给他制掉一个骰子的这个状况，我觉得可能对我来说更有意思。但我不知道这个AI方面有没有这个可能。",
      "speaker": "发言人3"
    },
    {
      "time": "01:04:22",
      "text": "其实是有的，就是像我们刚才我们输入同样的prom，它能输出两首不一样的歌曲，它就是随机数的机制。但这随机数它是引入在生成的每一步，就是它从左到右生成，它每一小段20毫秒的音频生成的时候，它都有一点随机，甚至有一些如果我们直接从模型角度来讲，你是可以去调它的所谓的叫做温度。温度就是说你是让它很严格的把每一次推理的最大概率的那一步输出出来，还是说你不允许他去尝试着去找一些不那么大概率的，可能中等概率，但是也过得去，说不定他可能给一些surprise。每一步都是有随机，所以我们听出两次不同的输出，它在伴奏上完全不一样。但是好像又有一个核心的东西是相同的，这个就是现在的随机的方式。但是我们以后肯定会尝试不同的随机方式，就是说能不能在人类可以理解的语义上去控制这样的随机，这样是会是一个最理想的情况。",
      "speaker": "发言人4"
    },
    {
      "time": "01:05:24",
      "text": "好的，非常的精彩。谢谢Roger，谢谢冯老师。",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:28",
      "text": "谢谢好，谢谢各位。",
      "speaker": "发言人4"
    },
    {
      "time": "01:05:35",
      "text": "今天Roger提到的关于AI到底是如何生成音乐的，其实他还制作了非常精美的PPT。如果大家觉得听起来不过瘾，可以去B站或者youtube上等一等我们硅谷101的视频，我们会给大家更加清晰的图像化的展示。好了，这就是我们今天的节目。如果大家喜欢我们的节目，欢迎在你所收听的音频渠道来订阅。我们中国的听众可以通过小宇宙、喜马拉雅、苹果播客、蜻蜓FM、网易云音乐、荔枝播客和QQ音乐来关注我们。海外的听众可以通过苹果播客和spotify来关注我们。另外大家也可以在youtube上搜索硅谷101播客来关注到我们。我们的搜索词是硅谷101播客。如果大家在搜索的时候出现了我们硅谷101的视频，大家也可以一起关注。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:28",
      "text": "最后在节目的结尾，我们还尝试了另一个AI的生成工具，叫做audio。我们要求它生成一段嘻哈音乐。其实原本我们有打算说生成一段中文版的说唱，但是我们在实验的时候实在是听不清楚歌词。最后依然奉上一首AI创作的英文锡海月，希望大家喜欢。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:50",
      "text": "In the valley, whether data flows like streams, which holding the world, tracing digital dreams, bits and bites and rhythms on the pulse of innovation, we ride the time line. From detective fields down to the complete streets, the companies of progress seats britain rise from the labs with the future spell in the silicon nation. All our stories I have.",
      "speaker": "发言人1"
    },
    {
      "time": "01:07:28",
      "text": "AI. To me, my mind, you can believe so, say keep. Go back for back for.",
      "speaker": "发言人1"
    },
    {
      "time": "01:07:55",
      "text": "We are about in tech revolution.",
      "speaker": "发言人1"
    },
    {
      "time": "01:08:17",
      "text": "冰雹是空军，the炮弹i can some。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "本次讨论集中于人工智能（AI）在音乐创作领域的应用，特别是AI生成音乐的能力、对新音乐类型的探索以及对传统音乐行业可能产生的影响。参与者讨论了如SONO等AI音乐生成模型，如何利用简短提示创作音乐，尽管当前技术在完全模拟人类音乐创作过程方面有限，但展示了巨大的潜力。讨论中也触及了AI生成音乐的原创性、版权问题，以及它对音乐行业未来可能的贡献。尽管存在对音乐质量与版权保护的担忧，但共识是AI作为辅助工具，能为音乐家创作提供新视角，增强音乐体验，预示着音乐创新的未来方向。",
    "qa_pairs": [
      {
        "question": "AI生成音乐的效果如何？",
        "answer": "最近在生成音乐方面非常有名的一个音乐模型是sono，它可以根据一段简单的提示生成一段非常好听的音乐。在我们身边的圈子里很火，测试效果不错。但专业人员对sono生成音乐的效果的看法各有不同。",
        "time": "00:01:03"
      },
      {
        "question": "除了sono外，还有哪些生成音乐的软件？",
        "answer": "我听说过几家，比如audio stable audio，还有一些开源的，如refused meta之前出的music jam，以及google的muc LM OpenAI以前做的joke box。不过，这些软件的效果都差不多，可能互相借鉴。",
        "time": "00:02:06"
      },
      {
        "question": "为什么最近感觉sono是最火的呢？",
        "answer": "我认为sono是最胆大的，因为它率先发布了他们的AI生成音乐模型。其他大公司如facebook、google等技术领先，但考虑到发布技术可能带来的社会影响，尤其是音乐版权问题，sono在法律风险和社会影响方面的处理更为大胆，所以先将其公诸于众。",
        "time": "00:02:29"
      },
      {
        "question": "那我们来听一听sono的测试效果，感受一下现阶段这些文字生成音乐模型发展到了什么阶段了？",
        "answer": "好的，我会根据你们的要求，尝试生成一些专业且有难度的音乐，例如悲伤的摇滚乐，并尽可能具体限定主题、乐器、年代等。",
        "time": "00:04:30"
      },
      {
        "question": "生成的音乐质量如何？",
        "answer": "生成速度很快，但第一版歌曲在音乐层面可能没有完全体现出设定的情感态度，缺少了主歌到副歌之间的推进过程以及情绪上的显著变化。相较于人类创作，AI目前还无法完全捕捉并表达真实的情感共鸣和写作动机。",
        "time": "00:10:17"
      },
      {
        "question": "AI生成音乐达到了人类平均水平吗？",
        "answer": "在一定程度上可以说达到了，但在音乐产业中，平均水平可能不足以出类拔萃。不过，在满足一些基本需求，比如需要背景音乐或特定风格音乐时，AI已经能够达到应用水平。",
        "time": "00:13:10"
      },
      {
        "question": "AI生成音乐在实际应用中的表现如何？",
        "answer": "AI在小制作领域，如影视配乐方面，由于其定制性能更好，能提供更贴合需求的音乐。然而，AI取代传统音乐产业中某些部分的能力仍有待提高，尤其是在经济利益和艺术水准上的表现。",
        "time": "00:13:38"
      },
      {
        "question": "AI音乐创作中，为什么它无法像人类那样根据音乐速度来改变情绪表达？",
        "answer": "AI目前在细节把控上有限，可能是因为训练数据中并未充分涵盖对不同速度下音乐情感变化的理解。如果将哀乐加快几倍，原本的悲伤情绪可能会变为快乐，这是由于音乐速度直接影响了听感和情感解读。",
        "time": "00:14:50"
      },
      {
        "question": "为什么AI无法理解80拍每分钟这个要求，以及它是否能理解悲伤情绪？",
        "answer": "目前AI从测试结果来看，在理解和运用特定节奏（如80BPM）及表达悲伤情绪方面存在困难。这可能是因为训练过程中并未有效利用BPM标记信息，或者AI当前的生成机制无法精确捕捉和转换特定情绪与音乐节奏、旋律的关联。",
        "time": "00:21:13"
      },
      {
        "question": "AI生成的音乐为何难以达到头部音乐的质量，以及其悲伤情绪表达不足的原因是什么？是否可以通过使用更优质的训练数据，比如包括完整乐谱和版权音乐，来提升AI音乐的质量和情绪表达？",
        "answer": "AI生成音乐受限于其训练数据，这些数据主要来源于免版权音乐库，而非头部音乐产业。因此，AI无法生成类似Taylor Swift等高品质音乐作品。对于悲伤情绪表达不足，是因为AI在建模时没有全局观，仅按照输入数据顺序逐秒生成，缺乏从整体框架到局部细节的有序构建过程。使用如Spotify全部歌曲作为训练数据理论上可以提高AI音乐的质量，但实际操作中涉及到版权和伦理问题，目前业界禁止直接使用版权音乐库进行训练。即使技术上可行，如通过合成数据训练，也可能在作曲上的效果不尽如人意，因为现有的音乐软件模拟真实乐器声音的程度还不足以满足高质量音乐创作的需求。古典音乐由于版权保护和录音质量等问题，可用的创作素材相对较少。",
        "time": "00:18:01"
      },
      {
        "question": "这两首生成的曲子相较于电影配乐有哪些不同之处？",
        "answer": "虽然这两首曲子都给人以电影配乐的感觉，但它们与真正的交响乐相比还存在一些差距。第二首比第一首更接近古典音乐，旋律写作和律动上不再高度重复，有了动机逐渐发展的感觉，但仍缺乏打击乐、定音鼓等多元乐器的运用，整体上更偏向于低音弦乐和混在一起的木管、铜管乐器。",
        "time": "00:31:54"
      },
      {
        "question": "这次生成的音乐作品在写作水平上相比之前有何提升？",
        "answer": "相比最初的测试，这次生成的音乐在写作水平上有显著提高，但仍未达到理想的交响乐水准。有些部分还比较像是抓彩票般随机，虽然有较好的片段，但在对特定乐器的要求上并未完全满足。",
        "time": "00:32:57"
      },
      {
        "question": "对于AI未能准确生成特定乐器声音的问题，你是如何看待的？",
        "answer": "这个问题与训练数据集的标注有关。AI根据训练数据集学习音乐结构和元素，如果给出的提示词与其理解范围不符（如orchestra或procuration），它可能无法精确区分并生成特定乐器的声音。如果提供更多与音乐流派和乐器相关的明确标签，可能会得到更好的生成效果。",
        "time": "00:34:46"
      },
      {
        "question": "如果按照你的要求，是否有可能通过后期制作改进这首曲子，使其符合交响乐的标准？整体上给这款AI音乐生成产品的评分是多少？",
        "answer": "理论上有可能通过分声部改编并添加乐器来达到甲方预期的音乐水准，但这会涉及较大的工作量。目前，AI生成的作品虽然可以作为灵感来源，但直接作为完整作品还存在较大差距。如果从创作要求的角度看，由于未能完全满足乐器使用的要求，我会给五分；但从听感上来说，可以打6到7分左右，因为整体上听起来比较像音乐。如果严格评判，可能只能给不到6分，因为有些硬性标准未达到。",
        "time": "00:33:34"
      },
      {
        "question": "对于AI未来的发展方向，你有什么看法？",
        "answer": "AI未来的发展可能需要关注声源分离技术的进步，以便更好地理解和训练每一种乐器。同时，期待AI能够支持更多输入方式，如音频输入，以便音乐人能够根据自己的创作需求进行精准指导和灵感启发。",
        "time": "00:36:35"
      },
      {
        "question": "音乐人对于像Sono这样的AI音乐生成产品的态度是兴奋、恐慌还是持中立态度？",
        "answer": "作为一个音乐人，我对Sono产品的态度是谨慎乐观。虽然意识到AI技术可能对行业造成冲击，但同时也认识到它能有效提高工作效率，让音乐家有更多时间专注于创作核心构思。虽然AI目前无法完全取代人类在音乐创作中的独特思考和文化积淀，但如果AI能够跨越基于统计学的壁垒，发展出真正的智能和创作意识，那么整个行业确实会面临挑战。不过，在此之前，人类可以通过规范和道德约束来确保AI安全发展，因此我对AI带来的影响保持谨慎乐观。",
        "time": "00:40:59"
      },
      {
        "question": "副歌在音乐创作中的特点是什么？",
        "answer": "副歌其实是一种运用对位法来作曲的形式，它着重于两个音之间的关系及其和谐与不和谐之间的转换。在副歌写作过程中，有很多严格的规则，比如平行三度不能超过三组，不能使用平行的纯五度和纯八度等理论化的要求。这种创作方式较为逻辑化，限制严格，导致音乐发展到一定阶段后出现了古典音乐以寻求突破。",
        "time": "00:43:27"
      },
      {
        "question": "为什么古典音乐取代了副歌成为主流？",
        "answer": "古典音乐的出现是因为副歌创作规则过于严格，限制了音乐人的创新空间。严格的创作框架使得音乐在发展过程中需要寻求新的突破，进而催生了古典音乐。",
        "time": "00:44:48"
      },
      {
        "question": "AI能否通过学习生成类似巴赫风格的音乐？",
        "answer": "在训练数据集里，AI可以尝试根据特定prompt生成类似巴赫风格的音乐片段。尽管生成的音乐可能听起来与原曲相差不大，但在某些关键元素如震撼感、主题呼应及严谨逻辑等方面，AI目前还无法完全达到原曲的质量。",
        "time": "00:45:09"
      },
      {
        "question": "AI对于赋格这类具有严谨逻辑性的音乐类型是更适合还是更不适合？",
        "answer": "AI在音乐领域的研究历史表明，对于像赋格这样逻辑性强、注重对位法的音乐类型，AI可以通过学习乐谱数据进行建模和推理，但在当前的技术阶段，如果仅基于少量听过的作品进行训练，AI可能无法准确捕捉到复杂声部间的呼应和变奏。然而，对于更偏向于逻辑推理的AI，它在音乐生成领域可能会表现得更好。",
        "time": "00:50:04"
      },
      {
        "question": "音乐技术和心理学如何融合在一起？",
        "answer": "音乐技术和心理学的融合主要体现在心理声学方面，例如音量大小与信号幅度的关系、掩蔽效应以及听觉感受的统计规律等。此外，在音乐实验设计和评价过程中，也会运用心理学的统计方法来界定音乐好坏。",
        "time": "00:52:26"
      },
      {
        "question": "学习音乐技术对研究音乐相关大模型的帮助是什么？",
        "answer": "学习音乐技术有助于理解音乐在数学层面上的本质，尤其是对不同尺度上的组织结构的理解，这为开发大模型提供了理论基础和创新思路。",
        "time": "00:53:22"
      },
      {
        "question": "是否存在比苏诺更好的音频生成软件？",
        "answer": "从用户体验角度看，苏诺可能是最好的C端音频生成软件。但从代码层面看，可以根据用户需求组合出最适合音乐人的工具，实现从寻找灵感、延续乐队主唱的生命力到音乐风格转换等各种功能。",
        "time": "00:54:35"
      },
      {
        "question": "AI对音乐人的日常工作有哪些帮助？",
        "answer": "AI对音乐人日常工作很有帮助，即使最终产品形式各异，其研究过程本身就极具价值，能辅助音乐创作与创新。",
        "time": "00:57:31"
      },
      {
        "question": "AI能否像人类一样将情绪转化为音乐，并引发听众共鸣？",
        "answer": "这是非常有意思的一件事，AI如何将个人情绪逐个还原成音符，并通过音乐与广大听众产生共鸣。",
        "time": "00:57:53"
      },
      {
        "question": "AI在音乐创作中的作用是否受限于已有模板和规律？",
        "answer": "音乐和新闻等领域的写作都有固定的手法和模板，AI目前虽能快速生成高质量作品，但受限于基于统计学的模型，难以无中生有，实现完全意义上的创新。",
        "time": "00:58:14"
      },
      {
        "question": "AI能否实现“无中生有”，即创造出全新的、人类尚未尝试过的音乐元素组合？",
        "answer": "AI可能无法完全无中生有，因为它基于已有的数据进行学习和创作。但若给予足够时间和演算空间，理论上能创造出符合人类审美的新组合方式。",
        "time": "01:01:39"
      },
      {
        "question": "是否有可能在AI中引入随机数机制以增强音乐创作的新奇性？",
        "answer": "AI中确实存在随机数机制，目前在生成过程的每一步都有随机性，每生成一小段音频都有可能产生不同的结果。未来可能会尝试更高级别的随机控制，让AI创作更具探索性和惊喜感的音乐。",
        "time": "01:04:22"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探讨AI在音乐生成领域的突破与挑战",
        "summary": "在硅谷101的这一期中，主讲人红军邀请了冯建鹏和Roger陈，共同讨论了AI在音乐生成方面的进展，特别关注了名为“sono”的音乐模型。他们探讨了AI生成音乐的效果、版权问题及社会影响，指出虽然技术上已经取得进展，但版权和音乐产业格局的潜在变化仍是主要挑战。"
      },
      {
        "time": "00:03:43",
        "title": "探索音乐生成模型：挑战与发现",
        "summary": "讨论集中在使用音乐生成模型创造特定情绪和风格的音乐上。通过尝试生成不同主题（如求职、失恋）和风格（如摇滚、说唱）的音乐，参与者对模型的当前能力有了直观的了解。特别挑战模型生成悲伤的摇滚音乐，评估其在保持特定情感和音乐结构方面的能力。结果表明，虽然模型能在一定程度上捕捉到指定的音乐风格，但在音乐的情绪表达和结构变化上仍存在不足，尤其是缺乏人类作曲中的情感深度和创作动机。"
      },
      {
        "time": "00:09:57",
        "title": "探讨AI音乐生成与人类情感表达的差距",
        "summary": "生成的音乐虽能满足基本需求，但未能充分展现人类情感，特别是与人文态度和情感共鸣的深度表达。AI目前难以复制经典音乐作品中的人文精神和情感深度，限制了其在音乐创作领域的广泛应用和认可。"
      },
      {
        "time": "00:11:07",
        "title": "探讨AI在音乐创作中的水平与应用",
        "summary": "讨论集中在AI是否能达到人类音乐创作的平均水平，以及其在音乐产业中的应用和价值。提出AI作曲虽可能达到一般水平，但在音乐产业中出类拔萃、成为经典存在疑问。然而，在特定需求如短视频背景音乐制作上，AI展现出优势，尤其是在定制化音乐方面。同时，也指出了AI音乐在经济利益上的挑战。"
      },
      {
        "time": "00:14:39",
        "title": "音乐的速度与情绪表达及其对AI的挑战",
        "summary": "音乐的速度，如80拍每分钟（BPM），对音乐的情绪表达至关重要。改变一首歌的速度可以显著改变其情绪色彩，如将欢快的歌曲放慢可使其变得悲伤，反之亦然。尽管AI在生成音乐方面取得了一定的进步，但对于速度和情绪的精细控制仍然存在挑战。这是因为AI模型的训练数据主要基于免版权音乐库，这些数据可能不足以让AI理解并准确复制人类音乐制作中的复杂性和细腻的情感表达。此外，AI目前还难以达到创作出与顶级音乐家如Taylor Swift同等品质音乐的水平，其生成的音乐更接近于普通免版权音乐的效果。"
      },
      {
        "time": "00:18:26",
        "title": "探讨AI在音乐创作中的局限性",
        "summary": "在音乐创作中，人类通常采用从宏观到微观的逻辑，先确定整体框架和流派，再细化到每个部分的和弦和配器。而AI模型，如大元模型，则缺乏这种全局观，它采取的是逐秒生成的方式，导致音乐的过渡和结构可能显得突然和不自然。此外，AI在歌词创作上虽然能保持主题正确和押韵，但往往缺乏深度和灵魂，这些是AI相比人类创作的主要局限性。"
      },
      {
        "time": "00:21:12",
        "title": "BPM信息在音乐训练中的应用困惑",
        "summary": "对话者对BPM（可能指节拍每分钟）在音乐训练中未被有效利用表示诧异。尽管训练材料中每首歌的BPM都有明确标注，但似乎这一信息并未被充分利用。他们认为，虽然技术上解决这一问题相对简单，但目前的版本中，这部分信息被视为不重要。预期未来可能会增加更多限制性条件来更好地利用这些信息。"
      },
      {
        "time": "00:21:41",
        "title": "探讨AI在音乐创作中的挑战与版权问题",
        "summary": "对话集中在AI音乐创作的挑战上，特别是情绪表达的缺失和版权问题。讨论指出，由于训练数据的局限性，AI难以创作出能引发共鸣的作品。此外，使用版权音乐作为训练数据存在法律和伦理问题，尽管技术上可能实现创作类似经典歌曲的音乐，但存在侵权风险。未来可能需要音乐人和AI创作者之间达成新的协议，以合法使用音乐作品进行训练。"
      },
      {
        "time": "00:23:31",
        "title": "音乐版权和AI音乐生成的挑战",
        "summary": "讨论集中在音乐版权问题、经典交响曲的版权保护期限以及AI在音乐创作中的应用挑战。提到一个名为fairly trained的组织关注音乐版权问题，讨论了版权音乐和公共领域音乐的区别，以及作曲家去世后版权保护期限。强调即便乐谱可自由演绎，录音版的版权仍归录制方所有。探讨了使用AI生成音乐的可行性和局限性，特别是音色和演奏方法的精确复制挑战。提出直接用AI生成音乐与生成乐谱的不同挑战，以及对古典音乐录音资源的限制。"
      },
      {
        "time": "00:27:03",
        "title": "探索AI生成音乐的潜力与局限",
        "summary": "对话聚焦于尝试使用AI生成以交响乐团英雄为主题的器乐曲，特别指定了包括弦乐、木管、铜管和打击乐在内的乐器配置。经过多次尝试，虽然生成的音乐在听感上接近电影配乐，但在满足特定乐器要求和达到真正的交响乐形式方面存在差距。评价指出，尽管AI在提供创作灵感方面表现出潜力，但在满足具体音乐制作要求上仍有不足，特别是在乐器使用和音乐复杂度上。总体评分反映了对生成音乐的适度认可，同时指出了改进空间。"
      },
      {
        "time": "00:34:27",
        "title": "探讨音乐生成技术及其未来发展",
        "summary": "讨论集中在音乐生成技术上，特别是如何让AI更好地理解和生成特定乐器的音乐，以及如何通过改进训练数据集来提升生成音乐的质量。指出了目前技术在乐器识别和音乐风格上的局限性，并提出了声源分离技术和直接支持音频输入作为未来的发展方向，以期更深入地理解和生成音乐。同时，也提到了当前技术对于音乐人来说作为灵感来源的潜力，但强调了需要更多针对音乐专业人士的产品和服务。"
      },
      {
        "time": "00:37:42",
        "title": "音乐人对AI技术的谨慎乐观态度",
        "summary": "音乐人对AI技术持谨慎乐观态度，认为虽然AI能提高音乐创作和制作的效率，解放生产力，但人类在音乐领域的独特性和深层次思考能力是AI暂时无法替代的。尽管AI在某些领域展现出了取代人类的潜力，但在音乐创作方面，由于缺乏自主意识和创造力，AI尚不能完全取代人类。音乐人相信，随着技术的发展，人类会通过法律和道德规范来约束AI，确保其在安全的框架内发展，从而对音乐行业产生积极的帮助。"
      },
      {
        "time": "00:41:43",
        "title": "探讨音乐生成的质量和语言差异",
        "summary": "讨论者指出，使用苏诺生成的英文歌曲效果优于中文，认为这可能与训练数据集有关。在分享了冯老师创作的高质量歌曲后，讨论者自我反省，认为自己的生成歌曲较为普通。此外，他们还讨论了即便给出悲伤的指令，生成的歌曲也倾向于欢快，推测可能是因为大多数免版权音乐适用于广告，较少使用悲伤音乐所导致。"
      },
      {
        "time": "00:42:56",
        "title": "探讨副歌的作曲方法与AI音乐生成",
        "summary": "对话中提到了副歌作为一种作曲形式，它通过严格的对位法进行创作，考虑音符间的关系，如和谐与不和谐的转换。副歌写作中包含主题（subject）与回应（answer）的交互，以及对音程如三度和平行纯五度、纯八度的使用限制。此外，讨论了副歌创作的逻辑性较强，以及尝试用AI生成副歌的可能性。最后，提到了副歌因为其严格的条条框框，随着时间发展逐渐被其他音乐形式所取代。"
      },
      {
        "time": "00:45:09",
        "title": "探讨AI生成巴赫风格音乐的挑战与可能性",
        "summary": "对话中讨论了使用特定prompt生成巴赫风格的音乐片段，对比原曲《D小调托卡塔与赋格》的差异。讨论者指出，尽管AI生成的音乐在某些方面与巴赫作品相似，但在复杂性、声部之间的呼应和逻辑推理方面存在显著差距。进一步探讨了赋格作为严谨逻辑性的音乐形式，对于AI音乐生成的挑战，以及AI在此类音乐创作上的潜力和限制。"
      },
      {
        "time": "00:51:20",
        "title": "音乐技术与AI的融合实践",
        "summary": "讨论集中在音乐技术的学习，包括音乐制作、心理学、认知科学等多学科知识的融合，旨在探索音乐作为情感语言的深层次理解。特别强调AI在音乐领域的应用，如心理声学、音频生成软件等，展现音乐的本质是组织声音，以及如何利用这些知识开发大模型，实现音乐的创新应用，如灵感寻找、音乐风格转换等。"
      },
      {
        "time": "00:55:32",
        "title": "音乐与AI的跨界合作探索",
        "summary": "对话中表达了对音乐制作中引入人工智能（AI）技术的兴趣和看法。音乐被看作是认知领域的一部分，可以通过电信号和化学物质等方式影响人的情绪和思维。AI技术的引入，不仅能够提高音乐制作的效率，还能为音乐研究带来新的思路和方法。讨论强调了AI在音乐领域的应用，不一定要追求完美，而是在研究过程中与音乐学科的交叉合作，能够产生很多有价值的研究和创新。此外，还提到了音乐创作中的手法与模板，将其与新闻写作和剧本编写的固定写法进行比较，强调了在创意工作中模式和手法的重要性。"
      },
      {
        "time": "00:58:52",
        "title": "探讨AI在音乐创作中的潜力与限制",
        "summary": "音乐创作最担心的是无聊，人工智能(AI)虽然能在已有基础上快速进步，但能否无中生出创新作品仍是问题。音乐的发展是基于不断的创新和风格转变，而目前的AI创作主要基于对已有数据的总结和重新组合，尚未能超越人类已有的创作范围。虽然AI有可能通过不断演算生成符合人类审美但未曾尝试过的组合方式，其自动识别出这些创新可能仍有难度，需要人类审美进行筛选。长期来看，人类与AI可以共同发展，AI的进步能激发人类创作出更优秀的作品，形成良性循环。未来，音乐领域可能见证人类与AI作品的共同进步和共存。"
      },
      {
        "time": "01:03:04",
        "title": "探讨AI在音乐创作中的随机性应用",
        "summary": "讨论重点在于是否能在现有的AI技术中加入随机数生成机制，以创造出全新的音乐元素，如音色或节奏型，从而超越传统的排列组合方式。目前AI在音乐生成过程中已引入随机性，通过调整“温度”参数允许模型探索中等概率的输出，以产生不同的音乐片段，但仍保留一定的核心相似性。未来的研究方向是尝试在人类可理解的语义层面上控制这种随机性，以达到更理想的创作效果。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [],
              "content": "AI在音乐创作领域的应用越来越广泛，能够根据简单的提示生成不同风格的音乐作品。"
            },
            {
              "children": [],
              "content": "存在的技术挑战包括对音乐情绪的精确捕捉、音乐结构的合理构建、以及版权问题的处理。"
            }
          ],
          "content": "AI音乐生成技术的现状"
        },
        {
          "children": [
            {
              "children": [],
              "content": "训练数据集的选择和质量直接影响生成音乐的质量和风格。"
            },
            {
              "children": [],
              "content": "AI通过统计学方法学习音乐的结构和情感表达，但目前主要依赖于已有的音乐作品，缺乏真正的创新。"
            },
            {
              "children": [],
              "content": "技术上可通过调整随机数生成机制来增加音乐的多样性和创新性。"
            }
          ],
          "content": "生成音乐的技术细节"
        },
        {
          "children": [
            {
              "children": [],
              "content": "对音乐创作和音乐产业的潜在影响，如音乐创作效率的提高、音乐制作成本的降低。"
            },
            {
              "children": [],
              "content": "AI音乐生成技术可能改变音乐产业的生态，但也引发了关于版权、原创性和艺术价值的讨论。"
            },
            {
              "children": [],
              "content": "讨论了AI音乐生成技术对于音乐教育、音乐治疗等领域的潜在应用。"
            }
          ],
          "content": "AI音乐生成的应用和影响"
        },
        {
          "children": [
            {
              "children": [],
              "content": "专业音乐人和AI技术专家对AI音乐生成技术持谨慎乐观态度，认为它能够辅助音乐创作，但难以完全替代人类音乐家的创造力和情感表达。"
            },
            {
              "children": [],
              "content": "提出未来研究方向包括增强AI音乐生成的情感表达能力、解决版权问题、以及如何让AI音乐生成更具创新性。"
            }
          ],
          "content": "专家观点和建议"
        },
        {
          "children": [
            {
              "children": [],
              "content": "用户对AI音乐生成作品的接受度取决于其音乐质量、情感表达的真实性和音乐的创新性。"
            },
            {
              "children": [],
              "content": "随着技术的发展，AI音乐生成可能实现更高水平的音乐创作，包括情感表达和音乐创新。"
            },
            {
              "children": [],
              "content": "讨论了如何利用AI音乐生成技术为音乐产业带来新的商业机会和创新。"
            }
          ],
          "content": "用户体验和未来展望"
        },
        {
          "children": [
            {
              "children": [],
              "content": "音乐产业需要适应AI音乐生成技术的发展，包括版权法律的调整、音乐创作和制作流程的改变。"
            },
            {
              "children": [],
              "content": "AI音乐生成技术可能促进音乐产业的多元化发展，提供更多样化的音乐内容和创新的音乐体验。"
            },
            {
              "children": [],
              "content": "讨论了音乐人如何利用AI技术提高自身创作效率，以及如何在AI音乐生成作品中保留个人风格和创意。"
            }
          ],
          "content": "音乐产业的适应与变革"
        },
        {
          "children": [
            {
              "children": [],
              "content": "AI音乐生成技术目前尚处于发展阶段，虽然在提高音乐创作效率和降低成本方面展现出巨大潜力，但在音乐的情感表达和创新性方面仍面临挑战。"
            },
            {
              "children": [],
              "content": "音乐产业和音乐人需要积极适应AI技术的发展，利用其优势同时保持音乐的个性化和创新性。"
            },
            {
              "children": [],
              "content": "未来，随着技术的不断进步和音乐产业的适应调整，AI音乐生成技术有望为音乐创作和音乐产业带来更多的可能性和创新。"
            }
          ],
          "content": "结论"
        }
      ],
      "content": "AI音乐生成技术讨论脑图摘要"
    }
  }
}