{
  "pid": "61cbaac48bb4cd867fcabe22",
  "eid": "63e19fb40d7e8eaa72117c47",
  "title": "EP 26. 【生成式AI专题2】ChatGPT的技术与商业演进：对话Google Brain&Stability AI",
  "task_id": "2yjoqzbmeo28q68l",
  "transcription": [
    {
      "time": "00:00:03",
      "text": "欢迎来到onboard，真实的一线经验，走心的投资思考。我是Monica.",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:09",
      "text": "我是高宁，我们一起聊聊软件如何改变世界。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:15",
      "text": "大家好，欢迎来到omber，我是Monica。自从OpenAI发布的ChatGPT掀起了席卷世界的AI热潮，不到三个月就积累了超过1亿的月活用户，超过1300万的日活用户，真的是展现了AI让人惊叹的能力，也让很多人直呼这就是下一个互联网的未来。有不少观众都说希望我们再做一期AI的讨论区，于是这次硬核讨论就来了。这次我们请来了google brain的研究员雪之，它是google大语言模型pum pathway language model的作者之一。要知道这个模型的参数量是GPT3的三倍还多。另外还有两位AI产品大牛，一位来自著名的stable diffusion背后的商业公司stability AI，另一位来自某硅谷科技大厂，也曾在吴恩达教授的landing AI中担任产品负责人。此外莫妮卡还邀请到一位一直关注AI的投资人朋友bill当做我的特邀共同主持嘉宾。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:17",
      "text": "我们主要讨论几个话题，一方面从研究的视角，最前沿的研究者在关注什么？现在技术的天花板和未来大的变量可能会在哪里？从产品和商业的角度，什么是一个好的AI产品？整个生态可能随着技术有怎样的演变？更重要的我们又能从上一波AI的创业热潮中学到什么？最后莫妮卡和bill还会从投资人的视角做一个回顾总结和畅想。这里还有一个小的update，在本集发布的时候，google也对爆发式增长的ChatGPT做出了回应，正在测试一个基于lambda模型的聊天机器人a prentice spot正式发布后会有怎样惊喜，我们都拭目以待。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:02",
      "text": "AI无疑是未来几年最令人兴奋的变量之一，Monica也希望未来能邀请到更多一线从业者从不同角度讨论这个话题。不论是想要做创业研究产品还是投资的同学，希望这些对话对于大家了解这些技术演进商业的可能，甚至未来对于我们每个人、每个社会意味着什么，都能引发一些思考，提供一些启发。这次讨论有些技术硬核，需要各位对生成式AI大模型都有一些基础了解，讨论中涉及到的论文和重要概念也会总结在本集的简介中，供大家复习参考。几位嘉宾在北美工作生活多年，夹杂英文在所难免，也请大家体谅了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:49",
      "text": "欢迎来到未来，大家enjoy。给大家先做一个简单的自我介绍，你们自己过去的一些经验。一个fun fact就是你最喜欢的一个生成式AI的项目。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:05",
      "text": "对，大家好，我的名字叫王雪志，我现在是在google brain做research scientist。对，我在google差不多到现在已经有快六年的时间了。我的主要研究topic是包括large language model，以及language model里面的reasoning。然后我我在过去我之前是在在join google之前，我是在CMU拿的那个machine learning的PHD。然后我最喜欢的generate AI project。",
      "speaker": "发言人3"
    },
    {
      "time": "00:03:42",
      "text": "我其实对那个language model所有的方面都比较感兴趣，然后我自己本身topic是比较偏向于natural language reasoning这边的，所以我对如何on lock large language model的各种capability是非常感兴趣的。然后去年的话其实有好多paper在这个方向都是很有意思的，就我们自己组做的有包括那个train of salt和self consistency，都是用一些prompting的方法，能够让拉large language model能够更好的做各种各样的reasoning。包括比如说数学上的reasoning，或者common sense上，或者一些symbolic就是呃呃模式性的reasoning。对我我觉得这些project都是很有意思的。然后在之前的话，我去年也有一些其他的paper，比如说说有那种能让拉的model做zero shot reasoning的project，我觉得也是特别有意思的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:04:41",
      "text": "大家好，我叫邓玉东，我是WAI的技术产品总监，主要负责stable diffusion理算法等等相关的一些工作。我的背景其实不是ML的科班出身，我之前是做产品的，在腾讯、百度，然后后面去了咨询公司bcg其实一直都做产品数字化等等的工作。2021年的时候，对接触到了这些AIDC的技术。当时最早还是从VQ干的黑板开始，然后开始自己探索这些技术，后面就逐渐进入到这个领域，也在很多开源项目里面有了一些贡献。说后面加入ability t，我说到最喜欢的项目，其实就要回到2021年。当时有一个notebook clip guided的this fusion，那可能是我最喜欢的一个项目，也是我相当于把我带入领域的。这个notebook是我写的，他其实是整个怎么说呢，就是最近很boom的stable distribution等等的一个非常早期的，但是又是非常重要的一个工作，验证了这个就基于这个，比如说我们现在做这些embeds，比如基于一个小的语言模型，能够引导这个fusion model去生成它的整个的图像内容。然后也有很多社区的人开始加入参与这个工作，参与这部分工作来探索这个应用。",
      "speaker": "发言人4"
    },
    {
      "time": "00:06:17",
      "text": "我好奇你是怎么加入到这个stability AI的，你可以简单的介绍一下你这个reval work的经历。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:25",
      "text": "好的，也是去年年终的时候，当时我还在做我自己的consulting的项目，其实很忙。但是周六周日因为我对这个技术特别感兴趣，周六周日我就花时间在写了几自己的door book，然后维护自己的开源项目上面。那个开源项目当年用的人不是很多，叫majestic diffusion。但是他是当在当年那个later diffusion的那个时代，可以生成比较高质量的那的包括人像，然后一些艺术品艺就是AI艺术这样的一个notebook，其实非常接近于stable diffusion，当然没有stable diffusion量这么高。",
      "speaker": "发言人4"
    },
    {
      "time": "00:07:13",
      "text": "在建设这个开源项目的过程里面，就认识了很多社区的人，包括其中也包括stability的一些同事。然后当时在stability的那个时间点，有招揽一波开源开发者。我是在那一波被招揽的开源开发者里面加入了WP。",
      "speaker": "发言人4"
    },
    {
      "time": "00:07:36",
      "text": "我发现现在真的是全球remote work的风潮，真的是真的是让越来越多借着这开源社区的成长起来的公司可以知道在全球范围内招揽到人才。我觉得接下来可能是一个非常有意思的一个趋势。好，谢谢一周分享。然后我发现果然这这次这次几位嘉宾都非常的硬核。我真的可以跨过了这个市场上的一些噪音，很多技术这个方面去了解到底技术的一些可为和不可为我相信对大家应该也会很有帮助。但我们会经常讲的深入浅出一些。一文可以来跟大家做一下自我介绍。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:14",
      "text": "好的，我叫易文，我现在在硅谷做这个ML的PM然后我是应用物理出身，我本来是我本来的理想是作为一个物理学家，我主要做的我研究的物理的这个课题主要是半导体物理。但是到了我毕业的时候，实在是找不到工作，别人跟我说你可能挺适合做PM的，所以我就去。后来我说什么是PM他们说你来了就知道了。我的职业生涯大概有五六年的时间，一直在做硬件的PM，比如说我在苹果做了苹果手机，在亚马逊做了M3 echo，后来出去创业第一次就是七八年前，第一次出去创业，接触了computer vision，然后一直过去的七八年一直在做computer vision。几5年前我在landing，我是应该是landing的第一批最早的一批员工了。那你还是文达老师创造的，然后他创他18年创办的，主要是用AI来服务于制造业和农业。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:20",
      "text": "有一个方法就是stable depute用的是d noy的方法来生成图片。这个d noising第一批使用的noising来做做diffusion后处理的这个人。第一个提出这个东西的人叫Peter bill，他其实是吴老师。以前2019年还是2018年的博士生。再往你再往早一点的话，最早是干嘛？那17年18年的时候，我们也尽量大量的使用干来做生成式的这个模型。比较有名的就是像cycle干，beauty gun这像这种东西。其实gan的提出人，这个烟gold fellow，他的硕士导师也是吴老师。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:02",
      "text": "说一说一个fun fact，就是一个很有意思的项目。我有一个黑客朋友，他做了一个APP叫做draw things。他应该是我知道的第一个把civil diffusion成功编译到手机上的，这么一个应用。所以你现在你如果现在下载joe things的话，你可以在这个，你可以在IOS这个平台上下载了它。然后你可以使用这个手机做influence。实际上这是很难的，因为哪怕是台很很好的台式机，做influence也是很费劲的。但是他是最早一批成功在手机上编译，并且成功能够运行inference。如果大家有兴趣可以下载一个。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:45",
      "text": "好呀好，果然这个黑客已经先行大一步。这次也是邀请到了一位投资人朋友啊bill行，以后来跟我一起来做解剖host，要不bill也可以跟大家简单介绍一下自己。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:59",
      "text": "好，hello大家好，我是五源资本的bill，也是简单介绍一下自己。我之前在北大读的计算机，然后毕业之后就一直在做战略投资和财务投资。目前在五元的这个成长期的团队主要在看软件，还有AI等这个底层技术创新的方向。",
      "speaker": "发言人5"
    },
    {
      "time": "00:11:18",
      "text": "说到关于AI的fun fact的话，我觉得比较有意思。就是我今年从年初开始一直在关注hugin face这个平台。其实上面有非常多的开。源的模型。然后新的AI相关的进展，开发者都会去share在他的space和mol hub里面。因为之后也会谈到开源模型的商业模式。",
      "speaker": "发言人5"
    },
    {
      "time": "00:11:40",
      "text": "另外一块就是其实我发现在推特上有非常多的AI相关的插件。比较有意思的还是说，有人用这个ChatGPT和这个搜索结合做了一个网页的插件版。这个我也是现在一直在使用，使得说现在这个ChatGPT的效果比这个原始版本对于新的一些新闻，然后做一些实时的内容的效果会更好了。",
      "speaker": "发言人5"
    },
    {
      "time": "00:12:05",
      "text": "自我介绍环节都非常有启发性。我觉得从这个一开始，因为的确前面提到这个ChatGPT GPT three three point five的出现，的确让大家一下子破了圈，让感受到了这个AI的魔力。所以我想这个雪芝也是在google做了大型语言模型这一块的研究。我想我们所有关很多关注ChatGPT的行业人，他可能都会关注到这个google也开发了一个大型的语言模型path，这个pathrick。但对于一些可能还不那么熟悉的朋友啊或雪芝可以简单跟大家介绍一下，就是什么是goos，google这个palm，然后也可以简单的可能high level跟大家介绍一下。他在这种架构，或者说一些一些你觉得比较重要的特点上，跟其他的像GPC或者其他的一些这种语言模型有什么不一样的这个地方。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:02",
      "text": "好的，google的这个palm是在去年大概四月份左右发布的。他们是说是叫做passway language model，它是google现在发布的，我想应可能应该是市面上最大的一个language model，然后它是有它最大区别应该是它有540个billion的parameter。然后它本身的架构是一个left to write，从左到右，然后decoder only就只有一个decoder的那个language model。",
      "speaker": "发言人3"
    },
    {
      "time": "00:13:36",
      "text": "他们的优势在于，首先它capacity特别大，因为它有540 billion per meter。所以我们发布那个paper的时候，其实我们当时在paper里面也秀了。他在很多task上面都有非常好的performance，基本上都是那个state of the art。包括比如说正常的natural language processing，就nature language understanding的task，或者是natural language generation的task，他们都是有很好这基本上是现在最好的perform，就是当时发布的时候最好的performance。然后另外我们在paper里面还写了就是palm因为他这个大的capacity，他还顺带unlock了一些emergent abilities。比如说我们在里面举了一些例子，比如说你用一些prompt就可以让palm解释一些笑话，或者是可以让他做一些很复杂的task。比如说是reasoning task。这些能力是之前的一些小猫所不能达到的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:32",
      "text": "然后它跟GPT three的具体区别，GPT three其实也是一个left to write decode only language model，也是transformer best。然后可能最大的区别就是size上的difference，palm是一个540 billion的primate model，然后GPT three是一个175 bill primate的language model，所以GP three要小很多。然后具体到一些training上，detail的上面的difference的话，那两个都还是有一些细微的区别的。比如说palm的那个training coppers跟GT three是不一样的。然后呃另外一个比较重要的factor是说，你在training的时候，到底让这个model见过了多少token，就number of tokens，他们跟GPT three也是不一样的。然后再具体到一些可能更细微的，我觉得可能很多人不是那么care的，细节可能是比如说你pum里面做是怎么做toga ization的，然后GPT three怎么做toga ization，这可这里面也有一些细微的区别，这些应该就是基本上最大的区别了。对，但是这两个东西basically还都是具，你如果说下面架构的话都是一样的，都是一个decoder only的transformer based的language model。对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:46",
      "text": "我我我有个问题就是问雪芝，我看了一下GPT3和GPT2的论文，GPT3的和GPT2最大的问最大有一个区别就是它它抵扣的后面的那些发音，在GPT2里面都是zero shot，所以它那个准确率特别差。然后在GPT3里面，它有些task就是one shot，还有future learning的，然后一下就把那个准确率给干上去了。这个方面的，第一我第一个问题就是你觉得你觉得是不是从这个角度来说，数据在这个file task里面还是非常的重要的。也就是说前面这decode generalization，就GPT3这个generalization是是能力还是有限的这是第一个问题，第二个就是。他们在这个抵扣的出去以后，他是怎么去处理那些特殊的这些各种不同的task呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:51",
      "text": "首先fine tuning跟few short是不矛盾的两件事情。不管是palm也好，GPT two也好，GPT three也好好，你在deport就pretrail完了这个车。这个model之后，你都是可以either做fine，或者是做few shot，或者zero shot。然后find tree的好处就是说如果你有一定size的training data set的话，你就可以find tune这个language model。然后让这个logo model adapt到你自己的这个specific task上面。然后他就可以在这个task上面performance特别好。然后future的跟zero show区别是说，假设你没有一个一定set的training set的话，比如说你现在有一个新的task，然后你完全没有任何data，然后你希望用这个language model去解决这个task，那你唯一可以做的就只有zero shot和few shot，就你没有办法用file的方法。对，这是find有点跟zero show few shot的具体区别。",
      "speaker": "发言人3"
    },
    {
      "time": "00:17:44",
      "text": "然后另外一个针对你第一个问题，其实是这样子，就是你其实做find或者zero future都是可以的，就在这三个model上都是可以做分别的事情的，取决于你有没有这个确定set。但是GPT two跟GPT three最大的区别就是当GPT three把capacity，就是它model capacity增长到175变量的primate的时候，它paper里面有写就是他unlock了这个叫做in context learning或者是few short的ability。就是说你model size在小的情况下，比如说GPT two，或者是在之前那些model，比如bert或者t five。但model size很小的情况下，他们是不太拥有zero shot或者few shot的能力的。所以在这些model的情况下，你基本上只能用find tuning的方法，才能让model达到一个在某一个task上面达到一个可以的OK的performance。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:35",
      "text": "但是当GPT three把那个model size增长到175辩论premature的时候，他们就发现这个model自己就拥有了in context learning，或者这个叫做zero shot和few shot能力。然后在这种情况下，你不用再去further find tune这个model。当然你也可以翻tune，但是instead find tune，你其实可以直接对这个大size的language model做zero shot，或者然后你会发现他的performance其实可以很好。然后这个能力在小小size的model上面是不太存在的。就是你在你在GPT two上面，你是这个zero show或few，它performance就会特别差。这个是小model跟大model上面一个能力上的基本上的区别。然后对我我觉得我。",
      "speaker": "发言人3"
    },
    {
      "time": "00:19:19",
      "text": "是不是可以这么理解，就是你的当你的前面那个decode足够大的时候，我很多的context，他所谓的in context，你是不是因为前面的decode足够大了以后，我能够我的我的文本见过足够多，我能够学到的represent就足够多了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:37",
      "text": "对，这个事情到现在为止还没有一个特别sorry的分析。但是有很多paper试着去解释这个in context learning的ability是怎么出来的对，我们现在发现的就有一个empirical finding，就是说当model size达到一定程度之后，然后这个一定程度其实也没有人发现它的cut off到底在什么地方。对，但是我们有一个imperial finding，就是说如果model size达到一定程度，然后他的这个in context learning的能力他就自己出来了。这也是GT three那个paper里面他写的一个部分，它有一个subsection在介绍这个。",
      "speaker": "发言人3"
    },
    {
      "time": "00:20:11",
      "text": "对，然后你具体可以想，如果一定要解释为什么那么话其实有很多paper在解释这个为什么有些paper把它解释成为一个类似于basic inference的东西，你首先是你model size足够大，然后你其实model里面承载了一定的数据量之后。然后这个model在做in contest learning的时候，其实就是说你给他几个类似的example，他就能从类似的example里面推导出你要做的这个task的pattern是什么。然后你现在给他一个这个task上面新的问题，他就能用它推导出来这个pattern去完成这个新的问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:20:49",
      "text": "就能完成这个task。就是像你说的，实际上GPT3他对这个contest的理解能力的增长是其实他到底room count是什么？其实很有很多理论，但是没有我就没有看到特别简单的这个呃没有看到特别简单的解释。而且在GPT2出来了以后，GP3出来之前，如果我们看bird和GPT2他们对那个language的semantics的理解，bird是强于这个GPT2的。但是到了GPT3了以后，我发现突然发现他对这个context的理解好像也不比bard差多少。所以这就让但是他其实不知道他在每次他他是一个文本预测器。你在预测后面的文本的时候，那你你其实不知道后面的文本是什么。但是你你居然能够你居然能够对这个contest理解，比boss这样知道的文本前文本后所有的信息的这样的这个分类器还要好。这个听起来就感觉我就不是，其实我那个时候就觉得这个超完全超出我的理解的这个范畴。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:57",
      "text": "对，其实在这上面也有很多paper试图去解释，就是你到底encoder decoder好，还是decoder only也好。然后这个东西也没有太也没有定论，基本上的其实encoder跟decoder没有什么太大区别。其实你想他们都是transformer base的对吧，他们都是knowledge representation的一个方式。我觉得大部分paper其实最后你就研究到最后就发现你其实encoder出来跟decoder only出来这个performance其实也没有差太多。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:30",
      "text": "对，然后你说bert跟GPT three比的话，那GPT three还是比bert。首先bert就没有in contest learning的能力，对吧？GPT three还是有in contest learning的能力的。其次你要fairly的compare这两个model，其实也不算很fair。因为你做你用word的话，你必须要进行find tuning对吧？然后GPT three的话，它很多task，它不用进行fine tune，他就用zero shot或者few shot，其实就可以达到很好的performance。然后你拿zero shot future of performance跟fan tune on performance比，其实也不是一个很fair的比较。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:04",
      "text": "我感觉对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:04",
      "text": "然后另外一个是bird很小，你的GP3很大。GP3有175比特，but各种size就是在million level的，所以这两个也不是可以比的。然后我觉得这里面可能最大区别，如果一定要说GPT three为什么比bert就在很多task上面能力要强很多的话，我觉得是因为juty three你想如果他因为首先它capacity更大。他一既然有175 billion的premature，然后其实他training的时候，见过的token也会更多。如果你想如果一个小孩子学的东西的话，他如果比如说他只读过像birth，是只读过VK pedia跟book copies。他这是两他有两个唯一的pretrail copies。然后GPT three是读过web上的很多更多就是更高coverage the copies。你想如果让同一个小孩去读这两个copse的话，那那个小孩最后学的那就哪个能力会更强对吧？那肯定是读过更多copse的那个小孩更强，对应应该是可以这么解释。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:01",
      "text": "我们看到就是我们看到包括微软什么，各个公司也都在推出自己这个大模型。我们未来会看到就是这些模型都在往越来越多的参数去走。在这个增加参数的过程中，我会看到哪一些可能的挑战和瓶颈，或者说还有哪一些除了增加参数之外，就是对于提高这个模型的能力还能够有比较大的影响的一些一些一些改进的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:30",
      "text": "从我这边来讲的话，我觉得可能另外一个最重要的factor其实是去年一篇paper。那个paper是从deep mind来的，然后那paper叫去了，然后他那个title好像是什么training compute optimal language models。然后它里面最重要的一个finding是说，instead in addition to model size，可能最大的另外一个区别就是你在确定过程中见过的token数。然后他们发现比如说你把同样的一个language model，你比如说把它pretend在一个地方，他们提了一个车那个model。对，然后你那个地方可能并不是optimal的。你有时候可能portray你你你比如说定了一个model size 175B然后你有一个training copies，然后你确定到某一个point你就停了，对吧？他们发现其实那个point可能并不是最优的point。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:25",
      "text": "你如果把同样的model你什么事情都不变，你让他继续train，就让他见过的token更多的话，这个model的capability还是会继续增长的。然后他在那个paper里面推了一个option的公式。就是说你对于每个model size的话，model capacity的话，你去你让他建多少个token是最优的对，然后这个事情其实非常重要。也就是说除了model size之外，你这个model在training for trading过程中到底见过多少个token，是一个也是一个非常重要的factor，就是决定了最后model的capacity会model performance会怎么样。然后像我们这个palm paper其实也是有类似，我们其实用那个推论也去证明了一下，做pm我们四月份发那个paper的时候，所有的model包括我们62B的model，540B的model，见过的那个token size是一模一样的，都是接近于0点80个token，应该是0.78到0.79个确认token之间。对，我们去年大概八月份九月份的时候，用training那个idea further去把那个palm就continue for training，就是让他见过的model，让他见过的token size double了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:36",
      "text": "我们后来推出了一个，你可以看我们现在palm paper有一个appendix。然后那个appendix有一个model叫做palm trailer prom trailer。就是说我们把palm 62B的那个model，它原来见就第一次train pretrail的时候，见过的token数是大概是0.8T然后我们把它double了。就是我们continue portraying了一模一样的时间，就是让他见过的token double了。然后我们发现这个62B的这个palm model，其实很多task上performance甚至超过了540B的那个那个model的performance。所以等于说你model size固然是一个重要的factor，但其实还有一个很重要的factor，就是这个model在retraining过程中到底见过了多少token。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:19",
      "text": "就他见过的token数，也就是其实你可以想象，如果是比喻成一个小孩他看书的话，他你可能有个web office，对吧？那他是看了一半的web office，还是看了所有的web office？他web office看了一遍还是看了两遍，其实对他最后的performance也是有很大影响的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:35",
      "text": "就是分了两三年，我们会看到越来越大的这个last lengths model。还是说你们现在感觉其实他这个参数的增长，其实已经到了一个瓶颈期。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:46",
      "text": "这个事情首先我觉得scale up是一个easy route，就很多人还是会take这个route，因为你永远不知道它的limit在哪，对吧？然后scare up就是一个就是相当于你是一个很容易往上走的方法，你就是throwing更多computation power就可以的事情。所以很多人还是会继续scale up的。我不觉得现在model到了limit，然后其实不是有很多有很多新闻说，比如说GPT four有可能是一个trade size的model对吧？所以这样wise我觉得还是有继续往上升的空间的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:21",
      "text": "其次从那个trainer或者他们trailer的performance的结果我们可以看到，就是在model size之外，你见过的token数，就是我们我们这个copps其实到现在还是没有饱和的。就是我觉得你对你你model size可以继续往上scale up。当然如果你的copies变得更大的话，你model size自然也得scale up，不然的话这个model也记不住那么多的东西，吧？所以我觉得网上scale这个还是应该是有一定空间的。然后这个limit在哪儿，现在也没有人知道，因为还没有人给到那个地步，不过也有可能很快就有人知道了。对，然后另外一个就是我觉得现在很多study都说，其实我们现在即使我们有很大的web cops，但这个web copies我们现在确认的时候还是sample过的。所以它里面还是有很多tail knowledge，可能language model是记得不是很好的。所以这里面还是有空间让model见到更多的copse里面的内容，然后更好的记住里面的technology dge这些东西。",
      "speaker": "发言人3"
    },
    {
      "time": "00:29:19",
      "text": "我想把research和产品化稍微分开一点，从research和模型建立的角度上来说，完全统一scale up是一个easy road，而且它它可见的就会有比较好的效果。但从deployment上面来说，其实即便是我们现在说的pom或者说GPT three GPT马上要来GP four这些他一百多B的参数量，其实对于推理来说已经会有一个比较高的成本了。那就更不要说我们还要再去skill up。就即便是我们说硬件的进步，我们的架构在进步，但几百B的这样的参数量对于计算来说都会是一个很大的一个burden。包括各种部署，我们包括各个小的场景，如果想做find等等这样的一个参数量下面，任何的操作都会是一个很大的一个压。对于想要做这样做的人来说，都会是一个很大的压力。",
      "speaker": "发言人4"
    },
    {
      "time": "00:30:16",
      "text": "在不同的场景下面，从产品的角度上来说，比较大家确实会比较期待能看到一些更多的更轻量的模型。可能几十倍是不是能够更多，是不是能够在现有的架构结构下面去做蒸馏？是不是能够探索出更轻量的解决方更轻量的解决方案。在现有的这即便是我们可仍然需要他去看大量的这个train token，但最终能够负责于deployment的部分应该是足够轻量的，这样这个应用场景才能更好的成长起来，否则会有一个比较大的一个成本压力。",
      "speaker": "发言人4"
    },
    {
      "time": "00:31:01",
      "text": "我觉得这个角度特别好，到时候我们可以就是这个大模型也好，还有在这个不是training，还有推理，在实际应用中落地的一些一些一些挑战和一些最佳时间。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:13",
      "text": "我这边也跟进问一个问题，因为很多人也提到说当前的AI是data centric machine learning。刚才学者也提到现在模型越来越大，然后学者也一直在探寻怎么去unlock这个模型的新的能力。对于未来这个foundation model的发展的话，模型规模变大，会不会高质量的训练数据变成了一个比较大的瓶颈呢？",
      "speaker": "发言人5"
    },
    {
      "time": "00:31:41",
      "text": "如果问我的话，那是的，我那取决于你要拿这个model去做什么。对，我们确实发现在有一些task上面，这个数据的quality还是非常重要的。其实在palm里面，我们应该有写过，就是我们pretrail coppers的那个selection。我们会倾向于手include一些high quality的data，比如说VKPDA book cops这些都是high quality的。我们会尽量的把所有的data都include进去。然后其次比如说是web document的话，你如果像网上的那个document，那它的质量就会他们的质量就会比较参差不齐。这样子的话我们会根据比如说document它本身的quality去sample。就比如说高质量的高quality的document我们可以会sample的多11点，然后低quality的document的话我们可能会sample的少一点。",
      "speaker": "发言人3"
    },
    {
      "time": "00:32:29",
      "text": "我们palm的prety copers大概是这样决定的对对对，但这个事情quality好与坏这个很难说。比如说有些model，你比如说想想让他在一些比如说conversation这种ability上面performance特别好的话，那你不得不include一些conversation的data。但conversational data，比如说你只能从redit或者一些别的地方过来，然后这些quality可能就质量有些时候很难保证。所以也不是说你想要high quality data在某个抖音上就一定能拿到high quality的。所以high quality当然非常重要。但是也有时候我觉得是网上数据数量也是有限，也不是有我们可以随便控制的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:14",
      "text": "我我可以我可以插一句讲data quality这一块，但是我不能提供这个语言上面的language model上面的一些inside，但是我可以提供一些CB上inside。如果你的task是计算机视觉的话，它的那个它的质量跟质量数据质量在我们看来，尤其在做产品的人看来是远远重要性是远远超过这个模型本身的。尤其在我之前在蓝点的时候，我们大概我们在做这个就是在做manufacture这个行业，给他们做SARS，然后做分类模型和分割模型，做任何的pass。我们使用我们几乎使用过市面上很所有的主流模型，甚至我们还会使用一些sota的模型。就比如说我们刚开始做的时候是2018年的CVPR。我们甚至把整个CVPR全部都扫了一遍，大部分的引用次数高的模型全都用了一遍。然后我们再然后再做了一些在做了很多关于不同模型同样数据的对比，以及同一个模型不同数据的对比，以及不同模型和不同数据的对比。最后的结论就是数据本身的质量以及数据的标注的质量，都对最后的结果产生了决定性的作用。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:39",
      "text": "所以那个时候2019年，应该是2019年年初的时候，就吴老师写了一篇文章叫做data centric AI。当时我们写那篇文章的最大的原因就是在于这个data它是我们觉得data是非常重要的，尤其是在这个language还好一点。我们觉得我们那个时候一直觉得language的做语言模型的人很幸福。你直接上你上网下载就行了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:06",
      "text": "我们要拿到比如说我在我们去做那个有一个客人，客户是韩国的车商，韩国的车厂，我们给他做这个质量检测的这个分类模型，我们可能要我们拿到一个类型的模型，图片拿到5张1个类型图片，可能要在这个生产线上一两个月的时间才能拿到五张这个类别的那你出来的话，我们的模型出来，一开始我们想到说，它有一个分它的分类模型里面有个类别，我们没有任何相关的数据怎么办呢？当时就是说我们用自由shop，自由shop根本就不行，完全过不了他那个过不来的测试。后来大家就想别的办法，就想到说我们使用当时刚刚18年，那我们使用干吧，我们干两个。这个生成的图片出来就生成出来的图片那个模型训练是很难收敛的，收敛出来的这个图片又不够真实，所以最终你就只能等待真实的数据，这个给我们了很大的困扰，所以我们才会认为这个数据是很重要的。但是，同时我们看这个GPT，就像我刚才问这个问题一样，就是我们看GPT2和GP3的变他们之间的性能的变化。虽然我同意学制的观点，就是说你这个income，你这个in contest learning可能是一个很重要的东西。虽然我没有太读懂，但是我的真的给我最有共鸣的就是他的那个fine tune task里面，有了除了ZO shot以外，有了one shot和和这个few shot。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:48",
      "text": "我看到他们大部分的在那个apple to apple comparison里面，大部分的那个zero shot learning的准这个task准确率在30左右。但是one 12的平均值居然达到了四十多，这一下子就是30%到50%的这个提升。就一张图，不是一张图，sorry, 是就一个数据点。你就达到了30%到50%的提升。我觉得这一点也也这点也算是怎么说呢？也算是一个信号，说明这个数据是很重要的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:24",
      "text": "如果以后每一个领域这样，每个领域其实你要去圈都只需要非常少的这个数据的话。那是不是以后就是build一个要去做一个非常具体场景的模型，其实它的这个成本其实是越来越低了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:40",
      "text": "这个我有可能的我觉得模型本身应该是同通用模型。实际上到后到最后通用不同的通用模型，它在同样的特别高的数质量的数据面前，他们的表现很有可能是类似的。我打个比方就是我们原来做在在制造业上做那个分类的时候，一开始就用rest的。因为这个rest net是rest是图片，当时是图片分类里面最最通用的那个程序那个那个网络。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:13",
      "text": "我们后来发现一开始这个分类的水平是不好的，没有达到我们客户的要求。但我们客户要求也很高了。可能99%以上的这个accuracy就F1F1f one school。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:27",
      "text": "非常高，不是像这种什么60% 50%这种是非常高的那非常高，我们开始觉得是不是有一个什么特殊的模型可以达到它呢？所以我们试了很多跟reset类似，但是又跟它不一样的模型。像unit，像mobile net这些，或者什么retina net，所有的这些模型我们都试过一遍。但是我们发现可能有高有低，但是大家都在一个水平线上。直到有一天我们拿到了标注质量特别高的模型，数据泵一下你一串，你发现所有的模型他们的准确率都上升了一个台阶，大家都挺厉害的那最后我们发现最后我们就问自己说那是模型厉害，还是数据厉害？我们的结论就是还是数据上更厉害。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:11",
      "text": "所以我们最后就提出来了两个，吴老师中提出两个概念，一个是data 3g ai第一个，第二个是small data ML他所说我觉得他所说的small data并不是说我们不需要特别多的数据。而是说第一我们的数据要质量特别高，第二就是我们的数据需要平衡。也就是说其实跟那个to alizon，就LM里面的ization是类似的。你如果能在一个高危空间去去去做很好的对对一些有意思的重要的feature，做这个很很好的数学表述的话。那我其实只要这个数学表述是存在的那我们的数据的质量也是足够好的。那你就能看到你你一定能看到这个feature，你能看到这个feature，你的所有的相关的vision上面的task应该都是质量会很高的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:09",
      "text": "对，就是如果从生成模型角度上来说的话，其实我们现在的经验是一开始的他阶段能看到的数据量以及它的丰富程度是非常重要的。量可能会比对于我们来说量第一阶段量会比质更重要。当然会必须要满足一点最基础的要求。比如说文本和图片需要对齐，这一部分的质量是需要求高的。但比如说对于图片本身的质量，我们指的质量是美学的质量。或者说它的图片我们图有一个图片质量评分的一个系统，就是它的这个清晰度等等。这一部分不需要特别的高的pretend的阶段，但需要尽量的多。这样能够给language model，我们可以给我们的这个生成图片，生成模型里面负责semantic，负责language那一部分更多的输入。",
      "speaker": "发言人4"
    },
    {
      "time": "00:41:05",
      "text": "然后再这样生成的一个基础模型，我们再对它进行翻译。翻译的时候切换成美学评分高的质量评分高的数据集量可以少很多。通过这样的一个方法，能够让他在能够生成更多的内容，同时对于理解更好的同时，生成的质量也更高一些。然后包括对一些specific domain，比如说大家现在看到的一些像dream boost这样的应用，或者说是一些其他的fine tune之类的应用。",
      "speaker": "发言人4"
    },
    {
      "time": "00:41:35",
      "text": "基于一个我们已经训练好的通用大模通用的这个图像生成模型，想要扭转到某一个领域里面，其实需要的时间是非常短的。现在比较先比较好的方法可能几十分钟去做一个在一个消费级GP上GPU上去做翻，就可以把一个通用的图像生成模型扭转到扭转成一个从specific图像生成模型，前提是没有给他植入新的概念，如果要植入新的概念需要时间更长一些，可能需要几个小时。我看的比较多，比较细节的话可能需要几天，但这都是消费级GPU能做的事情。",
      "speaker": "发言人4"
    },
    {
      "time": "00:42:12",
      "text": "从这个角度上来说，是图片生成模型需要一个极大的图文。对这一个图文对的图片文本对齐需要好，但我图片质量本身不需要太高。其实我们说的图片完全文本对齐质量高，也不需要特别的高。就像clip这个这篇文章的贡献很大的一部分就是说这种比较稍微lose的这种对齐的文本，对也可以训练出很好的图文本图片的这样对齐的模型。然后再就是在doma specific以及我们最终训练高质量模型的时候，数据质量对于后面的部分是非常重要的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:42:59",
      "text": "我们刚才聊了很多large model的这个话题，正好就跟一舟聊到大家也非常关注的这个stability AI就是生这个生成式这个图片。我想对于我想很多人相信都已经都已经知道这个stable diffusion，还有这个stability ai，但是对于有些可能还不那么熟悉这个朋友会想请一周可以给大家简单做一个介绍，它背后大致的一个原理是怎么样的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:27",
      "text": "好，两个问题，一个是stable diffusion到底是什么？Stable diffusion刚才大家聊的时候提到它是一个annoyed的一个模型。但是它不完全是它是一个被该，它是一个有condition的analyzing。它是一个能够前面会有一个小的语言模型，我们叫encoder tex encoder。然后这个taxi coder负责把文本转化成计算机能够理解的一堆evidence，或者说我们叫那个hidden states，就语言模型里面的hidden state。",
      "speaker": "发言人4"
    },
    {
      "time": "00:43:56",
      "text": "然后我们把这个语言文本文本encode成计算机能够理解的这些语言的in bedding以后，我们把它fed到一个顶一个unit里面。这个unit负责的是基于这个文本完成一系列的降噪过程。就从噪声中每一步从根据文本生成相对噪音比较低的图片，然后再一一级一级一级一级这样的去把它生成出一个完整的图片。但这个图片目前还不是人眼可以理解的，目前是一个就在计算机中的表示。然后我们还有一个VAE在后面，通过这一个VAE再把这一个计算机表示的这个图片皆拔成人。能够理解的就是RGB图片，就正常的一个完整的一个图片。简而言之就是给一段文本经过几秒钟的时间，它可以生成一个跟你的文本描述尽量相似的一个图。",
      "speaker": "发言人4"
    },
    {
      "time": "00:44:58",
      "text": "他跟之前的一些大家看到的像之前有类似diffusion clip guided diffusion，然后condition在这个文本lector上，condition在这个clip的上面的一些生成模型有什么区别？在那之前其实大家还有一个大家印象比较深，应该还有这个耷拉e two这个系列的模型。那三个馍三个区别，一个是它开源，那开源的意思是我可以拿到weight，我可以拿到模型推理的代码，我可以在自己的消费级PPU上去做部署。这个开源其实是stable stable disease能够成功的一个非常大的一个原因。它吸引了大量的之前可能没有办法访问到API或者访问到API。不知道API后面发生了什么事情，想自己开发一些东西的开发者，个人看一些甚至是爱好者来把这些模型来用起来，这是一。",
      "speaker": "发言人4"
    },
    {
      "time": "00:45:53",
      "text": "然后二是它的生成的部分，我们的生成的就是我们的target不一样。我们target不是生成finalities尽量高的图片，而是生成感知效果尽量好的图片。这样生成的出来的图片我们翻完了以后，也许在整体的annoyed的就是如果从数值上去评估的话，它的noy ability可能是不如一个特别通用的一个模型的。但从感知的效果上来说，从生产出这个可用的图片的效果上来说，它的效果是更好的这是2。",
      "speaker": "发言人4"
    },
    {
      "time": "00:46:31",
      "text": "然后还有一点就是社区，然后这个社区其实跟太原我们比较近了，在stable在在stable division训练的过程中，以及后面的这些应用的过程中有大量的不同的开发者来参与到，让应用成长的非常的快。这一部分也是让building能够被很多消费者用起来，像有外部UI有invoke KAI，想部署到本地的。然后国内有很多不同的厂商，国外也有很多厂商部署了基于stable decision服务。然后让大家能够看到说，这样的一个纹身图片的一个模型到底能够做到些什么。得到当然也跟这个模型的site本身比较小，也就几百M然后加上test code也就一个B这样的一个size有关。大家都可以比较轻量的推理起来，成本也很低。",
      "speaker": "发言人4"
    },
    {
      "time": "00:47:31",
      "text": "这个正好刚才问也问了雪之类似的这个问题，就是我觉得这个领域其实竞争也非常激烈，对吧？我们看到除了stable diffusion之外，就OpenAI的这个交易，然后就没journey，还有gool也有这个image。帮大家理解一下我们现我们怎么看待这几种模型的差异是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:55",
      "text": "我们这么说，像达拉毅这样，先从达拉一开始说，达拉E其实定义他给他在这个领域来说是个非常大的一个贡献。包括一开始的论文，然后后面的发布出来的服务，其实给文生图领域设置了一个说是标杆也好。因为我们很多的工作其实都是由达拉伊的这篇论文引领的。里面有很多内容的唯一部分的然后后面的fusion，然后后面的fusion的部分，open I之前也发过几篇DO关于这个division model的论文。这也是我们很多工作的基础。这是从学术角度上来说。",
      "speaker": "发言人4"
    },
    {
      "time": "00:48:39",
      "text": "从产品角度上来说，大家以一和二给大家一个非常II Candy或者说非常大的一个冲击。可以有产品可以做成这样的事情，但他没有做到的是什么呢？因为API是封闭的那API封闭的API其实对于二次开发来说是有一定的限制的。虽然我们可以在上面去做二次开发，但是二次开发大家可能会有很多担心。比如说最经典的最近出现了一个case，就是jasper基于GPT3开发出了API以后，那OpenAI出了check ChatGPT我怎么办的问题。那那但自己。",
      "speaker": "发言人4"
    },
    {
      "time": "00:49:19",
      "text": "如果是开源的模型。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:21",
      "text": "大家不会有这个担忧，这是一。然后另外其实对于技术的理解的基于API去做的话，与你自己拿到了模型，自己去完全看里面的代码还是不一样的。比如说像dream boost这样的应用，然后像这个后面很多把一些老把一些曾经语言模型的方法放到那个图像模型和lora这些应用。如果是只是在API level的话，可能不会有很多开发者来参与的。这些应用可能出来更晚一些。像这样我们一个开放的模型，大家都可能比较会比较快的可以参与。",
      "speaker": "发言人4"
    },
    {
      "time": "00:50:07",
      "text": "达拉E说回说这几个产品的区别。达拉E的它是一个相对封闭的一个API，然后它可能没有能够他代替了一波浪潮，但没有达到那么大的一个impact。但in pack已经非常大了，我们要那个credit这一点，但他依然是我们可以说这一波文生图里面的一个非常重要的，或者说是一个里程碑式的一个应用。",
      "speaker": "发言人4"
    },
    {
      "time": "00:50:38",
      "text": "但他还有一个，现在大家为什么社区对他没有那么喜欢，或者说个人消费者对他们没有那么喜欢？因为他生成的图片的风格更倾向于说我们叫stock photo，更更一本正经。他可能缺少一些，不管说是tic也好，还是一些比较created的元素在里面，他他比较会比较那个orthodox一些。那从社区和个人消费者和创作者的感知上来说就没有那么好。但他对设计师以及一些实际的图片工作者来说，可能是一个不错的应用，有可能是一个不错的模型。正好跟他正相对的是midi journey。",
      "speaker": "发言人4"
    },
    {
      "time": "00:51:20",
      "text": "那made journey的意义是什么呢？Middle journey它是一个社区，它具备了大量的创意，创意工作的这种大家大量的个人消费者对于这个领域感兴趣的人，可能开发者没有那么多。它更多的是一个以creative为核心的一个社区。",
      "speaker": "发言人4"
    },
    {
      "time": "00:51:35",
      "text": "那这个社区它的还有它的模型会有一个特点，是它的模型其实单纯从模型的能力上来说，跟大家E和stable division差别有很大吗？可能没有很大，但它的生成图片的质量，以及你需要去跟图这个模型交互的方式是非常简单的。你需要一个短prompt stable dimension。大家可能知道那个所谓的咒语或者说那个长prompt，你需要几十个词去get它，让它生成一张非常接近你的描述。你可以非常精确的去控制，然后生成质量也很不错的一个图片。但是你需要付出一些me journey的特点，特别是往现在他从V1、V2、V3走到现在的V4，很大的一个特点是你不需要去做这件事情。",
      "speaker": "发言人4"
    },
    {
      "time": "00:52:21",
      "text": "你需要一个非常短的这几个词就可以生成一张图，非常好看的图。然后这张图的构图是好的，美会有一定的美感，并且有media journey自己的风格印记在里面。它是一个很好的to c端的或者是to创业者的一个应用。它非常容易控制，可用易用效果也好。然后有一个很好的一个社区围绕在这里，你每天在社区里面看到可以看到大家都做出非常很多很多好玩的图来。",
      "speaker": "发言人4"
    },
    {
      "time": "00:52:53",
      "text": "Stable diffusion in between它是一个基础模型，我们在美甲上做了一些东西，但是我们没有特别的在易用性，或者说在把它扭转到某一个领域里面。他他你可以去给他生成沟通，你也可以拿它去生成这个Midjourney这样的艺术的的图片。但是你可能需要付出一些effort，不管是翻翻也好，还是需要用一些long form的方式去去condition它也好。它是一把像瑞士军刀一样的，你可以什么事情都可以做，但做每做好每件事情的可能都不如暂时不如这个领域的专业工具的这样的一个模型。那你需要想把它做成你想把它做的在某一个领域做的特别好的话，就需要做一些比如说by tuning，或者说是pump的事情。那基于它就可以有很多不同的应用，像dream booth真boost有非常多的人。",
      "speaker": "发言人4"
    },
    {
      "time": "00:53:51",
      "text": "现在可能有十几成千上万的模型在外面，都是大家已经翻听过的模型。刚听到各个领域。也会有说像基于这个模型尝试去做一些其他任务的去翻，甚至把它翻到这个有一个特别有意思的应用是把它翻译成到了一个我们一我们声音其实是波形，对吧？他把它波这个波形翻送到了生成的图片里面，所以你生成出来的是一张web的图，然后再把这个声音这个图拿去播放，把stable diffusion直接转成了一个音频生成模型。有人做了这件事情而且成功了，很有意思，效果还不错。",
      "speaker": "发言人4"
    },
    {
      "time": "00:54:38",
      "text": "对，但是它只能是短的，因为它那个图很小。但就是这一类的应用，是不管是就是加拉意是做不到的。因为你首先你拿不到模型，没想不到做这件事情，那made journey也不行。因为它不是一是还没有开源，二是即便开源了，它这个模型本身可能也已经是一个heavily tune to这种非常有设计风格图片的一个模型。",
      "speaker": "发言人4"
    },
    {
      "time": "00:55:04",
      "text": "Stable division是一个相对开放的，但在每一个领域都不是一个特别是一个更基。怎么说开放的foundation model，还是一个foundation。所以这三个的区别主要在于这一点，这里可能风格化会更明显一些，更像一个产品new journey是一个更像一个产品的东西。",
      "speaker": "发言人4"
    },
    {
      "time": "00:55:27",
      "text": "Ability是开源这个模式，那对于开源这一块的这个模式不是很了解的同学，那stability它的这个商业模式是怎么样的？现在我们看到的或你们遇到的就是开源，你VS就是直接提供个API，刚才其实你也涉及到一些这两种模式，它可能有什么process cons.",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:52",
      "text": "开源我感觉还是一个很快一个可以让一个领域快速成长的一个很好的一个路径。Stable division验证了这一点。然后我之前有非常多东西验证这些就是从零，不管从linux说也好，还是说一些我们现在看到很多数据库，用数据库应用也好。开源还是开源，是让一个技术普及一下，普及的一个非常重要的方式。也是让这个领域能有更多人开发贡献去让更多应用成长起来，让这个领域快速推进的一个方式。",
      "speaker": "发言人4"
    },
    {
      "time": "00:56:26",
      "text": "说到商业模式，其实开源商业化这一边，你这个话题也不是一个新的话题了。大家对于开源商业化有各种不同的讨论。从一个现在正在做开源，或者说把自己的主要能力全部commit开源的一个角度上来讲。它的好处是明显的，我们刚才提到了。坏处可能也比较明显，就是我的商业化没有那么直接。我不能说像卖一个封闭的API，而且我有明确的这个compact edge，你达不到我的模型，我的模型就都是比你强。那我们API卖的比你贵，我的API卖的比你好，你没有办那我没有办法。那这样对于这个公司的商业化能力会有更多的要求。",
      "speaker": "发言人4"
    },
    {
      "time": "00:57:09",
      "text": "对，会有更多的要求。比如说那那要么就是分成两个部分，基础模型的部分。我要基于基础模型提供服务的话，我需要比其他的基础模型提供方的有更大的吸引力。吸引力来自于可能亟需要来自于不同的地方。不管说你有更低的成本，我的API就是比你便宜。因为我的那个架构做的好，也就是这算是一个到另外一个就是比如说是不是会提供更好像围绕这一个模型，因为更了解或者是一些我们的研究更更我们的研究走的更往前的一些原因，围绕这个模型能够提供更多更好的服务也好，这是一部分。",
      "speaker": "发言人4"
    },
    {
      "time": "00:57:55",
      "text": "因为模型出模型太太远了，也不代表说所有的模型的所有的内容都会开的那还是会有一些能耗在里面的这是一部分。另外一部分就是基于我们能够训练出这些模型的，已经有track record的这些能力。这个训练模型的能力本身我们拿去商业化。这就是比如说去做给企业，给一些创意公司，给一些大型的创业公司，或者说给一些互联网服务服务商等等去做定制化的模型。然后再去设计，基于一些私有数据去做模型的训练。他是因为基于所有数据数数据去做的模型的这一部分肯定是没有办法开源的。当然这一部分模型客户会去拿来做什么，就跟科跟一些商业都有关系，我没有办法去细说。",
      "speaker": "发言人4"
    },
    {
      "time": "00:58:50",
      "text": "但这这像这一部分的通告就还是顺畅的。而且毕竟因为开远了，毕竟因为我们这开源的项目有trucking record。大家也知道说，这个东西确实可以用起来的，开源项目已经被证明过了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:59:08",
      "text": "那是不是后面去做合作，去做这种deliver也会更顺利一些。主要是这样的一个逻辑，他会跟闭源的商业逻辑非常不一样。但同时也是一个之前被验证过的商业逻辑。但是站在他同大模型领域，从基础模型领域这样的一个商业逻辑，到底可以走到什么样的一个how far can we go？这个还是一个可以我们正在探索的一个话题。",
      "speaker": "发言人4"
    },
    {
      "time": "00:59:40",
      "text": "对，因为其实开源在像数据库，还有一些这种数据数据产品上，其实也相对成熟，这个上市公司也都有了。但的确基于开源的这种AI的商业其实还是比较少的。正好问一下这译文。因为译文其实一方面是在这个科技大厂做machine learning的产品经理，另外自己也做这个天使投资。而且我想也是经历过上上一波AI AI热潮的热潮人。所以我好奇就一文你怎么看待这个AI的商业模式设计这一块。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:22",
      "text": "对我的那个观点可能比较我的观点比较鲜明，可能或者说某些人看来可能会比较偏激，所以我希望大家都take a great。他有很多，我就基于我自己的体会来讲，首先我要说从模型的角度来说，我非常赞同其实我我非常赞同那个stability AI的这个决定，就是把这个模型开源。有一些我我有一些OpenAI的朋友跟我讲过一些数据，就是说无论从内部数据来看，还是从外面的我们我们能我们能感知到的这个变化来看。",
      "speaker": "发言人2"
    },
    {
      "time": "01:01:00",
      "text": "大意刚出来的时候，大e two刚出来的时候是非常火的。但是一旦stability出AI出来以后，今天已经没有人讲大意了，这是为什么呢？这是一其实我们仔细想想的话，你从产品的角度来想想，其实是不难理解的。今天这一代以the noising diffusion为主的这种这种这这这套solution，他的演技是非常快的这是第一点。第二点是其实生成是AI，在图片生成这一块的话，它的这个problem face是什么样子的，没有人知道，它定义的非常不好，大家全部都在探索中。你说什么样的process space是有意义的、重大的、值得投资的和值得投资人去投资，或者值得企业家去创创业的呢？其实我就就我们之前讲过，我最近两个月AIGC的公司看了有两三百家，图片和语言可能各占一半一半，可能图片稍微多一点。",
      "speaker": "发言人2"
    },
    {
      "time": "01:02:00",
      "text": "我没有，我基本上很难看到，可能对我来说我能满意的problem space definition，可能也就只有不到10家公司我能看到的那也就是说其实哪怕这十家公司，你也只是只是我觉得我觉得他们的定义还可以，但不因为以我自己有限的见识来说，我们也不一定都是对的。那那既然在这个既然大家就第一不知道你的promise的是正确的promise的是什么。其次你也不知道你的现在solution space是不是最佳的。我打个比方就是stability，刚才一周说的很，我觉得我也很赞同一点，就是me journey和me journey大意和这个stability他们其实他们的solution，从你看到他们solution开始，他们你就会发现他们solution去对准的那个go是不一样的。就是说他们心中认为的AI生成式AI的这个生成式AI的这个产品的这个problem space的理解也是不一样的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:03:00",
      "text": "那那现在最最需要的是什么？是更多的人来试图理解它。所以一个开源的一我认为一个开源的环境才能够你才会有，你才会很容易的建立这个生态。你看现在bd建立的开发者生态和大邑建立的开发生态相比，后者我觉得我个人说句不客气的，就是可能会比speed要它的活跃度要差很多。我觉得这是space的优势，这是第一点。第二点就是回到去看我们这些AI我之前上一家公司是AI我们可以叫做AI SARS1.0的公司。",
      "speaker": "发言人2"
    },
    {
      "time": "01:03:36",
      "text": "那AI SARS1.0的公司里面，我们有一个我们一个最大的PKC位，就是没有人能在模型上挣钱。你今天你打个比方，你SARS1.0，我没听说谁对吧？我没听说rest net发明人对吧？他做了一个renee d的API他在facebook他做了一个专业的API然后拿出去卖钱是不可能的，没有人会买的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:03:56",
      "text": "邵宁波的开也没有人通过，比方开源某某一个model的证。",
      "speaker": "发言人1"
    },
    {
      "time": "01:04:00",
      "text": "对吧？那没有，所以对之前JF就是google的GFD写过一篇文章叫做the legacy ML system。他会讲出一个整个ML ops的系统里面会有model的工作，只占了5%，其他全部是hidden technical dead of our system。那篇文章对我的影响非常大。它里面就讲说你从第一张图片，你从第一个data point进来，到最后你你你你把你的模型deploy出去，然后再做monitoring retrain。这些才是一个真正的commercial ML系统的一个111个1个一个端到端的流程。其实当我看到这篇文章的时候，我第一件事情想到的是什么呢？第一件事情想到的就是以前那个linus就是那个linux的核心作者，他讲过一句话，他说你的你的你的软件piece of code，其实你把它看成你piece of code，你可以也可以把模型看成piace code，peace of code.",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:02",
      "text": "它只有这个所谓的commercial value，就是商业价值，或者说叫交换价值。今天我有这个模型，我有这段代码，你没有我们一锤子买卖，我十块钱卖给你。这是30年前、40年前、50年前软件行业就是这么做的。但是现在未来往你你如果往未来看的话，所有的软件背后都代表着服务。所以你的你未来的所谓的commercial value，就是你的交易价值几乎一定是趋向于零的。你的软件背后包含的服务价值一定是趋向于一一定是越来越高的那那这件事情告诉我们什么呢？代码未来一定是越来越不值钱了，但是代码背后银行的服务是值钱的。所以我认为开源是我认为开源其实开源对于每一种模型来讲的话，每一类的模型来讲，其实都是应该来说都是有利的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:03",
      "text": "一旦你开源了以后，当你对你的当当你的你的这个eco system里面的人，或者包括你自己对problem space有了新的理解。有了对solution space有新的理解，你想改你的模型的架构，或者说你想你想优化你的模型在某些地方的deployment，就是在服务，在surface step里面的优化。那这些事情它的效它发生的效率会远远高于一个闭源的系统。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:34",
      "text": "打个比方，如果他IE的这个方向，他产品的方向是错的，就没有人用。他想改的话就他们那一人改。但是如果假设ability，打个比方，我们就随便瞎说。Stability现在现在的这个stable division stability division的in pending model 2.0，他最多是768乘768的这个分配数，这个数字不准。Making this up。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:54",
      "text": "但是如果说。他的这个in的模型这个版本，他对这个艺术美工非常重要，非常有用。一堆做美工的人觉得他很有用。但是这些人需要的不是768乘768的，人家需要4比3的5个mac的或12个mac的图片。那可能这些人自己就会可能会去想办法给他把这个模型改成五个麦克或12个麦克的输出。那这个比你要subletting，自己去改。如果你是一个客户，你去找stability说，你给我改一下，他可能付不起这个钱。",
      "speaker": "发言人2"
    },
    {
      "time": "01:07:27",
      "text": "所以我觉得这个ecosystem还是挺重要的那另外就是其实因为我自己也看也投过一些开源的公司。我觉得开源的公司的这个商业模式是完全不缺商业模式，你就最基础的最大开门你就走linux model就可以了，subsequent model就走那个红帽的model就行了。当然除了红帽帽，红帽的model也不一定是唯一的model。你可以有很多很多，就像刚才一一周说的，你可以有你你在这之上加载任何一样的任何的增值服务，可能都是非常有价值的。所以最近我也觉得其实再再插一句就是GPT就GPT现在ChatGPT现在非常火。但是如果有一个跟ChatGPT1样好的开源模型出现了以后，我个人感觉很有可能会那个模型的后面形成的这个eco system，会甚至可能会比今年ChatGPT要更毁。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:26",
      "text": "上一步我没有看到成功的这个AI开源公司出来，这一波我们预期会有不一样。是因为这个模型是因为什么原因使得这个model现在现在这个business model现在又变得是是可行的。",
      "speaker": "发言人1"
    },
    {
      "time": "01:08:41",
      "text": "对我刚我我其实我我自己有一个第二提出来的供大家参考。就像你说的，现在ChatGPT ChatGPT它已经开始提供有偿服务了，然后GPT3肯定他他也有这个commercial的或者professional版本的API服务。他之所以他之所以现在会有很高的人气，有两个原因。第一个他没有open source count，第二个就是他的那个模型训练，GPT3的模型训练已经比较贵了，大概100到200万美金。开发者虽然sabi也不便宜，60万美金，但是如果你往前看的话，到了GPT4GP4，我听说他的那个我我我这是我最近刚刚听说的这个rumor，说他的最开始的模型有100个缺点。这个parameter。他的训练成本可能在千万美金级别。",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:36",
      "text": "那如果我们做一个假设，GPT4可能2023年底2024年初出来。那我们打个比方，到了2027年GPT捂出来的时候，他的训练成本会不会上亿呢？假设还没有，假设他接近上亿，这个时候确实你就会发现说这样一种服务它还是服务。那这样一种服务可能只有像房这样的公司有这样的财力去稳定的提供了。那那可能可能那在这个时候，可能GPT这种类型的服务，它就变成一个像pass一样的东西。小企业已经不是初创企业可以去参与，在在底层已经不是初创企业可以参与的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:10:14",
      "text": "所以核心还是训练成本在改变。",
      "speaker": "发言人1"
    },
    {
      "time": "01:10:18",
      "text": "刚才因为提到的说模型本身的scale，然后训练成本，这是很重要的一个因素。刚稍微说的多一点的话就是如果下一代的商业模式是必然的话，那开个人开发者会变得更痛。因为他他去从零开始replicate一个内部的fusion，或者说是大家E所需要成本跟从零开始republic一个u low的成本是完全不一样的。有了我姑且我还是能做的。但到了stable diffusion这个级别，虽然我们在把不停的把这个训练成本压下来，最后可能降到19 10万美元多一点，几十万美元或者是奶罩不到12万美元。如果模型不大的话，但这个成本对于创业者和个人开发者来说都是很大的一个点。API和开源技术模型的意义就变得非常的明显，这只是一个方面，刚才这是成本方面。",
      "speaker": "发言人4"
    },
    {
      "time": "01:11:14",
      "text": "另外一个我想说一下，domain的不一样，就上一代的模型都会有一个特点。我们离直接的消费场景和直接的应用场景。我们先不说工业领域有非常多的应用，安防应用等等等等，但离职C端直接感知的消费场景都比较远。除了我除了这个，大家可能感觉到智能音箱是上一波说C端突然一个某一种AI突然走进C端。那就智能音箱扫地机器人，以视音频视频，以语音识别语义，然后到CV的等等这些应用都都在都藏在这些东西里面。但它只这个模型本身离消费场景还是比较远。",
      "speaker": "发言人4"
    },
    {
      "time": "01:12:00",
      "text": "就在在stable diffusion之前，我们是曾经听没有没有听过哪个模型。或者说在direction model之前，我没有听过哪个模型是一个爱好者会上会想方设法的去学python。然后或者不学python，我也要想方设法至少搞明白这些check point怎么回事，我要去拉模型way，这种事情我没有听过的那这个领域走到C端了以后，这个应用场景是指数级的增长，那就给了卖AI这件事情带来了一些可能性，这种可能性其实有一些侧面的反应的不是很好啊，但是是有一些侧面的反应。现在淘宝上有很多转卖为journ服务的，都还都还是卖了一些钱的那这是一个侧面反应，不是一个我们说的他对这个领域应该有的应用。但其实这是就是从这个角度上来说，我们看到的一些可能性。相对于上一代而言，直接做商业化的希望要大一些。",
      "speaker": "发言人4"
    },
    {
      "time": "01:13:13",
      "text": "我这边有一个关于开源闭源商业生态相关的问题，也想听听三位嘉宾的看法。因为当前的这个仿tax model还是仅仅提供这个API的服务，对于客户来说切换成本还是比较低的。我们看到其实很多的创始人也拿现在的这个商业生态来去类比。十几年前的这个安卓生态或者闭源的这个IOS生态，大家怎么去看呢？未来不管是开源还是闭源的foundation model提供商，有没有机会去形成像安卓还是IOS的这个生态平台。通过提供更多的更重的这开发接口，还有相关的开发者的产品，真正的提高切换成本。然后真正的让更多的高质量的用户形成商业上的粘性，以及这样的平台生态在工程上还有产品上应该如何实现。",
      "speaker": "发言人5"
    },
    {
      "time": "01:14:13",
      "text": "对，这个我也听说了，我也听朋友也说过了。但是我个人是不太认为他们能做成基础的操作系统的。还是回到还还是回到刚才那句话，还是回到刚才jack d的那篇文章，你的黑灯technical death有95%跟模型是没有关系的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:14:35",
      "text": "然后其实我也不是特别，我也觉得这个和IOS的这个类比也不是特别的恰当。我以前的苹果就是做手机的IOS的。这个IOS其实它之所以这么强，他的ecosystem这么强，他是把握住了两个最最基本的逻辑。说句把你把它说的你把说的好听一点的就是develop speed和user revenue。然后你说的稍微大白话一点，就是说你花多少钱，你能收到多少钱。那么在这个在安卓不同的型你在安卓不同的那个类型的手机上和IOSIOS上相比，你会发现IOS develop speed和develop的这个overhead cost是最低的，develop speed是最快的，然后它的revenue又是最好的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:15:28",
      "text": "你看苹果其实是不太会做游戏的。但是你会发现如果你去我正好有一批做游戏的朋友，在几年前，我就没有最新的数据了。在几年前的话我得到的信息是说，同一个游戏的一个游戏的制作室，一个game studio，它一套代码可以几乎把所有的最新的七8个IOS设备全部都覆盖到。然后就不需要完全不需要重复开发，然后他在上面的收入却远远高于安卓，安卓是每个设备都要统一开发，所以你从这两个角度来说，我们要问如果，我就要问了如果今天这个OpenAI你要去host一个所谓的操作系统，对吧？那你你给你给开发者提供了什么样的价值？你给他的这个revenue在哪里？你给他的这个develop speed在哪里？这个我感觉OpenAI没有任何的思考，所以我觉得没有办法去判断说他是否能做出类似于操作系统这样的eco system。",
      "speaker": "发言人2"
    },
    {
      "time": "01:16:30",
      "text": "我也比较同意这一点，我们没有办法拿一个大模型来解决所有的问题。就算是我们说以后language model大，一桶GP4GPT5GPT5能够走到一个真的非常贴近于AGI的这种文本交互的一个感体验。但他离生产环境还是远的。因为生生我们生产环境需要的东西不是一个一个我不是一个语言模型。我们需要的是一个能够一整套体系，从产品设计到产品本，到跟用户的交互，到后面需要跟上的人工的服务，到整体的。如果是电商产品或者其他的牵头供应链产品和供应链到后面等等。",
      "speaker": "发言人4"
    },
    {
      "time": "01:17:21",
      "text": "我们很难说以一个模型来称这件事情。它虽然模型在里面可能会配在一个非常重要的一个部分，非得用meta for的话，我理我感觉这相比于一个底层的操作系统，它可能更像是一个平台的一个提供商。有点像一个甚至是甚至有可能像一个consult自己的感觉。",
      "speaker": "发言人4"
    },
    {
      "time": "01:17:47",
      "text": "去去给大去给不同的行业，不同的产品解决这部分问题。他产品对它的依赖不在于它的平台的能力，他也很难hold住整个入口。能提供能力的这部分，我不怀疑他可能会被植入到非常多的产品里面。",
      "speaker": "发言人4"
    },
    {
      "time": "01:18:09",
      "text": "对，我我我就想打个比方，就是说我我自己觉得我自己个人觉得他最可能的是成为pass服务的一部分，pass里面的instance一部分。你比如说AWS，那AWS里面AWS里面有一种类型的AI的客户叫call center，对吧？你电话打进来以后，你你你比如说你今天去打电话，中国可能都是有会有很多人工，在美国基本上没有人。你打以后他就会有电话提示说，你你要你要问什么？巴拉巴拉，这其实里面就有这个，其实这里面就是ASR加上NLP。那ASG NLP的话，你在被你的掰，看今天的掰看是怎么做的？肯定是EC to serve了是EC to serve了。",
      "speaker": "发言人2"
    },
    {
      "time": "01:18:52",
      "text": "比如说打个比方，serve了bird，然后又serve了一个什么confirm model。打个比方哈那那你在开对于开发者对开发这个call center application的这个开发者来说，他需要去配置他需要去配置正确的birth的version对吧？然后再配置正确的EC。EC instance你是要8个AMD，你还是要那你还是要video，这是才是问题的最最关键的地方。当然如果我能看到，就是说如果我们能做出一个通用的像GPT这样的通用的language model，他他可以统一的所有的这些这些这里面的这些任务，他可以把ASRASR和这个NLP，还有其他一堆所有的这些任务都给统一了，你就一个模型就serve了。",
      "speaker": "发言人2"
    },
    {
      "time": "01:19:35",
      "text": "那在这个时候我就不需要去让开发者来配置了，我就直接我我我AWS可以直接往上面搁一个开源版的，比如说GBT neo x。打个比方，然后你都不需要选，你就不需要选ECQ了，你不需要配置ECQ，你直接配置这个模型上去就好了，他就能给你那这样的话开发者的开发速度得到提升，它的成本也可能得到降低。因为在这个时候你把它抽象出来了以后，你把这个API抽象出来了以后，你下面他你下面的硬件怎么选择呢？肯定是哪种硬件便宜。这个时候你可以有你自己的objective，你可能要QOS去优化QOS，你也可能要优化你的cost对吧？那它自动就给你优化了，那这个时候他可能就会成为pass服务的一部分，我觉得这个是很有价值的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:20:25",
      "text": "所以说这个open I自己做不成，但是他有了一个渠道叫做microsoft。对，我们最近看到这个，我觉得挺有意思。正好那个AWS we大会上，我看到这个AWS跟stability AI也有很紧密的合作。然后最近其实microsoft跟这个OpenAI的一个deal也是引起了大家注意。应该是几年前microsoft就已经在open I上投资了一个billion就十亿美金。然后最近好像看到是他们应该是在准备去sign，一个ten billion 100亿美金京的一个OpenAI的融资，要加起来11个billion的dollar的投资拿回来之前，他可以分到OpenAI75%的profit。",
      "speaker": "发言人1"
    },
    {
      "time": "01:21:12",
      "text": "我们经常有个经典的一个说法，就是说这个创业公司跟传统巨头的比拼，就在于这个传就在于这个传统巨头去anyway自己之前就创实践创新之前这个set up，能不能够解决好他自己这个distribution这个渠道的问题。比方上一波AI我没有看到任何说一个用AI来做，比如说这个drug discovery，这个药物研发的公司，好像没有看到有什么成功的长出来。但是我们现在看到的是，几乎所有的做药物研发的传统公司，其实都已经在开始多多少少应用上了一个AI所以我觉得一个对一个一个AI的创业公司要要接下来要怎么去随着这个技术演进，去做出他的所谓mote和护城河。我觉得还是一个挺挺挺值得关注的一个事情那正好刚才其实我们讲了很多business model事情。",
      "speaker": "发言人1"
    },
    {
      "time": "01:22:16",
      "text": "那what's next？下一步到底是什么？我个人的感觉是这个下一步其实里边其实有两个方面，一个是更偏science，更偏研究这一块，可能另外一方面就是更偏engineering这一块。我们稍微拆开来说，从研究这个层面来说，我们现在的这些尝试，他还有哪一些limit。他通过基于现在这个fundamental的这种逻辑的这些可能一些挑一些优化和微调，要给大家怎么样的一个天花板。要不这个雪芝听你来聊一聊。",
      "speaker": "发言人1"
    },
    {
      "time": "01:22:48",
      "text": "好，对，因为我个人的研究方向是偏natural language reasoning的。然后我们其实去年一年的研究也表明，就现在老祖land model，虽然他在很多NOP的task上面performance非常好，但是你如果给他一些更加chAllenge的task，它的performance还是不够令人满意的。比如说像reasoning这种比较复杂的task，就我们当时说这个东西其实有type one跟type to type one。就是说有一些task你是需要fast thinking。就是我问你这个问题，你立马就能答出答案。这些test上面来来来mode已经做的很好了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:23:25",
      "text": "然后另外一边就是type to type two。就是说我平时问你一个问题，比如我问你一个数学问题或问你一个微积分问题，你可能要想很久，或者你要很清楚的逻辑思考，就把这个结果给推出来。像这种问题的话，现在large land model做的还是比较差的。所以在很多的这些更加chAllenge或者更加complex的这种test task上面，拉出来model还是有提升空间的这也就是我之前说为什么现在还是有scale up的空间。因为我们现在并不知道页面在哪，就是在很多test上拉这个model，还是我们觉得还是有提升的空间。对。",
      "speaker": "发言人3"
    },
    {
      "time": "01:24:00",
      "text": "然后另外一边的话，我觉得model在有一些东西上面，比如说像ChatGPT，其实有很多人你看twitter上的thread，或者有人发blog post，就是做了一些研究也发现比如说try GPT，它的factuality其实并不是特别好。等于说比如说你问他一些问题，他会给你一个非常看上去非常令人信服的答案，但是有时候这个答案可能是胡编乱造的，就是他背后并没有证的证据支持。比如说你作为一个人类，你看这个答案，你就知道有里面有一些逻辑可能是错的，或者里面有一些事实是胡编乱造的对，然后这个可能也是一个将来需要提升的东西。",
      "speaker": "发言人3"
    },
    {
      "time": "01:24:41",
      "text": "然后还有一个是safety方面。Safety方面就是说你如何保证这些generative出来的东西是安全的。然后他不会对比如说任何一个种族产生bias。这也是一个比较重要的方面。因为现在你想这些large model也好，或者vision large vision models也好，就生成的model也好，就他们生成的东西完全是根据他们的，最后生成东西是根据training的那个distribution tion来的。然后你可以想见，在现在的这个世界上，这个trend in dispute本身是带有一定的bias的。所以相应而来的就是这些model也自然会在生成过程中带着这些bias。所以如何保证比如说这些model将来生成的东西是安全的，然后它不会比如说implicitly对某一些人或者某一些东西产生bias，这也是非常重要的对不然的话你想有些人用它的时候，就会觉得这个结果对自己并不是很好。",
      "speaker": "发言人3"
    },
    {
      "time": "01:25:40",
      "text": "对，五号阶段雪是你前面提到的那前面提到那两点就是对于现在这个模型还比较有圈子，你觉得说是现在我们通过一些一些可以说是微调它可以实现，还是说我们可能需要下一个类似于transformer或者说这种attention model这一些比较fundamental的breakthrough才能够去解决的呢？",
      "speaker": "发言人1"
    },
    {
      "time": "01:26:03",
      "text": "这是个很好的问题。对，其实我们去年其实发了蛮多paper在研究这个topic。我觉得这个是同样就同时需要两方面的努力的。一方面是在fundamental这个model上面还是需要一定的breakthrough。然后另外一边是说在fundamental这个model之上，我们如何用一些更好的更novel的technique能够unlock这些model，这在这些事情上的一些capability。",
      "speaker": "发言人3"
    },
    {
      "time": "01:26:28",
      "text": "首先在foundation model那边，我们发现scale就scale就model skill还是非常重要的。比如说你拿一些小的model，你在上面叠再多的fancy的technique，其实有些时候还是解决不了那些非常难的task。所以foundation model的scale，foundation model本身的capability是非常重要的，这个是scale那一方面可以解决的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:26:47",
      "text": "然后另外一方面的话就是说如果你在上面再apply一些novel technique，其实我们去年写了一些paper，就是比如说我之前提到的，比如train of soft，就是一个可以unlock model reasoning的一个一个方法。如果没有try of thought的话，即使是再好的model，我们当时试了一个数学reasoning task，这个数学reason也不是特别难，大概是初中数学题的样子。对，我们当时比如说用palm 540B的那个model。比如说540B你觉得它size已经很大了，对吧？但是如果你直接做future learning的话，它的performance其实大概只有20%不到的accuracy的样子。就是他只能做到5分之1的问题。但是用了我们那个train of salt的那个novel的technique，是一个更复杂的prompting的方法，我们就可以把这个performance提到大概60%的accuracy。所以把从20%到60%还是区别非常大的。所以一边是foundation model的本身的能力，然后另外一边是你如何在上面做一些更加novel的这个是要researcher research，recipe tips就是。将来能研发出更好的technique，能on lock这些能力，或者也list出这种。",
      "speaker": "发言人3"
    },
    {
      "time": "01:27:56",
      "text": "对我很赞同雪菊说的，这是这几个方面，尤其是今天的ChatGPT，他对那个facts的理解是很有限的。吴老师写过一个很有意思的chat PT，他说为什么5比10大？然后ChatGPT会给你给你写上200字，告诉你，给你论证一下为什么5比10大。然后我们我们自己我们会发现就很多facts他都不太清楚。",
      "speaker": "发言人2"
    },
    {
      "time": "01:28:26",
      "text": "还有一个很有意思的地方就是对文献的引用。因为看起来GRGBHRGBT它是比如我读了paypal以后，我看起来他的春季赛应该是从跟在在网上call来的。然后有网上扩，也有也有维也有维基百科这样的高质量数据，也有realize里面这种很复杂的数据。所以我所以比如说打呃有一个很有意思的例子，就是他对他在中文的ChatGPT，他对唐诗的理解是很糟糕的。就是你他你这个你会发现他连唐诗三百首都没有背过。你你比如说我去找了一个非遗，不是最好的这个诗人。比如说我我引用了李商隐的诗，他跟我说这是杜甫的，然后说是杜甫哪首诗，你会发现杜甫根本没写过那首诗，那首诗的名字和诗都是他自己编的。所以他在fax上面是有问题的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:29:21",
      "text": "然后还有，但是我不知道GPT4会不会在这个上面有一些解决的方案。这个可能是拭目以待了。然后另外一个方面就是他在对话上是不行的，他不太能够去理解这个提问者的这个问题。并且当我我我看他的那个论文上面GBD3和chat GBD的一些介绍来说的话，他引入了很少量的单单轮次对话的数据。所以他当你的如果你问他一个问题，你对他的回答不满意。你说比如说我今天跟问他说，我明天要去纽约，你告诉我纽约最好的餐馆是哪一家？他会给你一个没有太没有他有帮助的这个回答。这个时候你再去追问的时候，你会发现他完全找不到主题了。",
      "speaker": "发言人2"
    },
    {
      "time": "01:30:12",
      "text": "这个问题其实我知道他已经开始做一些GPT，四肯定在做一些补救。那那他的补救直接补救的方法就是他最近那个GPT3好像OpenAI出了一个GP3的chatbot，这个IOS应用。我去我我去test fay里面申请，好像没申请到，但是你如果有装了这个应用以后，你可以你你就会出现一个像imessage或者微信那样的对话框。",
      "speaker": "发言人2"
    },
    {
      "time": "01:30:41",
      "text": "你可以不停的和这个ChatGPT聊天。当你不停的和他聊天的时候，在这个手机里面他就会一直他会告诉你，我会要收集你的信息。那这个时候你会和他生成很多很多的对话信息。在这个情况下他可能会拿到很多这样的。当然你在这个网页晚上面也可以得到很多对话信息，他会他一定会把这些对话的信息数据拿去做训练。然后这个有可能，我觉得是有可能提高他多轮次对话的性能。但是我不知道他自己GPT3的这个架构设计里面，它是不是能够把这些康泰都都学到这件事情我不知道，但是我希望他能够在把多轮对话的康泰的学的更是更透彻一些。",
      "speaker": "发言人2"
    },
    {
      "time": "01:31:26",
      "text": "我这边还有一个关于大模型能力提升的问题，请教一下学知和各位嘉宾。一方面就是关于文本的模型的能力。刚才一文也提到，现在ChatGPT对于中文的文本的生成还是有非常多的问题。那这样的问题能不能够之后通过工程上训练更多的相关的数据，就能够得到比较好的解决。然后第二点就是我也听到很多foundation model通过训练github上的代码数据，还是很明显的提升了对于这个自然语言的推理能力。我想这也是模型迁移学习的一部分。我不知道这个论断是否是对的，以及未来的话，当大模型其实学到更多的多模态的数据之后，能不能够对其他的modality的能力上也有明显的提升。",
      "speaker": "发言人5"
    },
    {
      "time": "01:32:22",
      "text": "对，这是个很好的问题。首先第一个问题，你说如果中文这个是multi lingo的问题，我不太确定GPT three或者ChatGPT在pretrail copps里面中文占的比例是多少。但是根据现在大模型的所有portrait disputation来看，除了英文首先肯定是主要的就占主要部分的一个pretrail的部分。然后其他语言的话基本上是占比较小的比例的，所以我猜中文在里面占的比例应该比较少。如果你想让拆GPT在中文上面能力更好的话，或者任何其他大模型中文或者其他语言能力更好的话，你可以让他见到更多，就提升那个copps的比例，然后pressure时间可以更长一点，让他在那个copps上面adapt更好一点。",
      "speaker": "发言人3"
    },
    {
      "time": "01:33:08",
      "text": "对，然后关于其他模态的问题，你觉得是个很好的问题。首先code代码数据的训练是不是能帮助提升reason，你这个答案是肯定的对，因为我们做过很多实验，其实GPT就ChatGPT它的那个base model其实是GPT3.5那个model。然后那个GPT3.5它其实是有两个version的，一个是text version，一个是code version。他们有个叫text event的东西，也有个叫code event的东西。然后code event是另外在code data上面在train过的。然后我们当时比过那两个model的那个在reasoning上面的performance。我们发现在code上面train过的那个model，reasoning的performance要比只在text上面train的那个model要好很多。所以code代码数据训练肯定是能帮助reason能力的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:33:55",
      "text": "然后我们当时看了一下，大概是因为get hub上面的很多code，它其实提升了model在manipulate symbolic的那里。因为code你可以想象成是很多symbol的一个你在操控那些symbol，然后你需要很清晰的逻辑把那些symbol操控好，这样才能得出最后正确的答案，对吧？所以这个portrayal的这个code portrait的训练是对他提升reasoning能力很有帮助的，这个是原因。",
      "speaker": "发言人3"
    },
    {
      "time": "01:34:23",
      "text": "然后未来如果加其他新的模态的数据的话，我觉得这个model是可以提升其他模态能力的。就比如说其实已经deep mind已经有篇paper叫fly wingo。对，fly wingo里面其实有多模态，它既有vision data也有text data。然后他把vision跟text data interleaf起来。",
      "speaker": "发言人3"
    },
    {
      "time": "01:34:40",
      "text": "最后问问题的时候，他会给你个图片，然后问你他可以回答，比如说这个图片是哪个城市，然后他可以reason说，这个图片里面比如有很多车或者很多高楼，它有可能是纽约或者什么。就是他他其实是在你在确定过程中加多模态的时候，你是能让这个model有多模态的能力的。然后这个其实也适用于其他模态，比如说像robotics或者别的东西。就是你在确定当中如果能加的话，就是model是同时可以有多模态能力的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:35:11",
      "text": "然后还有你最后一个问题，说这些模态是否会相互帮助，我觉得是很有可能的。你想人在学习的时候，不可能你从小到大只是对着text学，对吧？你你同你在学text的时候，同时也看到了很多，比如说image video然后audio之类的。然后这些模态互相之间肯定是有interaction的。你如果能在model training当中加把这些模态都加进去，然后让他们interaction能够最大化的话，其实是能够互能够让这些模态互相进行帮助，让model就整体的能力得到更大的提升的。这个也是我觉得现在很promising的一个方向。然后很多公司其实也都在研究这个。",
      "speaker": "发言人3"
    },
    {
      "time": "01:35:51",
      "text": "这个其实就引申出了一个很很重要的一个对未来的预期。比如说开源的模型，其实它在文生图效果很好，大家也用的这个数量其实比大力要多的。但是会不会未来几年，就是这些大厂的闭源模型，他们因为训练了更多这个维度的数据，然后他们有更大的参数。所以他们可能在长线上，反而在在某个特定领域还是会比这个开源模型效果好啊。我不知道这个你会怎么看。",
      "speaker": "发言人5"
    },
    {
      "time": "01:36:22",
      "text": "我觉得开源模型也可以引入多模态，然后确认时间更长。我不觉得这件事情是互相排斥的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:36:31",
      "text": "图片生成的这一块，你先看看还有什么你觉得可能的限制和未来的一个主攻的会提升的方向。",
      "speaker": "发言人1"
    },
    {
      "time": "01:36:42",
      "text": "就从图片来说，我们能我们对模型的自己的能力限制，现在还是有一个比较明确的理解的。我打一个比方，我经常打这个比方说，我们抓一个画师出来，我不想跟他沟通清楚，说一个甲方想跟他沟通清楚，说要把什么东西画出来，要经过几轮交互，要花多少时间，然后你只有用77个token，只有7 77个单词。现在就给模型描述出清楚这个现实，答案是不是那么现实？那沟通的but with是不够的那怎么提升我们跟模型提沟通的班子，其实是一个比较是一个low hung food就比较容易去解决的一个问题。就需要不同的模型，然后不同的condition的方式。这不能说是很多很很明确的research progress，因为这个怎么做大家是清楚的，只是需要花一些时间，有一些know how的问题可能需要去解决。这是一个短要明确的短期的一个方向。",
      "speaker": "发言人4"
    },
    {
      "time": "01:37:44",
      "text": "长期来看，图片模型我刚才提到了有一点非常好啊，我我也我也我也非常相信这件事情是一个在多模态这件事情上面，我们现在的图片模型上面用的这个语言能力，其这是非常低的。低到什么程度呢？我们的语言模型几百M一个币多一点，那跟我们上百币动辄上百币的现在真正的大模型大语言模型来说，其实差的非常的多。提升模型的语言能力也已经被验证了，说是一个让提模型生成能力提升的非常好的一个方法。但我们好像看到了一个cash hold，就是有它它提升到某一个领域，某一个瓶颈之后，再往上可能就会比较难。怎么能让模型的语言能力变得更强，乃至这种以多模态的方式去做这个图片的生成，让效果变得更好，这也是一个方向。但这是图片部分，往后说的话，其实扩展模态是比较重要的一件事情。",
      "speaker": "发言人4"
    },
    {
      "time": "01:38:47",
      "text": "像比较大短期的视频模型，3D模型，应该都是会在2013年2023年会发生的事情。2023年大家会看到一些基础的视频和3D模型出来，然后有一些应该也会被开源。这一部分希望能从这个领域去看，说怎么去推进更多应用场景的探索。",
      "speaker": "发言人4"
    },
    {
      "time": "01:39:18",
      "text": "在outman其实也很多次的提到接下来这个多么他应该是他们发展的主攻的方向所以这个可能对很多对这个块牌不是很熟悉的朋友来说，我想可以麻烦学智给大家大家简单的介绍一下这个多模态为什么认为他对于这个进一步的提升那么重要。",
      "speaker": "发言人1"
    },
    {
      "time": "01:39:38",
      "text": "首先它为什么重要？我觉得人类比人类的学习，首先现在单模态是比较这些model是比较容易train的。比如说language model的话，你或者你只缺一个language model，或者只缺一个vision model，那它的input非常的固定。然后你可以用一个同样的encoder去encode所有的信息，因为它的input output是一致的对，如果多模态的话，可能最大的难点就是你怎么把不同的模态alliance，能够让他们之间的interaction最大化。然后我之所以觉得这个东西非常promising，是就是我刚说的类比于人类的学习方法，对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "01:40:15",
      "text": "假设你作为比如说你小孩子的时候，你如果只读书的话，你学到的知识是有限的。但是如果你同时见到了image或者audio或者是video的话，那你其实是这些模态之间是互相可以有interaction的。比如说你读书，你比如说想做一些space上special上面的reason。比如说你想向前走了五步，你再向右走了五步，你现在在哪个方向对吧？你读书的话，在这些东西在你看来它只是一些text，你其实没有你如果没有你如果没有眼睛的话，你是不知道这个东西具体对应的是什么。但是你同时如果看到了图片，或者你在就是你真的移动过的话，那你知道这个text其实它对应的比如说是图片上的一个向前向右的，就一个斜方向的，是这样的一个东西，对吧？所以你如果在这些模态之间，如果互相能学到一些交互的东西的话，它是能互相August就是互相提高你对每一个模态的理解能力的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:41:14",
      "text": "对我觉得这个事情非常重要，因为我觉得这个将来可以unlock很多很多别的ability。比如说self driving，self driving你其实比如说你单你用一个language model能解，或者单用一个vision model能解决，就是self driver里面的很多问题，应该很难对吧？你想你你人之所以比如说能开车开的这么好，是因为你在多年的experience之间中间你学会了比如说这个simo对应着什么，然后比如说这个词对应着什么，这里面你看到的东西是什么。然后你从这些多模态的交互当中你学到了一些东西，然后你才能推理，然后你才能更好的进行应对。所以我这才是我为什么觉得其实很多公司现在也在往这个方向发展，就是说如何能引进多模态。其实单模态大家其实现在这条路已经走的差不多到limit了，都大家都已经scale up到差不多到头了的阶段。你可以在网上scare up一点点，但是大家都差不多知道你scale到这个程度，大概现在performance是什么样。然后单模态其实已经差不多研究到一个boat neck的阶段。其实他们就很多人其实都觉得下一个promising的方向是把多模态结合在一起。然后你互相让这些多模态互相之间能够interact，然后能够maximize他最后学到的东西，就是你这个人对于这个世界的整体把握的这个能力。",
      "speaker": "发言人3"
    },
    {
      "time": "01:42:37",
      "text": "现在我们看到我们要真正去做好这个多模态的难点，主要核心难点在哪呢？",
      "speaker": "发言人1"
    },
    {
      "time": "01:42:43",
      "text": "你单模态的话，其实你只要一个encoder就够了，对吧？你text有个text encoder，或者vision有个vision encoder，然后它的所有input都是一致的。你用同一个toga ization同一个encoder，你就可能你就可以encoder出来一个unified representation。",
      "speaker": "发言人3"
    },
    {
      "time": "01:42:57",
      "text": "但是如果多模态的话，这个非常tRicky。因为text它会经过一个text encoder进变成一个representation video image会经过一个image encoder变成一个image representation，对吧？然后你这之间就是这个东西怎么online在一起，然后怎么互相让他们interact，然后interaction能够maximized，这些都是非常难的对，之前那个flamingo paper他们用了一个比较好的方法就是interleaf，就是把text跟image互相插在就是互相插在一起。对，比如一个image下面跟着一个text，一个text后面再跟着一个image，image后再跟着一个text。对，然后他是先把image通过一个image encode到一个presentation，然后再用一个language model就把那个text encode到另外一个text的space。然后通过这种interleaved的方式去train这个model，最后让那个model能够生成一个reason model text这样子。所以你怎么把这些互相多个模态unify在一起，变成一个这整个model的training到底object是什么？然后你怎么把这些多模态结合在一起，就变成一个unified representation。",
      "speaker": "发言人3"
    },
    {
      "time": "01:44:05",
      "text": "以及让他们模态跟模态之间的interaction最大化，就是让他们互相能真的产生作用。不然的话你就是在单圈一个text model跟单一个vision model，对吧？所以你要把他们会在interact得到最大化，这个是我觉得是个比较大比较难的部分。",
      "speaker": "发言人3"
    },
    {
      "time": "01:44:20",
      "text": "对，而且更不用说video了。Video的话处理起来更麻烦。你可以想象成，比如video的话，它可以割成一帧，然后每帧的话它分别可以有image，也可以有text，对吧？你比如把把它transcript搞下来的话，它就另外有个text，然后你要把这些东西都alien在一起，然后你怎么处理帧跟帧之间的关系，然后怎么又跟另外的text。比如说这个video有个title，然后这个video有个audio，就怎么把这些东西全alien在一起，就是个比较大的难点。",
      "speaker": "发言人3"
    },
    {
      "time": "01:44:46",
      "text": "刚刚我们讲到就是当我们想到这个next step是什么的时候，一方面是我们刚才讨论的这个science这个research的这个层面需要需要哪一些提升。我觉得其实我们也很重视实际落地的这个场景。比如说我怎么去考虑这个influence的成本，要使用这样的一个生成式model或者说这个大模型，把它开发成自己想要的应用。我们现在看到从这个工具的角度来说，还有哪一些大家觉得比较有挑战的这个地方。就是以后像这个stability AI这种提供这个model的这些公司以后大家会不会把这个就是我们现在的这个模型是不是跟上一代这个AI也许是否需要一套新的工具链。",
      "speaker": "发言人1"
    },
    {
      "time": "01:45:30",
      "text": "我先从现在的工具链来说，从开发从模型开发角度上来说可能还好。因为现其实跟research现在的习惯有很多的是是是对应的。但是从部署的角度上来说，现在工具链确实还是有一些问题的。特别是如果要翻译我翻译我有必要去，特别是针对终端场景的环境，我有必要去完全的理解这个模型里边每一层在做什么。我需要我我有必要去配置，看的整个一个很大的一个py touch也好，还是tensor floor也好，就在这个框架下面重新去逛一个完整的twenty job，似乎不用这个东西可以变得更简单。",
      "speaker": "发言人4"
    },
    {
      "time": "01:46:13",
      "text": "有现在有一些开源的方案是说我给你rap的GUI，web的GUI里面，那在GUI里面就做了这件事情。这他也不一定是最终解决方案。那针对各个场景的翻译是不是应该有更简单的工具，更简单的服务？我们的答案是。如果是的话，我们要做什么？这是我们要探正在探索的事情。",
      "speaker": "发言人4"
    },
    {
      "time": "01:46:36",
      "text": "您现在看到这一块工具链上有哪一些你觉得可能的痛点？",
      "speaker": "发言人1"
    },
    {
      "time": "01:46:42",
      "text": "我们现在最直接的其实是API，然后API现在也在有不同层次的API，这其实是工具链的一部分。再往后的我们只能说我现在我们在探索，因为这也确实是一个作为开源公司，然后作为我们现在正在做的这种，我们做foundation model的直接的下一下一个环节，可能是比较重要的一件事情。我们我我只能回答说我们在探索，但没有一个具体的答案。",
      "speaker": "发言人4"
    },
    {
      "time": "01:47:11",
      "text": "我可以说一下我们之前的应用就是那种中型的比较小的模型，你这是一方面。另外一方面，我大模型的应用可能刚刚开始。所以所以所以我可能有一些猜测或者说有一些推测。小模型的话它它会尤其在edge这一块，比如说LT、车载，它一直是属于开支，属于资源受限的这么一个环境。那就主要的大部分的不是compute的这个限制，而是memory的限。意思你在你的模型在load你的数据的时候，你总会hit memory wall。一般来说算力并不是可能是一个更小的问题。结论就最后怎么去解决这个矛盾，会有很多的这个其实有已经一开始有很多的的公司在在试图解决这些试图解决这一类的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "01:48:05",
      "text": "比如说你可以有很多办法吗？你比如说你可以把模你的模型裁剪一下，你可以把你的这个你可以把你的这个数据类型改一下。你把你是IPIPCC，你就改成inter int 8，你是inter 8，再可以改成inter 4。然后你再做实验看看，我从IP16到int 8，我的这个quality ML quality下降了多少？Inter 8到inter 4 quality下降了多少？这些quality下降是否能够承受？",
      "speaker": "发言人2"
    },
    {
      "time": "01:48:29",
      "text": "另外就是再往下还有一些同还有一些我们看到一些人就在做什么呢？在做编译器的优化。我在编译器上我我比如说我有一个我会有一个比较比较好的编译器或编辑的库。",
      "speaker": "发言人2"
    },
    {
      "time": "01:48:43",
      "text": "那这个编辑的库把不同的计算资源，通常我的很多芯片里面既有CPU有GPU对吧？然后还有可能还有DSP或者是有NPU。他们的编译器是不一样，他们program language和program帽子也是不一样的。有的用open cell，有的用黑light，有的用c entrance。那你怎么去统一它，然后在IP之间他们的这个你怎么统一IP之间让out the run time overhead，你怎么统一他们之间的这个memory to memory的overhead，你怎么去优化这些东西。",
      "speaker": "发言人2"
    },
    {
      "time": "01:49:14",
      "text": "很多公司在做这些这些事情。其实去年我们我我跟我们的朋友们投了一家公司叫OEML，我们觉得是比较好的。他他做了两件事情。他在上层，在模型的这个层面，他根据你的要求，相当于做这个harvard specific的prony。然后在下层它会去作为针对你不同的嵌入式的系统。比如说你是高通的芯片还是NDDI的芯片，它根据它的下面编译器的特点，高通的芯片它用的是LVVM的这个编译器，利用哭的那对于这些不同的编译器，你会使用什么？你你你会你你你应该你应该引用什么样的库，这些东西他们也做了一些自动化的处理。",
      "speaker": "发言人2"
    },
    {
      "time": "01:49:59",
      "text": "到最后，我我我听说他们的这个业务成长还是很快的这从侧面也说明说也说明这个需求一直是存在的那其实大厂也有在做这些事情，你比如说google的auto ML autom AL，虽然早期来说是更多的有这样的有个更多的model architectural search的功能。它更多的是面对ML quality，就是你希望得到质量更好的模型。但是同时你在知道什么是质量好，什么是质量不好的模型之的时候，你也会知道他们的模型的尺寸和他们的和他们相关的latency performance会是什么样子的那这个时候其实你也可以做，他也可以变相的做这个model acceleration对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "01:50:50",
      "text": "那AWS出了一个产品叫做CG maker neo。Neo做的工作也是类似的，他虽然做的不怎么地，但是他在media上做的还可以。他等于是他试图捅，他做的和OMML有一些类似。他试图统一所有现有的嵌入式系统做inference。嵌入式系统的不同的compiler，然后比较这些compiler之上这些芯片厂商的compiling的库，然后说我搞一套抽象化的这个compiler出来，然后你你只要你就像选ECQ1样，你选择了相应的这个硬件，我就给你做相应的加速inference加速和优化。",
      "speaker": "发言人2"
    },
    {
      "time": "01:51:33",
      "text": "但是从现在看来的话，它上面现在他主要的官方的合作伙伴是有安霸和安坝，intel和media可能还有高通。但是我从他的客户的角度来看，我采访访谈他一些客户，大概来说的话，只有NVIDIA平台上的客户是基本满意的。但是你话说回来，其实柯达本身自己的编译器做这些工作已经是很不错了。所以我觉得CGCG maker h neo可能需要再进一步的他可能要再进一步的迭代。但起码从AWS的角度来讲，他已经重视到了这个问题。我现在说的都是这种中型的模型，就比如说bert或者是rest night这种类型的上一代的这个模型。那是大模型怎么变？我觉得这是我我我也没因为大模型这个东西，GBB3GB3.0 stable division刚刚出来，我其实没有，我我我的我认为我们的思考和也是不充分的，数据也是不充分的，我只能做一些发表一些观点。",
      "speaker": "发言人2"
    },
    {
      "time": "01:52:42",
      "text": "首先我觉得大模型的training肯定是需要优化的。未来我们可以想象GPT5，假设GPT5GP61次training，按照现在的这个训练范式来讲的话，可能要上亿了。那上亿美金一定哪怕是像微软这样的企业，他也不对他来说也是一也不是一个很好的选择。而且你看现在GPT3，我看到GPT ChatGPT这个GPT3.5，我自己的感觉就是我用了两个月，我感觉他前前后后可能大我能感受到的这个跟金也就是它的retraining可能只有三次。",
      "speaker": "发言人2"
    },
    {
      "time": "01:53:17",
      "text": "你可以想象如果GP6两个月train 3次，那那六个月就是train 18次。那18次1次的retraining是一亿美金的话，那不就是18亿，一年就18亿美金。这个capex也这个capex也不是这样的大厂能够很轻易的承受的。所以一定会在我认为一定会在training的two chain上面有所突破。我觉得这个上面反而是小公司的一个优势。",
      "speaker": "发言人2"
    },
    {
      "time": "01:53:43",
      "text": "我最近也在看一些serve，我认为有一些三甚至我自己投的serve里面有机会解决这个问题。就是把你的training的cost，把你这个大模型的training cos一下，给你降低一个五倍。我认为training的cos cost saving应该是会很重要的，其实在这里面我稍微插一句，就是刚才雪子说的这个多模态mode model input。实际上今天多模态对于language model来说是一个新事物，对我们VCB的人来说反而是个老事情，就是茅台model input。",
      "speaker": "发言人2"
    },
    {
      "time": "01:54:11",
      "text": "我们到2022年就开始已经在我自己的工作应用上用上了。因为不是因为我们先进，而是因为我们实在没办法了。我自己做的工作可能还有一些这个不能说，但是我可以说一下，就是在2020年的时候，我们我们一个我们在线下meet up跟那个android capacity有过一个有过一个访谈。那个时候他刚刚安凯，当时还是tesla的这个叫drive的head。然后他当时AID完了以后，我们当时的感觉他没有讲透。但是我们的感觉是说他一定用了茅台model input base的茅台task learning。也就是说后来我们去问他，当然他也可能也不他也没有直接正面回答，但是我们非常确定它的input里面一定有肯定是有有他的这个视视频，就他的video然后有它的关键帧。因为所有的vision这种self专用运行的model，一定会有关键帧的input。",
      "speaker": "发言人2"
    },
    {
      "time": "01:55:07",
      "text": "然后第三个有MU那IMU的input是一个MU就是输出的是quote，中文叫做可能叫四元素。这个扩展它是一个向量，然后它是以比如说1000帧2000帧这种数据来出的。就像刚才雪子说的，这个MU的输出和关键帧的MU的格式，关键帧的格式和这个video的格式都是不一样的。这个时候在2021年的时候，如果大家注意到的话，你会发现2020年到2021年的FSD，很多的用户早期用户的反馈是他们更提高了很多。",
      "speaker": "发言人2"
    },
    {
      "time": "01:55:40",
      "text": "但在那个时候你会发现有两个很值得注意，很值得玩味的点。第一个是他慢慢的取消了他的这个雷达，他的radar。然后第二件事情是他坚决不用来的。很多人觉得伊隆马斯脑子脑瓜是不是被驴踢了，是不是？但实际上他并没有丧失理智，他其实很多的时候是考虑这个exactly，就考虑刚才雪芝说的这个问题。就是说如果我再加个radar，再加一个radar，再加个激光雷达。这些数据记录我的ML model我做，我再把这两个茅台model的input搁进去了以后，我有没有给呢？",
      "speaker": "发言人2"
    },
    {
      "time": "01:56:14",
      "text": "那假那那那这个我们可以想象，首先第一，他们早期的这个game是不完整的，尤其是reader，他们会他们明确就提在一次QNA上明确提了我reda对我的date pipeline来说是非常痛苦的，但是对我的train training是没有gain的。然后later的话，我的integration，我的data public an integration的cost会更高。然后有没有变我不知道，然后我现在发现但是我现在发现我的关键帧加上我的video再加上我的MU我的gain在后，我只要加大我的模型，我后面的gain是没有，我的店还live set还没有开，那我还不如先把这三种mode先给它挖掘到头，然后再去考虑要不要加来的。其实我觉得这是他的这是他为什么不加leda和取消radar的一个很重要的原因。所以这其实是跟多模态是有关系的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:57:06",
      "text": "所以我可以理解，其实这个是我们应用多模态的时候需要考虑的一个trade off？就是我把更多的这个input加进来，它肯定是增加我的这个复杂程度。它最后的这个LI可能在不同的场景它是不一样的，不是在所有场景都都不太是好。",
      "speaker": "发言人1"
    },
    {
      "time": "01:57:22",
      "text": "对，那你这个里面就很有有一个很很有意思的是美国某一线L4的这个自动驾驶的工大厂，它的它的这个模型现在每一次的模型训练，它里面是有有雷达也有激光雷达的，它一次模拟训练的成本大约是在900万到1300万美金之间。那他的那我我我我我然后在这里面在这里面这个多模态我还我们还不提多模态的后面的训练了，就提多模态前面就是你把这些数据光做ETL可能就要花到上百万美金，你想想这是什么概念？那这个其实你的多模态的选择，哪些模态对你是对你是有gain的，是你值得投入的，在什么时间段是值得投入的？我觉得这个是一个很有意思的一个问题。对对对，CD来说我们已经趟过这些雷了。我想的话对这个LM来说的话很可能，当然我也不太懂LOM。但是对于LOM来说，你怎么选择这个输入的模态，它这些模态是不是每个模态都有很明显的概念？这些可能也是值得考虑的问题，并不一定每个模块都是有gain的对。",
      "speaker": "发言人2"
    },
    {
      "time": "01:58:39",
      "text": "对我想也许等到这个GPT four出来，或者这个多模态这个东西出来了以后，我们可以有一次follow up的讨论。好，我们最后最后一个问题，其实也是更落地的一个问题。你们觉得你作为一个产品经理，可能在设计和思考产品的时候，应该考虑需要考虑哪一些？应该怎么样更好的能够把这个AI融入到这个产品里边。",
      "speaker": "发言人1"
    },
    {
      "time": "01:59:05",
      "text": "对我觉得我虽然我可能恰好做了很一些产不少产品，它的这个solution里面用了使用了air technology。但是对我来说我还是更关心我作为PM我更关心的是problem space，就是有什么样重要的problem，比这个东西比AI是不是适合做一个好的solution更重要。但我觉得有一些我首先会关注，因为我其实作为一个AIPM，首先是个PM，所以我关注重要的问题，然后这个问题如果足够重要的话，我再来看它的solution是什么。这里面不一定需要有，我觉得不一定需要有很多AI的这个工作，或者AI的这个成分在里面。",
      "speaker": "发言人2"
    },
    {
      "time": "01:59:48",
      "text": "我记得我自己第一个产品，我自己第一个ML的solution，就是很多年前做这个quality inspection的。十年前了，我们直接就用的是SDM sse m，是一个什么60年、40年老的一个machine technique。但是他能够他能给我那给我的公司一年节省大约可能五六千万美金的成本。你帮他们让你出五六千万美金，实际上是一个很其实我觉得是一个很好的产品。这个不一咱不一定需要用LOM来做一样的事情了，SDM就够了。所以关注problem space是我最重的这是我是我觉得是首要的，特别对我影响很大的这个门头model是我在亚马逊学到的。",
      "speaker": "发言人2"
    },
    {
      "time": "02:00:34",
      "text": "亚马逊的时候在亚马逊的时候我们有一个因为你也在亚马逊待过，其实我们都对那个PR FAQ是非常熟悉的对，所以我自从进进了亚马逊以后，到现在这么多年了，可能7767年了七八年了。然后我认为PRVPU是一个非常好的思考工具，告诉我怎么从客户出发，然后怎么work backwards。然后今天我如果今天第一天发这个PRKQ，那我的客人会问什么样的问题？然后我应该怎么回答这些？这样的话不容易遗漏。",
      "speaker": "发言人2"
    },
    {
      "time": "02:01:14",
      "text": "现在我们看到的，我我我现在我最大的体会是两点，一点是可能要想清楚究竟想做什么。其实就刚才说的那个你们说的problem space的那个问题，想解决的是什么问题？那是不是已经有一个明确的问题在心里？你在找寻找一个技术来去做这件事情，这是一种mental model。然后这在以这种mental model来做产品的话，是比较容易做出比较好的垂类的产品，更容易做出比较好的垂类产品的，这是一种方式。",
      "speaker": "发言人4"
    },
    {
      "time": "02:01:48",
      "text": "然后另外一个另另外一条就是第二点，也是相当于进入到另外一个门头model，是我对技术非常的了解，那我在对于技术了解的情况下，能够看到了一些exciting的技术。那exact想把这些exciting的技术拿去做应用。我看到一部分这样的case。那这种case可能最也最重要的事情也是要回到是真正的应用场景来。怎么能看到了一个在线的技术？我不是要做一个技术demo，要做的东西是拿这个技术去解决实际的问题。这时候就要回来看说我熟悉的是什么，我了解的是什么，或者我身边能够触及到的资源又是什么，能够以什么在我懂这个技术，能把这个技术应用好的前提下，有什么领域是我熟悉的可以去解决的。而不是说纯从技术角度出发去寻找这个能让技术去来寻找去售技术的方式，我感觉所以说回来还是怎么去跟应用领域去贴合，怎么去解决实际问题，怎么能做出一个让用户真正喜欢的产品，是核心。因为我最早也是做用研出身的，所以对我我会比较在意真正的贴近用户端，B端也是用户端，对，就这样的一个思维方式。",
      "speaker": "发言人4"
    },
    {
      "time": "02:03:25",
      "text": "这个节目的最后，你觉得有哪一些话题可能我们今天没有涉及到，但是你个人personally接下来在AI这个领域还会比较关注的。作为我们最后的一个closing.",
      "speaker": "发言人1"
    },
    {
      "time": "02:03:36",
      "text": "我是比较偏向于research方面。所以我接下来对large link model，接下来还能all lock一些什么capability非常的感兴趣。对我觉得OpenAI在做一些非常promising的东西，然后google也在也有很多research相关的东西在做。然后将来的话我觉得多模态也是一个非常promising的方向。我觉得如何能让machine learning model能达到人的capability，能像人学习这个世界一样，利用各种模态互相交互，达到最大化。就是以尽量少的training时间，得到最大能力的提升，也是一个我非常感兴趣的方向。",
      "speaker": "发言人3"
    },
    {
      "time": "02:04:21",
      "text": "对我的想法其实跟雪石的类似，我觉得今天所有的哪怕是大模型年也没有走出对他30VI的这个范畴。我是希望看到有人今天哪一天能够提出新的方法来做真正的来做真正有接近人类智能这个原理的这种AI模AI技术。也就是说我希望有人看看到有人能够把data AI of seed表。",
      "speaker": "发言人2"
    },
    {
      "time": "02:04:53",
      "text": "想要自己把原来自己做的东西颠覆掉，是吧？",
      "speaker": "发言人1"
    },
    {
      "time": "02:04:57",
      "text": "对我觉得我觉得个人觉得就是data三这个AI现在是很重要的。但是我认为它一定不是，它一定是一个过渡AI发展的过渡时期。真正的智能是不应该过度的依赖，像现在这么依赖data.",
      "speaker": "发言人2"
    },
    {
      "time": "02:05:15",
      "text": "的那我可能就会想看到说基于现在的语言模型，现在的这个图像模多模态的图像生成模型等等，到底能够把我们的生产应用推到什么程度？因为现在其实说白了，我们的语言模型和生成模型的使用都还偏向于单点式的应。没有，就是你会看到针对一个小一个生产环节里面的一个小问题，我会有一个专门的一个解决方案。就像图片生成也好，还是语言模型也好。我很期待说能有一些创业者也好，创业者或者是大厂能把这所有能力拼起来。来自不同的不同的模型，不同模型的应用拼起来，能够cover一整个工作流，做出一个完整的产品。就比如说是目前我们有看到的像photoshop这样的产品，它的不它在不断的自我更新的过程中，逐渐的向这个方向去改变。也很想能看到有没有能出现一些AI原生的，从这个模型角度思考出发，然后同时带上了用户中心的思考，用原生的AI的工作解决方案的出现。",
      "speaker": "发言人4"
    },
    {
      "time": "02:06:33",
      "text": "对，我们也希望看到未来这个AI不止声称，我觉得的确作为投资人，一方面也希望看到现在AI的这个能力越来越强。另外一方面的确更加exciting的是AI真正可能很多我们原来已知的东西。比方说我所关注的可能一些企业服务软件的一些整个软件的可能一些流程都完全颠覆掉。",
      "speaker": "发言人1"
    },
    {
      "time": "02:06:54",
      "text": "非常感谢几位嘉宾周末的这个时间，也感谢bill作为这cohoes一问出了非常棒的问题。谢谢好，谢谢几位，拜拜。两个多小时的讨论，我觉得也是非常的酣畅淋漓。跟几位大牛聊完，也我也把这个bill扣下来，多跟我聊几分钟。我们从投资人的视角来聊聊我们的我们的一些收获。辩友，你觉得刚才我们的聊天可能有哪一些让你觉得比较印象深刻的这个点？",
      "speaker": "发言人1"
    },
    {
      "time": "02:07:32",
      "text": "对我觉得我现在还沉浸在刚才的那个交流中，就是信息量非常大我觉得有有两点其实让我印象非常深刻，而且都是很底层的思考。一个是一周有提到说，其实这次的AI和比如说五年前当时图像视觉的这个AI最不一样点就是这次AI的创新其实真正是收集到了跟人交互的一系列的多维度的数据。其实我会让我其实更加深刻的去想说，它的应用场景会不会跟人人的交互更加相关一点。",
      "speaker": "发言人5"
    },
    {
      "time": "02:08:16",
      "text": "第二就是说其实一文也提到一个很深刻的点，其实跟商业生态。因为我也问问到，其实他对未来谁能去建类似IOS和安卓生态的思考。他提到一个非常重要的点，就是当年不管是IOS还是安卓，其实都是有端侧的创新的。他其实是提到了一个叫d developer speed，就是一套代码能不能够适配所有的端侧的应用。而像open I能不能够去提供这样的能力，或者其他大厂能不能创造这个生态，其实给了我非常多的这个角度的启发。可能原来的从投资人的角度来讲的话，很多的思考维度还是单一的。就是需要更多的这样的跟产业里的去讨论，才能真正去抓到这个问题的本质。",
      "speaker": "发言人5"
    },
    {
      "time": "02:09:09",
      "text": "对，尤其是因为几位都有实际AI落地的，我觉得落地的这个经验，就是让我一方面觉得说一一方面觉得说原来原原来我们在这种大模型的这种探索，其实还在非常早期的。我觉得听雪之分享了很多他们的研究，就感觉现在哪怕在fundamental的这个model没有突破性的改变情况下，其实我们现在看到的真的可能都只是冰山一角。就你觉得这次这次这个AI的这个热潮也好，你觉得跟上波有什么不一样的这个地方你去看一个生成式AI的一个一一个start up，可能你的主要的关注点跟以前你看这些AI的公司可能会有哪些相同和不同的地方。",
      "speaker": "发言人1"
    },
    {
      "time": "02:10:00",
      "text": "对我觉得不同地方。其实就是创业的门槛确实是明显变高了，尤其是如果是做这个底层的foundation model创业公司，其实全球范围内也都屈指可数。而且很可惜现在还都发生在北美这边，就是国内的也有些团队我们在关注，但是数量上还是会会相对少一点。",
      "speaker": "发言人5"
    },
    {
      "time": "02:10:25",
      "text": "我觉得这里面其实包含了两类，其实之前让我就超过我们预期的地方，就是之前其实在两三年前的时候，我们也会关注这个transformer的论文，关注bird的进展。但是有有两点其实是啊就是超过我的预期的那第一点就是说其实工程上的这个进展是比我想象的要快很多的，尤其是这里面还伴随着很明显的头部效应，就是open I凭借他在人才团队数据上的先发优势。其实一次次的在效果上其实是打破了我之前对AI的应用能力的设想。",
      "speaker": "发言人5"
    },
    {
      "time": "02:11:06",
      "text": "第二其实我之前认为说，transformer是不是就是一个更加scalable的一个统计学的模型。现在我们从效果上来来看的话，其实他是比我想到的更贴近人的方式在学习。而且在不同维度上都可以在能力上迁移学习，相互增强。所以导致跟上一代的区别就是当时我们看上一代的AI应用还是非常偏产业导向，就是通过转接神经网络去解决行业的一个具体问题。但这次的创新其实让我的关注点其实会在应用未来的这个应用生态上，其实更贴近一些更general的人类的需求。其实不管是to c还是to b可能能我相信未来真正跑出来的创业的独角兽，都应该是解决一个更加更面，甚至是更立体的一个通用的能力的领域。而不是再像过去一样。说我是一个比如说人脸识别，视频识别的一个单点。",
      "speaker": "发言人5"
    },
    {
      "time": "02:12:13",
      "text": "那我们看到其实现在的一些早期创业公司还处在一个单点的形态。其实大家普遍觉得这肯定是一个非常初期的状态。所有人其实都在期待说谁能够真的是让他的产品与人的生活形成比较高粘性的一个习惯，然后真正融入到这个企业的这个工作流程。我觉得现在的如果往未来的几年去看的话，其实这波的AI的技术创新是我相信是有一能力去实现这样的一个产品的效果的。",
      "speaker": "发言人5"
    },
    {
      "time": "02:12:50",
      "text": "那你现在在看一个AI的公司的时候，你最关注哪一些方面？",
      "speaker": "发言人1"
    },
    {
      "time": "02:12:57",
      "text": "对，其实核心还是两点，如果是如果如果他是做底层的infrared的这个公司的话，不管是做foundation model还是类似的产品，其实人才和经验还是非常关键的。我觉得这里面最大的区别就是说和上一代的AI相比，真正的有经验的去学训练过千亿参数模型的人才，其实在最近几年还是非常稀缺的。因为需要百万美元以上的成本的投入，所以他们没办法在大学在学术机构获得这样的经验。拥有这样实战经验的头部的人才leader，兼具技术经验和管理能力。",
      "speaker": "发言人5"
    },
    {
      "time": "02:13:42",
      "text": "其实我我觉得这是一个创业公司做底层模型的基础。应用的话，我觉得这个其实是个开放性问题。我感觉到所有的人都在讨论未来的应用生态该怎么建，但是其实没有人有一个明确的answer。这里面其实我们更多的还是去考验创业者他整个的一个产品设计能力，这个市场定位，包括他对用户的感知。这一点其实现在也很稀缺。因为我们看到很多的AI创业者都很多是来自模型的research的部门，或者是这个paper论文的发表者。他们有没有能力有很好的产品感知。其实我觉得现在也是我们核心比较看重的。",
      "speaker": "发言人5"
    },
    {
      "time": "02:14:35",
      "text": "对我感觉现在的确是对于应用层创业团的要求其实是很高。就是你需要对这个problem本身非常的了解，同时你又需要很了解就现在这个AI what is capable of，对，然后又能够去随时去跟进他现在这些这些这些进展。现在如果投这个领域，你觉得会太早吗？就是我讲的比方应用层就好像faced比方说facebook，myspace这些公司出现之的的时候，其实其实这个互联网其实已经发展了，它这个底层的这个info已经发展了一段时间。那你觉得现在在我们感觉整个方foundation model这个fa他自己都还在整个forming整个还在成熟的过程中的时候，会有一些的timing上的风险了。",
      "speaker": "发言人1"
    },
    {
      "time": "02:15:24",
      "text": "对这个问题也特别的有意思是不是too early to investment。然后我觉得其实现在应该是说不能过早的投过多的钱，就是因为技术还在有非常快速的变化。但是好的一点就是我自己个人还是非常相信这次的这个技术的变化，其实会诞生非常多的全新的市场。所以说其实创业者的优势就是它会比大厂能更早的去定义新的这这个需求，新的客户群体。然后在技术的快速迭代中，优先的去把这个新一代的产品做起来。所以我自己觉得可能比较合适的方式是大胆假设，小心验证。其实投资也是一个概率学的游戏，就一边通过少量的投资来去验证自己对大方向的假设，然后一边去观察技术的变化。",
      "speaker": "发言人5"
    },
    {
      "time": "02:16:23",
      "text": "对我我觉得很同意你说这健康这个时候仍然有很积极去做投资。跟可能跟这个行业里边一流的这些创业者，或者创业的核心的圈子，我就保持一个engagement。现在在整个底层这个环境都还在都还变化的时候，其实对创业者来说也不适合说你马上就做一个几十人的研发团队，然后就朝着一个方向去奔了。可能他自己就更需要去做一些小步快跑的一些迭代。",
      "speaker": "发言人1"
    },
    {
      "time": "02:16:56",
      "text": "是的，其实优秀的创业者是可以带领我们穿越周期的。",
      "speaker": "发言人5"
    },
    {
      "time": "02:17:00",
      "text": "是真的是啊你也提到就是我现在训练这个模型，它的这个成本越来越高。但是但其实这个趋势肯定是成本越来越低。我觉得这个stable diffusion也就刚开始出来的时候，这个训练成本也就是600K那我觉得以后真的是像这个一周说的，如果要降到10万美金或者说几万美金要做模型的这个创业的话，那这个时候他的这个护城河又又在哪儿呢？",
      "speaker": "发言人1"
    },
    {
      "time": "02:17:35",
      "text": "对，这个也是一个特别好的问题。我的感觉就是可能之前大家的关注点都在于训练的成本。比如最开始这个open I训练这个GP three花了千万美元的成本。但随着整个模型效果的演进，我发现说这个能力其实变成了一个非常综合的一个因素。",
      "speaker": "发言人5"
    },
    {
      "time": "02:17:55",
      "text": "首先在训练之前怎么去获取高质量的训练数据。包括我听到我也有一个几百人的外包的数据的等于半监督的标注的团队。这个其实门槛越来越高了，可能现在还是一个公开的数据集。但是未来如果这些大厂也好，创业公司也好，能够拿到更多的生态合作伙伴的私有数据的话。其实数据的质量本身其实就已经让很多创业公司难以说我0到1的时候快速来实现了。",
      "speaker": "发言人5"
    },
    {
      "time": "02:18:27",
      "text": "第二就是模型的，其实我我相信说模型的这个参数量跟模型的成本也是一个相互跟进的节奏。我听到现在很多人训练千亿参数的model，其实成本已经可以降到这个百万美元级别了。但是我们也很快能看到，可能明年新的这个模型的大小可能也会等比例的提升。",
      "speaker": "发言人5"
    },
    {
      "time": "02:18:50",
      "text": "第三块儿我觉得可能更加稀缺的还是我之前提到的一点，就是真正有非常丰富的这个模型整套流程程的工程经验的人，其实我觉得在这几年还是比较少的。原因就是说真正能够历练的黄埔军校还是集中在头部的这几个做模型的大厂里面。然后他们的人数人资源也非常有限。创业公司其实想组建一个规模化的团队也是有一定难度的。所以我个人角度感觉，其实目前看来这几个头部大厂还是有大概两三年的一个先发的优势。而且他们的能力其实是跟创业公司的差距是在拉大的。但这肯定不是他们真正长期的护城河。往长线看的话，还是说谁能够构建比较好的商业壁垒，那才有可能真正把自己的市场的地位长期的去维持住了。",
      "speaker": "发言人5"
    },
    {
      "time": "02:19:53",
      "text": "对对我我觉得的确是这样。现在我们面临的整个政治经济环境其实都比较的比较比较复杂。我们也看到，虽然说就坦率来说，虽然说中中国现在也有越来越多的创业者研究机构在做这一块的跟进。但是跟国外现在还是挺有差距的。而其实上一波的这个AI的创业，在最底层上，其实中美两边其实很快也就拉齐了。在这个应用层的不同的市场环境下，的确就长出了不同的应用层的未来。就我们看到这些中国的创业的这AI这个领域的创业机会，它可能跟国外会有一些不一样。",
      "speaker": "发言人1"
    },
    {
      "time": "02:20:34",
      "text": "这个地方对这也是整个投资行业大家讨论比较多的很有意思的话题。几个我自己的观点第一个就是说中国有没有会不会出现像OKI这样的公司。我自己的感觉是说这可能是我自己个人觉得应该是一个两三年的一个落后时间线。就是当前中国的困境就是中国的还是比较缺乏大模型的高质量的人才。但我们看到其实海外的这些公司，其实很有可能未来两三年之后，他们会扮演黄埔军校的角色。那现在比如说他们当时可能会有一些华人的公工程师，然后再比如说这些大厂有过真正的large language model的训练经验之后，逐步的组建团队来回国。这可能是我我的一个个人的一个预期。时间上的话可能刚好也是一个小几年的时间。",
      "speaker": "发言人5"
    },
    {
      "time": "02:21:38",
      "text": "第二就是比较重要的就是因为未来长期的护城河还是依靠商业生态搭建的。而这两边中美是一个相对隔绝的环境。所以说只要中国能够有机会去搭建不错的这个底层大模型的团队，哪怕说在效果上，在这个技术进展上，最最开始的时候都有几年的落后。但是一旦这个模型真正的从商业角度被中国大量的C端和B端用起来的话，我觉得这个生态应该还是中国有一个自己独有的一套环境。而且在应用层，其实中国还是有非常丰富的工程师相关的人才。所以一旦这样的一个商业闭环转起来，中国的开发者真的能够通过拉large language model或者findon model赚到钱的话，其实我倒并不担心说长期中国做不出来类似他的产品，但有可能会有点像自动驾驶，或者是其他领域。可能中国的企业跟海外可能稍有一些技术上的差距和落后。但好在就是现在整个学术界还是比较开放，所以很多know how还是能够跟进学习的对。",
      "speaker": "发言人5"
    },
    {
      "time": "02:22:54",
      "text": "如果是像civil diffusion这样的公司，像这样的产品，它已经是开源了。其实国内的很多开发者一直以来我们都很关注开源这个领域。其实中国的开发者在所有开源的这个项目上的贡献和积极的程度，其实是绝对不亚于甚至是领先世界的那我想现在虽然说我们现在看到这个large language model，还是OpenAI这样的。我觉得未来几年，无论是google还是别的公司会有一个开源的出来，我觉得应该是大概率的一个事件。对我觉得如果一旦有这样的一个大的这种开源的就开源的东西出来的话，那我觉得其实国内至少把这个应用起来，我觉得应该是一个挺挺很可期的一个事情。",
      "speaker": "发言人1"
    },
    {
      "time": "02:23:39",
      "text": "我那天还跟一个国内某大厂的内部，他们研发同学聊。他们就说因为他们是他们有短视频这个业务，他们就是用这个AI生成生成一个生成这个素材，说发现这个stable diffusion的这个效果一般。然后他们就拿这个daily的这个paper就自己就开发了一套，前后可能也就一个多月的时间，然后发现这个效果还更好，马上就可以在他们的场景里边就用起来了。所以我觉得未来其实这个对于一方面来说，是我自己个人感觉，就是给我更大信心说只要这一些基础的技术我们能够access到，那其实我们要在上面做很多改良。我觉得在在中国这些人才队伍里面，我觉得是完全不是问题的。",
      "speaker": "发言人1"
    },
    {
      "time": "02:24:33",
      "text": "而可能另外一方面，但对于in general，我觉得创业公司来说，可能大家真的是要去思考的。就是说你真的是怎么样做成一个闭环。可能对于一些大公司来说，环已经在那了，我只是把这个我只用把这个环做更好。那就对于一个创业公司来说，可能就真的不能从一个单纯的拿着锤子找钉子的一个思路，我可以把你们现在做什么，我可以把你这个做的更好。而真正要去从主要是从用户现在所面临的实际的痛点去去出发，来去来来来去考虑。",
      "speaker": "发言人1"
    },
    {
      "time": "02:25:05",
      "text": "可能我就是有一些可能表面上看起来，比如说生成。什么短视频素材，这一些我感觉可能表面上看起来比较直观的这种AI技术的应用。如果没有在商业上有一个很好的设计的话，就很快就会变成一个同质化的一个11个1个竞争。甚至可能这个领域都不存在，就可能就是对吧？看抖音这些大厂就把作为把它作为自己生态的一部分了。那这个也是是的是的。",
      "speaker": "发言人1"
    },
    {
      "time": "02:25:33",
      "text": "需要想清楚。",
      "speaker": "发言人2"
    },
    {
      "time": "02:25:36",
      "text": "我们展望一下AI一些场景，你觉得你有哪一些让你非常exciting的一些一些未来？",
      "speaker": "发言人1"
    },
    {
      "time": "02:25:47",
      "text": "对我我尤其是今天参加了Monica的这个podcast of，我其实更加让我兴奋的还是跟人相关的。我觉得可能之前的所有的AI的应用，包括底层模型讲的故事，还是解决一个具体场景的一个具体问题。然后可能很多也是录了落到产业工业。但是我非常期待在今年明年，真的有非常不错的产品经理，他能够真的去定义某一个大的应用领域，让AI真的是啊跟人一样去交互，然后解决一个人类的大面的需求，甚至是人类会跟AI形成非常强的绑定或者使用习惯。这可能是我非常期待未来一两年有没有这个产品的出现和技术相关的创新了。",
      "speaker": "发言人5"
    },
    {
      "time": "02:26:42",
      "text": "对，就现在就是我觉得可能未来是不是人的这个能力，技术这个能力，站的这个需求都会要改变。就是因为现在你看chat GP已经可以帮我们做那么多的这个事情了。以前我们可能看一个找一个比方说找一个投资analyst对吧？或者找一个律师。我们可能要找你这个写报怎么样，你收集收集总结资料的能力对吧？这个总结能力怎么样。",
      "speaker": "发言人1"
    },
    {
      "time": "02:27:08",
      "text": "但我觉得现在可能接下来大家的一个能力就变成说谁更有更好的prompt engineering的能力，就谁会问AI问题。因为你其实问的问题不一样，你得出来这个效果是不一样的。那是不是某也许未来对于这个技术的技术技术的演进，可能这一块需求会越来越低。但是不管怎么样，我觉得很有我自己的一个while的一个想象。我可能是2010年出生的孩子，可能会需要一个我们现在我非常不一样的一个能力战。可能如何去使用一个AI to如何去获得AI问题，可能会能够也许会能够极大的differences很多人的生产力。",
      "speaker": "发言人1"
    },
    {
      "time": "02:27:50",
      "text": "对的，包括如果人类的很多高频的工作还是娱乐需求，已经跟某个AI产品形成非常深入入的使用习惯的话，那那其实这个产品的价值就会非常大了。",
      "speaker": "发言人5"
    },
    {
      "time": "02:28:05",
      "text": "对，比如说一个投资分析师，他可能对这个行业没有另外一个人了解，但是他特别会用AI也许真的他的效率就会比另外一个人要高。现在想想觉得好可怕，感觉自己快要被颠覆了，希望不要。",
      "speaker": "发言人1"
    },
    {
      "time": "02:28:19",
      "text": "是的，而且我们已经看到有这个论文的著作上已经写上了ChatGPT的名字。有些人有些学者已经直接会明确写。他说我们一起来去发表这个学术的paper.",
      "speaker": "发言人5"
    },
    {
      "time": "02:28:36",
      "text": "我就看看到那个read hofman。他launch了一个一个serious，就是他跟这个chg BT的聊天，就是这个pocket的内容。那个pocket就是他跟ChatGPT聊天，然后再用一个另外工具把ChatGPT的生成的文字转成这个语音。",
      "speaker": "发言人1"
    },
    {
      "time": "02:28:53",
      "text": "我的power总在想说，我是不是也要做这么一期，我跟他GPT聊聊天，你啥时候把我颠覆了？好，我觉得今天感谢我来作为我的一起跟几位几位这AI领域的朋友一起来做这次的头脑风暴。我自己也收获非常多，这个领域我觉得日新月异。希望我们这一期播客能够对于一些对这个领域感兴趣的朋友有一些帮助。我们也期待看到，中国跟美国都有更多的全世界，我觉得都有更多的AI的创业者，我们一起来一起来打造是一个很amazing的未来。好，谢谢phil.",
      "speaker": "发言人1"
    },
    {
      "time": "02:29:36",
      "text": "感谢莫妮卡。",
      "speaker": "发言人5"
    },
    {
      "time": "02:29:38",
      "text": "两个多小时的硬核讨论也许有些烧脑，但是希望你们也跟Monica一样，觉得收获满满，不虚此行。在这个看上去sexy热闹又挑战和机遇并存的领域，希望有更多的朋友来跟我们一起畅想，一起探讨、一起创造。关于这个话题你有什么想法，欢迎在评论区或者莫妮卡的公众号跟我互动，期待听到你在做的事情，一起碰撞出更多火花。我们下期再见了，感谢大家的收听。如果你喜欢我们pocket内容，欢迎你点赞并分享给可能感兴趣的朋友。有任何建议反馈都可以在评论区留言，我们都会很认真的看的。如果你在用apple podcast收听，也希望你花几秒钟给我们打个五星好评，让更多人了解到我们我们下次再见。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "本次对话深入探讨了人工智能技术的多个方面，包括ChatGPT与谷歌Palm模型的影响、开源模型的重要性以及AI的商业化。讨论涵盖了AI研究、产品开发和投资的经验，指出了AI技术的最新进展、面临的挑战和未来趋势。对话强调了小规模投资在验证假设和观察技术变化中的重要性，以及采取小步快跑的迭代策略对于创业者的必要性。此外，还探讨了AI领域的投资机会，特别是模型训练成本下降的趋势，以及数据获取、模型参数量与成本的关系。讨论还涉及了AI与人类交互的未来，表达了对技术演进和生产力提升的乐观态度。最后，对话强调了构建强大的商业生态对于保持市场地位的重要性，以及开源与闭源模型商业模式的考量。",
    "qa_pairs": [
      {
        "question": "AI无疑是未来几年最令人兴奋的变量之一，能否请几位嘉宾简单自我介绍并分享一下最喜欢的生成式AI项目？",
        "answer": "大家好，我是王雪志，现任google brain research scientist，专注于large language model和其中的reasoning相关研究。我最喜欢的生成AI项目是关于利用prompting方法提高大型语言模型推理能力的各种工作，例如数学推理、常识推理和符号模式推理等。",
        "time": "00:03:05"
      },
      {
        "question": "易文，能否简单介绍一下自己，以及你的职业转变经历？Bill，能否简单介绍一下自己以及在AI领域的有趣发现？",
        "answer": "大家好，我是易文，在硅谷担任ML产品经理，拥有应用物理背景。原本的职业理想是成为一名物理学家，但毕业后因找不到工作而转行做起了产品经理。职业生涯中，我先后在苹果、亚马逊等公司负责硬件产品管理，后来接触并深入研究计算机视觉领域，并在吴恩达教授创办的Landing AI中担任产品负责人。大家好，我是五源资本的bill。我毕业于北大计算机专业，毕业后从事战略投资和财务投资工作，目前主要关注底层技术创新，尤其是软件和AI方向。在AI领域的一个有趣发现是Hugging Face平台，它提供了众多开源模型和AI进展的分享，以及推特上有很多AI相关的插件，其中有个插件将ChatGPT与搜索结合，提升了实时内容的效果。",
        "time": "00:08:14"
      },
      {
        "question": "雪芝，能否介绍一下Google的Palm模型以及与GPT-3相比有何不同之处？",
        "answer": "当然，Google的Palm（Pathway Language Model）是在去年四月份发布的，是目前市场上最大的语言模型之一，拥有540亿个参数。其主要区别在于规模之大，以及架构上采用从左到右、仅包含一个decoder的结构。相比GPT-3，Palm在参数量上有显著优势，表现出更优秀的性能，并且能完成一些更复杂的任务，如解释笑话或进行复杂推理。不过，两者都是基于decoder-only的transformer架构，但在具体训练细节如训练数据量和token处理方式上存在一些细微差别。",
        "time": "00:13:02"
      },
      {
        "question": "GPT3相比GPT2在处理不同任务时有何不同，尤其是在zero shot和one shot方面？",
        "answer": "GPT3在处理不同任务时，通过增加模型容量（如达到175亿参数量级），解锁了in context learning或称为zero shot和few shot的能力。这意味着当模型大小增长到一定程度后，它能直接在没有额外训练的情况下，对新的、未见过的任务进行zero shot或少量数据（few shot）的快速适应和执行，而无需像GPT2那样依赖fine tuning。这是由于GPT3模型在训练过程中接触到更多的数据和上下文信息，从而提高了其对各种任务的理解和适应能力。",
        "time": "00:17:44"
      },
      {
        "question": "在GPT2和GPT3中，fine tuning和zero shot、few shot之间有何区别和应用场景？",
        "answer": "fine tuning与zero shot、few shot是不矛盾的。在GPT2和GPT3中，都可以进行fine tuning、zero shot或 few shot。fine tuning适用于有一定规模训练数据集的情况，可以让模型适应特定任务并获得更好的性能。而zero shot和few shot则是在没有特定任务训练数据时采用的方法，其中zero shot是指模型直接应用于新任务，而无需任何预训练；few shot是在少量相关数据支持下进行快速适应和执行。GPT3在模型容量增大后，发现其在zero shot和 few shot上表现优于GPT2。",
        "time": "00:16:51"
      },
      {
        "question": "GPT3的in context learning能力是如何产生的，以及它与模型大小的关系是什么？",
        "answer": "目前尚未有确切的理论解释in context learning能力是如何产生的，但有实证研究发现当模型大小达到一定程度时，该能力自然出现。GPT3在模型尺寸增长到175亿参数量级时，展现了强大的in context learning能力，即使在没有额外训练的情况下也能对新任务做出有效响应。这表明随着模型参数量的增长，模型能够从更多的上下文信息中学习到更丰富的表示，进而提高了对新任务的理解和解决能力。",
        "time": "00:23:04"
      },
      {
        "question": "除了模型大小之外，还有哪些因素会影响模型的表现和能力？",
        "answer": "除了模型大小外，模型在训练过程中见过的token数量也是一个关键因素。DeepMind的一项研究发现，对于给定的模型大小，让模型在训练过程中见到更多的token可以显著提升其性能和适应能力。例如，通过让模型继续训练并使其见过的token数翻倍，某些模型在一些任务上的表现甚至超过了更大模型的性能。这说明在模型规模不断增长的同时，增加模型在训练过程中的数据曝光度也是提升模型能力的重要途径。",
        "time": "00:24:01"
      },
      {
        "question": "在不同的应用场景下，对于产品而言，是否需要更轻量化的模型以降低部署成本？",
        "answer": "是的，在不同的场景中，确实会期待看到更多更轻量级的模型。目前的大模型虽然在训练阶段能够取得较好的效果，但在推理阶段由于参数量大，对于计算资源和部署来说是一个负担。因此，如果能探索出更轻量化的解决方案，并确保在部署部分足够轻量，将有助于推动应用场景的发展。",
        "time": "00:30:16"
      },
      {
        "question": "当前AI领域中，随着模型规模增大，高质量训练数据是否成为瓶颈？对于未来foundation model的发展，随着模型规模增大，高质量训练数据是否会造成瓶颈？",
        "answer": "这取决于具体的应用场景。在某些任务上，数据的质量至关重要，例如在Palm模型中，我们会优先考虑使用高质量数据如VCPDA书籍等，并根据数据质量进行采样。然而，在某些情况下，比如对话模型，可能不得不使用从Reddit等来源获取的可能质量参差不齐的数据。尽管高质量数据很重要，但有时网络数量有限且无法随意控制，这也是一个挑战。模型规模增大确实可能让高质量训练数据变得更为关键，但也要看具体应用场景。例如，GPT模型在zero shot学习中，即使只有少量高质量数据，也能通过fine tune获得显著提升。这也暗示了未来每个领域的特定场景模型构建成本可能会越来越低，前提是能够获取高质量且平衡的数据集。同时，提出了data-centric AI和small data ML的概念，强调数据质量、平衡以及在高维空间中对重要特征的良好表述，即使数据量较少也能达到较好的效果。",
        "time": "00:31:41"
      },
      {
        "question": "数据质量对于计算机视觉任务的影响有多大？对于图像生成模型而言，在生成模型阶段，数据量和数据质量的重要性如何？",
        "answer": "数据质量对于计算机视觉任务的影响极为重要，甚至超过了模型本身的影响力。在实际产品开发中，尤其是在做制造业的质量检测分类模型时，获取高质量的真实数据极其困难。而通过对比不同模型和数据集的表现，得出结论是数据质量和标注质量对最终结果起决定性作用。在图像生成模型的初期阶段，数据量和丰富程度比数据质量更为重要，但文本与图片的对齐质量必须很高。随着模型训练的深入，高质量数据对于理解能力和生成质量的提升至关重要。对于特定领域的fine-tuning，可以快速将通用图像生成模型转向特定领域，但在此过程中，数据质量仍会对最终效果产生重要影响。",
        "time": "00:33:14"
      },
      {
        "question": "能否简要介绍一下stable diffusion和stable AI的工作原理？",
        "answer": "Stable diffusion是一种基于条件分析的模型，它首先通过一个语言模型（如text encoder）将文本转化为计算机可理解的隐藏状态。然后，一个单元负责根据文本逐步生成降噪的图片，最后通过VAE将计算机表示的图片解码为人眼可以理解的RGB图片。整个过程能在几秒钟内根据文本描述生成与之相似的图片。",
        "time": "00:43:56"
      },
      {
        "question": "在之前的模型中，比如diffusion clip guided diffusion和condition在文本上的一些生成模型，它们与stable diffusion之间的主要区别是什么？",
        "answer": "stable diffusion的一个重大优势在于其开源性，这意味着用户可以获得模型的权重和推理代码，并能在消费级PPU上进行部署。这种开源性质吸引了大量原本无法访问API或不知道如何利用API自行开发的开发者、个人甚至爱好者来使用这些模型。此外，stable diffusion在生成部分的目标与其它模型不同，它更注重感知效果好的图片生成，而非追求最高数值评估的图片质量。同时，stable diffusion拥有活跃的社区，在训练和应用过程中吸引了众多开发者参与，部署方便且成本低，支持外部UI和服务的本地化部署。",
        "time": "00:44:58"
      },
      {
        "question": "当前竞争激烈的文生图模型中，例如stable diffusion、OpenAI的DALL-E和其他类似模型，它们之间有何差异？",
        "answer": "达拉E（DALL-E）在学术领域做出了重大贡献，它的发布引领了许多相关工作的进展。从产品角度看，stable diffusion和DALL-E等模型存在明显区别。DALL-E通过封闭API限制了二次开发的可能性，而开源模型则消除了这种担忧，允许开发者更自由地进行创新和集成。另外，开源模型能让社区成员基于模型原始代码进行深入研究和二次开发，比如像dream booth这样的应用就利用了这一点。",
        "time": "00:48:39"
      },
      {
        "question": "达拉E和其他模型（如stable diffusion和midjourney）相比有何特点？",
        "answer": "达拉E因其相对封闭的API，在文生图领域未能达到预期的广泛影响，但仍然被视为该领域的里程碑。相比之下，midjourney是一个以创意为核心的社区，用户可以使用简洁的prompt快速生成高质量、具有美感且带有社区风格印记的图片，极大地方便了C端用户和创作者。而stable diffusion则是一个基础模型，具有广泛的适用性，可以被用来生成各种类型的图像，但可能需要付出更多努力去fine-tune以适应特定领域的需求。",
        "time": "00:50:38"
      },
      {
        "question": "对于开源商业模式，以stable diffusion为例，其商业模式是怎样的？",
        "answer": "stable diffusion采取开源模式，这让技术得以快速普及并促进了领域内的快速发展。对于公司而言，开源商业化的挑战在于无法像销售闭源API那样直接获取商业利益。不过，开源项目可以通过提供基础模型服务、围绕模型提供更多更好的服务，或者利用训练模型的能力为企业提供定制化模型训练等有偿服务来实现商业化。同时，开源项目因其成功案例和实际可用性，在合作和交付方面也可能更为顺畅。",
        "time": "00:57:09"
      },
      {
        "question": "大意刚出来时很火，但后来在stability出现AI后就不再被关注了，为什么会出现这种情况？",
        "answer": "这是因为stability推出的AI产品在技术演进速度上非常快，并且在图片生成这一领域的问题定义并不明确，大家都在探索中寻找有意义、重大的、值得投资和创业的方向。同时，对于大意这类公司的产品来说，其定义可能并不是最佳或最准确的。",
        "time": "01:01:00"
      },
      {
        "question": "当前最需要的是什么？在AI SARS1.0时代，存在哪些挑战？",
        "answer": "现在最需要的是更多的人来尝试理解和改进AI技术。开源环境能够更容易地建立生态，例如与stability相比，开源项目在活跃度上可能优于大意。在AI SARS1.0时代，一个主要问题是没有人能在模型上直接赚钱，即售卖API或模型服务。模型工作在整个ML系统中只占5%，其余部分是隐藏的运维和技术成本，这与未来所有软件背后代表的服务价值形成对比。",
        "time": "01:03:00"
      },
      {
        "question": "开源对于各类模型有何益处？",
        "answer": "开源对于模型的迭代和优化具有显著优势。一旦开源，开发者和社区可以更高效地理解问题空间和解决方案空间，并根据需求修改模型架构或部署优化。此外，开源有助于形成活跃的生态系统，提高商业价值。",
        "time": "01:06:03"
      },
      {
        "question": "开源与闭源在当前AI模型发展中的商业生态构建上，是否有机会形成类似安卓或IOS那样的生态平台？",
        "answer": "虽然有人试图通过提供更丰富的开发接口和相关开发者产品来提高切换成本和用户粘性，但个人认为，基础模型提供商不太可能形成类似iOS那样的强大生态系统，因为大部分技术价值并非直接与模型相关，而是体现在底层技术支持和用户营收等方面的综合考量。",
        "time": "01:13:13"
      },
      {
        "question": "OpenAI如果要host一个操作系统，它能为开发者提供什么样的价值，尤其是在开发速度和收入方面？",
        "answer": "OpenAI目前并没有考虑提供类似操作系统级别的生态系统，它没有从这些角度来思考能给开发者带来的价值。",
        "time": "01:15:28"
      },
      {
        "question": "对于使用大模型（如GPT系列）解决所有问题的看法是什么？",
        "answer": "我们很难用一个大模型来解决所有问题，尤其是在生产环境中，需要的是一个整套体系，包括产品设计、实现、用户交互以及后续人工服务等多方面，而不仅仅是文本交互。",
        "time": "01:16:30"
      },
      {
        "question": "OpenAI的定位可能更接近于什么？当前模型是否需要更底层的突破，还是可以通过微调现有技术实现提升？",
        "answer": "OpenAI可能更像一个平台提供商或者consultant，为不同行业和产品提供解决方案，其核心在于提供一套API服务，而非底层的操作系统。目前的研究表明，一方面需要在基础模型上有重大突破；另一方面，也需要开发出更创新的技术来更好地挖掘现有模型的能力。例如，scale model本身的能力和创新技术的结合是关键。",
        "time": "01:17:21"
      },
      {
        "question": "OpenAI是否有可能成为AWS等云服务的一部分，提供特定功能的实例服务？",
        "answer": "是的，OpenAI最可能成为类似AWS的pass服务中的一部分，提供特定功能的实例服务，例如ASR和NLP等，并且能够统一多种任务，简化开发者配置，提升开发速度和降低成本。",
        "time": "01:18:09"
      },
      {
        "question": "OpenAI与微软的合作关系如何？",
        "answer": "OpenAI已获得微软数十亿美元的投资，并计划签署新的融资协议。微软可能会在OpenAI获得75%的利润，这显示了传统巨头对创新技术的接纳和渠道整合能力的重要性。",
        "time": "01:20:25"
      },
      {
        "question": "对于AI创业公司而言，如何随着技术演进构建自身的核心竞争力（护城河）？",
        "answer": "随着技术发展，AI创业公司需要在研究层面探索现有模型的局限性和天花板，在工程层面寻找新的突破点，以及解决模型在复杂任务上的表现不足、事实准确性问题、安全性问题等。",
        "time": "01:21:12"
      },
      {
        "question": "GPT3是否通过收集用户信息来提高多轮对话的表现？",
        "answer": "是的，GPT3可能通过收集用户与其进行对话时产生的大量信息，利用这些对话数据进行训练，从而提升多轮对话的性能。",
        "time": "01:30:41"
      },
      {
        "question": "针对ChatGPT在中文文本生成上的问题，是否可以通过训练更多的中文相关数据得到改善？训练模型时加入代码数据是否有助于提升自然语言推理能力？",
        "answer": "如果想让ChatGPT在中文上表现得更好，可以通过增加中文预训练数据的比例，并延长训练时间，让模型在中文上适应得更好。加入代码数据训练确实能帮助提升模型的推理能力，因为代码训练有助于模型掌握操控符号逻辑，进而提高其在推理任务上的表现。",
        "time": "01:32:22"
      },
      {
        "question": "未来如果加入其他模态的数据，如视觉、机器人等，模型是否能提升相应能力？",
        "answer": "加入新的模态数据后，模型是有能力提升其他模态能力的。例如，结合视觉和文本数据训练的模型，能够在多模态交互中受益，整体能力得到提升。",
        "time": "01:31:26"
      },
      {
        "question": "不同模态之间是否会相互帮助，促进模型能力的整体提升？",
        "answer": "不同模态之间很可能互相帮助，人类学习过程就是多模态交互的例子。如果在模型训练中能够实现不同模态间的最大化交互，将有助于整体能力的提升，这是一个非常有前景的研究方向。",
        "time": "01:35:11"
      },
      {
        "question": "开源模型和闭源模型在长期发展中的表现会如何？",
        "answer": "开源模型也可以引入多模态训练，两者并不排斥。闭源模型由于训练了更多维度的数据和拥有更大的参数量，在某些特定领域可能长期表现更好，但开源模型通过不断改进和引入多模态训练也能取得进步。",
        "time": "01:35:51"
      },
      {
        "question": "对于图片生成领域，目前有哪些限制和可能的提升方向？",
        "answer": "目前图片模型的一个主要限制是与模型语言能力之间的沟通不足，需要通过改进模型的语言能力及探索多模态方式来增强图片生成效果。同时，长期来看，提升模型的语言理解和多模态互动是关键的研究方向。",
        "time": "01:37:44"
      },
      {
        "question": "多模态为什么对模型提升非常重要？",
        "answer": "多模态重要是因为人类学习过程中的多模态交互能够最大化信息的整合与理解，类比于模型学习时，多模态的互动能帮助模型更全面地理解和处理不同模态的信息，从而提高其整体性能和推理能力。",
        "time": "01:39:38"
      },
      {
        "question": "如何进一步推进视频模型和3D模型的发展？",
        "answer": "预计在2023年会有基础的视频和3D模型出现，并有望开源。推动这些模型的发展，探索更多应用场景是重要的研究方向。",
        "time": "01:38:47"
      },
      {
        "question": "当前做好多模态模型的主要难点是什么？",
        "answer": "做好多模态模型的核心难点在于如何有效地整合不同模态的信息，使其能够在模型训练中互相作用并最大化交互效果，以及如何构建统一的表示形式，让模型能够从多个模态中获取并整合信息。",
        "time": "01:42:57"
      },
      {
        "question": "在处理Video数据时，存在哪些挑战？",
        "answer": "处理Video的挑战在于其可以分割成帧，每帧可能包含image和text信息，需要将这些部分整合在一起，并处理帧与帧之间的关系以及与其它text（如title、audio）的关联，这是一项复杂的工作。",
        "time": "01:44:20"
      },
      {
        "question": "目前在工具链方面，有哪些大家认为比较有挑战的地方？",
        "answer": "当前工具链在部署阶段存在一些问题，尤其是在针对终端场景环境时，配置和理解模型每一层的功能、优化模型大小等方面较为困难。虽然有一些开源方案提供GUI来简化操作，但这并非最终解决方案，针对不同场景可能需要更简单易用的工具和服务。",
        "time": "01:46:13"
      },
      {
        "question": "您现在看到这一块工具链上有哪一些你觉得可能的痛点？",
        "answer": "目前最直接的痛点是API层面，不同层次的API是工具链的一部分。此外，在探索如何解决模型在边缘计算、车载等资源受限环境中的问题，例如通过模型裁剪、数据类型转换等方式平衡性能与资源消耗。",
        "time": "01:47:11"
      },
      {
        "question": "对于大模型的应用，有哪些潜在的解决方案？",
        "answer": "大模型应用同样面临训练成本高昂的问题，未来可能需要在训练流程上寻求优化。同时，有一些serve技术尝试降低大模型训练成本，例如通过特定技术减少训练开支。此外，多模态输入对语言模型来说是一个新趋势，但在实践中需权衡增加多模态输入带来的复杂程度与实际效果之间的trade off。",
        "time": "01:53:43"
      },
      {
        "question": "在您看来，对于采用多模态的AI技术，怎样选择对产品有价值的模态以及何时投入？",
        "answer": "这是一个很有意思且值得探讨的问题。例如，在某一线L4自动驾驶大厂中，一次模拟训练的成本高达900万至1300万美金，这还不包括前期对数据进行ETL处理可能需要的上百万美金成本。因此，在投入多模态时，需要考虑哪些模态对产品是有价值的，并在何时进行投入以获取最大收益。",
        "time": "01:57:22"
      },
      {
        "question": "在AI领域，从产品经理的角度，您认为在设计和思考产品时应该关注哪些方面？如何更好地将AI融入到产品中？",
        "answer": "作为产品经理，在设计产品时首先要关注重要的problem space，即解决的核心问题是否足够重要，而不是急于寻找AI作为解决方案。虽然AI很重要，但不一定每个产品都需要AI技术或大量AI成分。例如，我早期的一个产品仅使用了40年历史的SDM技术，就为企业节省了五六千万美金的成本。因此，首要任务是明确问题空间，并确保所选技术能够有效解决实际问题。",
        "time": "01:59:05"
      },
      {
        "question": "您接下来在AI领域会关注哪些方向？",
        "answer": "我个人比较偏向于关注large language model以及未来可能的新技术发展，例如OpenAI等公司在做的研究工作，同时也对多模态方向非常感兴趣，希望看到如何通过利用各种模态互相交互，让机器学习模型具备接近人类学习能力，并在较少的训练时间内获得更大的能力提升。",
        "time": "02:03:36"
      },
      {
        "question": "现在看AI公司时，您最关注哪些方面？",
        "answer": "对于做底层基础模型或类似产品的AI公司而言，人才和经验是至关重要的。目前真正有经验训练过千亿参数模型的人才非常稀缺，因为这需要投入百万美元以上的成本，在学术机构或大学难以获得这样的实战经验。因此，在看AI公司时，会特别关注拥有实战经验和管理能力的头部人才及其领导的团队。",
        "time": "02:12:57"
      },
      {
        "question": "在AI领域，现在对于应用层创业团队的要求高吗？投资在这个阶段合适吗？",
        "answer": "现在的确是对应用层创业团队要求很高，需要深入理解问题本身和AI技术的当前边界，并能紧跟技术进展。虽然技术变化快速，但现在投资还为时尚早，因为底层模型技术还在成熟过程中，但相信这次的技术变革会诞生很多新市场。因此，更合适的方式是大胆假设，小心验证，通过少量投资来验证方向，并密切关注技术动态。",
        "time": "02:15:24"
      },
      {
        "question": "对于未来模型训练成本越来越高的趋势，护城河会在哪方面体现？",
        "answer": "护城河可能体现在几个方面：一是获取高质量训练数据的成本和方式；二是模型参数量与成本之间的关系，随着技术进步，参数量大的模型成本可能会降低，但也可能有新的更大规模模型出现；三是具备丰富模型全流程工程经验的人才储备，目前头部大厂在这方面有一定优势，但长期来看，谁能构建良好的商业壁垒更为关键。",
        "time": "02:18:27"
      },
      {
        "question": "中国是否会出现类似OpenAI这样的公司，并且在商业生态搭建上有什么优势？",
        "answer": "预计未来一两年内，中国可能会出现这样的公司，主要是由于缺乏高质量人才的问题，但海外公司拥有相关经验和资源，可能回国后帮助中国建立类似的团队。此外，中国拥有庞大的工程师资源和应用场景，一旦底层大模型在商业上被广泛应用，形成良好生态，那么中国完全有可能研发出类似甚至超越OpenAI的产品。",
        "time": "02:21:38"
      },
      {
        "question": "对于创业公司而言，如何在这个领域脱颖而出？",
        "answer": "创业公司需要思考如何形成一个完整的商业闭环，不能仅依赖基础技术，而是要从解决用户实际痛点出发，创新并定义大的应用领域，让AI能够像人一样与用户交互并满足需求。同时，未来对prompt engineering能力的需求也可能变得至关重要，谁更擅长有效提问，谁就能更好地利用AI解决问题。",
        "time": "02:25:47"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探讨AI未来：技术前沿与商业应用",
        "summary": "随着OpenAI发布的ChatGPT引领AI热潮，本期节目聚焦AI的未来趋势。邀请了来自Google Brain的研究员和两位AI产品专家，以及一位投资人，共同讨论AI研究的最新动向、技术的天花板及未来可能的变化。从产品和商业角度出发，探讨了优秀AI产品的标准及其生态演变，并回顾了上一波AI创业热潮带来的启示。此外，也关注了Google对ChatGPT的回应以及未来AI对我们个人和社会的意义，力求为听众提供对未来技术演进和商业可能性的深刻理解。"
      },
      {
        "time": "00:03:04",
        "title": "王雪志与邓玉东分享在AI领域的研究和经历",
        "summary": "王雪志介绍了他在Google Brain担任研究科学家的工作，主要研究大型语言模型及其中的推理能力。他拥有CMU的机器学习博士学位，对自然语言推理特别感兴趣，特别是在增强大型语言模型多方面能力的研究，如数学推理、常识推理和符号推理。邓玉东分享了他从非机器学习专业背景转向技术产品总监的路径，主要负责稳定扩散算法等方面的工作。他在腾讯、百度和BCG有产品和数字化经验，后因对AI技术的兴趣逐渐深入该领域，并通过开源项目贡献进入了稳定性AI。他特别提到了自己写的notebook，以及如何通过自己的项目在开源社区中与stability AI建立联系，并最终加入该公司。这次对话展示了两位嘉宾在AI领域内的深厚积累和贡献，以及开源社区对于技术发展的重要作用。"
      },
      {
        "time": "00:08:13",
        "title": "从物理学家到ML项目经理的跨界之旅",
        "summary": "易文，原本应用物理学出身，梦想成为物理学家，研究半导体物理，但因就业市场不景气转行做产品经理（PM）。在五六年的时间里，他先后在苹果和亚马逊担任硬件产品经理，后创业转向计算机视觉领域，成为一家使用AI服务于制造业和农业的公司早期员工。他介绍了AI领域的有趣项目和人物，以及开源模型的商业模式。同时，Bill，一位来自五源资本的投资人，分享了他在AI领域的观察，包括对hugin face平台的关注和AI插件的使用体验。"
      },
      {
        "time": "00:12:04",
        "title": "探讨Google的PaLM模型与ChatGPT的区别",
        "summary": "对话中提及了Google的PaLM模型，强调了其5400亿参数的巨大容量，使它成为市场上最大的语言模型之一。PaLM模型采用从左到右的解码器架构，展示了在自然语言处理任务上的卓越性能，并解锁了一些新兴能力，如解释笑话和执行复杂推理任务。此外，还比较了PaLM与GPT-3的区别，主要在模型大小（参数量）和训练细节上。尽管两者都基于Transformer架构，但PaLM在规模和某些训练方法上有所不同。"
      },
      {
        "time": "00:15:46",
        "title": "GPT-2与GPT-3模型能力对比分析",
        "summary": "讨论了GPT-2和GPT-3在处理不同任务时的主要区别，特别是GPT-3通过增加模型容量至1750亿参数，解锁了在特定任务上进行零样本（zero-shot）和少量样本（few-shot）学习的能力，显著提升了模型的泛化能力和特定任务的准确率。同时，探讨了数据在微调和少量样本学习任务中的重要性以及如何处理不同任务的策略，包括直接应用预训练模型与进一步的微调。"
      },
      {
        "time": "00:19:19",
        "title": "探讨模型大小对学习能力的影响",
        "summary": "对话内容涉及了模型大小对“在上下文中的学习”能力的影响，特别是指出当模型大小达到一定程度时，模型的在上下文学习能力会显著增强。讨论了GPT-3通过庞大的参数量（1750亿个参数）和大量的训练数据，能够在不进行微调的情况下实现较好的性能，而相比之下，BERT模型则需要针对特定任务进行微调。此外，也提到了尽管存在许多尝试解释这一现象的论文，但关于为何模型可以做到这一点的确切原因仍然没有定论。最后，讨论了模型参数增加带来的挑战和可能的瓶颈，以及除了增加参数之外提升模型能力的其他可能方法。"
      },
      {
        "time": "00:24:28",
        "title": "模型训练中数据量的影响与研究进展",
        "summary": "去年来自DeepMind的一篇论文指出，在训练计算最优语言模型时，除了模型大小外，模型在训练过程中见过的token数量是影响模型性能的另一个重要因素。论文中提出，即便模型大小固定，通过增加模型接触的token数，模型能力仍可继续增长。该发现对于理解如何优化模型训练过程具有重要意义。之后的研究进一步验证了这一观点，特别是在Palm模型上，通过加倍训练数据量，使得62B的模型在多个任务上的性能超过了540B模型的性能。这表明，在参数增长到达瓶颈时，增加训练数据量可能是一个有效的提升模型性能的方法。"
      },
      {
        "time": "00:27:45",
        "title": "探讨模型规模扩展及其在研究与应用中的挑战",
        "summary": "对话中讨论了模型规模（scale up）的扩展被视为一条易于实现的路径，由于计算能力的增加可以促进模型性能的提升，而且模型容量的界限尚未可知。提及了GPT-4等可能的大规模模型，暗示模型规模仍有增长空间。同时指出，随着训练数据（token数）的增加，模型大小自然也需要扩大以适应更多的信息。讨论还涉及了现有的网络文本副本可能不足以覆盖所有知识领域，因此模型在记忆技术知识等方面仍有改进空间。从研究角度看，单纯扩大模型规模是一个见效快的方法，但实际部署时，巨大的模型参数量（如GPT-3的百亿参数）会带来高昂的计算成本，对硬件和架构提出了重大挑战。因此，探索更轻量级的模型和解决方案，适应不同场景下的应用需求，成为了一个重要的研究方向。"
      },
      {
        "time": "00:31:13",
        "title": "高质量训练数据对AI模型的重要性",
        "summary": "讨论强调了高质量训练数据在AI模型发展中的关键作用，特别是在模型规模不断扩大的背景下。一方面，对于特定任务，数据的质量被发现具有极其重要的影响，因此在预训练模型的选择过程中，会倾向于包含高质量的数据，如书籍内容，而对网络文档等质量参差不齐的数据则采取根据质量进行采样的策略。另一方面，对于计算机视觉任务，数据及其标注的质量对最终模型表现具有决定性影响，这一点在实践中得到了验证。因此，尽管模型的规模和复杂性在不断增加，但高质量训练数据依然是解锁模型新能力的关键。"
      },
      {
        "time": "00:35:05",
        "title": "数据质量和模型训练的重要性",
        "summary": "讨论集中在如何处理有限和质量不一的数据以优化模型性能。一个案例是为韩国车商开发的质量检测分类模型，面临数据不足的挑战。初期尝试使用生成的图片进行模型训练，但结果不够理想，强调了真实高质量数据的重要性。此外，通过比较不同模型在少量高质量数据下的表现，得出数据质量比模型选择更为关键的结论。同时，探讨了GPT模型在不同数据量下的表现，突出了即使是少量数据也能显著提升模型性能的可能性。总结强调了数据质量和平衡对模型成功的重要性，并提出了关于如何有效利用有限数据的思考。"
      },
      {
        "time": "00:41:03",
        "title": "图像生成模型的优化与特定领域适应",
        "summary": "讨论集中在如何通过翻译和质量评分高的数据集减少数据量，以提高图像生成模型的内容生成量和质量。此外，介绍了将通用图像生成模型快速适应至特定领域（如dream boost应用）的方法，指出在没有引入新概念时，仅需几十分钟即可完成模型适应，而引入新概念则需要更长时间。还提到了图片文本对齐的重要性以及在特定领域和高质量模型训练中，数据质量的重要性。"
      },
      {
        "time": "00:42:57",
        "title": "Stable Diffusion模型原理及应用介绍",
        "summary": "Stable Diffusion是一个通过条件性分析生成图片的模型，它结合了一个小型语言模型作为文本编码器，将文本转化为计算机可理解的隐藏状态，再通过一系列降噪过程生成图片，最后通过VAE转换为可识别的RGB图片。与之前的生成模型相比，Stable Diffusion的开源性、生成的感知效果及强大的社区支持使其在开发者和爱好者中得到广泛应用。它的轻量级特性（模型大小仅几百M至一个B）使得在消费级GPU上进行推理变得容易且成本低廉。"
      },
      {
        "time": "00:47:29",
        "title": "文生图领域中的模型差异与应用",
        "summary": "文生图领域中，达拉E、Midjourney和Stable Diffusion等模型各自具有特点和应用范围。达拉E作为封闭API的代表，虽然对领域有重要贡献，但限制了二次开发的可能；Midjourney以其简单的交互方式和高质量的图片生成，适合个人消费者和创作者；Stable Diffusion作为开放模型，虽然具有广泛的适用性，但需要更多的调整和优化才能达到特定领域的最佳效果。这些模型的差异主要体现在易用性、图片风格以及开放性上，满足了不同用户群体的需求。"
      },
      {
        "time": "00:55:25",
        "title": "开源模式下的AI商业化路径探讨",
        "summary": "开源模式促进了技术领域的快速发展和普及，特别是对于AI领域来说，开源能够吸引更多的开发者参与，推动技术和应用的迅速进步。然而，开源模式下的商业化面临挑战，如直接的商业模式不明确，需要企业提供更具有吸引力的服务或定制化的解决方案以实现盈利。对于开源AI项目，商业化的途径可能包括基于基础模型提供更优质的服务、依托开源项目的良好记录为企业提供定制化模型训练等。尽管存在挑战，开源AI商业化是一个已被验证的商业逻辑，但在AI领域仍处于探索阶段，尤其是在大规模模型应用方面。"
      },
      {
        "time": "01:00:20",
        "title": "开源模型对AI发展的影响及商业模式探讨",
        "summary": "对话内容围绕开源模型对人工智能领域，特别是生成式AI的推动作用以及相关商业模式的探讨。首先，讨论了开源模型如Stability AI的决定对AI发展的影响，指出开源环境能够快速建立起生态系统，并促进了技术的发展和应用探索。其次，通过对比不同公司和模型，强调了生成式AI领域内问题定义和解决方案空间的多样性以及探索性。同时，讨论了开源模型对于商业模式的正面影响，如通过服务增值来实现商业价值，而不仅是通过代码销售。最后，提到了开源模型在实际应用中的灵活性和适应性，以及未来可能的商业模式，如参照Linux和红帽的模式，强调了开源对于技术创新和商业成功的双重促进作用。"
      },
      {
        "time": "01:08:24",
        "title": "探讨AI模型训练成本对商业模式的影响",
        "summary": "对话中提到，随着AI模型如GPT-3和预计的GPT-4的复杂性和训练成本增加，仅有财力雄厚的公司能承担高昂的模型训练费用，使得AI服务变得类似基础设施服务（PaaS）。指出模型训练成本的上升对于个人开发者和小型初创企业来说是一个重大挑战，强调了开源技术和API服务的重要性。未来，AI模型的商业应用可能会因为训练成本的提高而变得更加集中于大型企业。"
      },
      {
        "time": "01:11:14",
        "title": "AI模型在消费场景的商业化可能性",
        "summary": "在AI技术发展的背景下，上一代的AI模型通常与直接的消费场景和应用场景保持一定距离。尽管工业领域和安防应用等对AI有广泛的应用，但这些技术距离C端消费者的直接感知相对遥远。智能音箱和扫地机器人等产品，借助语音识别、语义理解以及计算机视觉等技术，是AI技术向C端市场迈出的一步。然而，直到Stable Diffusion和Direction Model等技术出现，AI模型才开始真正意义上接近消费者，并激发了爱好者学习相关技术的兴趣，这标志着AI领域向着C端市场的直接应用和商业化迈出了重要一步。与之前相比，这一转变带来了指数级增长的应用场景，也为AI技术的商业化提供了新的可能性。尽管市场上出现了一些负面现象，如淘宝上转卖模型服务的情况，但这也从侧面反映了AI技术在C端市场应用的潜力和增长空间。"
      },
      {
        "time": "01:13:11",
        "title": "探讨开源闭源商业生态与操作系统生态系统的类比",
        "summary": "在当前的商业生态中，有观点将现有的API服务模式与安卓和IOS操作系统生态系统进行类比，探讨未来开源或闭源的生态提供商是否有可能形成类似的生态平台。观点指出，尽管存在这种可能性，但要想真正提高用户的商业粘性并形成稳固的生态系统，需要通过提供更多开发接口和相关产品来实现。同时，有人对此表示怀疑，认为目前的模型和技术，特别是OpenAI，还未足够成熟到能构建类似操作系统的基础生态，强调了开发速度和收入回报在生态系统建设中的重要性。"
      },
      {
        "time": "01:16:30",
        "title": "大模型在实际应用中的局限与未来发展方向",
        "summary": "对话中讨论了尽管大型语言模型，如GPT等，能够显著提升文本交互体验，它们离真正解决生产环境中的复杂问题仍有距离。实际应用需要的是一整套体系，从产品设计到客户服务等多方面，而非单一模型。大型语言模型更可能成为平台或服务的一部分，为不同行业和产品提供解决方案，类似于平台提供商或咨询服务商的角色。讨论还提到了通过整合如ASR和NLP等功能，通用模型有潜力统一处理多种任务，从而简化开发流程和降低成本。此外，讨论还触及了大模型在药物研发等领域的潜在应用和商业模式，以及科技巨头如微软对AI创业公司的投资策略，强调了在技术演进中创业公司构建竞争优势的重要性。"
      },
      {
        "time": "01:22:16",
        "title": "大型语言模型的研究挑战与未来方向",
        "summary": "当前大型语言模型在处理复杂的自然语言推理任务时存在局限性，特别是在处理需要深入逻辑思考的任务上表现不佳。尽管在简单的问答任务上表现良好，但对于需要深度推理的问题，模型的表现仍有提升空间。此外，模型在事实准确性和生成内容的安全性方面也存在问题，如可能生成含有偏见或不实信息的回答。未来的研究需要集中在提高模型的推理能力、准确性以及生成内容的安全性和无偏见性上。"
      },
      {
        "time": "01:25:38",
        "title": "探讨模型创新与技术微调的双重路径",
        "summary": "对话集中在如何提升现有模型效能的问题上，指出单纯依赖模型规模的扩大或引入变革性的技术（如Transformer）可能不足以解决问题。一方面，基础模型的突破仍是必要的；另一方面，通过应用新颖的技术手段可以解锁模型的潜在能力，如通过“思维训练”提升模型在特定任务上的表现。此外，还讨论了当前模型在事实理解、文献引用准确性和多轮对话处理等方面的局限性，并对GPT-4可能的改进方向进行了展望。"
      },
      {
        "time": "01:31:26",
        "title": "大模型能力提升方法讨论",
        "summary": "讨论集中在两个方面：一是如何通过增加中文相关数据训练来改善大模型（如ChatGPT）对中文文本生成的问题，二是探讨通过训练代码数据提升自然语言推理能力的可能性，以及对未来大模型能通过学习多模态数据来增强多模态能力的展望。增加中文数据比例和延长训练时间可以提升大模型的中文处理能力。代码数据训练有助于提升模型的推理能力，因为编码涉及操纵符号和清晰的逻辑。多模态数据（如视觉和文本数据）的训练能显著提升模型处理多模态数据的能力，并且模态间存在相互帮助的潜力，模仿人类学习过程中的多模态互动，为企业和研究者提供了一个有前景的研究方向。"
      },
      {
        "time": "01:35:49",
        "title": "开源与闭源模型的未来趋势及挑战",
        "summary": "对话集中在开源模型和闭源模型的未来发展上，强调开源模型在文生图领域的优势及使用广泛度，同时提出闭源模型可能因训练更多维度数据和拥有更大参数，在特定领域超越开源模型。指出开源模型可通过引入多模态提升效果，并讨论了模型与用户沟通的挑战，以及提升模型语言能力的重要性。长期来看，扩展模态，如视频和3D模型的开发，将是未来发展的重点。"
      },
      {
        "time": "01:39:15",
        "title": "多模态技术在AI发展中的重要性及挑战",
        "summary": "多模态技术被视为AI领域未来发展的重要方向，能够模拟人类的学习方式，通过不同模态间的交互提高模型的理解能力。与单模态模型相比，多模态模型能够处理和融合多种类型的数据，如文本、图像和视频，从而实现更复杂任务的解决，如自动驾驶等。然而，多模态技术也面临着挑战，如如何有效地融合不同模态的数据，以及如何设计模型以实现模态间的最大交互等。此外，对于工具链的需求也在不断变化，需要更加简单易用的工具和服务来支持多模态模型的开发和部署。"
      },
      {
        "time": "01:47:11",
        "title": "探讨模型优化与编译器技术在资源受限环境下的应用",
        "summary": "讨论集中在如何在资源受限的环境下优化模型，特别是对于边缘计算和嵌入式系统。提出了模型裁剪和数据类型转换（如从FP16到int8或int4）作为减轻内存限制的方法，同时评估这些修改对模型质量的影响。此外，讨论了编译器优化的重要性，包括为不同硬件平台（如高通、NVIDIA芯片）选择合适的编译器和库，以及通过编译器技术统一不同计算资源的编程语言和优化运行时开销。提到了一些公司和项目（如OEML、Google的AutoML、AWS的CG maker neo）在这一领域的努力，它们尝试通过自动化的处理和编译器抽象化来解决模型优化和加速推理的问题。最后，也简要提及了大模型（如GPT-3）的训练和优化挑战，展望未来大模型可能的发展方向。"
      },
      {
        "time": "01:53:17",
        "title": "多模态模型在自动驾驶中的应用与挑战",
        "summary": "对话集中在多模态模型的成本、训练次数与自动驾驶技术的关系，以及如何有效整合AI于产品设计中。讨论指出，训练大型模型的成本巨大，强调了对训练成本降低方案的需求，特别是在多模态输入的情况下。提及了在没有增加更多传感器（如雷达和激光雷达）的情况下，通过加大模型复杂度来提高性能的可能性。同时，探讨了多模态选择的重要性，即确定哪些输入模态对模型性能提升是有价值的。最后，提出了产品经理在设计产品时，应考虑如何将AI有效地融入产品中，以实现最佳性能。"
      },
      {
        "time": "01:59:04",
        "title": "产品经理视角：问题空间优先于技术解决方案",
        "summary": "讨论重点在于产品经理（PM）在开发产品时，应更加关注于问题空间而非直接的技术解决方案。即使某些产品可能利用了AI技术，对于PM而言，首要任务是识别并解决重要的问题。讨论强调了从客户角度出发，通过PR FAQ工具回推（work backwards）以明确解决的问题和客户需求的重要性。此外，还探讨了产品经理应如何基于对技术的了解，将新兴技术应用于解决实际问题，而非仅停留在技术演示层面。重点是强调了理解用户需求，贴近用户端，以及将技术实际应用在解决用户问题上的重要性。"
      },
      {
        "time": "02:03:35",
        "title": "探索未来AI技术的发展方向",
        "summary": "对话内容主要围绕未来AI技术的发展方向，特别是对大型语言模型的进一步研究以及多模态技术的潜在应用进行探讨。讨论者对OpenAI和Google在AI研究方面的进展表示关注，强调了使机器学习模型能够像人类一样通过各种模态学习并交互，以实现更高效的能力提升的重要性。他们期待能看到AI技术不仅在技术上有所突破，更能颠覆现有的一些企业服务软件和流程，推进AI的广泛应用和集成，从而创造出全新的AI原生产品。此外，也提出了对目前AI发展依赖大量数据的质疑，希望未来AI技术能减少对大数据的依赖，迈向真正的智能。"
      },
      {
        "time": "02:06:54",
        "title": "探讨AI创新对未来应用生态的影响",
        "summary": "讨论中提出，当前AI技术，尤其是与人交互相关的多维度数据收集，以及AI创新在商业生态上的潜在影响，与五年前的图像视觉AI技术有显著不同。特别强调了AI技术在提高开发者效率、适配端侧应用的能力以及其对未来应用生态建设的重要性。讨论还指出，与以往产业导向的AI应用相比，当前的AI创新更关注于满足更广泛的人类需求，强调了未来AI技术在实现通用能力领域解决方案的潜力。同时，指出了创业门槛的提高，尤其是对于底层基础模型的创新公司，并对AI技术的快速发展及其对应用能力设想的影响进行了讨论。"
      },
      {
        "time": "02:12:47",
        "title": "AI领域投资的重点与挑战",
        "summary": "在AI领域，尤其是底层模型公司，人才和经验至关重要。与上一代AI相比，具备实际训练千亿参数模型经验的人才十分稀缺，因为这种经验的获得需要巨额投资。对于创业公司而言，拥有技术和管理能力的头部人才成为基础。在应用层面，产品设计能力、市场定位和对用户需求的感知是考察重点，而这些能力在许多AI创业者中较为稀缺。投资AI领域的时机也是一项挑战，技术的快速变化使得过早投资存在风险。创业者需要对所解决问题有深刻理解，同时紧跟AI技术的发展。投资策略应为大胆假设、小心验证，与行业一流创业者保持紧密互动，关注技术迭代，采取小步快跑的方式进行产品开发。"
      },
      {
        "time": "02:17:00",
        "title": "大模型训练成本与技术壁垒的探讨",
        "summary": "随着技术的进步，模型训练的成本呈现下降趋势，但初期的高成本以及高质量训练数据的获取、模型参数量与成本的关联、以及具备丰富模型开发经验的工程师的稀缺性，共同构成了技术壁垒。头部大厂凭借先发优势和资源集中度，在短期内维持领先地位，但长期而言，构建有效的商业壁垒是维持市场地位的关键。当前，政治经济环境复杂，中国在AI领域的跟进虽有进展，但与国外仍存在差距，特别是在应用层面展现出不同的发展方向。"
      },
      {
        "time": "02:20:34",
        "title": "中国AI和投资行业的发展前景",
        "summary": "讨论集中在几个关键点：首先，中国在AI领域，特别是大模型方面，目前可能比海外先进公司落后两到三年，主要原因是中国在这一领域缺乏高质量的人才。预期是，随着海外经验丰富的华人工程师回国，这种差距将逐渐缩小。其次，未来的竞争优势将基于商业生态系统的构建，尽管中美在这一领域存在隔阂，但中国有能力建立起自己的生态系统，尤其是在模型应用于C端和B端后。再次，强调了开源技术对中国AI发展的重要性，认为未来开源模型的出现将大大加速中国在这一领域的发展。最后，提出了对于创业公司的建议，即需要找到商业闭环，并且真正从用户痛点出发进行创新，避免同质化竞争。整个讨论对未来AI技术的应用场景表达了乐观的态度，尤其是对中国开发者和企业在这一领域的潜力持有信心。"
      },
      {
        "time": "02:25:44",
        "title": "期待AI与人类深度交互的产品创新",
        "summary": "在最近参加的Monica的播客中，主讲人表达了对AI未来应用的强烈兴趣，特别是期待AI能与人类进行更加自然的交互，解决广泛的人类需求，并形成强大的使用习惯。讨论指出，目前AI应用多集中在解决具体问题和产业应用上，而对于能够实现与人深度交互的AI产品的期待越来越高。随着技术的发展，人们的能力需求也在发生变化，例如，现在人们可能更看重如何高效地利用AI来增强个人生产力，而不是传统的信息搜集和处理能力。随着ChatGPT等技术的进步，未来可能会有更多依赖AI来完成的工作和娱乐活动，这将极大改变人们的工作方式和生活习惯。此外，讨论还提到了如何通过与AI的对话来发表学术论文，以及将AI生成的文字转化为语音的新应用。最后，主讲人呼吁更多的人参与AI领域的创新，共同推动技术的发展，以实现更加美好的未来。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [
                    {
                      "children": [],
                      "content": "参数量: 540亿"
                    },
                    {
                      "children": [],
                      "content": "特点: 架构为Transformer-based decoder-only, 大容量使模型具有强大的生成能力"
                    },
                    {
                      "children": [],
                      "content": "新颖能力: 解释笑话、复杂推理任务等"
                    }
                  ],
                  "content": "Google Brain's Pathway Language Model (PaLM)"
                },
                {
                  "children": [
                    {
                      "children": [],
                      "content": "参数量: 1750亿"
                    },
                    {
                      "children": [],
                      "content": "特点: Transformer架构, 强大的文本生成和理解能力"
                    }
                  ],
                  "content": "OpenAI的GPT-3"
                },
                {
                  "children": [
                    {
                      "children": [],
                      "content": "模型参数量继续增长"
                    },
                    {
                      "children": [],
                      "content": "研究重点: 模型在特定任务上的泛化能力, 大模型的零样本和少样本学习能力"
                    }
                  ],
                  "content": "未来趋势"
                }
              ],
              "content": "Large Language Model (LLM)"
            }
          ],
          "content": "AI技术发展"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [
                    {
                      "children": [],
                      "content": "基于扩散模型，生成高质量图像"
                    },
                    {
                      "children": [],
                      "content": "开源促进开发者和社区的快速参与和应用创新"
                    }
                  ],
                  "content": "Stable Diffusion"
                },
                {
                  "children": [
                    {
                      "children": [],
                      "content": "开源模型加速技术普及和应用发展"
                    },
                    {
                      "children": [],
                      "content": "商业模式的多样性"
                    }
                  ],
                  "content": "社区与生态"
                }
              ],
              "content": "开源模型"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "商业化能力强"
                },
                {
                  "children": [],
                  "content": "模型更新和维护有保障"
                },
                {
                  "children": [
                    {
                      "children": [],
                      "content": "高成本限制了模型的普及"
                    },
                    {
                      "children": [],
                      "content": "开源模型的普及对其构成挑战"
                    }
                  ],
                  "content": "面临的挑战"
                }
              ],
              "content": "闭源模型"
            }
          ],
          "content": "开源与闭源模型"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [
                    {
                      "children": [],
                      "content": "服务化和定制化服务"
                    },
                    {
                      "children": [],
                      "content": "企业级应用的定制模型训练"
                    }
                  ],
                  "content": "开源模型的商业化路径"
                },
                {
                  "children": [
                    {
                      "children": [],
                      "content": "API服务和专业版本API"
                    },
                    {
                      "children": [],
                      "content": "企业级集成解决方案"
                    }
                  ],
                  "content": "闭源模型的商业化路径"
                }
              ],
              "content": "商业模式"
            },
            {
              "children": [
                {
                  "children": [
                    {
                      "children": [],
                      "content": "对底层技术的长期投资潜力"
                    },
                    {
                      "children": [],
                      "content": "应用层创业公司的快速发展潜力"
                    }
                  ],
                  "content": "技术趋势对投资决策的影响"
                },
                {
                  "children": [
                    {
                      "children": [],
                      "content": "技术快速迭代带来的投资风险"
                    },
                    {
                      "children": [],
                      "content": "高成本和技术壁垒"
                    }
                  ],
                  "content": "面临的挑战"
                }
              ],
              "content": "投资视角"
            }
          ],
          "content": "商业模式与投资视角"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [
                    {
                      "children": [],
                      "content": "融合文本、图像、视频等多种数据模态"
                    },
                    {
                      "children": [],
                      "content": "增强模型的理解和生成能力"
                    }
                  ],
                  "content": "未来技术趋势"
                },
                {
                  "children": [
                    {
                      "children": [],
                      "content": "更广泛的应用场景"
                    },
                    {
                      "children": [],
                      "content": "更贴近人类智能的工作方式"
                    }
                  ],
                  "content": "应用前景"
                }
              ],
              "content": "多模态AI模型"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "商业模式的持续探索"
                },
                {
                  "children": [],
                  "content": "技术突破和成本降低的双重挑战"
                }
              ],
              "content": "商业与技术挑战"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "关注底层技术创新和应用层创新"
                },
                {
                  "children": [],
                  "content": "考虑技术的长远发展和应用场景的潜力"
                }
              ],
              "content": "投资机会"
            }
          ],
          "content": "未来展望"
        }
      ],
      "content": "AI技术发展与应用讨论脑图摘要"
    }
  }
}