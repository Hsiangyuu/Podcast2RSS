{
  "pid": "61cbaac48bb4cd867fcabe22",
  "eid": "638787d3882ce82fb6459490",
  "title": "EP 20. 【生成式AI专题1】对话Meta AI大牛、投资人、创业者：生成式AI机会与挑战",
  "task_id": "dexp9j6mbrvlq5ol",
  "transcription": [
    {
      "time": "00:00:03",
      "text": "欢迎来到onboard，真实的一线经验，走心的投资思考。我是Monica.",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:09",
      "text": "我是高宁，我们一起聊聊软件如何改变世界。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:15",
      "text": "欢迎大家回到Amber，我是Monica。这次我们讨论一个当下非常火热的话题AIGC，也就是AI生成内容。近一年来如果你对科技创业有所关注，就会发现这个领域陆续有很多创业公司，即使在资本的寒冬中，估值和商业上都取得了让人非常惊叹的进展。比如开发了开源文字生成图片模型stable diffusion的stability AI2019年成立，今年就融资1.1亿美元晋升独角兽。自动生成文字内容的公司，比如copy AI jasper，都是成立不到两年时间就实现了数千万美金的收入。在国内也有很多创业公司加入了AIGC这个创业热潮。这不禁让人回想起五六年前那一波AI的热潮，技术和资本热度上似曾相识，但是商业和产品化上又会有哪些新的可能性，哪些值得思考的挑战呢？",
      "speaker": "发言人3"
    },
    {
      "time": "00:01:07",
      "text": "这次播客我们就请来了硅谷的几位嘉宾，从AI研究员、投资人和创业者三个角度一起来聊一聊这个话题。田渊栋老师，很多AI的小伙伴应该都熟悉了。作为meta也就是原来facebook AI研究院fair的资深研究员，他也是一路见证了AI强化学习、深度学习这几年的研究进展。最近也刚刚发表了一篇长文本生成的论文。蓝是少见的硅谷亚洲女性投资人，她是basis sets ventures创始合伙人，投资了给我AI在内的几十家AI公司。而蒋全从产品和设计转身创业，他所创立的montera I入选了今年的yc将AIGC用于产品管理中。",
      "speaker": "发言人3"
    },
    {
      "time": "00:01:48",
      "text": "自我介绍环节，你也会听到几位嘉宾非常精彩的经历。另外特别的是，这次我们请来了一位客座的khost indigo卢，他是微博早期创始团队成员，离开微博后转身投资他的公众号。Indigo的数字镜像有关于AI元宇宙web 3等话题非常深入的探讨。他的加入让我们对技术的讨论又多了一些未来感，也是非常感谢几位嘉宾在感恩节周末来一起讨论这个话题。有投资人的视角和判断，有创业者务实的思考和探索，更多技术人对技术的思辨和畅想，发散的非常有意思。话不多说，enjoy.",
      "speaker": "发言人3"
    },
    {
      "time": "00:02:25",
      "text": "要不先从这个in go开始，我们今天这一次扣host可以给大家简单介绍一下你自己。然后等一下几位嘉宾也可以给大家简单介绍一下你们的经历，还有你们在AIGC领域所关注的一些东西。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:36",
      "text": "我现在人在温哥华，对，温coper这边，我应该是在2009年，最早相当于是我们从新浪里面孵化了新浪微博这样一个产品。我们是最早的相当于是cofounder一样的这样一个团队。然后我们一口气就做做了大概666年左右的微博，然后就离开了。在然后在应该是在离开之后，我自己也做过一个小提琴。",
      "speaker": "发言人4"
    },
    {
      "time": "00:02:57",
      "text": "对，做过创投。当然我们主要投的是中国大陆的一些偏消费和这种和互联网系的案子。对这个可能最有名的一个是我个人的投资叫什么？在李佳琪他们这个团队对他背后的公司这一家对他是偏向于直播的，社交和直播的直播电商的。之后我就在在在北美这边，可能主要做的多的也是在做一些顾问工作和一些投资工作。",
      "speaker": "发言人4"
    },
    {
      "time": "00:03:23",
      "text": "可能刚才莫尼克介绍我写博客也是从去年开始的。我就为了在学习这个新的科技和市场，也正在筹备一些想做二级市场投资的基金。所以说我就把这边比较新兴的科技的行业，我都做科普的方式给对外输出。我跟莫妮卡认识也是通过我自己的这个博客和他认识的。目前正在做AI的这个方向的一些文章，而且也在做类似的课程。因为我个人以前技术背景程序员，所以说对这个东西我会比较感兴趣。今天也带着问题来了，对，然后可以跟大家交流一下。",
      "speaker": "发言人4"
    },
    {
      "time": "00:03:55",
      "text": "好好，我也找到一个资深的q host来加持是吧？非非常非常激动，希望几位嘉宾可以跟大家简单的介绍一下你们自己。然后通常我的惯例是每一位介绍自己以后加一个conference。这次可以让大家这个提议就是跟大家介绍一个AIGC的领域，你目前比较关注的一个公司或者一个一个项目，可以跟大家简单说一说为什么。好，要不我们就从袁东老师开始。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:22",
      "text": "好，对，我首先第一个就是说我这边是做研究的对吧？做那个比较一线的一些比较客厅edge的一个研究。我们这边主要还是做强化学习和优化，还有一些深入学习的一些分析。AIGC是一个很有意思的领域，正好就是我们我这边有一篇有一些文章对吧？这文章可以生成比较有长的连贯的故事。这个其实是一个也不是说是说是重金押注了，只是说是一个就是我得知的这样一篇文章，那确实效果还确实不错的那对，在这往上最后可能再往下可能还会再往下做一些。对，那么这篇文章主要做的动作，是因为现在大部分火是那个基于image的，也可以生成大量的非常真实的照片，就是根据那个词可以用词来生成图，这个图的质量都非常高那我们这边我现在制作的这篇，其实已经投出去了，而且已经中了是中了今年那个EMIP，在中东会开会去开会，我可能不会去，然后我们一坐回去。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:25",
      "text": "这篇其实主要是解决另外一个问题，就是怎么样生成长文本。就是说你现在就算UGB3这样很大的模型，那个open ID模型，你用真正长文本也会产生不连贯的问题，就是说你可能生成了一大段，那么长是非常长，但是它写着写着就会歪掉，前面一段可能在写的是啊，比如说写的是什么，动物世界，写到就后面就变成了变成什么孤胆求生这种，就是这种不连贯的这样一个故事。怎么样让这故事变得连贯了，反正变得跟小说一样，就是有前后是有一个恰当是比较连贯的一个情节角色。是实质上难解决的问题，我们这篇文章设计一个系统叫RE3。这个系统是通过一些prompting nearing的这样一些技术，能够生成比较前后一致连贯的成本。是这样的一个篇文章。在这篇文章里面，我这边主要是发挥就是我作为业余小说家的一个一些一些一些一些一些直觉和经验。就是人类写小说跟机器生成文本其实是不一样的思路，如果如果使用人类写小说的一些思路其实确实可以让机器生成文本的思路做出来的东西会更好一点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:39",
      "text": "陈老师可以跟大家简单提一提你自己比较关注的一个AIGC领域的这个公司或者项目。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:46",
      "text": "那就是说既然我们这边做的是consistent的这个long text nation，对，那肯定还是会再继续关注文本的生成能不能更长，能不能更更一致。对，主要是这些。能不能比如说结合我们自己的强化学习的那个方向，这个强项主要是这样的一个方向。当然了就是说怎么把它和图像结合起来，也是一个重要的一个关注点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:11",
      "text": "好，我发现这个不愧是这个researcher做自我介绍，这个researcher的内容比自己的这个经历介绍所以更重要。但是我想说应该是田老师应该是在在拜上很多年的时间了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:23",
      "text": "对对对对，我忘了忘了这个自我介绍这个句子了。我可能一讲research有点讲比较长，对我在北大已经八年，快八年了是吧？对好，对，然后115年15年1月份入职，然后到现在差不多快八年的时间了，一直是在做那个研究。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:41",
      "text": "好的，那可以说也是上一波和这一波的AI都都见证了。等一下我们正好可以结合历史聊一聊。要不澜可以给大家。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:50",
      "text": "介绍一下好，大家好，我简单介绍一下，我是在中国出生，然后来美国读博士，我是读的脑科学。读完博士以然后我就去做了一个start up。然后start up退出以后去麦肯锡纽约，主要是在纽约在上海做了一年，去做这个management consulting。后来比较荣幸的很早期的加入dw box，是那边比较早期员工来到硅谷。然后当时是投资并购部门负责投资并购的，我们收购了很多很多的公司。2016年2017年的时候，我就离开draw BOX，然后去创办了basis ventures。",
      "speaker": "发言人5"
    },
    {
      "time": "00:08:31",
      "text": "我们是一个早期的基金，主要是集中在投种子和A轮的公司。我们其实主要focus在AI和automation，所以近大概四五年之内投了40个到50个没基金，大概投25个公司，所以两期基金可能是大概50个左右，这个cool company大概是这样，我base summer cisco。最近其实有很多从中国来的创业者想在这边想创业，欢迎大家一起来交流。",
      "speaker": "发言人5"
    },
    {
      "time": "00:09:07",
      "text": "Fun fact，我刚才听那个train说是他以前在skill。我其实是scale最早的一个投资人之一2016年投了他最早的一轮，当时估值是15个million，那个时候touch school应该是最早的一个AI native的一个公司。那他上一轮的工估值可能上一轮公司可能是a point three billion。所以这个就最早的一个I投资，就这样，谢谢。",
      "speaker": "发言人5"
    },
    {
      "time": "00:09:35",
      "text": "太这个太重磅了，而且我看到好像skill最近也是推出了一个AI做to AI的一个工具。是好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:45",
      "text": "对，这个有公司都会。因为这些model最近都做出来，integration都很容易。其实像GDP three他很好几年前就做出来，只是没有一直全部都开放。所以最近开放了以后，很多公司都去跟他integrate上做很多不同的东西。这个串的还是很有意思，我们可以继续聊吧。Scale其实18年在alex他的那个CEO founder来中国18年。对，当时我们去参观tiktok，然后当时比较震撼，因为他那个take talk的这个August比较厉害。",
      "speaker": "发言人5"
    },
    {
      "time": "00:10:18",
      "text": "正好我们可以正好这次又可以从不同的角度来聊一聊了。好，那纯可以来聊一聊。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:25",
      "text": "好，大家好，刚才听了特别激动，这边我the scale之前的一个网站上来的照片都一直都很大，就在那个的page那边。然后袁东老师我也是经常在推特上面和linking上面看到他分享了一些特别好的inside，所以非常激动在这里大家好，我是蒋纯，也可以叫我寸寸，目前是montera I的一个co founder。我们公司主要帮软件公司团队自动分类和标注这个用户反馈，然后在你写技术文档、产品文档的时候关联出来，生成一个初步的一个产品文档，需求完成以后，自动再帮你自动生成与提出需求的用户交流的一个性化文本，完成这样一个从收集用户反馈到执行再到沟通的一个流程。",
      "speaker": "发言人6"
    },
    {
      "time": "00:11:07",
      "text": "我四年前从大学大学毕业以后，一直在自动驾驶，然后data和ML这块领域做产品和产品设计，也是很有幸经历了高速成长公司。比如说uber scale AI创业之前，在一家叫做unfolded的一个大型地理数据处理公司作为head product，去公司去年被4K收购，所以三个月前我就按耐不住了，就开始和我的口红的人开始做monitor AI。刚从YC毕业，刚完成了一轮种子的，也可以说是刚踏上这个征程，特别期待和大家交流。",
      "speaker": "发言人6"
    },
    {
      "time": "00:11:39",
      "text": "Fun fact AIGC最喜欢的一个公司，现在这个好的公司实在是太多了。我觉得除了我自己的公司之外，强推一家我好朋友的公司，叫做RTOARTSIO。我觉得他特别神奇的点，就是特别特殊的一个切入点，是相比于alexa或者说是playground这种，他们可能是第一家把这个艺术家风格作为一个主体的AI体系的一个公司。因为大家也知道image model这种知名艺术家的风格是prom的关键。所以我觉得他这个切入点就可以引发出非常多关于艺术教育，版权之类的讨论，我特别看好他们的前景，就这样。好的。",
      "speaker": "发言人6"
    },
    {
      "time": "00:12:15",
      "text": "我们第一个话题，我们先从先回顾一下历史，因为几位都是在这个AI这个领域有挺也挺长的时间。我们来看其实在如果大家记得的话，其实可能1516重点就是这个computer ation。就计算机视觉为代表的这个AI也其实火过一波。但所以现在我们看到，包括现在很多像这个me journal stability，其实也都是在我们也看到是在视觉方向。所以也请请几位回顾一下历史，就是在这一波我们看到真正FAI的这一块浪潮，跟那之前我们的看到这个AI的阶段还有什么不一样的？这个地方我想可以先请田老师来聊一聊。就从技术的这个角度，就现在我们看到了这个TVI到了技术上跟之前他是做了哪些准备，使得这个整体的现在能够成为一个大家可以商用的一个技术。而跟上一波这个AI相比，就是您所在这个技术和研究的这个领域，大家可能现在关注的关注的点会有什么不一样？",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:15",
      "text": "好，对我确实也是算经历过以前上一波那那AI那些人了，对吧？因为之前人我很早以前是做围棋的，就是刚刚进facebook的时候是做了个比地方还早一点。对，后面还做了那个open go，当时是重现了alpha zero，就是这个软件这个strong superhuman的围棋的软件。然后当时打败了很多韩国棋院的一些骑手，给他们很多的时间去去跟这个AIPK，然后PK不过，然后我们获得20比0的成绩，那当时是18年的事情了，所以就是说那个时候确实第一波是那个游戏和和board game是把大家拉起来的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:00",
      "text": "大家可能会觉得那么厉害，能够把很难的一个问题解决了。这个问题可能就是在解决之前，大家可能认为围棋可能是这辈子永远人类是永远是能战胜机器的。其实发现不是这样子，所以这波打破人类认知，导致了大家愿意把钱投进AI这个领域，现在是我觉得当时是这样子的，那那段时间确实因为整流性model其实也是也是一个比较有意思的方向。我其实一直是看文章的时候，看的比较多的话就会看到这些文章，对吧？那么区别其实很清楚，就是之前的AIAI诊流程model就是用的是gain来trend的。Gain有个问题就是训练不是很稳定，然后训练出来的那个结果其实也不一定非常好啊，所以这倒是很大的一个问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:45",
      "text": "对，大家可能有没有看过，网上有个一张帖子，就是2015、15年、16年到18年、19年生成出来的图像是有多大的进步，你发现的进步是非常巨大的，就说在这个训练这个过程，让这个训练变得不稳定之后，就是让这个训练过程变得非常简单，或者非常的非常平顺，这个是一个整个AI界的一个不懈努力之下，最后达成了这样一个结果。最近我们可能大家都不用gain了，要用那个diffusion model那么一点点的再加细节加上去。这个model去年起来虽然说比较慢，但是确实比较稳定。然后得到结果也比那个的那干的效果要好啊，这是其中一个的一个突破的一个点。另外一个点就是说是transformer的一个一一个引入。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:30",
      "text": "Transformer主要的一个好的地方是它能够把多模态的数据放在一起，进行对齐，然后把一个模态的信息转到另外一个模态上去。这个非常重要。因为以前比如说你的训练或者生成图像，有些时候一种是无条件生成的in conditional那个generation。就是说我给它一个随机数种子，它生成一个图形，那么生出来而不可控制，你并不想让它生成什么，就是并不知道他要生产出来什么东西，所以这个是很大的问题。但是这个虽然说可以用了，但是他还没有做到商业化。因为商业化其实很多时候是需要指定生成的是什么样的图像，能够在什么地方应用。这是一个controller的这个QT。以前的矛盾其实是比较有限的，传送以来，一个好的地方是我可以用那个文字去控制图像的生成效果。因为传送有个动模态的融合能力，所以我可以把图像，可以把那个文字都转化成transformer的token，又转化成transformer ebel ding 18年之间，他们之间是相互之间可以翻译的，你这样的话你就可以把那个文字变成图像，通过这个方式就就能够就能够训练的也比较好啊。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:37",
      "text": "我觉得另外一个可能的一些突破，就比如说像clip这个loss function。有些losunger的改进，其实能够让训练出来这个embedding就变得更精细，可能理解更多的或者更深入的语义。比如说我告诉这个模型A在B上面，很多的模型可能不能理解这个语义，但是有些模型你可以理解这个语义，那么用这个语义就会很好的控制这个图片，那么通过这些比较大比较好的这样的一个进步，最终能得到一个比较好的或者说受控制的一个是图像生成模型。这是为什么现在那么火的一个原因所以说就是现在能火就是要得益近十年来大家的不懈努力。把这个图像生成的效果一点点在往上推，一点点往上推进，最后达到这样的效果，应该是这样子。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:23",
      "text": "我非常感谢，我觉得钱老师的这个综述做法好。刚才其实您提到的像这个对抗式网络，这个game transformer这些。如果不甚了解的同学，我会把这个大概的解释放在我们的show动词以后大家可以看，正好从投资的这个角度来，也是一直在做着AI0的投资。也可以跟大家分享一下你所看到的这一波跟之前的这个不一样，有什么让让你觉得非常非常exciting的事情。因为我想一个问的比较直接，就是其实上一波那个热潮之后，我会发现当时很多其实真正做这个computer vision，做AI的公司，其实我们后来看到成功的其实并不是很多。那这次会有什么相同和不同的地方？",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:01",
      "text": "我觉得AI的hip大概每每四五年就有一波，所以其实对几十年来总是有这个AI的hip。我当时成立杯斯赛的时候，17年当时有一个比较火热的一波，现在又是一波。我觉得这次和上次最近的一次主要的不同。当时从技术上袁总讲的挺的很好。",
      "speaker": "发言人5"
    },
    {
      "time": "00:18:23",
      "text": "从商业上来讲，主要就是看这个technical technically是不是good enough。因为每次近几十年来的strugling，就是你和human level的这个accuracy和这个performance相比，你到底是有多接近或者多好。其实这一波出来的这些技术上来讲就已经就已经非常好了。所以大家非常很很惊讶这些结果有这么好啊，这样的话其实有很多的use case，举几个例子，以前的这些其实大的公司都是被这些呃，是，独占的。比如说apple，比如说microsoft，amazon, 这些都不是一些AI platform。他们都是解决一些比较basic大家的问题的那进一波的这些因为技术非常好的，所以这些新的use case会出来，会有一波新的AI native platform。我觉得这个是我最我最激动的一点。",
      "speaker": "发言人5"
    },
    {
      "time": "00:19:21",
      "text": "这些的use case这些新的公司，我觉得大概分成两种。一种是基于在这些最好的战略model，基于这些像OpenAI这model上建立一些公司。比如说现在我们看见copy AI jasper，其实有很多很多公司现出来我们自己投的，有这个opener，有with com，有fast AI有很多的都在基于这些model上建立一些公司。还有一波其实现在大家说的不是很多的，是一些解决非常复杂问题的工业问题的。比如说我们投了一些公司叫tomas warning，就是焊接机器人。比如说，即使是自动驾驶的汽车，还有一些建筑机器人，就construction robot，这些其实是非常难的一些问题。这些model不是只能解决非常少的一些问题的问题的公司就这些公司会起来，只是这个时间的问题。所以我觉得两方面我都是啊比较看好，就看什么样的temporizing。近几年我觉得是这些小youth case会被figure out。5到10年我觉得很这些automation AI很多很多公司会有一波非常多的AAAI native公司会出来。",
      "speaker": "发言人5"
    },
    {
      "time": "00:20:31",
      "text": "这个我其实也我我这个其实也多问一句，就是我正好其实在1516年那会儿，我正好也是在我正好是在一家非常早期的AI创业公司。然后也是以一开始也是跟他相关的，我印象特别深刻。就是当时我记得我们刚开始做的时候是当时是facebook，现在是meta的这个open pose刚刚出来。然后那个时候就是那个时候我们觉得我们做这个model又比faced这个facebook当时做的又快，而且又能run on edge，然后就各种都很好。但是很快就会发现，可能过了几个月对吧，所有人都掌握了所有人都掌握了这个技术。后来什么这种抠图，这种就有这种识别，都变一下子就变得非常的普遍了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:09",
      "text": "所以就像蓝刚才说的，后来好像就是然后后来好像没有哪个公司说基于这个contribution可以做出了一个比较好的公司。那我们会看到现在好像很多公司都在拼自己的我的model就是我们的model就是fine to的怎么样。那那等到技术最终都被comment了以后，那我那这次谁能够真正的赚到钱能够赚到钱this is model会跟之前有什么不一样吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:34",
      "text": "我觉得这是good question。现在就很明显的有大概其实三波公司，一波就是专门做moto。其实像OpenAI，像像这个呃呃呃就是还有一些大公司，现在做都做自己的model。他们有很多很多的基金，像microsoft已经投了一个并列更多。这样的话，它其实你training model是要有很多的这个钱。很多research要train model的，我觉得winner还是会concentrate。",
      "speaker": "发言人5"
    },
    {
      "time": "00:22:00",
      "text": "有最多基金的这些公司，因为吹mode是非常珍贵的那第二播这些公司其实就建在我刚才说建在这些model，用他们model去找这些场景的这些公司能够找到非常specific use cases，然后去main test。这些公司你跑的最快的其实是可以赚很多钱是可以赢的。因为做帽子公司他不会有那么多时间去做这些use case。那第三波其实很多时候都用不上这些报道，因为这些这些公司他们必须得建自己的新的model，是非常specific viral。比如说焊接机器人这个东西就是你有很多的这个实在太难做了，你要自己做一个机器人，现在很多model是用不上的，你要自己要做自己model，也会去leverage off the shelf。这个东西我觉得其实如果能做出来，就基本上是一个hundred b and o的公司。我觉得这三波，我个人都非常看好，就看作为投资人来讲，我每个赛道都会去看，都会去投。",
      "speaker": "发言人5"
    },
    {
      "time": "00:22:53",
      "text": "好的，那正好讲到这个能讲到新的方向，肯定要问问这个创业者了。蒋晨可以跟大家聊一聊，为什么你当时会选这个方向来去创业。然后也可以给大家简单介绍一下，说你们的像技术站未来对这个商业化是怎样的一个计划。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:11",
      "text": "这个是我每天每天睡不着我睡不着的问题。对，我们就是pretty fit into咱刚才说的这个第二波的公司。然后就我个人经验来讲的话，我大概五年前就是那个AI上一波hype的时候，刚毕业，然后当时就选了加入自动驾驶这一块的方向。当时我记得我的manager说就跟我说说你有计算机和设计背景，那你应该利用这个优势去把最复杂的技术抽象和简单化，并且创立人和用户与这个技术之间的一个trust。然后我觉得我的职业方向就一直在他当时给我说的这句话的方向上讲，然后做montreal I也是机缘巧合，因为大概在四年前的时候，我在uber的时候就非常痛苦。收集用户反馈和写产品文档，然后再跟用户反馈的这几个就有用好多好多个不同的to我。然后从我的角度来看的话，它不仅仅丢失的是一个沟通的成本和一个时间成本，更是丢失了这个highly valuable数据。所以当想到这个monitor idea montera I idea的时候，我就跟我客观的说，我说like if you can find a place to connect the feedback to you spects，and then inform the feedback, respect and advice for some.",
      "speaker": "发言人6"
    },
    {
      "time": "00:24:28",
      "text": "这会是一个不光是能够给现在的这个产品经理或者产品团队，甚至说是and manager带来非常多like instant benefits。而从这个企业角度来讲，他把各个方面的数据给串起来了。这也是我觉得AI能够帮助到最大地方，那从一个business角度来讲的话，因为我们现在才做了这个第三个月，我可能之前我一开始想的是OK，那我们就做这样的一个platform，收集这个user feedback and january prospects and and then back users，tell them like what we deliver. 这是非常好非常清晰的思路，但是也是之前想要做，我们要努力的去做这个prompt engineering，努力的去做这个fine tuning，在我跟更多越来越多的用户聊的过程中，可能发现他们更需要的是，比如说这些order grouping，user feedback, auto tagging，user feed back.",
      "speaker": "发言人6"
    },
    {
      "time": "00:25:21",
      "text": "这会给他们带来一个更直接的一个benefit。然后还有一个生成式的带来的最大的好处是啊，他们能够自动generate email，然后告诉提出需求的用户说给你好多少天前提出的这个需求，然后再给你加一些like personalized message，to make the conversation between user and product in Better。所以可能说就是生成式AI在preda management或者说prodder development这个角度，还是要像刚才两位说的一样，就是说要找一个非常细的一个u case。然后可能也是从先从短的文本开始，然后再慢慢的过渡到一个生成一个非常长又非常高精确度的一个超额的。这是我三个月以来的一个感悟。",
      "speaker": "发言人6"
    },
    {
      "time": "00:26:08",
      "text": "刚才有听到就是说生成长文本的问题。对嗯，因为我我个人做了一些研究之后就是发现因为现在大量的模型，其实在这个自然语言数据的NLP领域里面，其实就是transformer。然后我不知道田老师这边看你们在transformer，现在用它它这个attention的机制，应该挺难生成大段的这样的连贯性的前后有关联性的长长文本。再往后面从你们这边角度来看，如何让整个文章的结构化？应该是会有什么突破出这个模型之上。",
      "speaker": "发言人4"
    },
    {
      "time": "00:26:43",
      "text": "对，因为我们这篇文章其实就是为解决这个问题，就是当时我在生成比较长的小说，我长的是story的长的故事。对，如果你只用传answer来生成的话，那确实会出现上下文丢失的这样的情况。丢掉。对对你说着说着他就不知道跑哪去了，离题办理，然后接下来你就再也回不去了，对吧？或者说陷入恶性循环这种情况。对，当时那那我们这篇文章已经发表了，对吧？所以就是他他这个一个关键的点就是说要控制它的prompt，就是在输入框。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:11",
      "text": "中O.",
      "speaker": "发言人4"
    },
    {
      "time": "00:27:11",
      "text": "K对就是我要把过去的那个文本的细节，文本的那些summary和角色的一些设定，还有角色一些特质，包括整个文章的主题都要放进那个prompt里面去。这样的话生成出来文本才会有的放矢，它才会有一个比较好的，或者比较跟以前的文本一样的，或者说一个比较连贯这样的一个架构，这个是一个很重要的一个点，你会发现就是你把那个上下文放进prompt里面之后，生成出来的文本就会好很多。当然了，我们这边之后还有一些后处理的一些不知道。比如说有一个就是重新再重重采样的一过程，你可以生成比如说20段。然后我们有一个方法可以把这个20段，比如说排一个序，然后只取最相关的一段，然后作为下一段来处理。这样的话生成出来文本就是又长了又连贯，那目前我们可以生成2000到比如说7000词的英文词的这样的文本。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:04",
      "text": "还是比较连贯的那相当于是还是用了transformer的模型，只是在上面对。",
      "speaker": "发言人4"
    },
    {
      "time": "00:28:09",
      "text": "其实对我们还是用的那个我们这篇文章还是用的GPT3，有时候不来的transform用transformer来做的。当然是这样，这篇主要是用来生成或者是故事，或者说小说，这样的一个东西。对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:24",
      "text": "对，就这是我刚才一个疑问，就是在这个下面其实就涉及到人工智能的另外一个问题。因为像3 former，它其实好像是所有模型的一个终结模型。现在来看它可以把任何数据都变成token，然后从另外一边变成token输出出来，应该可以图像文字，其他的什么钉钉，什么序列都可以。有没有可能这个transferral会把更多的东西给统一了。您前面讲到的，在这个之上在推动它实现不了强强结构的逻辑。是不是在这个逻辑，就像模拟人类思维的这个逻辑之上，会有一种新的模型诞生，它会形成这种模型再结合起来。这我这个我我很我我个人随意思考的，我想要一下这个问题。",
      "speaker": "发言人4"
    },
    {
      "time": "00:29:04",
      "text": "我们可以回过头来讨论。因为我到难等下要提前走，所以我插一个问题，插一个这个资本家资本家关心的这个资本家。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:11",
      "text": "对。",
      "speaker": "发言人4"
    },
    {
      "time": "00:29:12",
      "text": "就是对，因为我就讲到，因为刚才讲的这个generate VI的这个business model，就是我想这个也想请来介绍一可能介绍一个你们在这个领域看这个交易to VI的这个公司的时候，你们最关注的几个点是什么。然后另外一个也是从我最近的一些，一些思考的角度是那怎么去看待真正在这个领域的公司的优势。比如说我们看到最近其实像，notion这些公司也都在推出自己的，AIGC的一个功能。就像你说其实像有了大模型，这个对于不仅是小公司，那现在这种incoming其实他们自己也挺有优势的那到底是说未来我要不要说我要做一个很好的文本生成的公司，或者我要做一个很好的很好的比方说视频宣传公司，那是不是可能不如像notion或者是grammar这些。我已经有很多客户，我把一个功能作为我产品的一部分。其实一下子来很多用户，或者说比方抖音对吧？抖音来做一个自动生成视频的一个工具，是不是它的这个优它这个渠道所有渠道distribution的优势，会对于很多setup的未来的发展会是一个比较大的一个挑战。就会好奇从投资和商业化的这个角度，来听听这个蓝的一个想法。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:24",
      "text": "我觉得这个great question，我们其实看的时候关注两个点。第一个就是回到本源，看看你做的这个公司有没有真的去解决用户的问题。很多公司其实model很好，我们建一些东西其实你看起来就是像一个玩具一样的。它它其实没有解决很大的问题。如果能够invite到一个workflow，能够解决真正的大家的痛点的话，这个use case让大家愿意付费。这个其实我们看的就是很多的一点。",
      "speaker": "发言人5"
    },
    {
      "time": "00:30:52",
      "text": "举个例子，我们有个呼叫叫WI他们其实就是对于这个product design，不是我们说的是design，你去design shoes，design course这些东西，你在它的这个软件上画一个车，他就马上帮你涂色，马上就可以6g models，可以变成一个之前要花很好几天好几个礼拜的东西，才能建成的一个product。这个东西大家是愿意付钱的。所以像这样的use case，我们其实是非常看重的。Similar a opener, 它其实有很多这个UCC现在大家已经开始付费了，我现在因为他们还没有搬去out of，所以想给他们保个密。",
      "speaker": "发言人5"
    },
    {
      "time": "00:31:33",
      "text": "第二个是我们很注重一点就是speed of generation。就是你刚才说的这个gold market和in comments他们有的一个很好的advantage，就是他们有这些客户，有这些已有的科员。他们如果可以很快的把他们这个产品就变得更好，那他们可能就是理论上来讲应该是。会更快的去赚更多的钱，但是问题就是他们没有那么快。所以start up最最有效的一点之一就是他们速度非常快。所以我们看这些founder时候，要看他们的speed dating，他们能做多快，他们这个产品能够做的多好。",
      "speaker": "发言人5"
    },
    {
      "time": "00:32:10",
      "text": "所以第一和第二，你要看的话，它其实是是相悖的。In comments他们是有很多客户，有很多客源，有existing good market dirigo tion，但是他们就是不够快。所以这些新的技术出来，新的这些东西出来，他们就很难去很难去integration不是最难的，就很难的是你怎么能够建一个product是在已有的客户的海北之之之之中之中，是让他们可以用上来的。这个是不是只是说你AAPI就可以做到的，你需要重新去想你的这个产品要做成什么样子。我觉得这个事情可能才做的比较没有优势的一点。那反过来讲，这个start up虽然他没有这个distribution，没有这个呃客户，但是他可能重新就像一张白纸上你想画什么都可以。如果能找到这个pinpoint，能够能能够找到这个use case，那其实他会走的很快。",
      "speaker": "发言人5"
    },
    {
      "time": "00:33:04",
      "text": "所以这两点其实一直都是就像好好像是一个皮筋儿一样的，两边都在拽着，是一个一个一个fine baLance。所以我们在投资的时候会比较看哪个公司。如果既有痛点，那只能让痛痛点，又要付钱，然后又能快的话，那这个肯定会投的。但一般都是会是一个trade off。我觉得其实这个时间其实更perfect，可能不好意思，要去有一个confident。如果以后还有什么需要讨论，大家有兴趣讨论的，可以在推特或者其他的邮箱里都可以跟我联系，谢谢。今天可以跟大家聊聊的很开心。",
      "speaker": "发言人5"
    },
    {
      "time": "00:33:41",
      "text": "好的，我会把咱的这个推特也放在也放在这个show到里边，大家可以在twitter上跟他互动，有非常棒的inside。正好其实我觉得刚才的这个问题，其实我也想去follow up一下。我们再让我回来去看这个技术问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:53",
      "text": "我只是想畅想，其实AI的这个行业它是蛮涌现式的，它它突然会有一个新的一个模型，一个model，会把之前的东西全部都，所以说大幅的提高效率。所以说在这个里面创业，他就像大海里的颠簸一样，他突然间你就可以永生而起。所以说我在问前面那个田老师这个问题，就现在圈的模型就是这样一个万能模型，就是在他之后我们想实现更强的逻辑，把这个逻辑给实现人类的这种结构能力给实现了。那是不是意味着还会有更新的这种不一样的模型出现，来把这些模型给融合起来。对我我能解。",
      "speaker": "发言人4"
    },
    {
      "time": "00:34:30",
      "text": "这当然是终极问题，很好的问题，很好的问题。对我觉得是这样，就是你们看的东西都是涌现的，但是我们看到的就不是涌现了，就是很多事情就是已经有苗头了，对吧？就是说你文章看的多了之后，你知道这个东西会出来会有效果，当然预见到效果特别好，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:44",
      "text": "比如说你说civil division是你们看到的突然冒出来一个问题，其实不是，就比如说就像今年年初，比如说那个DAAAE对吧？Dala e me too, 去年DALAE德拉E其实已经挺惊艳了，就比如说它能生成出来，比如说一个一个一个牛油果的椅子？这种感觉非常漂亮。对，那个时候已经有。就那个时候其实它的它没有做到场景生成，做到物体生成，有物体生成出来不错，在场景上来说还不是特别好对吧。但是今年LEVE two，然后这边有那个make up，make sing、make a video, 这边有很多的那种版本的。就是东西已经出来了之后，才会有stable division。所以这个过程的技术其实是有一个非常的一个非常渐进的，或者说一个非常的一个情绪的一个过程。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:28",
      "text": "学术界这边其实大家都有一个有就看能看得到，有一条路能过去，就是再往前，你比如说那个NVIDIA，有一些比如说model，比如get model，那甚至很难，毕竟是人脸对吧？然后D麦那边有没有big gan也生成很详细，变成图片，就是图片生成尺寸越来越大的，然后效果越来越好的，所以所以真的没有surprise，就是确实大家一直在不停的努力，慢慢终于努力到露头了之后，被上一届人发现了，那么有厉害。是你们觉得好像涌现其实不是这样子，所以transferred好像是比较突然，还是他之前就有transformer？其实很久，201年就2017年，2014年，我就是2017年，那也是那篇论文，对吧？对，而且这个它其实本身也是一个比较大的突破。因为对那边其实主要的突破就是参数比较少了很多，十倍还是五倍，那效果更好了，就是跟相对以前我来说，当时他出来的时候，其实这个学术圈里面就会觉得这个很不错了，这个非常好啊，非常有效果。当然了当事人因为很多问问题，比如说长文本非常慢，比如说它是一个平方级的一个指数一个复杂度，那么还有很多时间花了很多时间去改进它，然后去做。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:33",
      "text": "我就想说干脆田老师把那个速度这个问题，performance问题再把它上一个台阶，影响着下游的公司。",
      "speaker": "发言人6"
    },
    {
      "time": "00:36:44",
      "text": "对，就是说像陈思傅当当刚刚出现的时候，也没有那么火了。因为它是一个surprise model的一个一个另外一个architect，对吧？但是他一旦搭上了，比如说self super model，搭上了一些不用用label可以训练的模型，那马上就火了。然后就这两个东西搭，然后因为你有大量的数据可以分，那么你就是bert。Bert一出来之后，整个NLP的领域，比如说你跟大家聊天，他们短信都跑了，他们可能会觉得以前NLP是这么玩的，然后不知道一出来以前就不用玩了，就把他这个厂子砸掉，就是换就是在以前可能是不同的，比如说PA或者不同的那个language的task。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:20",
      "text": "它要单独训练一个模型，然后得到更好的效果。那么要单独标注，单独把那个数据放进来，对吧？但是等到bird一来，我就在boss上放听就好了，或者说bod不动，然后穿一个subsequent的long three model就好了。这整个改变了训练的流程，所以这个其实当时在业内也是很大的一个震动，这个都是很重要，这些东西都是都有联系的。这样的话为什么才会让陈世贸这个模型大行其道？大家永远觉得这个很有前途。我再往正在往下走，才会有以后就会有多模态的这样的一个模型的诞生，对不对？这都是人脸上的，所以这个都是像你们说你说逻辑对吧？逻辑上面有有另外一条线就是那个搜索。其实你说alpha go alpha zero这种像我们这个open goal都是通过搜索来决定什么样的什么样的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:07",
      "text": "有一个叫做从路径搜索的算法是吧？就蒙特对。",
      "speaker": "发言人4"
    },
    {
      "time": "00:38:11",
      "text": "有很多算法，很多很多搜索算法，所以搜索其实早就就有了。对，所以并不是说是啊突然冒出来说我们家的搜索不是这样子，搜索早就有，在阿法狗之前也是很多很多人花很多时间去做搜索。围棋的程序很早前就有了，唯一的区别就是以前的微程序没有深入神经网络，现在用了，突然间把它突破，就是有这样的一个技术的连贯性。所以以后的模型如果要要有突破，也是通过把这技术连贯性拼起来，或者说有新的一些模型拼错。一个新的模型一个对你现在这样一些是对，也不是说是有人看到想出来，因为它里面的各个各店其实以前就已经有了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:46",
      "text": "对，那现在田老师觉得你就是您所看到的这个general to CI相关，有没有一些就是你觉得还可能还在非常早期，但是可能或者一些paper也就有一些sn是有可能的方向。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:59",
      "text": "这个很多很多了，就是大家业外人都觉得要同世界了，业内人都觉得太蠢了。就是这样的一个然后生成我们著名文章之后，你就我作为一个业余小说家，我看了他生成出来小说，实在太太太太太蠢了，对吧？就算他成了，就算他是前后之间有连贯性，但是你要看每个角色之间有没有动机，有没有故事，有没有高潮，有没有结尾，那个角色之间有没有互动，角色之间的互动是有没有一个紧张感的，能够带给读者一个读下去的感觉，这都没有。对这些东西非常难做。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:31",
      "text": "然后还有就是说你要写一部比较长的故事的话，有很多的非常的细微的地方是要注意的。这些细微的地方其实一般的原模型是很难去抓住的。比如说在你这部小说里面，某个词代表一个特别的含义，或者这个词和这个人是有关系的，但这种其实很难在一般的文本里面能抓到的，这种都是很难做到。就比如说在这个文本的语境下，或者说在这个故事的语境下，他是就是问这个脱口之间的关系。这个就无法用大数据去去搞定了，这种都是一个非常困难的一个问题，这种其实很难做，而且现在我我我不觉得要通过大的模型能够解决这个问题，就比如说这是一个例子，还有一个例子就是说比如说做推理，做那种数学上的推理什么。现在确实有很多mass for AI的，或者AF mass这样的一些工作，但他们能解决的就是说比如说解决一些已有的一些数学问题，比如说奥林匹克竞赛的一些问题。你这个问题已经有答案了，而且知道大家知道就是通过已有的一些数学的一些定理，能够推导出来最终的那个答案，对吧？其实就拼就塑造效率怎么样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:40",
      "text": "但是大数学家不是这么做大数学家做数学问题的时候，很多时候是啊他会为了解决流水问题，那自己在是自己在搞一套数学工具，或者说有一个基本的一个思想或者思路去做。这也是就是基于问题本身有什么样的一些特别的一些结构，他有自己发现，利用这个结构去更好的搜索这个问题。这个都是空白，这个都非常难做，现在没有什么办法可以做这些东。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:04",
      "text": "那我想讲什么？你们你们是基于什么样的这个模型，然后你们在发展过程中发现了哪一些比较全面性的地方？",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:13",
      "text": "对，就是创业公司就非常难。因为你你的最终目的还是要赚钱。然后对于这个技术，下一项技术什么时候出来，你永远是一个未知数。但是你又要有一定的预测。比如说如果就如果我知道GPT four会包含哪一些新的更新的话，我可能有一些现在在做工作就不会去做，我们现在等一下刚刚一个问题是，对，还有一个就是我在比如说在融资的时候，因为当时突然之间这个生成式AI就很火，在我看来也是有点火的非常突然。然后在融资的时候就会很多人就问，你这个用generate的NAI用在哪里？然后就会一遍又一遍显示说我们这个GPT three上面的战略的AI只用在帮你生成一个个性化的文本，用来和你的用户来沟通。那可能我们其他的我们还有一个功能是detect similarity，就是查找这个文本相关度、相似度，来减少这个企业内非常多的depend非常多的like interconnection dependency。",
      "speaker": "发言人6"
    },
    {
      "time": "00:42:16",
      "text": "在最初产品开发的时候没有被发现这个问题，我们当时是在这个birth上面做的，所以我觉得就生成生成式AI火是一个好事情，这样子的话，大家所有创业者都在找这个商业化的方向，但是你真正开始fine，to真正开始from engineer的时候，因为由于比如说在写产品文档，你真的没法用户enter，然后给他出了一些genre。可能比如说这个用户是在web street industry，你可能给他了一些什么size industry inside。即使是一个比较好的一个problem engineering，比较好的一个fine too出来的一个model，还是要和你用户的interaction要息息相关的。就是用户需要给一个非常详细的说我这个公司在做某一样产品，这个产品是在某一个领域，这个领域有多少用户在用，这个领域是有多少的潜在用户，然后这个feature我当时也要做什么？这个feature有多少人来做，就是到后来你会有一种本末倒置的感觉。就是如果用户给了那么多的input，我为什么还要帮你来generate，对吧？用户直接可以就去写了，这也是我发现的比较好玩的一个部分。",
      "speaker": "发言人6"
    },
    {
      "time": "00:43:38",
      "text": "现在很多用AI生成文本的公司还是基于这个prompt。就这个提示词会说你发现要find tune到你想要的那个效果。其实你的提示词要非常的具体的都不是提示词了，是一个提示段落的一个一一个问题了。所以其实对于很多创作者艺术家来说，其实不是每个人的语言文字表达都可以那么的精确的。所以我就好从这个技术的这个角度来说，它是我们接下来就是我好奇就是我们现在看到哪些公司在这个方面，或者哪些研究的这个方面，有可能会有一些有一些突破。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:09",
      "text": "对，抛向田老师，我跟你说一下，抛向实用主义。先先让他先让他解释一下这个技术层面。",
      "speaker": "发言人6"
    },
    {
      "time": "00:44:16",
      "text": "首先我说明下，就是我我其实并不是做LP的那可能我以后要做LP的。因为这篇文章，所以我之前就是做强化学习做的比较多对吧？然后还有一个是神经网络的一些理论分析一些分析一些原理的一些理解，还有能优化，就这样这些方向对我觉得确实是一个问题。就是你要生成你想要的东西非常难，对吧？我看网上有很多的Steve defeat咒语，大家都叫自己的大魔导师。对他有大魔导师要画出搞出咒语来，然后才会有一些一张你想要图片的。所以这个其实很大的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:49",
      "text": "对，接下来你要怎么样能够让那个AI能够更减少，比如说这个咒语的长度，这是一个很大的问题。那么这个就需要AI理解一些有上下文的一些细节，对吧？让就不要让人把它灌进去，让他自己能理解。这个其实可能需要更好的模型可能需要比如说transworld上来做一些改进，然后比如说把transworld结合一些以前的一些模型，比如说什么是graph，或者说用把以前的知识用运用一些比如图像，或者是说用图图来表示。那这样的一个结构，可能会有一些帮助。接下来你怎么样去能够把具体语义上的一些非常settle的东西能够表现出来，那这样的话就能减少你70次的次数，这个是一个可能的问题。就是说怎么样personalize或者说怎么样concentrator ze你的model。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:34",
      "text": "这是的，你现在的模型都是我怎么怎么做呢？我有大量的数据，几个逼脸的数据，然后一把锁确认出来，大家都看完了，然后接下来但是这个矛盾本身怎么样把它应用到一个具体的场景里面去，这个很难。所以就说你要用到具体场景的话，你就面临这样的一个一困境。就是如果你要具体场景的话，你数据就变少了，所以你训练成模型就不行。那你数据多的话，你数据就很杂乱，每个数据它都从不同背景里面来，所以后又有一这样一个渠道，没有办法就是为特定场景打造一个非常强的模型，在这种情况下你怎么样能够提升效率是一个很大的问题，这可能是加了一个方向。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:11",
      "text": "多补充一下，就剩的那个田老师，我感觉针对这个生成，如果生成是AI针对特定场景，把这个生成的准确度提高到商业问题以后，大家可以接受什么才能赚钱？稳定性要提高，因为这个应该是一个方向。对，相当于把它给集中。因为现在有一些语音生成的公司可能没有用到这些技术。但是它的这个语音合成效果，还有这种人脸就是做成真人视频，然后在演讲，其实挺多情况下他都可以商用的这种产品。我个人感觉对吧？莫妮卡你看过的类似的公司，在国内也很多。",
      "speaker": "发言人4"
    },
    {
      "time": "00:46:45",
      "text": "不过他好的地方是就是说就算我需要很长的那个prompt，现在没关系，是可以用人堆。所以我才能还能开着，还还是能还是能用，可能这个是一个比较好的切入点。以后模型越来越好了，也许效果就越来越好人人力越来越少。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:00",
      "text": "我发现一个特点，我测试过两个同样的from在这个diffusion的，它好像你怎么筛词都OK了，但是那个扔进去好了。但是那个达利E的Q的那个那个里面，好像他对于短语的理解好像更好一些。嗯嗯嗯嗯嗯有可能。",
      "speaker": "发言人4"
    },
    {
      "time": "00:47:14",
      "text": "因为WE可能用的是keep，可能会比较好一点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:18",
      "text": "Keep有比较好的，对，更好一些。对，但那个diction就不行。",
      "speaker": "发言人4"
    },
    {
      "time": "00:47:22",
      "text": "来讲很多组合都会更好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:25",
      "text": "想听一听实用主义的创业者，你们在这个实践中怎么解决这个问题，或者在尝试什么方式。",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:32",
      "text": "这是田老师跟我说的，填填我的痛点，就像我就就像我刚才一开始说的，就是创业公司难就难在你没有办法有那么多的钱，那么多的时间去创造一个非常强的model。我们现在也会在做一些，比如说基于knowledge graph，可能再加上prominent，再加上fine tune这样子的一个model过来，然后争取把这个生成的一个prospects来越来越精确。但是同时他又说我要赚钱，我要去卖这个产品，所以可能更多的是从产品方向的一个曲线救国。比如说发现AAI tax对于你这个生成的个性化文本非常好啊。那这个个性化成本可以提高你和客户的一个沟通的效果，我们可能就是在这个阶段就会更focus在那一块，可能怎样提高这个生成的长文本的精确性？一个是从我们自己想的角度，就是说比这种做这种not graph做这种，反正还有一方面就是实时关注学术动态。",
      "speaker": "发言人6"
    },
    {
      "time": "00:48:34",
      "text": "其实想着看着如果GPT four出来之后，有哪些情况可能是马上就解决了的。有一些情况我们是可以等一两个月，就可以有一个比较新的一个解决方案。也就是摸着石头过河。",
      "speaker": "发言人6"
    },
    {
      "time": "00:48:49",
      "text": "从创业这个角度，大家其实真的是最怕就是起了个大早，赶了个晚集。比方说你可能原来在这computation上做了很多调优，对吧？然后突然一天这个神经网络出现了，反而能够和后来者居上。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:00",
      "text": "我觉得另外有一个商业层面的讨论如果大家还记得的话，比如说很多年多年以前有一家叫ma的公司，它就是可以生成你这个就是你给他照片，然后给然后他就把它变成这个油画效果。这应该是上一波AI浪潮。那当时就是很快，但很快我大家会发现这个公司也融了很多钱，然后也有很多用户，但大家很多也就不active了。那现在我们看到其实很多这个也有很多就用来生成图片的生成图片这个公司。所以我就好奇，那就生成图片这个事情，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:34",
      "text": "未来大家是期望说我这个图片像这个copy AI，还有什么jesica一样，它就是在某一个特定领域的生成图片。比如说像刚蒋宣讲到一个我这个艺术教育图片，还是说它就可以正成为一个工具，本身我就可以做到足够厚，就可以成为一个比如说billion dollar business，还是说我下游这个渠道，比如说我要生成图片，我可能就要做成下一个instagram，或者要做成下一个这个下做下一个抖音，他才有可能做好。这个用真的是AI来生来做一个工具。这个事情本身在哪一些领域我们看到也是可以做的比较比较深。哪些领域可能就是比较容易有这个渠道上的一些劣势。然后这个听大家的想法，我想出来聊一聊。因为你可能也跟你那位朋友聊到过。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:23",
      "text": "对对对，我那个朋友叫何琛，他也是一个连续创业者。其实我身边也有很多做这种generate的VI，但是他们都是做这些面向创作者的一些art generation，市面上这一类的retention都非常的差。就是因为生成式它的本身就是一次性的效果，对不对？然后很多时候也是停留在一个玩具的一个层面，这个感觉就像当时instagram做了一个to，然后这个to如果一直做to的话，它就不会成为instagram，可能现在有很多的这些做image generation的art generation的创业者也在往这个角度讲，小角度想。因为大家知道，我只修改一次图片，我只生成一次图片，它并不能让user有这个hook一个model出来。所以这是行业上创业者也是每天都在头疼的一件事情。",
      "speaker": "发言人6"
    },
    {
      "time": "00:51:18",
      "text": "Jasper就是每天都是啊我的一个动力来源。因为他们你要他们的生成性只是他们的其中很小一部分。他们最厉害是因为他们生成的东西能够promise for SEO算法，然后他们又有非常多的一些community education，有一些很好的一些上下游的服务，来帮你来post on social me directly。可能他们还会开始做AB testing，所以我觉得之后的AI能够成长为billion business公司，一定是和一个垂直的领域和workload结合的非常好的，否则的话工具的话就会变成，比如说你要什么转image to PDF，那都会网上找一下。因为这个BDF，那这样子的话对这些公司来说很难去建立，很难去提高这个retention，或者说根本就没有retention这个概念。",
      "speaker": "发言人6"
    },
    {
      "time": "00:52:13",
      "text": "莫迪卡我来补充一下，顺着你们这个话题，对你要说到甚至是AI刚才那个蒋春提到的，其实我我用过我体验了好多，其实我感觉大部分都是玩具，有的可能连玩具都比不上。对，一次性的。如果感觉这个里面把它垂直化掉，变成比如说我们只是说生成图片，先不说版权问题，其实大概是什么，是AI都还是版权问题。如果说面向一些business领域里面的，比如商业工具，生成图标、图表，就是把它往再再细化到某些这种钱channel里面去，会有价值一些。因为现在大量的在网上去买这些商业素材的人，也主要是买这些东西，它是转化率最好的。除了去get面积，买买摄影照片之外，然后剩下全部都是买图标了。所以这一块应该是如果小公司进去应该很快，只要你解决版权问题就好了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:53:01",
      "text": "好好的而且这个里面我觉得版权问题很好解决，对它和这个创作风格还不一样，也很通用的。我看到的google就前两周发的那个google cloud，它专门有一节讲的AI？我看能不能把google的google的那个办公套workspace里面的那个创作，就把我们刚才那个东西有些已经都实现了。就是这种巨头里面，它把一个功能，就把这些创作功能给实现了。这也是一个对创业公司来说是一种威胁。",
      "speaker": "发言人4"
    },
    {
      "time": "00:53:25",
      "text": "有可能对先是第一块，如果是其实对垂直领域一定是一个非常好的打法。因为现在最好的有retention的公司在AI generation方面，一个是做这个interior design，卖给这些地产经济generation，一个是做汽车generate的design，然后会卖给福特这些公司。然后还有一个说一个好朋友公司叫rose bot AI，然后他们就是想要取代这个stock image，对对对，stock image它本身是billion industry，这是三个attention特别好的公司。然后我觉得就是巨头总是会有很多钱去做很多事情，但是如果但是这样子的话，就不会有那么多骚扰。骚扰的一个优势，一个是刚才这个蓝老师说的就是快，因为快的本身不一不因为不仅是因为我们小团队迭代的快，还有一个是因为我们的risk没有那么高。因为做一个出去都出去做一个东西出去，如果碰到一些component issue，碰到了一些大公司无法承担的一些风险就无所谓。小公司反正就是光脚，那句话叫什么的？穿鞋的对，光脚的。",
      "speaker": "发言人6"
    },
    {
      "time": "00:54:39",
      "text": "光脚的不怕穿鞋，不怕脚。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:41",
      "text": "不怕穿鞋。对对对，对。然后还有一个角度就是小公司它定位比较明确。就是说如果用户我在网上搜索说我要general一个什么interior design image的话，那我就会去找一家公司做一件事情。而不是去看啊我在google的某一个项目的某一个feature里面，有可能能找到我能用的东西对。",
      "speaker": "发言人6"
    },
    {
      "time": "00:55:09",
      "text": "这个的确是，其实讲到这个大公司小公司的问题，就不得不我觉得不得不讲到这个跟也跟钱有关。就是因为刚才我们提到很多大模型现在要么就是大公司来做，要么就是这些像OpenAI或者stability这一些融了很多钱的公司来做。那就是我但其实我看了一下他们这个Prices，比如说OpenAI这个Prices，其实你想call一次这个API其实还是挺贵的。一方面真正做着大模型的就很贵。如果说我这个公司就是我要用他们的API来去来来去作为我主要这个business model话，就是几年前的这个AI讨论中，其实也有人提到过，就是到底的AI的cost就现在来说还是不便宜的。所以我就会好奇，就是说这个从cos这个角度，未来他会怎样去一个眼镜。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:57",
      "text": "比方说从我觉得这里面有两个角度，比方一个从商业化的角度是说，那那是不是也都会有大部分的cos都会都会交给这些提供大模型的这公司。另外角度就说是不是从技术上是不是有些优化。比如说是不是我们会逐渐的把计算的一些东西是不是越来越移到这个edge上。所以从这个cost的这个角度上，也想听听各位的讨论。我想听听小村聊一聊，就是你你对cost这一块可以分享一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:22",
      "text": "这个是我每天每天在是我每天在头疼的事情。对，我们现在GPT three每一个call的话，基本上它的平均的cos在six cents，就是六六分美元。所以我们的pricing也其实挺的挺简单的。就是说按照你不同的seat，不同的feature做一个pricing here。然后每一个teer也会有一个consumption gate，比如说如果你generate more than one hundred觉，like text or articles，我们会让你另外的付钱，但是我的确是觉得下一代甚至会产生一个新的一个pricing model。",
      "speaker": "发言人6"
    },
    {
      "time": "00:57:03",
      "text": "比如说你看ZPA，他们或者说是post talk，post talk的话，他他是一个做一个product and liquor，它是一个open source，他非常的受这个开发者欢迎，它其中一大部分原因就是它是纯粹的一个consumption base，就说你用多少付多少，所以我觉得有可能在这种情况下，下一代兔他可能就是一个trans consumption base。我花了多少钱？我我给你提供这服务，我从API那边花了多少钱，那我在上面传一个mult ware我就差多少钱，这样子的话就会让整个行业的一个pricing也越来越透明。但这的确就是我自己每天就是瞎想，所以最后来后来这之后这个Prices该怎么演变？然后这些foundation model它的change pricing会对我们这些创业公司会有什么影响？也是其实仔细想想还是蛮担心的一个事情。",
      "speaker": "发言人6"
    },
    {
      "time": "00:57:57",
      "text": "因为我投资比较关注像这种开源，还有这个数据库之间的方向。因为很多数据库的原因，他虽然说是这个开源给你，但真正能够把这个开源的一个产品用好的公司其实比较少的。虽然说这个stability主要是开源出来，你真的能够用好它，其实还是哪怕同学院上还是有不少成本的。我好奇田老师如果从技术角度会你也可以分享，就是现在我们有哪一些方向可以去把这个cos这个事情给降低的。我们现在还有哪些挑战？",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:28",
      "text": "降低的话其实有很多。比如说最近我好像清华那边有一个新的model，说可以把c deficient的那个step变变变短，对吧？叫DPM server。对，反正是比如说你本来要50次那个a to a省限变成了比如说30次或20次对吧？这种这是一种可能的一种变短的一个方式。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:48",
      "text": "比如说你把那个model的cost降低，你比如说你比如说你比如说我们要设定OPT，OP是我们自己的一个open south model，对，ODW303B你在设定这个model时候，你比如说你可能需要八块卡或者更多的卡，八块A100，你每次靠这个model就花很多钱去收藏。但如果这个model我们可以搞成更小的，都搞成比如说16位或者八位的，但是效果还是还差不多。那这样的话我们每次测这个model或者每次call这个mod时候，我这个代价我降低对吧？我可能用更便宜的GPU或者说用更少的GPU然后去得到这个。对这样的话你cos会降低，那么你可能对大家也会有帮助。这个我想一定会慢慢发生的。可能甚至到最后，比如说几年之后，大家每一个人自己有个in house GP3，或者说就是能存在自己的电脑里面，自己靠这个不用靠那个open I的服务，这都是有可能的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:39",
      "text": "如果是这样的话，那其实对于这个GT three，然后对于OpenAI这些要想要靠这个API对赚钱的公司来说，这会是个挺大的挑战。如果是开源，你魔都是开源，你的提供API那也也许会也也许会有不少公司的，我就提供更便宜的用便宜的fine to过渡的API，最后变得一个非常的很同质化的一个一一个事情。最终的这个赢家也许就还是要看这个非常垂直领域的对这个玩家了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:08",
      "text": "我其实挺挺同意这一点的，我觉得垂直是非常重要，因为有很多的small corners you need to cut。对就是说你如果要把这个东西打通了，有很多很多小地方。这些地方可能每个地方都不是需要太强的技术，但是都需要人或者花时间去把这东西做出来，然后把整个过程都做完。所以我觉得这是一个可能的一个思路。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:27",
      "text": "就比如说举个例子，就是说也许我们接下来的任务是我们有没有一个有没有一笔钱能花在上面。我们可以搞用AI做一个move出来，比如说AI做一个电影，或者说全部都是AI唑的，或者说就是净少的那个人工对吧？这种工作室这种模式。这样的话就是说我并不care我具体的哪个技术是谁提供，我们就是把这个东西做出来。所以这种都是啊这个可能是一种新的一个方案。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:51",
      "text": "对，这种我觉得这个可能会更好。因为比如我自己在写小说的时候，我会觉得，我这个工具非常不方便，也许我自己想写一点小的东西能够提高自己的效率，这种很多很多小的地方你没有那么多时间去写，那这个其实很大的一个需求。如果有一个公司能够把这些小事都做了，然后提供个n to n的一个解决方案的话，那是一个非常好的。而且这个护城河很高，很难一下子能够追上的。如果你只给大家提供API的话，就像他刚刚说的那样，很容易就被追上。今天你提供一个，明天这边新paper又提供一个。对最后对对对没办法赚钱。",
      "speaker": "发言人2"
    },
    {
      "time": "01:01:23",
      "text": "对我补充一下，我觉得还有一个角度，他们这些大的模型公司会开始做的事情是就有一点类似于ML ops。我之前在uber或者scale AI时候都是做这种like how developers to evalu model performance。那就在我们自己开发过程中也是就GPT其实它也有很多不同的版本。那我可能会知道a curry这个版本，我们可以用在某一个领域。或者说我们在try different from engineer的时候，又会有一个AB testing，或者说有一个benchmark，一个flow，这些都是我们自己现在就是自己扣出来的。",
      "speaker": "发言人6"
    },
    {
      "time": "01:01:58",
      "text": "但是觉得如果有一个platform或者说这些foundation model，可以给你告诉你说，你如果是用在这个领域，应该尝试一下我们这个什么绩点0绩点3.2.8版本。如果你在尝试另一个方面，你可以用这两个版本。这样版本有什么process and cos，他们各自cost是多少？这是一个也就是比较handy的一个方向。",
      "speaker": "发言人6"
    },
    {
      "time": "01:02:23",
      "text": "对，有点是吧。但是这个就是要也要想一下，这东西不能被取代，也许下半段两个东西都解决了，这个都是一些比较大的一些问题，就是可能需要一些具体的技术知识，知道哪些目前的那些知识是会被会被取代，有些知识很难被取代。",
      "speaker": "发言人2"
    },
    {
      "time": "01:02:38",
      "text": "应该是这样子。我补充一下，可能对于很多大公司巨头来说，他们都希望用一个通用的模型来解决所有问题。",
      "speaker": "发言人4"
    },
    {
      "time": "01:02:45",
      "text": "最后问一个比较ending也比较open的good question。The Edgar这个课程上面你设了一个garden AI的这个对对对的，这个relative AI其实是准备在顶点，那其实也就意味着好像离离这个破裂不是很不远的一个地方。从从你们的这个角度，你们觉得如果说你们觉得现在哪一些是关于这generative AI，哪一些是你觉得这个over hike的这个over estimated的，而哪一些可能你觉得它是有真实这个对你们来说是真实的一个价值，或者说你觉得甚至有可能是被大家可能underestimated的一些一些东西，可以从你的角度来聊一聊。要不这个张春可以来聊聊。",
      "speaker": "发言人1"
    },
    {
      "time": "01:03:24",
      "text": "我觉得在尖锐的AI给我的感觉就像几年前这个自动驾驶给我的感觉一样。大家都在说，然后这个have其实很快就会过去了，然后真正沉淀下来就是大家继续做事情对吧？针对ABI可能我觉得那些真正垂直到什么，给什么汽车做工业设计，给给一些。什么给一些做interview design这些非常明确的use case，一定是会沉淀下来的。",
      "speaker": "发言人6"
    },
    {
      "time": "01:03:51",
      "text": "其他的一些比如说帮你Jerry ava帮你Jerry其他的比较好玩的东西，希望他们能够朝更多的，比如说什么是media这个发展，那可能就会诞生下一个take talk，或者诞生下一个instagram。那些under asthal。其实我个人也是就是对interpret，也是对enterprise这块比较热衷的。所以我觉得有很多很多面向于enterprise这些AI told。比如说像rage AI比如说像其他公司，我们就是在我们就不会在over use like generate AI而是慢慢的看AI能够帮你真正的提高每一天的这个工作，这个是需要长期的去积累和踏踏实实干的。然后还有一个就是ML infront，就我刚才说的这些或者说ML puls这些什么。在猫的不断更新的情况下，给开发者提高更好的exchange，这是也是一块我觉得接下来会有很大成长空间的地方。",
      "speaker": "发言人6"
    },
    {
      "time": "01:04:49",
      "text": "这个其实也让我想到NLP很火的一段时间。后来发现很多所谓做自己NLP好像做的特别牛的公司，最后其实都没有起来。反而是我个人觉得在NLP做最好的家公司，公的完全没有标榜自己说NLP的对，但其实它本质是一个做sales，给他提高这个sales team的efficiency的这些公司。因为其实真的其实LP只是在中间很小的一个部分，核心还是这个business的value。",
      "speaker": "发言人1"
    },
    {
      "time": "01:05:14",
      "text": "对，就是我大致同意，就是我觉得垂直的方向上其实很重要。其实在做研究的时候，我们也是慢慢开始觉得垂直其实很重要。因为垂直的能够做大项目，这个其实对公司来说也是挺好的一个事情。对，因为研究一般有两类了，一类人是做方法的，还有一类人是做做项目的对，做方法的人可能会觉得有一个方法到处敲，有个锤子做好了之后到处去敲。然后做vacation的人就是我做锤子东西，我不管你什么锤子，把这个东西做出来维持。所以就是我觉得可能做那个vacation的，或者做那种垂直的方向其实更重要就是也有很多很很细的那些细节需要去抠掉。但是最后说整个过程做出来，其实很有很大一个impact。",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:55",
      "text": "对，就是并不是说我这个跟model很fancy，这个模特就我就是就用了在其实不是这样的，最终还是看具体问题具体分析。什么样的地方用什么样最好的模型，能够把问题解决了，这个是最重要的，案例比较务实的一个思路是比较好啊，我觉得这个其实也是比较重要的。就上来说，我觉得接下来可能一个是怎么样personalize一个model，一个拿来个model的怎么说，我觉得这个肯定挺有意思的一个问题。怎么样要能够把它做小，怎么能够把它做到一个比较比较大的一个也就是一个非常开裂的一个同样的一个性能。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:30",
      "text": "但是能够让他在每家每户上都能够用上，因为其实privacy是很大的问题，其实他们当时有我们把我们的文章公布了之后，在推特上其实有五百多个点赞，有人就在问了，说他们什么？就是每个人心里面都有一个myself story，就是可能有一些不太想给大家知道的故事，想希望这个AI可以帮忙把这个故事写出来，那么在这种情况下，你就没办法去cause GPT three。因为你close之后，你会觉得自己非常embarrass。那你这种情况下，怎么样能够让这个model最终能进入千家万户，能够把这个personalization的这个东西做好，能够让大家能够在自己的那个手机上，或者说自己的那个机器上能够用上这个模型，得到达到这个效果，这个其实一个很大的一个问题。如果有人能做到这一点的话，那可能大家愿意去用这个东西。",
      "speaker": "发言人2"
    },
    {
      "time": "01:07:20",
      "text": "这也是一个补充问一下补充问一下。我看到其实facebook最近也包括google也最近也推出了，也在做很多AI然后来生成不论是3D还是一个视频，而不是一个简单的图片的研究文化。田老师你觉得在在这一块，现在因为我们现在看到可能这些视频都还比较的初期，一方面比较短，而且这个质量可能还远不如这些图片。您觉得在要做成这个3D要做成这个视频，跟我们现在产品觉先比较突破，有什么比较难的地方？",
      "speaker": "发言人1"
    },
    {
      "time": "01:07:50",
      "text": "其实还挺多很难的地方。我觉得因为现在所谓那个maka video其实有很多照片，比如interpret对吧？或者说做一些interpretations可以得到一些结果，但是你要再往前就是几秒钟的视频。你可以做你几分钟的视频，你没法做几分钟视频。你需要剧情了，你需要有一个故事，就是你需要知道这个定位这个东西到底想说什么。包括封禁，包括有哪些角色，他们出现多长时间，有什么样表情，这个都是很大的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:16",
      "text": "这个现在技术很难解决，现在技术只能说你拉一下，比如说天上有只鸟让它飞一飞，然后地上有有个虫子，然后让他走一走。这样的一个就是相当于一个common sense一个视频。比如说你带一个超人斗篷，你看它飞了一下，那这种就是非常简单的。就是接下来你要把它拉长了，长到几十分钟，这个非常难，这个其实是一个很大的一个问题，需要下一步下一个对我感觉现在。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:39",
      "text": "generative VI实现不了，长视频短视频都很难。",
      "speaker": "发言人4"
    },
    {
      "time": "01:08:45",
      "text": "也就是说你要有剧情，你要有逻辑。对，有逻辑。有的只是可能有一个剧情是一样的了，就跟小说故事生成其实是一样的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:52",
      "text": "问题是他理解这个理解上下为难，还是他从理解到生成这个生成的上下文。",
      "speaker": "发言人1"
    },
    {
      "time": "01:08:58",
      "text": "这个都很难。生成本身是一个问题，就是因为生成你要consistency对吧？然后理解又是一个大大的问题。对你现在你要是神经网络去理解，比如说一部电影它的妙的地方在哪里？或者一段段短视频为什么能让你泪流满面？这个很难，非常基本上是能做出来，基本上是基本上达人的水平。所以这个又生效本上还要再。",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:22",
      "text": "等20年或者30年以上。",
      "speaker": "发言人4"
    },
    {
      "time": "01:09:24",
      "text": "对，应该再等一阵子。你这就是我个人觉得是至少要对模型的那个工作方式，就是可解释性要有一些理解，这样的话才能做出来。因为现在可能有瓶颈，就是说现在大家数据越来越多了，那最终数据会用完的。我就我也感觉到数据很难用完。比如说the model，我们把世界上所有的图片拿过来训练一下，然后我这模型非常的强大了，再怎么怎么能把再强大一点，大家不知道怎么做，有没有数据了，全世界就这么就用正面图对吧？这个可能是一个很大的问题，就是因为毕竟没有那么多画家给你画图，所以这是一个数据，我觉得之后永远都可能会撞上这堵墙。因为以前以为数据是无限的，确实数据当时是无限，但是现在数据越来越多，计算越来越强。数据就计算机可以很强，但是数据是不是状态瓶颈不知道。",
      "speaker": "发言人2"
    },
    {
      "time": "01:10:09",
      "text": "这个是一个很大的问题。所以回过头来，这又是这个大公司的一个优势，对吧？这个在数据的这个方面，或者说你自己成为一个闭环的一个优势，还是得最终还是得要自己能够产生。",
      "speaker": "发言人1"
    },
    {
      "time": "01:10:21",
      "text": "最重要像人类一样学习，我们不需要太多数据。所以说我们现在对大脑研究不清楚，所以大家也搞不清楚的，还有一定差距。",
      "speaker": "发言人4"
    },
    {
      "time": "01:10:29",
      "text": "这个就需要从根本上解决问题了。就是我们现在那些模型，说实在的也许都是在人类面前都渣渣，就说说难听点是这样。对，就是人可能真正的数据量可能是只有10分之1或者1%，最后结果还是更好的对，所以最终还是会可能会撞到这堵墙，这是一个另外一个墙，你现在大家可能还没看到，或者说看的比较少。因为大家可能会乐观的认为，也许我们这个AI的进展会更快，因为我之前的进展很快，我可以直接外面推就好了。但是其实以前是因为有数据，那等到数据到了到饱和了之后就很难讲光了之后怎么办？对。",
      "speaker": "发言人2"
    },
    {
      "time": "01:11:05",
      "text": "是不是说现在这些所谓的这个小样本学习这些方式，它还是没有到那个质变，还只能解决一部分的这个问题。",
      "speaker": "发言人1"
    },
    {
      "time": "01:11:14",
      "text": "没有，现在还早，现在还早，小样本还怎么想法？只是那实验室来玩玩的，就可能比比托姆斯可能高了，比如两三百分点，我成功了，发文章了，但是真的有用吗？不一定有用。",
      "speaker": "发言人2"
    },
    {
      "time": "01:11:28",
      "text": "你觉得这个话题最后你有什么补充吗？",
      "speaker": "发言人1"
    },
    {
      "time": "01:11:31",
      "text": "对你刚才问的就是这个type的问题是吧？对我感觉generative AI的这个还他预测的很对，刚好是很快就到了。对，因为大量的都是玩具，而且最后能够沉淀下来的估计还是我们前面讨论第一个垂直，而且非常垂直。它的市场我定位的找准，因为就好像现在我们用现有的这个，因为大家都做做应用，我们用现有这些模型和这些算法的极限性能，把一个东西做小，把训练集做小。",
      "speaker": "发言人4"
    },
    {
      "time": "01:11:59",
      "text": "另外一个，刚才田老师讲到的pride就是给private给私人去做定制化的这种输出，给企业或者给私人给特定的。包括我前面举的例子，我用某些声音合成输出成产品，或者人像输出成的产品。那个时候按照企业或者个人需求。定制出来的形象，像这样的东西它就比较容易商业化。因为我通过通这种OpenAI和大的引擎训练出来，因为有隐私问题，你不可能有有太多的影像可以用的。我必须得把它缩小范围来训练，或者把模型或者把数据量变小，然后专用去训练。",
      "speaker": "发言人4"
    },
    {
      "time": "01:12:29",
      "text": "这应该是在这一轮之后能够剩下来的一些产品。它能够走的方向就是说一个是垂直化，第二个是私有化，然后第三个可能是在之后这个里面为这些模型去做。刚才其实蒋春也提到了，就做那个ML的ops就是你为他服务的，提供这个工具机，帮他来做这种私有化或者垂直化的这种工具集，应该是一个比较好的方向。然后再往后面就可能是等着下一轮的这个模型升级了，有一个第四波或者说怎么样子的等等等等，模型的进一步的飞跃式进展。",
      "speaker": "发言人4"
    },
    {
      "time": "01:13:02",
      "text": "好好，我觉得我们今天讨论这个非常非非常充分，也非常感谢大家。我觉得非常不一样的这个视角，今天我们的核心就是跨越have，聊的都是一些非常落地非常实际的，就不论技术还是商业话题。也非常感谢几位在thanksgiving的周末的时间，然后希望下以后我们有更多的关于AIGC的讨论，一起来关注这个领域的一些进展。",
      "speaker": "发言人1"
    },
    {
      "time": "01:13:24",
      "text": "好，谢谢。",
      "speaker": "发言人6"
    },
    {
      "time": "01:13:25",
      "text": "各位。好，以上就是本次讨论的内容，也是有些意犹未尽。关于AIGC这个话题可以讨论东西太多，因为时间关系，很多话题我们也只能浅尝辄止。不过这个行业发展太快了，我们也会保持持续关注。也希望大家在评论中跟我们分享你的思考，还有你希望讨论的其他话题和角度。最后也别忘了关注我们的公众号，未来我们也会将更多的思考和组织的直播在公众号中跟大家分享。",
      "speaker": "发言人3"
    },
    {
      "time": "01:13:53",
      "text": "感谢大家的收听。如果你喜欢我们pocket内容，欢迎你点赞并分享给可能感兴趣的朋友。有任何建议反馈都可以在评论区留言，我们都会很认真的看的。如果你在用apple pocket收听，也希望你花几秒钟给我们打个五星好评，让更多人了解到我们我们下次再见了。",
      "speaker": "发言人3"
    }
  ],
  "lab_info": {
    "summary": "在这次播客中，讨论者们深入探讨了生成式AI的多个维度，包括其在特定领域和私有化定制中的应用价值，同时也不忘关注技术局限性和隐私问题。他们特别强调了AIGC领域的热度，通过稳定扩散模型和copy AI等实例，展示了创业公司在短期内的显著成就。从AI研究员、投资人和创业者的不同视角出发，嘉宾们分享了技术挑战、版权和伦理问题，以及开源模型进展、成本优化等议题。讨论聚焦于AIGC在艺术、设计和营销等领域的潜力，以及个人化和定制化服务的重要性。嘉宾们对AIGC技术的未来充满乐观，并表达了对其面临的挑战和可能发展方向的深刻思考，为听众提供了一个全面理解AIGC当前状态和未来方向的视角。",
    "qa_pairs": [
      {
        "question": "在AIGC领域，有哪些值得关注的公司或项目？AIGC领域中，您目前比较关注的是哪个公司或项目？",
        "answer": "我这边关注的是能够生成长文本的项目，比如我们最近发表的一篇论文，设计了一个系统叫RE3，它通过prompting techniques能够生成前后一致、连贯的故事文本。我们公司专注于文本生成技术的研究，尤其是如何生成更长且更一致的文本，结合强化学习的优势，并探索与图像结合的可能性。",
        "time": "00:05:25"
      },
      {
        "question": "陈老师，能否分享一下您在AIGC领域的关注点？",
        "answer": "我们关注文本生成技术的发展，尤其是能否生成更长、更连贯的文本，以及如何将这些技术与图像处理结合起来。",
        "time": "00:06:46"
      },
      {
        "question": "田老师，您能从技术角度回顾一下历史，看看这一波AIGC浪潮与上一波AI浪潮相比有哪些不一样的地方吗？",
        "answer": "当前这一波以视觉方向为主的AI浪潮，如计算机视觉等领域的发展，相比上一波AI浪潮，在技术上更加成熟，例如现在我们看到的诸如stability AI等公司能够商用的技术，以及当时相比，大家现在研究的关注点有所不同，更加注重实际应用场景和商业化进展。",
        "time": "00:12:15"
      },
      {
        "question": "在AI领域，是什么打破了人们认为围棋是人类永远无法战胜机器的认知，并推动了投资热潮的？早期的AI模型存在哪些问题，以及后来如何解决这些问题的？",
        "answer": "是围棋AI在比赛中取得的优异成绩打破了这一认知，使得大家开始愿意将资金投入到AI领域。早期AI模型如GAIN训练不稳定，结果欠佳。后来研究者们努力改进训练过程，使其变得更为平顺，并引入了Diffusion model等更稳定且效果更好的模型。",
        "time": "00:14:00"
      },
      {
        "question": "Transformers在AI中的主要优点是什么？",
        "answer": "Transformers的优势在于能够整合多模态数据进行对齐，并能将一个模态的信息转换到另一个模态上，比如实现文字到图像的转换，大大提升了生成图像的可控性与质量。",
        "time": "00:15:30"
      },
      {
        "question": "这次AI热潮与上一波热潮相比，在技术和商业上有哪些不同之处？",
        "answer": "这次AI热潮的技术水平已经非常接近甚至超越了人类水平，不再像之前那样存在较大差距。此外，由于技术进步，新的use cases应运而生，催生了一批新的AI native platform公司，这是与上一波热潮显著的不同之处。",
        "time": "00:18:23"
      },
      {
        "question": "当技术普及后，这次AI热潮中的赢家会与上一次有何不同？",
        "answer": "上一次AI热潮中，赢家主要集中在拥有大量资金支持的大公司；而这次热潮中，除了这些大公司外，还会有大量专注于特定场景、利用现有模型进行fine-tuning并找到具体应用的公司，以及那些必须研发自有特定模型的公司，它们都有可能成为市场赢家。",
        "time": "00:19:21"
      },
      {
        "question": "这次AI热潮中，新的公司会基于哪些方面进行创业？",
        "answer": "新的公司主要分为两类：一类是在顶尖模型（如OpenAI的模型）基础上构建的公司，如Jasper等；另一类是解决复杂工业问题的公司，如基于AI技术的焊接机器人公司、自动驾驶汽车公司和建筑机器人公司。",
        "time": "00:19:21"
      },
      {
        "question": "在生成文本时，为什么将上下文和prompt结合使用很重要？目前可以生成多长的英文文本，并且是基于什么模型实现的？",
        "answer": "将过去的文本细节、总结、角色设定及主题等放入prompt中，这样生成的文本会更具有针对性和连贯性。这样处理后，文本不仅更符合预期，而且整体架构也会更为一致。目前通过特定的方法可以生成2000至7000词的英文文本，这个是基于GPT3模型实现的，该模型能够将各种数据转化为token并进行处理。",
        "time": "00:27:11"
      },
      {
        "question": "对于使用transformer模型的未来发展，您怎么看？",
        "answer": "transformer模型可能会把更多不同类型的数据统一起来，未来可能会有一种新的模型出现，能够更好地模拟人类思维逻辑，并实现不同结构的融合。",
        "time": "00:28:24"
      },
      {
        "question": "投资和商业化角度上，如何看待Notion等公司推出的AIGC功能以及对初创公司的影响？初创公司在面对已有成熟市场和客户资源的公司时，有何竞争优势？",
        "answer": "投资和关注点主要有两个方面：一是公司能否真正解决用户痛点，是否有实际应用场景让用户愿意付费；二是初创公司的速度优势，能否快速迭代产品以适应市场变化。初创公司的主要优势在于其灵活性和高效的产品开发能力，能够抓住新的技术机遇迅速推出创新产品。而成熟公司在集成新技术、改造现有产品以适应新需求方面可能存在一定困难。",
        "time": "00:30:24"
      },
      {
        "question": "AI行业的发展是否会出现新的涌现式突破，形成类似transformer的万能模型？",
        "answer": "AI行业的涌现式突破确实存在，但很多技术进步是渐进式的积累和发展。例如，从DALL-E到LEMON，再到视频生成模型，这些技术在不断尝试和改进中逐渐取得突破，而非突然出现。尽管如此，未来仍有可能出现能更好融合现有技术的新模型，推动行业进一步发展。",
        "time": "00:33:53"
      },
      {
        "question": "在写一部较长故事时，有哪些细微之处是普通模型难以捕捉的？大模型能否解决数学推理领域的问题，如数学竞赛中的难题？",
        "answer": "在撰写长篇故事时，一些非常细微且深入的含义和关系是很难被一般模型抓住的。例如，某个词汇在特定语境下具有特殊含义，或者这个词与故事中的某个角色密切相关，这种基于上下文的关联无法通过大数据轻易解决，它涉及到理解和构建故事内部复杂的结构和逻辑。目前的大模型在解决已知数学问题方面可以发挥作用，它们利用已有的数学定理推导出答案，提高效率。但对于基于问题本身独特结构的复杂推理问题，大数学家会根据问题特征构建一套新的数学工具或思路来搜索解决方案，这类问题现有的大模型无法有效解决。",
        "time": "00:39:31"
      },
      {
        "question": "创业公司在发展过程中，尤其是在技术预测和融资方面遇到了哪些挑战？",
        "answer": "创业公司在发展过程中面临的问题包括：难以准确预测下一项技术的出现时间；在融资阶段，由于生成式AI的突然火热，需要向投资者解释其技术的应用场景（如GPT-3用于个性化文本生成和相似度检测），以及如何平衡技术研发与商业化的方向。此外，在实际产品开发中，发现用户的输入需求与生成内容之间可能存在脱节，即用户需要提供详细的背景信息和明确的功能需求，这使得生成式AI的辅助作用受到局限。",
        "time": "00:41:13"
      },
      {
        "question": "当前AI生成文本的技术局限性是什么？以及有哪些研究方向可能带来突破？",
        "answer": "当前AI生成文本多基于prompt，需要精确的提示词或提示段落，这对于非专业艺术家的语言表达能力提出了挑战。要实现突破，可能的方向包括改进模型使其能更好地理解上下文细节，减少对人工咒语的依赖；结合多种模型如transformer与graph等结构，以及运用图像或图表示方法；同时，如何针对特定场景优化模型以提高生成准确度、稳定性和效率，是一个重要的研究方向。",
        "time": "00:43:38"
      },
      {
        "question": "创业者如何在实践中解决生成模型在特定场景应用的难题？",
        "answer": "创业者通过结合knowledge graph、fine-tuning等方式优化生成模型，并关注学术动态以抓住新技术带来的机遇。同时，关注生成文本在具体场景下的应用效果，如个性化文本对客户沟通效果的提升，从而寻找产品化的路径。此外，也会实时跟踪前沿技术动态，比如等待GPT-4等新技术的出现，来解决现有问题或创造新的商业机会。",
        "time": "00:47:32"
      },
      {
        "question": "在AI生成图片或商业工具领域，比如生成图标、图表等，是否有可能找到价值点？",
        "answer": "是的，在商业工具领域，如果将AI垂直化应用，例如生成高质量的图标、图表等素材，由于目前市场上对此类商业素材的需求很大且转化率高，对于小公司而言，只要解决版权问题，这类应用确实具有较高的商业价值。",
        "time": "00:52:13"
      },
      {
        "question": "对于大公司与小公司在AI领域的竞争态势有何看法？",
        "answer": "大公司在资金和技术上有优势，但小公司凭借更快的迭代速度、较低的风险承受能力和更明确的定位，在某些垂直领域也能迅速发展。此外，随着成本问题的解决和技术创新（如降低成本、优化模型结构等），未来的AI服务可能会更倾向于消费级定价模式，这将对整个行业和创业公司产生深远影响。",
        "time": "00:53:25"
      },
      {
        "question": "AI模型的成本如何优化以及未来可能的变化趋势是什么？",
        "answer": "目前AI模型的成本较高，但未来可能会通过技术优化降低成本，例如减少模型调用步骤、使用更小尺寸的模型、迁移部分计算到边缘设备等方式。长远来看，也许每个人都能拥有私有化的基础模型，而非完全依赖云服务。对于依赖API收入的大模型公司，这种趋势将带来挑战，而能够提供定制化解决方案的小公司可能会获得竞争优势。",
        "time": "00:55:09"
      },
      {
        "question": "如何看待目前关于AI生成内容的价值估算以及未来潜力？",
        "answer": "AI生成内容就像几年前自动驾驶一样，初期被广泛讨论，但实际上真正沉淀下来的会是那些针对特定垂直领域如工业设计、面试设计等的应用。同时，AI辅助企业级工作流程、ML ops平台以及提供更好的模型版本选择和成本效率的工具，都是具有真实价值且可能被市场低估的发展方向。",
        "time": "01:03:24"
      },
      {
        "question": "在研究中，您认为做方法的人和做项目的（vacation）人的角色哪个更重要？",
        "answer": "我认为做vacation的人其实更重要，因为他们需要关注项目的整体过程，注重细节，并确保项目能够成功完成并产生较大的影响力。",
        "time": "01:05:14"
      },
      {
        "question": "接下来在AI研究领域，您觉得个人化模型是一个值得关注的问题吗？当模型变得非常个性化时，如何解决隐私问题，让模型能够在每家每户上使用而不侵犯隐私？",
        "answer": "是的，怎么样personalize一个模型，使其既能保持较小的规模又能保持高性能，这是一个非常有趣且重要的问题。这是一个挑战，需要做好模型的个性化工作，并确保其能够在个人设备上运行，同时保护用户隐私，这是实现广泛应用的关键所在。",
        "time": "01:05:55"
      },
      {
        "question": "对于当前AI生成3D或视频的研究文化，您觉得与现有产品相比，要实现这一目标存在哪些难点？",
        "answer": "主要难点在于技术上无法实现长时间、有剧情和逻辑性的视频生成，目前只能处理简单的动态画面，而要达到几十分钟甚至更长的高质量视频，需要解决剧情构建、角色设定、逻辑连贯性等诸多问题。",
        "time": "01:07:50"
      },
      {
        "question": "针对AI模型理解和生成高质量视频内容的问题，您认为主要瓶颈在哪里？",
        "answer": "瓶颈在于理解和生成两个方面，理解视频内容的逻辑和妙处很难，而从理解到生成的过程同样存在问题，尤其是保持一致性和故事性的挑战很大，可能需要更先进的技术或者更长的时间（如20年或30年）才能取得突破。",
        "time": "01:08:58"
      },
      {
        "question": "关于数据对AI发展的限制，您有什么看法？",
        "answer": "数据量的限制是一个现实问题，当数据增长到一定程度后，可能会成为瓶颈。大公司在数据方面的闭环优势能帮助他们产生更好的模型，但长远来看，如何有效利用有限的数据并进行小样本学习等方法还有待解决。",
        "time": "01:09:24"
      },
      {
        "question": "对于generative AI的发展趋势，您有何补充？",
        "answer": "generative AI预测很快会到来，市场定位应更加垂直化和私有化，例如针对特定企业或个人需求定制化输出，同时为这些模型提供私有化和垂直化的工具集也是一个很好的发展方向。在等待下一轮模型飞跃式进展的同时，应关注垂直化和私有化的产品落地与发展。",
        "time": "01:12:29"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探讨AIGC：技术进展与商业前景",
        "summary": "在本次播客中，讨论集中在了AI生成内容（AIGC）领域的快速发展上。近一年来，尽管资本环境趋于严峻，该领域内的创业公司如Stability AI和Copy AI Jasper等，在融资和营收方面均取得了显著成就。这波热潮让人联想到几年前AI领域的火爆，但在商业和产品化方面，这次展现出了新的可能性与挑战。节目中邀请了来自硅谷的AI研究员、投资人和创业者，包括Meta的资深研究员、亚洲女性投资人以及成功转型为创业者的蒋全等人，从多个角度深入讨论了AIGC的技术进展、投资价值和未来展望。此外，还特别邀请了微博早期创始团队成员加入讨论，为技术讨论增添未来感。"
      },
      {
        "time": "00:02:24",
        "title": "探讨AIGC领域的发展与应用",
        "summary": "在温哥华的一次交流中，一位曾在新浪微博团队工作并涉足创投领域的人士，分享了其对AIGC领域的兴趣及投资经验。特别提到对直播电商的投资，以及目前在北美从事的顾问和投资工作。另一位研究者介绍了其在强化学习、优化和深度学习方面的研究，特别是关注于如何生成连贯的长文本，提到了一篇已接受的研究文章，该文章提出了一种名为RE3的系统，旨在解决现有模型生成文本不连贯的问题。这次讨论不仅展示了AIGC领域的技术挑战和进展，也反映了参与者对于未来科技趋势的关注和探索。"
      },
      {
        "time": "00:06:39",
        "title": "专注AIGC领域投资与研究",
        "summary": "对话涉及陈老师关注的AIGC领域，特别是长文本生成的一致性以及与图像结合的技术方向。他提及自己在北大近八年的研究经历，并见证了AI的两波发展。另外，澜介绍了自己从中国到美国的学习和工作经历，包括在麦肯锡的工作，以及加入和离开dw box后创立basis ventures，专注于AI和自动化领域的早期投资。他们讨论了投资的项目和对中国创业者在硅谷创业的看法。"
      },
      {
        "time": "00:09:07",
        "title": "投资人分享对AI公司投资经历及展望",
        "summary": "一位早期投资人分享了对Skill的投资经历，提及公司从2016年的1500万估值到之后达到的3亿估值的历程。讨论中还提到了AI技术的广泛应用和对未来AI工具的期待。此外，蒋纯介绍了自己参与的Montera AI公司，专注于帮助软件团队自动化处理用户反馈和文档生成。同时，他看好一家名为RTOARTSIO的公司，因其独特的利用AI重现艺术家风格的技术。"
      },
      {
        "time": "00:12:15",
        "title": "AI技术演进与图像生成模型的进步",
        "summary": "回顾了AI领域特别是计算机视觉方面的发展历程，突出了从游戏领域应用（如围棋AI）到现今图像生成技术的转变。讨论重点放在了技术进步上，如GAN模型的不稳定训练问题、扩散模型的引入、Transformer模型对多模态数据处理的改进，以及CLIP损失函数的创新，这些都极大推动了AI在图像生成领域的商业应用可能性。"
      },
      {
        "time": "00:17:21",
        "title": "探讨人工智能领域的投资机遇与挑战",
        "summary": "对话中讨论了人工智能（AI）领域的发展，特别是对比了过去和当前AI热潮的不同之处。一方面，技术进步使得AI应用的准确性和性能更加接近甚至超越人类水平，从而开启了新的使用案例和AI原生平台的可能。另一方面，尽管技术的普遍化使得基于特定模型的竞争加剧，但通过解决复杂问题或提供独特的解决方案，仍然存在赚取利润的机会。此外，还提到了基于开放AI模型建立的公司和解决特定行业难题的AI公司作为投资方向。"
      },
      {
        "time": "00:21:34",
        "title": "探讨AI模型开发与应用的未来方向",
        "summary": "对话内容围绕AI模型的开发和应用展开了深入讨论。首先，指出目前AI领域存在三类公司：一类专注于开发AI模型，如OpenAI等，这些公司通常资金充裕，能够训练复杂的模型；第二类公司基于现有模型寻找具体的使用场景，这类公司通过快速适应市场来实现盈利；第三类公司则需要为特定任务开发新的模型，如焊接机器人等，这类公司有可能成长为极具价值的企业。随后，讨论转向一位创业者的经验分享，他强调了利用AI技术简化复杂技术、建立用户信任的重要性，并分享了其创业方向——基于用户反馈和产品文档的智能化处理，旨在通过AI技术连接用户反馈与产品改进，为企业带来即时效益。最后，讨论触及了生成式AI在产品开发管理中的应用，以及生成长文本的挑战和可能的解决方案。"
      },
      {
        "time": "00:26:40",
        "title": "解决文本生成中上下文丢失问题及人工智能未来发展方向探讨",
        "summary": "讨论了在生成长篇故事时，如何通过控制prompt来避免上下文丢失的问题，强调将文本细节、角色设定等放入prompt中的重要性。此外，还提到了后处理技术，如重新采样和排序，以提高生成文本的连贯性。使用GPT3和Transformer模型，能够生成2000到7000词的连贯文本。还探讨了Transformer模型在统一不同数据类型方面的潜力以及未来可能诞生的新模型。最后，讨论了投资和商业化角度，关注点包括生成式AI的商业模式、大公司在文本生成领域的优势，以及初创公司在面对大公司时的挑战。"
      },
      {
        "time": "00:30:23",
        "title": "探讨初创公司投资价值的两大关键因素",
        "summary": "在评估初创公司的投资价值时，关注两个关键点：首先，公司是否真正解决了用户的问题，强调产品设计应紧密贴合用户需求，如某公司通过技术快速帮助用户完成产品设计，体现了实际解决问题的能力，从而获得用户愿意付费的使用案例。其次，重视初创公司的产品迭代速度，即它们能多快地改进产品，这对于在已有市场中快速占据一席之地至关重要。同时，探讨了成熟企业与初创企业在市场适应性和创新速度上的差异，强调找到痛点并快速响应的公司更具投资价值。"
      },
      {
        "time": "00:33:53",
        "title": "探讨人工智能模型的进化与发展",
        "summary": "讨论集中在人工智能领域内模型的不断涌现和进步上，特别强调了模型演化的渐进性和预见性。提到过去的成就，如DALL·E在图像生成方面的突破，以及transformer模型的引入及其对AI领域的影响。指出尽管看起来像是突然的进展，但实际上这些突破是基于长期的研究和逐渐的改进。此外，也探讨了未来模型的发展方向，即通过融合现有模型以实现更强的逻辑和人类结构能力的模拟。"
      },
      {
        "time": "00:36:33",
        "title": "NLP领域的革命与技术连贯性",
        "summary": "讨论重点在于NLP领域内BERT模型的推出所带来的重大影响，及其如何通过利用大量无标签数据和自我监督学习模型，改变了传统NLP的处理流程和训练方式。此外，还探讨了技术的连贯性，如搜索算法在AI领域的应用，以及未来模型发展的可能方向，强调了现有技术的累积和新模型创新的重要性。"
      },
      {
        "time": "00:38:45",
        "title": "探讨人工智能在创造性和复杂问题解决中的局限性",
        "summary": "对话中讨论了人工智能在理解和生成复杂故事、以及解决数学问题方面的局限性。一方面，尽管AI能生成具有连贯性的文本，但往往无法捕捉到角色动机、故事发展等细腻元素，难以创造出有深度和吸引力的作品。另一方面，AI在解决数学问题时，虽然能应对已有答案和定理的问题，但对于需要创新思维和新工具的问题，AI目前难以提供有效的解决方案。这反映出当前的大模型在处理需要高度创造性与理解力的任务时仍存在显著限制。"
      },
      {
        "time": "00:41:04",
        "title": "探讨生成式AI在创业公司中的应用及挑战",
        "summary": "对话中讨论了生成式AI技术在创业公司中的应用及其面临的挑战。创业者分享了在使用GPT-3技术进行个性化文本生成和文本相似度检测方面的经验，同时指出了在产品开发初期未能预见的问题。此外，还讨论了融资过程中投资者对于生成式AI应用的疑问，以及创业者对生成式AI商业化方向的思考。特别提到了在实际应用中，即使拥有先进的技术模型，产品的成功仍需紧密结合用户需求和反馈。最后，指出了目前AI生成文本领域存在的问题，如对于创作者和艺术家而言，精确表达提示词的难度，以及市场对生成式AI技术的期待和挑战。"
      },
      {
        "time": "00:44:09",
        "title": "探讨AI技术在特定场景下的应用与挑战",
        "summary": "对话集中在如何使AI技术，尤其是生成型AI，能更有效地应用于特定场景中。提出的问题包括AI理解复杂语境的难度、减少生成所需指令的长度、模型在特定场景下的个性化与集中化挑战，以及利用大量但杂乱的数据训练出高效模型的困难。同时，探讨了提升AI生成准确度和稳定性，以及将其商业化的可能性，指出语音生成和人脸合成技术的商业应用前景。"
      },
      {
        "time": "00:47:00",
        "title": "解决文本生成精准性与创业挑战",
        "summary": "在探讨如何提升文本生成的准确性和创业过程中的挑战时，讨论集中在利用现有技术和资源，如知识图谱、模型微调来改善文本生成的精准性，同时注重产品方向的调整以实现商业价值。面对资源限制，探索低成本解决方案，如关注学术动态和新技术，如GPT-4，来快速适应和改进。创业过程中，强调避免因技术迅速发展而导致的努力落空，如神经网络技术的进步可能使原有的优化工作变得过时。"
      },
      {
        "time": "00:49:00",
        "title": "探讨生成式AI在商业领域的应用与挑战",
        "summary": "生成式AI技术，尤其是图像生成，曾引起广泛关注并吸引了大量投资。然而，这类技术的应用和服务很快就面临用户活跃度下降的问题，许多项目未能保持初期的热度。讨论重点在于，生成式AI能否从一个简单的工具升级为解决特定行业需求的深度应用，或是能否成为一个具有巨大商业价值的平台。此外，也提到了生成式AI需要与特定领域结合，提供垂直服务和增强用户体验，才能实现商业上的成功。许多创业者正在探索如何通过增加用户粘性、优化SEO算法、提供社区教育和上下游服务等方式，使生成式AI产品超越一次性使用的工具，成为具有长期价值的服务或平台。"
      },
      {
        "time": "00:52:10",
        "title": "探讨AI在商业领域的应用与挑战",
        "summary": "对话中讨论了AI技术在生成图片、图标、图表等商业素材方面的应用，强调了版权问题的重要性以及解决版权问题的相对简便性。提到了一些AI初创公司在特定垂直领域（如室内设计、汽车设计）取得的成功，以及这些公司面临的来自科技巨头的潜在威胁。同时，指出了小公司在迭代速度、风险承受能力以及明确的市场定位方面的优势。"
      },
      {
        "time": "00:55:04",
        "title": "大模型的成本问题及未来趋势探讨",
        "summary": "讨论集中在大模型开发和使用成本上，指出大公司和融资成功的公司如OpenAI在开发大模型方面具有优势，但API调用成本高昂。讨论者提出对成本的担忧，特别是对于创业公司来说，如何应对日益增长的模型使用成本成为一大挑战。对未来成本趋势的预测包括可能的定价模式变化，技术上的优化以及开源模型的利用，探讨了降低成本的可能方向，如模型轻量化、使用更经济的GPU等。同时，也提出了对未来可能出现的挑战，如大模型可能被更便宜的替代方案所替代，以及开源模型可能带来的市场同质化问题。"
      },
      {
        "time": "01:00:08",
        "title": "探讨垂直领域中AI技术的应用与挑战",
        "summary": "讨论重点在于垂直领域内AI技术的重要性，强调了在实施AI解决方案时遇到的种种细节问题，即使这些细节可能不需高度技术，但也需要投入人力和时间去完善。提出了一种可能的新方案，即通过AI技术来实现电影制作或小说写作等，以提高效率和创造力，而不特别关心具体技术的提供者。同时，指出了提供全面解决方案的公司的潜在市场价值，强调了构建高壁垒的重要性。另外，提出了关于模型性能评估和选择的挑战，以及对未来技术可能替代现有知识的担忧。"
      },
      {
        "time": "01:02:37",
        "title": "探讨生成式AI的现状与未来",
        "summary": "对话集中在生成式AI（ABI）的当前应用、潜力及其可能的发展方向上。一方面，部分AI应用如自动驾驶被认为可能不会如预期那样迅速实现，而真正有价值的将是那些能解决具体问题的技术，例如特定行业设计或面试设计工具。另一方面，对于AI在媒体领域的应用持乐观态度，期待能看到如TikTok或Instagram那样的创新。特别强调了企业级AI工具的重要性，这些工具旨在通过AI提高工作效率，而非单纯追求技术的先进性。此外，讨论还触及了AI模型的个性化、隐私保护以及模型大小和效能的平衡问题，强调了让AI技术更加贴近和实用化的必要性。"
      },
      {
        "time": "01:07:18",
        "title": "探讨AI生成视频的技术挑战与未来展望",
        "summary": "当前，Facebook和Google等科技巨头正在积极研究利用AI技术生成3D模型和视频，但这一领域仍处于初期阶段，存在诸多技术难题。一方面，生成的视频内容较短且质量不高，与生成图片相比仍有较大差距。挑战在于，要想生成更长的视频，需要有故事情节和逻辑，这要求AI系统不仅能够理解和生成上下文，还要保持内容的一致性。此外，如何使AI理解并生成有深刻意义的内容，如一部电影的精华或能引发情感共鸣的短视频，目前技术还难以达到人类的水平。未来，AI需要实现更高效的数据利用和学习能力，模仿人类的学习方式，而不依赖于无限增长的数据量。这要求从根本上解决模型的可解释性问题，并在大脑研究和AI模型之间建立更紧密的联系。尽管当前面临诸多挑战，但科技公司通过积累数据和优化模型，有可能在未来突破这些限制，实现更加先进和实用的AI视频生成技术。"
      },
      {
        "time": "01:11:25",
        "title": "AIGC领域的发展趋势与商业应用讨论",
        "summary": "讨论集中在生成式AI（AIGC）的未来发展上，特别强调了垂直化、私有化应用以及模型的定制化服务是该领域接下来的主要发展方向。指出，随着技术的进步，将会有更多针对特定需求的私有化产品和服务出现，同时预测模型的升级将带来行业的进一步飞跃。讨论还涵盖了利用现有模型和算法的极限性能，来满足特定市场或个人的定制需求，比如声音合成和人像输出等产品。此外，提出了为这些模型提供工具和服务的ML ops作为发展方向之一。整体上，讨论呈现了对AIGC领域非常实际和落地的技术与商业视角，强调了行业快速发展的现状，并对未来的发展方向做出了预测。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "开源文字生成图片模型：stable diffusion，融资1.1亿美元晋升独角兽。"
                },
                {
                  "children": [],
                  "content": "自动生成文字内容：如copy AI jasper，成立不到两年实现数千万美金收入。"
                }
              ],
              "content": "开源模型与融资进展"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "生成长文本的挑战与解决方案，如通过改进prompting技术提高连贯性。"
                },
                {
                  "children": [],
                  "content": "对比GAN和Diffusion Model在生成图像稳定性上的优劣。"
                },
                {
                  "children": [],
                  "content": "Transformer模型对多模态数据处理的贡献。"
                },
                {
                  "children": [],
                  "content": "通过技术优化降低模型生成成本，如DPM Server减少迭代步数。"
                }
              ],
              "content": "技术突破"
            }
          ],
          "content": "技术发展与突破"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "大模型API的成本问题及其对创业公司的影响。"
                },
                {
                  "children": [],
                  "content": "垂直领域应用的潜力，如特定行业设计生成。"
                }
              ],
              "content": "商业模式探讨"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "关注解决真实用户痛点的产品。"
                },
                {
                  "children": [],
                  "content": "速度和生成速度对于产品成功的重要性。"
                }
              ],
              "content": "投资视角"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AIGC在特定垂直领域如汽车设计、室内设计中的应用。"
                },
                {
                  "children": [],
                  "content": "创业者面临的挑战与机遇，如利用大模型进行创新应用。"
                }
              ],
              "content": "垂直领域和创业机会"
            }
          ],
          "content": "商业化进展与挑战"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "对未来模型发展方向的预测，包括模型小型化、私有化。"
                },
                {
                  "children": [],
                  "content": "对AI理解和生成能力的持续提升，特别是处理长文本和复杂逻辑。"
                }
              ],
              "content": "AI模型的演进"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "企业如何利用AI技术提高效率，如在产品管理和沟通中的应用。"
                },
                {
                  "children": [],
                  "content": "AI技术在提升用户体验、解决实际问题方面的潜力。"
                }
              ],
              "content": "技术和商业的结合"
            }
          ],
          "content": "未来展望与挑战"
        },
        {
          "children": [
            {
              "children": [],
              "content": "AIGC领域正在迅速发展，技术突破与商业模式创新同步进行。"
            },
            {
              "children": [],
              "content": "对于创业者而言，找到特定的使用场景和解决实际问题是成功的关键。"
            },
            {
              "children": [],
              "content": "未来，AI模型的进步将进一步推动AIGC在更广泛领域的应用。"
            }
          ],
          "content": "结论"
        }
      ],
      "content": "AIGC（AI生成内容）讨论总结"
    }
  }
}