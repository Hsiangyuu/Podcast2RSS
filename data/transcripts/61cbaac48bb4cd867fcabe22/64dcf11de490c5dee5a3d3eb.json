{
  "pid": "61cbaac48bb4cd867fcabe22",
  "eid": "64dcf11de490c5dee5a3d3eb",
  "title": "EP 36. 对话Deepmind, 英伟达大语言模型专家（上）：AI Agent智能体与开源LLM的应用、挑战与未来",
  "task_id": "p7g395y8d645qz65",
  "transcription": [
    {
      "time": "00:00:03",
      "text": "欢迎来到onboard，真实的一线经验，走心的投资思考。我是Monica.",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:09",
      "text": "我是高宁，我们一起聊聊软件如何改变世界。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:16",
      "text": "大家好，我是莫妮卡，承诺大家的大波AI上新来了。之前莫妮卡定了个小目标，要在硅谷的两个月录两期播客，看来可以翻倍完成了。这一次是跟科技早知道合作，嘉宾组合也绝对重磅，是莫妮卡一直非常期待的。首当其冲的就是dream范，英伟达资深研究员，更是twitter上AI领域的顶尖KOL。连亚马逊的创始人jeff visus都关注的人，你怎么能错过？他的每一条推特分析都是AI从业者的必读文章。另一位技术大牛戴晗俊是google deep mind的资深研究员，更是google新一代大语言模型games的深度参与者。更有意思是，这两位嘉宾都曾经在OpenAI工作过。",
      "speaker": "发言人3"
    },
    {
      "time": "00:01:06",
      "text": "最后大家都非常熟悉的硅谷上市公司华人高管Harry硅谷徐老师。每次来on board的串台都大受好评。这次在硅谷创新腹地毗邻stanford的panto，不知不觉我们就聊了近3个小时，实在是太惊醒了。于是我们分成上下两期，更方便大家的收听。",
      "speaker": "发言人3"
    },
    {
      "time": "00:01:28",
      "text": "上期的内容我们围绕最近AI领域最火的话题之一，generative agents生成式智能代理。两位资深研究员都对这个领域有着最一线的研究和实践经验。从auto GPT以来，general agents从技术到应用都有哪些新的进展，又有哪些技术和场景的挑战，由此延伸到开源与闭源大语言模型的竞争格局，我们都做了非常深入的讨论。如果你还没有收听过上一期Monica跟另一位AI研究员傅尧的访谈，那一定要去听一听。对比一下关于agent这个话题，业内显然还有很多尚未有共识的地方，这也是科技发展的美妙之处在下一期我们会讨论更多AI领域的核心话题，包括多模态大模型机器人落地AI对sas的影响，大语言的模型的发展史，未来畅想等等。更是精彩不容错过，赶紧关注on boy。最后几位嘉宾都是长期在美国工作生活，夹杂英文在所难免，我们就不接受抱怨了。那么enjoy。",
      "speaker": "发言人3"
    },
    {
      "time": "00:02:50",
      "text": "一开始还是请大家先做一个自我介绍，你们在做事情，你们所关注的领域。当然老规矩还有一个fun fact，就是你们最近发现的一个觉得比较意思的一个AI相关的一个项目也好，或者产品也好，那要不还从徐老师开始。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:07",
      "text": "好，谢谢大家。今天是非常高兴跟几个我觉得在行业里面我都觉得是做AI大牛的几位同学一起聊一下，包括金梵我们其实已经想要做一个podcast，已经做了蛮久了。关于我自己，我做了20，我在硅谷待了二十几年，前面十几年一直在做云，诸如操作系统、云计算，做做早期的VMV的员工研发领导，后来做了几个start up，最近八年开始做那个AI先是在greylock肯挟投资，然后自己做了一个AI的公司，后来被并购。然后最近又加入了palo networks，做engineering AI的高级副总裁。很快的讲一讲interesting的比较有趣的idea。因为我我更多的是觉得general AI，这一次的革命不只是对编程人员的，是不是他们的工作会不会很大变化？",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:06",
      "text": "Programme这件事情可能是变成一个人人都会在变成program这么一个角度。比如说我我儿子今年暑假他就做了一个比较有趣的project。他在一个初创公司做一个用AI来发现bug这么一件事情。那个公司叫meta bob，他就做了一件事情，就是去explain发现的那个bug是怎么回事情。然后就用large language model去。然后这里面你就会发现，怎么去用prompting，怎么去运用和vector database，是一件很多是一个art，对吧？我是觉得我从这一个例子上面来看，就是说我是觉得AI这件事情会变成一个更加民主化，这是我所看到的一个世界，是在朝这方面走好的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:49",
      "text": "大家好，我叫戴晗俊。我们现在是在google deep，之前在google brain，然后博士期间是在georgia tech。我的主要研究方向是在生成模型本身，包括它的生成模型算法以及它的对应的采样和优化的算法等等。当然这个生成模型也不仅限于蓝轨迹model本身，也包含比如说其他的图像生成模型，像diffusion model或者是啊结构化数据，包括像程序语言这样一类的生成模型。除了research本身之外，我也对怎么应用这些research到实际的产品应用中，我也是非常感兴趣。包括我们最近也是跟google cloud这边合作，在这次的google IO上一起launch了RHF这个product。希望说是用google自己的模型桥接企业用户他们自己的需求，然后通过我们提供的算法，把这个语言模型跟实际应用去结合起来。",
      "speaker": "发言人4"
    },
    {
      "time": "00:05:51",
      "text": "然后说到最近看到的比较interesting project，我的关注点可能会比较偏算法本身。我像我一开始提到的生成模新的一些可能更fundamental的一些算法。所以最近我看到的一个比较引人注意的是一个关于如何对大语言模型进行更高效的采样这样一个这样一系列工作。首先这个工作是今年年初或者今年年中，大概google research和define同时论文发表。当然现在变成一个机构了，之前两大的独立机构也是同时关注到这一点。采样算法本身也是决定了实际应用中如何能够把语言模型做到实时化，或者是至少降低它的这个latency。现在的large language model主要是based on autogas sive model。",
      "speaker": "发言人4"
    },
    {
      "time": "00:06:42",
      "text": "然后这个模型其实包括言论坤在内也是对他有一些诟病。因为他大家都知道，语言模型可能是一个一个单词这样吐出来。所以它会导致的一个问题就是你在解码的时候，你需要等到上一个单词吐出来之后，你才能解码下一个单词。所以这样的一个序列化的依赖，使得它在解码的时候不能够非常充分利用现在的并行的计算。所以这两篇工作名字叫speculative decoding，是在说如何我能够用一个小的模型，它可能会跑的比较快，先去帮你decode一下，然后用大模型去做judgment，然后看是不是要接受这个decode。所以这样的话就是它的灵感来源是源自于原来最早期的像CPU指令，CPU的这个pipelines。",
      "speaker": "发言人4"
    },
    {
      "time": "00:07:32",
      "text": "就是说比如说CPU在执行一些if condition，他要做brunch prediction的时候，instead of它会在那边等着去做完判断之后再执行。它会先执行，然后如果之后判断不对的话，再去重新执行对的那部分。那原理也类似在语言模型解码的时候，他会说我先用小的模型先去decode，完了之后再用大模型去做驾驶。这样的话它的速度其实能够提升两倍以上。所以这是我觉得最近是一个比较一个亮眼的项目。",
      "speaker": "发言人4"
    },
    {
      "time": "00:08:02",
      "text": "这让我想起来昨天晚上我们跟几个stanford的PHD在吃饭的时候，有一个同学就是说现在这个AI的主要是在看AI，那些基础的computer science的东西就会比较少一点。我说我其实并不同意，我觉得其实computer science的东西还是会在AI里面出现，对吧？然后就像你刚才说的这个，我做操作系统做了10年的时候，每天就在数这个instruction怎么去除prediction对吧？我觉得其实都差不多。说到你的一个风范的，我就看到在你停车的时候，我看到你的车子CSPHD，这还是比较一个perfect。我觉得应该跟听众报告一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:43",
      "text": "对，就是韩俊的这个车牌就是CSPHD，而且非常酷。到时候我把这个照片放到我们的这个show note里面。好，最后各位听众。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:53",
      "text": "朋友好，今天特别感谢Monica还有哈威老师邀请我来做这个podcast，大家好，我是jam fan n。我16年的时候是在OpenAI实习，然后16年到21年在stanford读PHD。然后21年毕业之后我就加入英伟达，然后现在是英伟达的高级AI研究科学家。",
      "speaker": "发言人5"
    },
    {
      "time": "00:09:14",
      "text": "基本上我整个career最感兴趣的话题是AI agent，就是人工智能的智能体。Agent的意思是他能够自主做决策，而不只是像ChatGPT1样。你问他一个问题他回答一下。他是能够take actions，能够做决定，并且能够是从他的这个决策的过程中不断的学习，不断提高自我。然后我感兴趣的AI agent的应用有三类，一个是在软件上的应用，就如何让一个AI它就像人一样来用软件，比如说通过鼠标和键盘，或者通过API等等。",
      "speaker": "发言人5"
    },
    {
      "time": "00:09:51",
      "text": "然后第二块我很感兴趣的是游戏里面的AI然后最近我带的团队做了一个项目叫void。然后这项目是让GPT4就设计一个算法，让GP4来玩玩minecraft就我的世界这个游戏。然后my club是世界上最流行的游戏之一，它是一个沙盒的游戏，然后里面有很多这种三维的不同的block比如说有啊木头，然后有铁器，然后你可以在这个游戏里面可以探索，然后可以craft各种不同的工具等等。然后我们发现只要设计一个足够好的算法的话，GPT它可以自主的探索，并且在这个游戏里面不断的学习。",
      "speaker": "发言人5"
    },
    {
      "time": "00:10:33",
      "text": "我觉得智能体在游戏这个领域里面未来应用非常的大。比如说如何设计这种开放式的，有无线故事线的这种游戏。就是游戏的设计师他不用提前决定是什么样的故事情节，然后每个人玩这个游戏他可以玩出不同的玩法，这是第二块。",
      "speaker": "发言人5"
    },
    {
      "time": "00:10:53",
      "text": "然后第三块，我觉得智能体的未来是会在物理世界里面，也就是机器人robotics。目前这种通用的机器人技术还没有达到。但是我觉得可能未来3到5年或者十年左右的这个时间线上，我们会看到大量的这种通用的机器人进入。不仅是工厂里面，还有家用的一个一个环境。所以大致是这三这个三块。然后刚才提到就是一个最近比较有意思的项目，我刚才讲的这些应用基本都是单个智能体，但是我最近对多智能体的交互非常的感兴趣。",
      "speaker": "发言人5"
    },
    {
      "time": "00:11:29",
      "text": "我有一个好朋友是我斯坦福学弟，他叫john park。然后他最近做了一个工作叫general agent。然后在这篇文章里面他提出了一个stanford small file，就是一个小的一个虚拟的城镇。然后在这个小城里面有25个AI智能体。他们其实每一个就是一个GPT。但是他们有不同的人格，然后有不同的自己的背景的故事。然后他们每天早上起床去上班，或者去学校，或者去医院等等。然后他们互相会讨论，会有各种集会，然后会一起吃饭等等。",
      "speaker": "发言人5"
    },
    {
      "time": "00:12:07",
      "text": "所以这样一个虚拟的小镇，我们就看到它就是这25个智能体能够不断演化，并且他们能够有自己的不同的这种social gazin，不同的活动等等，然后就非常有意思的一个模拟。所以我觉得多智能体的话，未来它的这个可能性非常的大。比如说像科幻片西部世界里面描述的那样，就是每一个AR它有自己的一个性格，自己不同的故事。然后最后能够演绎出非常复杂的一个在social interaction上面的这种无限的变化。对，所以这是我关注的一个项目。",
      "speaker": "发言人5"
    },
    {
      "time": "00:12:41",
      "text": "感谢。其实我觉得正好聊到这个agent，因为agent本身就是一个大家很关注的话题，不如我们就顺着刚才就提到这个agent就聊下去就好了。其实也就是几个月前，agent这个定义被被提出来。也我们也看到了，包括adapt对吧？然后包括最近有很多什么auto GPT。TA GPT AGGP等等的这些应用。但是他其实也对他有很多的争议，对吧？我就想这样去来聊一聊，就是你刚才提到了几种的agent的这个应用。就是你觉得agent它应该具备哪几个核心的构成。从技术和产品的角度来说。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:18",
      "text": "我觉得现在AI智能体的话就分刚才讲到的三种。但其实就一个是在虚拟世界里面，然后还有一个是在物理世界里面。然后我觉得这两类的做法，他们有相同的地方，但是还是有很多地方是不一样的。比如说举个例子，就是刚提到的第一个应用就是AI它控制软件，然后帮人来做一些生活中需要做的一些，比如说查查邮件我觉得这一类智能体的话，可能最好的方式是通过写代码。因为其实现在很多的这个软件它都是有API的，包括我们看到的ChatGPT的，它这个APP store。然后这个poin这个系统其实也是一种写代码的这样一个语言模型。然后用到这些软件的工具，然后通过API用的工具，把这些工具串联在一起，就可以实现很多的任务，这个我觉得是一种方式。",
      "speaker": "发言人5"
    },
    {
      "time": "00:14:08",
      "text": "然后另外的话，在游戏或者在机器人上面的话，那多模态的这个大模型是非常的重要。因为他们不仅是看到文本或者写代码，他们还需要能够有计算机视觉。然后他们能看到虚拟的一个三维的世界，或者现实的一个三维世界。但这边我觉得多模态是在未来会起到一个决定性的作用。",
      "speaker": "发言人5"
    },
    {
      "time": "00:14:29",
      "text": "所以要实现这个智能体，除了这个LM之外还需要哪几些部分呢？还是说它核心的能力应该怎么理解？核心能力就是由这个LM来决定的吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:39",
      "text": "对我觉得比如说对于机器人来说，我觉得有一个和LOM区别很大的地方。就是在训练大语言模型的时候，这个数据量是不成问题的。就是整个互联网上面这个数据都是可以作为训练。而且就是从这个互联网上scrip这些数据也非常的容易。但是对于机器人来说的话，比如说机器人的这些控制的一些数据是在网上下不到的，所以就意味着我们要自己采集。这个我觉得就让训练非常的困难。",
      "speaker": "发言人5"
    },
    {
      "time": "00:15:09",
      "text": "所以采集的话现在主流有两种方式。一个是通过模拟器，比如说物理里面的物理模拟器或者游戏的模拟器。然后另外一个就是买一大堆机器人，比如说几百个，然后就是让人来控制他们，或者让他们就自主的探索。但是在物理世界里面就直接采集数据。但是这两种的话都各有他们的利弊。所以我觉得现在这个问题其实是比训练大元模型要难很多的问题。就是为什么我们现在还没有看到通用机器人？",
      "speaker": "发言人5"
    },
    {
      "time": "00:15:38",
      "text": "对我我其实对刚刚jim的回答非常感兴趣。有一点是jim我知道你在做很多avoided agent这样的一个set，就是说agent需要跟这个环境去交互。我们看到很多就是把language model自己作为agent的这样一个setup，有没有说是有把language model或者foundation model作为environment这样一个setup。使得说我能够更face ful去模拟这个世界，以及让这个agent和environment的交互都变成两个利用foundation model本身的能力去enable的这样一个事情。",
      "speaker": "发言人4"
    },
    {
      "time": "00:16:15",
      "text": "对我我觉得foundation model是可以作为一个事件模型。然后这个意思是它可以模拟未来，它像自己是一个模拟器，然后它可以比如说在take一些action之后，他可以预测这些action可能会造成的未来的一些后果。然后通过这样一个方式的话，是可以生成一些这种人工的一些数据。然后通过这个也可以训练一些更好的智能体。所以我觉得这个也是一条思路。但是现在这个大语言模型它有pollution ation，会产生一些幻觉，所以它这个世界模型不一定非常的准，然后这个可能也会造成一些困难，所以我觉得这一块也是一个双刃剑。",
      "speaker": "发言人5"
    },
    {
      "time": "00:16:54",
      "text": "那我问一下想问一下徐老师，就您在这个企业这个场景里面，有没有看到一些跟agent相关的一些尝试。目前离这个落地相比存在一些主要的挑战在哪儿？",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:06",
      "text": "从一个落地的角度来讲，我觉得差距还是蛮远的。就好像澳洲GPT大约今年大概三月份、四月份突然很红火对吧？大家几乎每个推子好像都在讲GPT对吧？感觉好像就是人人都应该用，但你真的去用，你真的去做一些series的东西，其实我觉得可能没有一个人能做出来，但不代表这个direction是错的。我觉得这就像任何一件事情，我觉得都需要一些时间去mature。所以说从这个角度上来讲，我也是觉得我是非常相信这个agent的这个direction，以后要做一件事情，我们用large language model potentially去把一些事情给分解成为好的步骤。然后直接去调一些API的，然后直接去把一件事情做成。这我觉得是能做的，而且应该做的，但今天还做不到。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:59",
      "text": "今天比如说如果说我要落地去做一个客服，你你你去看客服的东西，很多时候他的问题不只是说是来回答一个问题，很多时候是需要去改变。比如说去update一些record，我觉得今天要用agent去去去做一些change record的这些东西，我觉得肯定是不成熟，能够回答问题。但我觉得两年、三年、四年以后的那个客服，我觉得就完全是可以去用agents去做。今天还很远，但是这个很远不代表时间很远，而是说这个落地还有很多的落差。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:35",
      "text": "韩军也可以聊聊从你的角度看他的chAllenge。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:38",
      "text": "对，首先我非常echo Howard说的GPT这件事情。因为auto GPT它能够让自己模型自己去调用自己。就是说它一是有多少个language model call这件事情它自己可以控制。所以带来一个问题就是可能你完成一件事情会本身需要非常多的迭代，但这件事情在比如说像客服或者这些应用场景中，这个latency是一个非常大的问题。",
      "speaker": "发言人4"
    },
    {
      "time": "00:19:03",
      "text": "然后第二个是about这个evaluation，其实说到agent可能也绕不开to use。那比如说我让这个agent去帮我去订个机票，那最后有没有订到或者订的是不是我要的机票。这件事情可能比较容易verify。但是你中间订机票这件事情，你也可能分解成好几个步骤。",
      "speaker": "发言人4"
    },
    {
      "time": "00:19:20",
      "text": "第一步，比如说你要去一个正确的网站，然后你要把相应的这个时间地点都要输。对，就是每一个step你都需要，最好是有这样一个中间的反馈，这个其实也跟传统的reinforce learning也非常相关。就是说作为强化学习，只让他做一系列action之后，让他最后得到一个反馈。他中间其实做的好和坏，他要花很长时间去figure out中间的这个到底好还是坏。所以怎么去做evaluation，特别是在没有完成target task的时候，中间的那些步骤怎么做去做，eventually也是一个非常急需的一个能力。对，然后包括这个具体你要调用那些错误的时候，有些错误可能它你用它可能会有一些consequence，不是reversible的一些consequence。",
      "speaker": "发言人4"
    },
    {
      "time": "00:20:09",
      "text": "当然也有一些work around的，比如说像我之前可能有幸做过一次那crust他的author's driving，他现在已经l phone在旧金山城里面对，但他的他也会碰到很多edge case，就比如说前面车突然停下来了，前面车到底是因为比如说他在卸货，所以你可以其实可以从对面借道过去，还是说你就应该等着他这件事情。Cross他的车他自己判断不了，他会发给后端，然后后端可能会有remote这样人为干预。对，可能这是一个mabe一个work round。但是在language model l在agent to youth里面有太多的这样的h case，或者说language mode。自己可能也不知道这是个h case，所以怎么去更safely的去做这个to you或者是啊regulated agent behavior，也是我觉得也是比较挑战性的事情。",
      "speaker": "发言人4"
    },
    {
      "time": "00:20:58",
      "text": "对我觉得evaluation的确是大家最常提到的一个话题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:03",
      "text": "对我觉得刚才浩宇老师还有韩俊说的这几个点都很有道理。因为现在就是在一个企业，或者是机器人，或者无人驾驶这些应用下面，就它的这个安全性非常的重要，可靠性、安全性都非常的重要。但这块我觉得现在的AI可能是只有80%到位。但是如果不是比如95%甚至99%到位的话，这些东西很难落地。所以我觉得其实现在最容易落地的一个智能体应用就是在游戏里面。因为游戏里面哪怕说错点话，甚至就是讲一些有些时候可能有些过分的话，大家都会觉得这个非常的娱乐性，就非常cute，对，非常的entertaining。对，所以就是非常在这个游戏这样的一个环境下，倒反而这些不一定是bug，反而是feature，就是这个感觉。",
      "speaker": "发言人5"
    },
    {
      "time": "00:21:46",
      "text": "所以说生成式的AI最近几年或者最近一两年就做的最好的，还是像jasper那个majority这样的，就是说做出来的东西creativity更重要。至于说是差一点，或者他把10%，这不是很重要。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:02",
      "text": "对，一直像character他们这种，比如说他作为情感陪伴，或者是作为模拟一个动画人物，或者是模拟一个celebrity跟你对话，其实中间说错话或者是乱说什么，其实你也不会太care。",
      "speaker": "发言人4"
    },
    {
      "time": "00:22:14",
      "text": "对，没有一个正确答案。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:16",
      "text": "不过我觉得caracter和major ney就是他们是creative，但他们并不是agent，因为他们没有在做这个决策，没有就是我们说的behavior。然后这一块的话，我觉得现在AIMPC这种long player character这一块才刚刚起步。然后我们现在还没有很多大的游戏场对这个AIMPC特别感兴趣，但是我们还没有看到他们大规模的部署，或者说做一个我们称作AI first的一个游戏。这整个游戏的体验就是一群AI智能体。然后他们在讲这个故事，然后每个玩家都能有自己的一个独一无二的体验，所以这块目前还没有看到，但是有一些有一些prototype。",
      "speaker": "发言人5"
    },
    {
      "time": "00:22:57",
      "text": "我举个例子，前段时间有一个叫病娇女友一个游戏，对，然后就是那个里面有一个女友，但是他有点crazy，然后你要相当于说服她，让你就是出这个房间。然后我就看到youtube上面有很多大V然后他们就在玩这个游戏，可以玩出各种不同的玩法，然后你可以有欺骗，或者你可以就哄他或者等等。对，然后完全是通过背后都是通过chat BT做的。所以这个是我觉得一个AI first的一个游戏。但现在大的一些就是呃3A级的这些游戏公司，目前还没有看到一些大的动作。",
      "speaker": "发言人5"
    },
    {
      "time": "00:23:35",
      "text": "其实我们也挺关注AI对于游戏这一块的一些创新，我们是比较喜欢的。跟你说这个病娇女友目前还很简单的一个形态，但是这个是所谓真正的是AI这个native的能力，你没有这个LM你就是做不了。有时候我会看到大家把这个只是把一个更聪明的NPC放在游戏里面，放了一个现有的比如现有的RPG什么。这游戏里面其实你把他对于这个游戏体验的改善，其实没有那么的对，没有那么的大，所以就变得有点鸡肋。但是我们其实还是很期待有更多这种全新的这种游戏模式被创造出来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:10",
      "text": "其实最近也看到有不少跟这个sanford小镇类似的一些这种游戏的idea。但是就像刚刚才大家说的这个，我觉得实际落地中包括memory length等等的，还是有一些挑战。但是我觉得一个新技术出来挑战大众很容易说。但是毕竟就刚才提到的这个呃欧洲GPT这个概念提出来，这个project提出来，其实也有几个月过去了，在大家刚才所关注的几个挑战领域，有没有看到一些这几个月在帮助这个H或OOGBT能够更好落地的一些进展。让我们觉得是对未来可能不要promising.",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:47",
      "text": "的jm可能看到的多一点。因为我我觉得至少推特上面我是时不时能够看到一些新的project概念。跟auto GPT差不多，感觉好像他们打磨了一点，我感觉我也没有和那个follow退款closely，但我感觉好像是层出不穷，还是有一些。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:03",
      "text": "你的感觉呢？我觉得是有一些，但是目前感觉就是真的部署了，真的在产品里面的好像还是寥寥无几。可能更多的还是从写代码的这个角度，但是可能也不是完全自主的把这整个决策的决策链都放进去。",
      "speaker": "发言人5"
    },
    {
      "time": "00:25:18",
      "text": "你觉得这里面有多少成分是因为基础模型的能力。就是说我今天这个基础模型GPT four已经不错了，但是还是有很多问题。如果说我到了GPT five、GPT six的一个level，说不定很多这些问题就迎刃而解或者自动解决了，还是怎么样？你从你的观点有多少是因为基础模型的原因？",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:40",
      "text": "我觉得可能有七八成是因为技术模型的原因。比如说举个例子，现在给GBD41个API，然后让他要完全按照这个API来，它有些时候还是会有lucena，就是它产生幻觉，然后他可能API用的并不是特别对。但这一块如果GPT5和6能够很精准的用API的话，那其实很多这里面的问题就能解决。比如说如果我们要一个AI来控制我们的这个browser，然后来订个机票或者什么的。这块万一输错了一个信用卡什么，这问题就特别的大。这块GP4可能还没有那么可靠，所以我觉得5和6会解决很多这样的问题。",
      "speaker": "发言人5"
    },
    {
      "time": "00:26:16",
      "text": "然后另外一点就是多模态。GB4理论上是多模态，但是现在大家能用到的就是公开的API，它还只是一个文本的API对，所以我们现在并不知道GP4多模态能做到什么程度，但是5和6的话务必是会是多模态会放在第一位。那个时候我觉得可能5和6甚至都能用于比如做一些游戏，或者说制造一些机器人的这些应用。因为它能够把这个像素或甚至视频输进去，所以我觉得这一块目前GP4还比较难做。因为我们必须要把这个图片或者视频转换成文本，然后他才能够去做做这个决策。",
      "speaker": "发言人5"
    },
    {
      "time": "00:26:54",
      "text": "我我非常echo jim这一点，就是关于agent的能力，其实更多的是在在这个模型本身，我可以提供另外一个观察。就是前两天在莫妮卡的活动中，星云也给了一个talk，关于让A正的自我debug这件事情。他的setting大概是这样，可能就是说你让这个agent去写个程序，然后这个可能他第一次不一定写的对。但是你可以通过这种prompt的方式让他去自我去回顾一下，看看你自己写的东西和那个语义的language的instruction是不是match。然后这样子做一两次迭代之后，他会发现这样比较强的模型，像GPT4，它就会正确率反而会提升。所以就是说通过A正能让他自我去修正的方式。但是这个能力比如说让他在GPT前一些版本去做同样的事情，他会发现这个反而会让他的point下降。",
      "speaker": "发言人4"
    },
    {
      "time": "00:27:47",
      "text": "但是其实在聊到这个agent的应用的时候，大家的确最常提到的就是这个holik。但是其实我们都知道how station是这个大模型自己本身，它基于这个架构本身不可避免的一个东西。Agent里面这个体现更明显，是因为它涉及到很多个多个步骤的执行。如果说这个是模型自己内生的一个无法避免的东西，那难道就意味着说我们得要另外一种底层模型才能够实现我们所期望的能够落地的准确度吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:19",
      "text": "其实我想借鉴一下正式面当时talk里面的一个观点，就是说如果模型自己不知道这个东西的答案，比如说你问模型，比如说它的knowledge是在2021年之前，你问他2023年谁是总统这样一件事情，他自己本身没有这个答案。但是你做instruction tunney的时候，你告诉他这个答案，那他为了去回答这个问题他只能去那啊那另外方也是，如果这个模型本身就知道答案，但是可能你为了是出于safety或者conservative的原因，让他告诉他你应该说不知道。那同样是另外一个direction relation，所以就是identify这个模型自己知不知道这个问题的答案，以及在对应的时候去做相应的回答。这件事情如果能够去解决这个事情，我觉得其实是一个能够放在门头里，或者是至少能够elevate这个pollution。然后大家也看到就是说像或者这些类似的技术，在现有的架构基础上，它确实能够有一定的信任。当然不是说guarantee它能够解决hycy inan问题，但可以greatly reduce the policy ation。",
      "speaker": "发言人4"
    },
    {
      "time": "00:29:25",
      "text": "我我我觉得对，首先我非常同意这一点。另外我觉得其实在一些特定的问题上面，可以通过更好的自我训练来降低和luca。比如说举个例子，就是写代码的这个agent，然后它写代码的话有一些编译器或者interpreter首先先能够给一些错误，然后这个错误就是一个信息，或者他会说就是某一行里面出了什么错，然后这其实就是一个signal。然后能够让他通过自我训练能够不断的improve。还有包括就是从探索，或说是在完成的任务上面，我们会知道这个智能体是否成功完成任务。然后如果他没有完成的话，它在哪里出了错。然后这些其实都是信号，可以让它来至少降低一些在一些特定的环境下的。Hello ation.",
      "speaker": "发言人5"
    },
    {
      "time": "00:30:13",
      "text": "所以说halston这个幻觉这个问题，你们两个人的观点是最终还是有有两个，一个是用强化学习去去解决，另外一个还是一个知识或者说是学习，如果足够多的话还是可以的。那你觉得像这个精准度，因为这样coding对吧？就它的对精准度的要求很高。你不能说就像那个驾驶车一样，你不能说1%的时候，虽然说今天hello是超过1%，但你即使降低到1%还是很高，对吧？你觉得就像coding这样的，能不能做到accuracy跟几乎跟不是语言模型产生出来的coding，就像我们那个google、facebook engineer写出来的话，大家都会有bug。但是说降低到那一个程度，你觉得是有信心吗？或者说短期内会有信心吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:03",
      "text": "我觉得是非常有信心的，因为最近有些论文也体现出这一点，就是GPT4d barging这能力其实非常的强，他可以看自己写的这个代码，然后看一些比如说编译器的错误信息。然后他会说可能是我这一步写错了，然后是因为这个原因写错了。然后他可以有这个think step by step这样一个过程，一个chain of thought的一个过程。然后他可以通过自我的debugging来改进他自己之前写的代码。所以我觉得这一块的话，GP4已经涌现智能还是挺强的。然后我觉得之后GPT5等等应该会在这个上面做得更强。",
      "speaker": "发言人5"
    },
    {
      "time": "00:31:39",
      "text": "就像浩伟老师您说的，就是即使是人的工程师，一般写第一遍代码一定会有bug。写完以后然后执行，然后看了这个bug report，然后能够精准的去修改这个代码，并且在重复刚才这个过程。如果我们能够完全模仿人的这样一个过程的话，我觉得之后就写代码能应该会越来越强。",
      "speaker": "发言人5"
    },
    {
      "time": "00:32:01",
      "text": "前一段时间我跟一个朋友Sarah郭，他提了一个观点。他说今天写代码的能力也就是写一个paragraph，写写一个function，但是不足以写一个file，或者说是更大规模的。我们顺着写代码这个角度，你觉得什么时候那个编程人员码农的写一个file，它都能够比较精准的能够写出来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:30",
      "text": "对我觉得这个可能需要long context，因为现在毕竟就是GPT4什么的，这个context的长度还不够，不足以写一整个文件一个很长的一段代码。就是它这个memory什么的都不太够。但是我觉得这一块的话，在未来几年应该是慢慢会得到改善。韩军怎么看？因为韩军是在前线来训这些最强的模型。",
      "speaker": "发言人5"
    },
    {
      "time": "00:32:52",
      "text": "这方面我也持乐观态度。然后主要是因为两个点，一个是其实主要核心部分还是在数据。其实我个人在free language model era也劝过这种debug ing的事情，就比如说让这个neural network去做the correct code。但是我们当时缺的是什么？缺的是我怎么知道给你一个代码应该改哪里，应该怎么把它改成一个对的，或者我哪里我怎么知道这个代码会出错。当时我们非常structure这件事情，但是后来reduce到去给他up上去爬一些他们的commit。我们觉得可能有些commit，如果他改的数量比较少，他可能是在修一个bug。所以就是通过这种方式去获得一些noisy的data。",
      "speaker": "发言人4"
    },
    {
      "time": "00:33:31",
      "text": "但是现在不一样，现在是大家用这个copy的或者这些产品越来越多，大家会其实主动的跟这个copilot，比如说去进行大log，或者是进行修bug的过程。其实是能给他more data，然后让他去再去improve。然后这种data是其实是更专注更高质量的。从这点上来说，我非常of optimistic。就是说它的debug或者是写代码能力会更进一步的提升。",
      "speaker": "发言人4"
    },
    {
      "time": "00:33:59",
      "text": "是一个几年的一个范畴，就是有大规模的突破。今天我们大家都对GPT four的能力非常的惊叹，对吧？包括我个人几个月前我是一直是觉得，但我最近几个月看了看，就包括我们刚才讨论吧？其实基础模型的能力还是不够或者说怎么样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:20",
      "text": "我现在想过了若干年，我觉得我们会忘记GPT four这个milestone。我觉得真正的milestone还是在后面的一两个，一两个就有点像apple我们都说这是一个iphone moment对吧？但是iphone moment就说老实话，即使在硅谷没几个人记得那个123对吧？多数人还是从iphone 4开始用起来的。所以说我觉得GPT4会会最终会成为一个very early version that no one even talk about IT。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:49",
      "text": "对另外一半是也非常echo这么说的。关于context length这件事情，大家可以看到就是to make这个to copilot或者是这种code他useful，你得去理解我自己的code base。然后自己code base可能已经写了很多东西，然后不大可能选3d context就increase contest length。我觉得是一个可能是一个比较简单的和好的方式。因为你其实也不知道什么应该放到contest里面，那你就全放进去。但是也会带来问题，就是一个是archie tecture alist它能不能接受。第二是即使在这样可能看到大家也可以看到很多能够说把context land到100K或者1 milan这样一些language model。那它的问题就是他能不能去理解这个context。所以是两方面都都可能会有。",
      "speaker": "发言人4"
    },
    {
      "time": "00:35:34",
      "text": "middle。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:35",
      "text": "对，但是现在我们看到就是像一些retrieval with的一些方法，我觉得是包括科帕拉的自己。比如说他们做的那个在VS code里面的pala gin，那其实也是有一定的是需要能力能够帮助你去alive的。这个problem我觉得对最初的问题是在能不能写长代码。我觉得这个能力上，我觉得现在是已经可以看到一些worker了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:35:56",
      "text": "我问一个具体的问题，因为其实刚才几位谈到这个agent的时候都在讲，比如说他用这个可能类似于GPT login的这个形态，你要写代码然后去扩API。那其实我们现在看到包括a APP在内，他的用的方法可能更直观。它其实就是控制你的这个屏幕，屏幕上你原本人应该怎么点的，然后他去操控那个屏幕来点。你们怎么看待这个agent的最后的这个实现方式呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:23",
      "text": "对讲到这个问题的话，16年的时候我在OpenAI做了，当时参与了一个项目叫open universe。然后当时那个项目其实就是Monica你刚说的adapt，他们现在想做的类似的一个形式。就是说是看这个screen，然后看这个屏幕上的这些像素，然后直接输出的是鼠标和键盘的控制。但当时那个时候还没有，16年的时候没有大语言模型，所以那个时候我们都是用强化学习的方式，然后这泛化能力就非常的差，基本上你训练一个任务，他就能做一个任务。但除了这以外，他就什么别的都做不了。",
      "speaker": "发言人5"
    },
    {
      "time": "00:36:56",
      "text": "然后另外我们也发现其实鼠标和键盘并不是一个很好的输出的一个方式。因为它其实从这个robust和可靠性的角度来说，你比如说这个鼠标稍微差了一点点，其实它问题非常大。而且它可能输入的话，它要求这个屏幕的像素非常的高，否则里面如果有个很小的一个按钮的话，你就按不到。对，所以其实我觉得这个方法是有它的问题的。所以我现在更看好是从语言模型曲线救国的一个方法，就是通过写代码。然后这个代码其实也是可以控制我们的浏览器。比如说像solarium这样的这些工具，是可以通过写一些代码，然后能够模拟鼠标和键盘，而不是真的控制。就说这个鼠标一定要在第302个像素这边做一个点击，所以这个是我现在的看法。当然adapt这个公司之后，他们产品会怎么样目前还不知道。但是我是觉得就是从这个大模型还有多模态这些角度来解这个问题会更好说穿了就是。",
      "speaker": "发言人5"
    },
    {
      "time": "00:37:57",
      "text": "还是用那个next token prediction，next word prediction作为一个目标函数来实现这么一件事情，要比去控制鼠标作为目标函数更加好。对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:10",
      "text": "通过写代码，通过生成文本的这个方式。当然这个训练的话可以有强化学习等等，这些方法也是可以的。",
      "speaker": "发言人5"
    },
    {
      "time": "00:38:18",
      "text": "对我觉得刚刚jim提到一个很好的点，就是关于多模态这方面。我觉得包括刚刚点网页的这个例子，如果作为蓝规矩mode，如果只是把这个网页的dom tree什么HDM乘三点去，你会发现它非常乱，然后它就是R的非常长。但是如果把它渲染成一个Y配置的话，其实相对来说是或者至少对人来说，你是更容易知道哪个应该点哪里。比如说他render出来那些高亮的，或者在下划线就highly active。它是一个hyper link，肯定可以点，然后点完之后可能会缺个，你到下个月1方面我非常echo这个就是jim说的multi mode的这方面。然后另外一方面确实就是我觉得可能鼠标点不一定是个坏事，然后可能是他能够说，至少他是visually和他的systematically都是有着互相帮助的一个成分。",
      "speaker": "发言人4"
    },
    {
      "time": "00:39:05",
      "text": "我记得当时GPT41出来的时候，有一个非常炫酷的一个demo。就是当时greg brock man在纸巾上面画了一个网站的一个草图，然后拍了张照，然后就说请生成一个HTML，然后跟我这个草图差不多，然后GP4能够理解那个像素里面内容，并且能生成这个。对，当然现在大家都。",
      "speaker": "发言人5"
    },
    {
      "time": "00:39:26",
      "text": "还用不了，正好聊到这个agent最后实现形态的时候，包括最近像戴尔这种形态的时候会想OK，其实这个并没有跟我原来完成事情的方式其实还是一样的，只是他现在是另外一个人完成。但是如果我们讲到像包括像我to GPT那种，我就会想如果那个是我们所期待的agent的未来，其实我根本就不用再看那个screen，我也不需要知道他他到底是操作了哪一个APP。他就是在他到底是在vik b的上面去订票，还是在booking dom去订票。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:57",
      "text": "我觉得这个对于所有这些tooth，就是这个two using的这个tooth意味着什么呢？我看前段时间大家不是有rumor说apple也在做他们的LM吗？我想他们当年siri的理想如果实现，那我们在每个人手机上线几十个上百个APP。如果真的都是由这个siri来去调动的话，其实我们根本都不需要知道，可能都不需要下载这些APP。那这个对于以后这个APP的这个生态又又意味着什么？这个到企业里面那对企业里面这些SARS又意味着什么？就开开脑洞，我问大家这个想法。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:32",
      "text": "我觉得这不需要开脑洞，我觉得这是铁板钉钉几年以后就会发生的事情。就是那个boss不管是software bots还是hardware box。Hardware box可能需要硬件的机器人，可能时间要长一点。就像jm刚才说的，有一些挑战对吧？技术上的挑战。但是我觉得soft box所谓的software box就是大语言模型基础上的那些那些不管是agent也好，或者说是软件也好，我觉得是会成为first class citizen。也就是说今天的sas也好，enterprise的软件也好，其实是基于前一代的技术对吧？就是不是以AI native的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:12",
      "text": "当你如果能够想象就copilot，不管是写github的copilot，还是microsoft的所说的office 3 sixty five的copilot，我觉得copal会成为几乎每一个enterprise software公司都会有自己的copy了这个产品，而且是作为主要的产品，在这五年之内会成为他们的主要产品。也就是说，今天我跟office打交道，我还要做很多事情，但以后的那个copilot会帮助我做很多事情。今天我到salesforce、workday, 很多事情要自己去workflow driven的。但以后很多东西其实我是跟那个copa在打交道。在这个copa作为first class citizen的时候，说老实话，包括我做一个程序员，我写的code。这个code最终是为是为了跟机器打交道，跟boss打交道，跟lunch language model打交道，这个是还是很不一样的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:59",
      "text": "举一个很简单的例子，我写document就是说我作为一个程序员，我会写document how to？怎么去用。我的以后不需要人不需要看这些东西，一个用这个软件的都是机器去去学习。所以说更重要的是你要把这个机器人friendly的那个document给产生出来。我们应该假设这个世界就是今后的五年会发展到语言模型，那个boss是一个class citizen。然后我们的产出，我们所做的东西要为他们服务，最终其实是我们自己的生产力提高。因为我我做任何事情，我就要跟我的system说一声，我是说的我说的system是large language model based system，large language model copy. 我觉得这是一个必然会发生的一件事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:44",
      "text": "对我我非常同意后卫的vision，以及我觉得这是一个解放生产力的一个新的机会。但是如果我作为软件开发商，之前我能够直接面对客用户，但是现在我面对是中间的一个中间上。那会不会比如说打击我作为软件开发商的一个积极性，或者说in the future，如果是有一个这样一个language mode agent的constrct这些软件的话。所以软件上怎么获利？",
      "speaker": "发言人4"
    },
    {
      "time": "00:43:14",
      "text": "我觉得我们人打交道就是一个口气，这可能是增加了一个one lay of ability，right. 我是跟一个copilot的打交道，我的助手打交道，但不代表我的助手in this case是软件，对吧？这个软件还是需要不同的其他的agent跟他合作把很多事情完成。所以我觉得软件还是需要的，只是人直接打交道的会很不一样一点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:38",
      "text": "对，然后我觉得很同意郝宇老师刚才提到的。我觉得现在可能几家大的公司有一个很强的优势。因为他们控制他们整个生态系统以及所有的API。比如说我们看到就是windows co pilot，像这个事情就很难，比如说adapt这种公司就很难做。因为微软控制所有的windows背后的源代码，他们想做什么样的，就是浩宇老师刚提到的board friendly的API他们就能做。但是要adapt这样子，一个第三方的公司可能只能通过鼠标和键盘，他他不是不愿意通过代码，他是没有办法通过代码。还有像adobe这种什么photoshop等等这些工具只有adobe有。所有的这些就是native的一些代码的API等等。",
      "speaker": "发言人5"
    },
    {
      "time": "00:44:18",
      "text": "然后这块我觉得大公司是有一个很强的优势的，并且他们甚至是可以把他们把比如说外面一些开源的模型，可能待会会提到lama 2这样的模型，然后能够微调在他们的这个产品的API上面。那这样一个模型可能就是说它的通用的写代码能力是不如GP4，但他就是在这个专业软件的这一组API上面写代码能力可能强于吉比利斯。然后这样一个模型只能够有拥有这些软件的公司自己去做，而且我觉得会是成为一个mote。",
      "speaker": "发言人5"
    },
    {
      "time": "00:44:47",
      "text": "对，其实我对关于如果agent的它只能接触到这些API层面的这种调用的话，其实也会带来另外一方面的问题。比如说像open ITS有那个plug in的那个storm，然后你可以never几个plugin。比如说当时问了一个非常简单的问题，谁是那个twitter CEO？然后当时因为马斯克已经step down了，当时有两个plugging都可以回答这个问题。一个他吹嘘自己是一个knowledge graph的plugin，所以chat BT会直接去调用那个plugin。然后他回答的是一个比较老旧的回答，之后还还是去CEO。但是另外一个判断是我from ala它其实是一个能够获取网站的时候，是那internet的上他的信息更新。但是无法阿尔法，你其实也不会想到它是一个能回答伊隆马斯克twitter谁是CEO这样一个问题。所以就是关于如果你确实想听说，如果你只能调用这个API，我觉得很难去放在馒头里去真的把这个东西做的有错。",
      "speaker": "发言人4"
    },
    {
      "time": "00:45:43",
      "text": "对，而且你刚才那个例子也让我想到，就是说他还得要知道到底哪一个to应该去调用。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:49",
      "text": "所以这个feedback loop特别重要。以及回到一开始说的evaluation，你可能一开始maybe你吃了一次亏，把这个图我的API描述的很好，我吃了一次亏。那我之后我知道你这个图可能只是需要这个API只是虚有其表。那我下次我可能就不调你了。有点像这种maybe banded setting这种我至少我愿意try一次，但是我需要有反馈告诉我这个到底行不行。然后使得我最后agent的知道in future al怎么去调用这些API。",
      "speaker": "发言人4"
    },
    {
      "time": "00:46:18",
      "text": "真的就提到为什么聊agent就聊那么久，我就发现agent的话特别有意思。就是我们一跟么投资人或者说researcher er是有的时候大家都会invision一个非常rose非常的让人期待未来每个人以后都有一个自己的agent。但是你我我那天办那个活动的时候，我不是收集大家的question。Nair你会发现大部分的人都在问，到底什么是agent的real US。因为大家现在看到的，坦率来说很多所谓的，尤其比方说企业强生agent大家觉得好像就是一个更聪明的RPA，我觉得是不是？可能浩伟刚说就是所有现在的A型的设计，可能都还是基于现有的这个工具，现有的本来是为人设计的这个流程。所以我们看到马上能够实现这个agent的，我感觉落地都还是可能未来我们回看都是一个很中间态或者很早期的一个。",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:07",
      "text": "我觉得这件事情是有两方面，一方面就像你说的，就是今天的agent可能它基于的模型是不是够，或者说是怎么样。但另外一方面，其实更重要的是很多人在说，这个没有什么太多的industry的breakthrough，对吧？就是说已经落地的agent，或者即使copilot的今天也不是一个production，就是说人人都能用的。就我说的co pilot是微软的windows的copilot，其实也是在在试。还有前两天有人在传，这个东西不怎么work或者怎么样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:40",
      "text": "我觉得这件事情，我觉得大家看的方向是错了，为什么呢？因为你就想任何一个大的大型的软件，不说AI不AI，就是我要大规模的去更新一下，怎么都是要12个月、18个月的事情，有什么软件什么？后来两个月就完全换了一个面目的，没有，所以说没有成熟的那个。And production我一点都不意外，我觉得可能明年我们可以开始看到一点，但是这东西一旦起来了以后，我觉得还是很快的。所以说我是刚才就说五年之内，我觉得那个agent bots being first class citizen，我觉得是一个铁板钉钉看得到的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:17",
      "text": "而俊刚刚也提到了这个拉马前两周，对吧？这个拉玛这个开源，我想对于整个业界来说，影响也是非常的大。其实我延续刚才我们A准那个话题，就是说假设A准是可能他是对这个底层语言模型要求相当高的一个场景。那会不会以后绝大多数软件都是基于agent run，那是不是说谁是最强大的agent的基座的模型？那是不是就有一种赢家通吃的感觉？这个对于开源的这个模型的生态又又意味着什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:53",
      "text": "对我我觉得拉姆22肯定是一个很大的一个stone。因为拉玛二它就是在各方面benchmark上面，比如说比外面的V库纳、方K等等，这些基础模型都要更好。确实应该是现在开源的基础模型里面最好的。对，但是有一点我觉得稍微有点失望的，就是lama 2的这个coding能力不是特别强，而且他们当时训练的时候coding这一块也没有就没有加足够多的训练数据。当然我觉得这之后老马可能2.12.2他们肯定会把这个补上。",
      "speaker": "发言人5"
    },
    {
      "time": "00:49:26",
      "text": "对，但是我觉得agent的话，可能这个coding能力特别强就特别重要。因为coding其实也是一种推理的能力，你要也是一种决策能力。所以这块我觉得拉姆二作为一个聊天机器人这一块，我觉得已经是基本上可能到GPT3.5的水平。但是在推理或者coding这一块可能还是弱一些。但我觉得这一个现在这个开源的这个社区和比如说3.5，我觉得在这个差距在慢慢的减少，这是一个。",
      "speaker": "发言人5"
    },
    {
      "time": "00:49:53",
      "text": "然后第二个我觉得这次怎么说比较惊讶，如果我们看老马二这个论文，然后它里面超过一半篇幅在讲safety，再讲他们是怎么做aligned。其实我觉得这个对于企业可能特别的重要。因为企业可能就是宁可他拒绝回答一个问题，也不能说一些非常敏感的话，或者说一些非常offensive的这些话。所以我觉得拉马尔可能专门是为了这件事情就下了很多的功夫。",
      "speaker": "发言人5"
    },
    {
      "time": "00:50:19",
      "text": "甚至有些时候我觉得稍微做的有点过头了。比如说大家可以去试一下拉马2 70 billion的模型，你问他，你能说hindy就是印度语吗？然后他会说我不能说hindy你必须要尊重，世界上那么多高手，我不能只是就是对我们来说可能是一个完全无害的一个问题。但是我觉得在企业的这个应用里面，可能这个是非常的重要。",
      "speaker": "发言人5"
    },
    {
      "time": "00:50:42",
      "text": "我有两个小观点。一个是莫妮卡一开始提到是不是有你发的，就只有赢家通吃这样一个局面，我觉得最终还是要看谁好用。不管是开源还是闭源，其实很多企业用户的use case他们也会提到一点，就是他们可能一上来并不是很care这个cost，但至少说。我quality要上去，quality上去之后咱再来谈怎么去降本增效。所以回到这个开源或者闭源也是一样。如果这个开源模型不足以强大到他能够撼动闭源模型的地位的话，我觉得归根结底还是回到他能力问题是跟开源和闭源这个有关系，但是不是很大。",
      "speaker": "发言人4"
    },
    {
      "time": "00:51:20",
      "text": "对，另外一方我觉得我个人的takeaway对拉曼来说，特别是拉曼兔来说，我们会看到各大云厂商其实也是争相在集成这个拉曼特，compare to之前的第一，这一方面也是因为它确实open了这个commercial license。这个commercial license就是大厂自己不能用，但是大厂可以把这个包装了给别人用。我觉得拉曼特其实还是比较实在的。因为你看到它的paper里面，它那个training curve，其实它还没有converge。Which means它给了你这个再去自己做domain n的pre train，或者是自己的时候去做翻译成这样一些，或者像前面提到的，如果说不行，你自己可以去让他更focus在code，或者让他更focus在medical，或者更focus在某一个等面的这样一个机会。",
      "speaker": "发言人4"
    },
    {
      "time": "00:52:02",
      "text": "对，我我我再补充一些，就是我觉得拉二其实倒是反而给更多的公司mote了。因为用GPT这种闭源的模型只是靠一个API就是没有mode的。但是我觉得拉姆二的话就是这个mode可能是公司里面，比如说自己的API就刚刚讲的可能adobe photoshop那些API然后还有公司里面自己的很多数据，然后他们能够微调拉马二在他们自己的这个数据上面。然后这样的话这个模型就只能够就私有的这个模型，在他们这个公司的这个drain里面就能够做的特别好。而且可能别人别的公司想要仿效，就只是用一下GPT3.5的话，是做不到它这个效果的。所以我觉得拉二这样一个更好的一个开源基座模型，其实我觉得对于更多的这个公司的这个business上来说，我觉得可能是一个更强的一个mode。当然我不知道浩伟老师怎么看。",
      "speaker": "发言人5"
    },
    {
      "time": "00:52:51",
      "text": "我讲一讲我自己看拉马2，拉玛二刚出来前几个小时，我其实是觉得，不就是another的开源的一个model。虽然说它确实至少从表格上面看出来，数据上看出来比MPT好发展好。但是大家如果记得的话，之前的两个月感觉是今天这个比你好一点，明天那个比你好一点。但是过了其实little ally过了几个小时，甚至一两天或者说一两天，我我我就我就改变我的想法了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:22",
      "text": "我为什么改变我的想法？因为我觉得以前大家非常分散，对吧？我今天用MPT，我用FL com，没有什么人gravitate towards，就是都都朝一个系统去，但是拉马去，我觉得整个工业界jm刚才也提到了，大家公司都在想要自己做mote，做mode。你说用OpenAI很难做，但是我要有一个自己有一个模型，很少有公司自有有自己。From the very very you know beginning of the base model.",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:50",
      "text": "对吧都是大多数都是用open source的。我就发现其实整个工业界都在朝这个方向在走。因为他发他他觉得这是一个我可以商用对吧？然后以后有没的以后还会有层出不穷的你其他的，大家对他的信对对其他model的就是一个信心，我觉得不那么足。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:10",
      "text": "然后几天之内，几个礼拜之内你就会发现innovation a lot of innovation，这个是一个生态的一件事情。所以说最终我觉得我觉得会蛮成功的。我觉得他成功主要是生态，就是让这个生态有这个信心，有愿意投入投资。我觉得今天新的投入多数人都基本上或者说已经改成炒拉二了。不是。所以说我的观点并不是说拉二这个model好在哪里，而是说大家都愿意去投入在这一个model，而不是投入在20 20分之1个。因为以前看有好的model可能有20个，对吧？都都我觉得这是一个蛮蛮大的一个一件事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:49",
      "text": "另外一个拉马2，很多人说它是android的，是一个苹果的IOS。我觉得这个analogy有点对。但我仔细想了想，我觉得可能更像的还是一个PC出来跟那个大型机。我觉得大型机的它能力可能很强，但是最终PC机出来以后就鼓励了很多innovation。",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:07",
      "text": "我们就去想一件很简单的事情，linux对吧？这个操作系统今天是风靡全球的，基本上主要的服务器都是在用linux。Linux就是当年linux toronto他就在家里用一个PC就是有了这么一个PC这个PC肯定是不能跟当时候最好的机器去比。但是他就给了他一个opportunity去去去写自己的innovation，写自己的代码，然后逐渐的发展。",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:31",
      "text": "所以说我觉得OpenAI或者说这一批的大模型，基础模型，或者我们叫frontier model，它肯定有自己的市场，有有自己的business。但是就给了大家一个新的一个eco system。这个eco system我觉得是完全不能低估的。不是说从技术上来讲，那个比人家好个百分之十二十，我觉得这基本上是微不足道的。而是说这个生态我觉得是基本上是可能是正式成立了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:00",
      "text": "我老师说的太好了，因为确实是lama 2出来几天，然后on trick policy什么的，就把它转化成一个C的代码，一个C的native的一个代码。然后还有各种比如说况tizer，各种整个开源的社区开始优化，拉马图就专门为这个模型做优化。",
      "speaker": "发言人5"
    },
    {
      "time": "00:56:16",
      "text": "你前面提到coding不好，就有人专门做CQO的那个fine tuning。然后他的那个token size不够，context size不够，然后就有人。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:25",
      "text": "做什么狼拉马什么的，这些对中文版的对吧？",
      "speaker": "发言人5"
    },
    {
      "time": "00:56:29",
      "text": "而且就是短短的两个礼拜之内，就一堆的inner微信出来。我并不觉得他做的好不好，而是在于大家都在这上面出力了。一旦在这上面处理了，我觉得这是一个很难逆转的一件事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:42",
      "text": "我觉得是有一个品牌效应在，就像当时stable division出来以后，然后不仅是工业界，还有很多学术圈里面的人都在stable diffusion上面做很多新的研究。比如说著名的control net，没有stable fusion就没有control net，就没有后面很多的这一套的研究的领域。",
      "speaker": "发言人5"
    },
    {
      "time": "00:56:59",
      "text": "这么想，前段时间不是有一篇文章还挺火，也挺有争议的，就是google OpenAI是否真的有mote，对吧？我们刚才讲了mode这个事情，因为以前大家看到，可能以前所谓的小模型时代，大家会觉得这个技术好像很快大家都追评都差不多就变成打榜游戏了。如果再看的话，那大模型因为这个pre train model需要的这个，有些人就会说，我们不应该用以前open source的这个来去比，我们应该用芯片的来去比，因为它前期的这个投入足够大了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:26",
      "text": "对我觉得你pick up挺好的。我更觉得模型是芯片的knowledge，而不是说是后面的。我觉得芯片你想芯片不是说人人的，我今天想做芯片我怎么去做对吧？但是ITTA做出来一个让PC能够用的这个芯片，然后我就能在上面做很多事情了。所以说他基本上拉马做的事情，或者说是开源做的事情是一般的个人不太可能有这个财力能力去做的。他帮你做到一定程度，一旦做到那个程度就可以了。然后你刚才提到的闭源模型，或者说这个free model跟开源模，我觉得这个差距还是在那边。而且这个差距不会是在短期内缩小。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:05",
      "text": "因为刚才杰米也提到了，可能拉马2可能是3.5，这当然也可能有点争议。但即使是3.5，那跟四还是GPT4还是有蛮大差距。大概率会发生的就是google也好，OpenAI也好，也会有下一代的产品，在几个月之内都会出来。就是说从性能上面来讲，我觉得会是甩掉拉马2，还仍然是会有不少。但这个不是说不重要的，因为蓝马腿也是在往前走，对吧？你如果说只是六个月到18个月落后，但是你只要一直跟着往前走，我觉得是这这是可以的。另外一个就像我刚才说的，这个eco上给你补掉很多的落地上的漏洞也好，或者说各方面的。否则的话你光是即使是frant model，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:49",
      "text": "我们也知道google或者anthropic本人爱的model不错，但是我真的就像我前面提到的，你真的要去落地做一些B2B的software，还是有一堆的东西。你如果我们用OpenAI来看，OpenAI没有去补这些漏洞。他他的他的engineer就是只是在搞AGI对吧？他没有再去想我怎么去做一个它让大家做B2B soft人舒舒服服，这不是他的工作重点。但是你在一个lama 2这个eco city里面，人家就会发现，这个C口不行的，我来给你补C口对吧？这个语言不行，我来给你补这个语言。所以说我觉得即使是reasoning capability差个好几个月对吧？六个月、九个月、12个月以上那个生态给方方面面其他的补足，我觉得还是非常显著的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:38",
      "text": "我同意这个mode可能确实不在这个生态方面。包括比如说像2 model release之后，大家都会各种会给大家框action，给大家lora adaptations，各种插件就会有了。如果google自己的新或者是open s自己新的模型的话，这些on tizer这些插件都是只能自己做对。",
      "speaker": "发言人4"
    },
    {
      "time": "00:59:58",
      "text": "但是在方面我觉得可能这个mode还是有一些。因为这个和之前像Operating system这样，比如说linux这个东西，作为linux可能自己它如果它open source了，大家比如说这些develop可以去。去修改这个壳，然后使得它有一些bug。比如说他就直接修改完了之后，所有人都可以propagate到。如果这样做类比的话，可能没有这样一个说提升lama 2模型本身的这样一个比较share的一个这样一个community或者说的类比。就是说如果你是在上面之后，finally但是你的fine ti可能是for某一个special purpose。",
      "speaker": "发言人4"
    },
    {
      "time": "01:00:36",
      "text": "很难说大家群策群力把这个base model的能力去提升上去。这个可能需要一方面consolidate的一些computer，然后另一方面这个base model的提升可能更多的是把这个Price stage，不太像是open source community现在能够去help with的一个事情。所以可能在base model方面确实会有一些mode。",
      "speaker": "发言人4"
    },
    {
      "time": "01:00:56",
      "text": "对呃首先非常同意哈维老师，还有韩俊刚才提到这几个点，我就补充一下。我是觉得最强的闭源模型和最强的开源模型，他们的差距只会越来越大，不会越来越小。对，理由非常简单，算力就是开源模型。我觉得现在大部分人做的其实是叫scale down，而不是scale up。因为这个开源社区里面，大家这个GPU什么都很有限，所以大家更愿意的是做比如说quantization这些优化，然后让它跑得更快。甚至我还看大家就是想把lama跑在iphone上面对吧？",
      "speaker": "发言人5"
    },
    {
      "time": "01:01:29",
      "text": "像这些事情我觉得是开源的社区最喜欢做的，也是可能是唯一能够做的几个事情，或者说是微调。微调在一个就刚才浩伟老师提到可能CQL不够好，就微调在CQL上也可以做一些事儿。但是从纯的这个叫raw IQ就是最强的这智商上面，我觉得就是要靠算力堆出来，没有别的办法。对。然后这一块的话像SL pic，还有open a，他们肯定就是在算力的集中这个程度上面是开源什么等等都是肯定达不到的。并且他们研究员的这个能力，包括他们最新很多算法就是开源的。",
      "speaker": "发言人5"
    },
    {
      "time": "01:02:03",
      "text": "社区不断在publish在公开他们的秘密，欧巴不公开场语。所以这就是一个很很大的一个信息的不对称。而且就是organize就是上次entry，有一次他就提到如果市面上有一篇关于transform的论文的话，OBA可能一般情况下都这五个月前就试过了，或者半年前一年前都试过这些，然后他们只是不publish而已。",
      "speaker": "发言人5"
    },
    {
      "time": "01:02:26",
      "text": "所以我觉得这一块的话，就从这个算法，还有包括从这整个数据排盘和从算力上来说，这个闭源模型只会走的越来越快。对最强的开源模型和最强的闭源模型之间的鸿沟会越来越大。然后anodic我觉得也是属于闭源的frontier模型。然后我就s pic目前在欧基本上opi第一，s topic第二。但我觉得他们俩跑的速度，我是觉得会超过最强的开源模型跑的速度。而且我觉得现在这个市场的这个饼足够大，然后我觉得open I现在也没有办法serve所有的人，所以s pic这一块我觉得他肯定是还是有很多business可以做的对。并且OI也GPU那么有限，就是influence也需要GPU service也需要GPU。然后这块我觉得最后可能就是一个在芯片上的一个可能最后的market share就是跟你这个芯片的数量比。",
      "speaker": "发言人5"
    },
    {
      "time": "01:03:18",
      "text": "我觉得如果在开源community的话，其实在小模型身上做迭代做实验，可能会甚至会比眉笔在大厂之内做的可能会更花一点，或者至少会百花齐放一点。使得说大家在这方面积累的经验，希望说能够去最后用scaling law contribute到开源模型的那个大模型的最后的那把球。对，当然也是非常同意俊宇说的，如果就是我发现他们毕竟在暗处，然后看看都在明处，然后我来问你们好的东西，人家写过去自己用就行了。所以确实猫的还会在。",
      "speaker": "发言人4"
    },
    {
      "time": "01:03:54",
      "text": "对我几个月前跟OpenAI和anthropy c的几个星爷的人，包括客房的在吃饭，结果一顿晚饭下来，我觉得就是一个共识。这个共识就是jm刚才说的，我们能够领先那个那个开源的模型，而且这个差距会越来越大说得很开心。",
      "speaker": "发言人2"
    },
    {
      "time": "01:04:16",
      "text": "主要是因为杨德坤不在场了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:04:20",
      "text": "所以我本来是期望是一个对打的一顿晚饭，结果是开开心心。",
      "speaker": "发言人2"
    },
    {
      "time": "01:04:25",
      "text": "这点我还挺好奇，因为技术的这个你说如果人才，但是说最近大家经常我看那个dream的dream的那个推荐也替代，觉得现在大模型更像是一种炼金术一样，对吧？它上面有很多可能这个可能不足为外人道也，或者说给你就告诉你了，可能你也很难去去去复刻的。但的确我们看到人才就是说这种所谓的商业或者技术秘密的这个事情就到底能维持多久。因为他再想去在暗处人才也是流动的。那到底在这个里边，你们觉得有哪一些是真正的无法去我也许知道也无法去复制的这个核心。比如说之前GPT4.",
      "speaker": "发言人1"
    },
    {
      "time": "01:05:05",
      "text": "的这些link，大家都可能都知道他一些模型的detail可能90%都是真的，比如说什么MOE架构什么，但这些知道了又怎样，确实知道不怎么样。因为大家也都可能不理解，你也知道他大概怎么做了，你就你也知道他在用串松了，可能就稍微修改一下或者是MOE架构。然后这些可能大家都知道，确实这方面可能不太能够说去复制，但是能够复制的是一些真的是一些这方面的积累，特别是我觉得人才差距也不大，但是主要是说你要能够去通过这个，还是我刚提到在小规模上实验，或者是这种不断的创新的error中，你积累的这些调模型的这些经验，以及它的一些很多的detail trip，以及包括scaling law。怎么在小模型上调的参数，怎么在大模型上，但是这些的话其实也是需要你划算力去学到的一些知识。",
      "speaker": "发言人4"
    },
    {
      "time": "01:05:58",
      "text": "对我觉得现在顶级着才基本还是在比如说open a and stop google之间流动互相流动。所以我觉得其实最后这些trade secret其实也是在这些闭源的frontier模型的这些组里面互相流动。所以我觉得这个闭源模型和开源模型这个鸿沟还是很难bridge。对。",
      "speaker": "发言人5"
    },
    {
      "time": "01:06:17",
      "text": "就我稍微不一样一点看法，我觉得今天或者过去两年你看到的我觉得是事实。但我觉得从一个长远的看法，硅谷的历史上从来没有人才固定在这几个公司里面流动。我不觉得，我觉得人员流出来自己就包括OpenAI或者怎么样自己出来做各种各样的公司。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:38",
      "text": "然后还是会我觉得真正能够去一个mode，不是在某一个individual的人才，而是在于一个collective的人才。人这个collected人才其实更多的是文化企业的一个文化。就好像有太多的公司颠覆前一代公司，难道前一代的公司他不知道怎么做吗？其实他知道怎么做，他也知道他也有足够的人才。但是他因为他的那个商业模式或者leadership各方面的原因，他就没做下去。更多的是文化，从来没看到过，就只就就只有一个公司能做，然后另外一个公司不能做。我觉得长期来讲不存在这个问题。",
      "speaker": "发言人2"
    },
    {
      "time": "01:07:12",
      "text": "但这个大语言模型跟以前稍微不一样一点的就是刚才jm提到的算力对吧？算力是一个因为它是一个必要条件，所以说我即使我今天比你们这边所有的人聪明，我没有这个算力还是没用，对吧？这是跟以前稍微不一样一点的。但这一点我觉得再给一个长期一点。",
      "speaker": "发言人2"
    },
    {
      "time": "01:07:33",
      "text": "因为算力这件东西，任何一个技术，你就你我们技术革命经已经已经经过了好几个周期了，一百多年你会发现再怎么样的贵气贵的技术，只要是mass production，只要是大规模生产的，它肯定是成本会大幅的下降。所以说我觉得用再长远一点的观点，我觉得算力也不会是成为一个创新的一个阻碍。所以说我觉得in the near term，在今后的一年、五年、一年、三年之内，我觉得可能那个front model它的优势会持续对吧？因为人才流动也没那么快对吧？然后那个更多的是算力，但我觉得超出三年之外，我不觉得这是一个最重要的因素。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:20",
      "text": "对我觉得这个讨论其实特别的特特别好。然后那回到其实刚才jim有简单提到一个，就是你说现在很多企业开始想要用这个开源的model，对吧？圈一个他自己的模型，他有更大的flash book，更大的灵活度，可以train更动态模型。这个我想把它稍微引申一下，扩展到一个其实也很有争议的一个话题，就是是否存在所谓的domain就domain specific的这个模型。因为刚才就讲这种情况是，那我是我自己企业基于自己特殊的需要。我们现在有很多人看到说他们在chain医疗，金融等等这个领域的模型。大家怎么看这些模型？当我们基础模型越来越强的时候，这些模型它是否本身是否会有壁垒，或者说是否有存在这个必要。",
      "speaker": "发言人1"
    },
    {
      "time": "01:09:08",
      "text": "我觉得你问这个问题可能方向就不对，因为为什么呢？你是觉得好像闭源的跟那个domain in a specific的model好像是对立的。我不觉得是对的，我觉得两个都需要的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:22",
      "text": "作为一个企业来讲，其实很多很多的task不需要很强的model，不需要很强的fronted model去做这些事情。比如说做一些我们那个name，entity，recognition对吧？这种这种task其实已经，至少从我们内部来看，今天的开源模型要做我们内部的这个NER这些事情是绰绰有余，不需要好的模型，就是说基本上都是能够做的。正确率是很高。我只是举其中一个例子。",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:54",
      "text": "其实我们的那个企业里面有不同的task。我觉得有很多很多的task不需要model就可以做得很好。有些东西就像我们前面也提到了agent或者说对accurate比较高的，我觉得是需要换的，model。所以说我是觉得长期来讲，一个企业做软件，我觉得会去要不时的去借鉴，或者说用到一些front的model。但是很多时候也可以用自己做，这是一个。另外一个企业，不管是金融安全还是国防，或者说什么领域，我觉得总归是有一些数据是啊是model永远拿不到的，所以说这个时候，你必须得有一部分的事情是要自己做的事。",
      "speaker": "发言人2"
    },
    {
      "time": "01:10:37",
      "text": "比如说用一个开源的模型，然后的所以说我觉得是属于这我的一个理念是一个it's a portfolio，就是说未来的世界不是说是frant model or一个dm specific model，而是我是觉得都需要的。你就看一个PC上面，它有一个六的CPU对吧？英特尔或者MD的，但还有一堆的chips，从来没有说一个PC上面只需要一个chip就够了。所以说我觉得potentially那个front的model是那个CPU是有可能的。但是还是有大量的IO也好，或者说做做很多事情也好，还是需要还有doma specific的model。我是我觉得这是必须的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:11:15",
      "text": "对我我很同意浩伟老师说的。我就补充一点，就哪怕现在闭源这些模型的公司，其实他们也会提供这样子一个fine tuning，就对于某些enterprise的一些合作伙伴的一个服务。比如说我觉得anthrops pic可能更多的是to b而不是to c然后OpenAI也是，还有包括open I其实有一个叫OpenAI start up fund。他们自己在投一些他们感兴趣的创业公司，其实每个公司就是一个vertical。然后比如说举个例子，有家公司叫harvey，然后harvey就是open I自己投的。然后我相信他们就是有一个可能内部的一个最好的Frank model，然后专门为法律去做了一个fine tuning。Harry是一家AI就是flaw的一个公司。",
      "speaker": "发言人5"
    },
    {
      "time": "01:11:54",
      "text": "对然后这个的话我觉得可能像这种frontier模型的这些公司，他们就会比较selective。因为他们自己的serving的这个能力，可能就是也是局限于现在有多少芯片。所以他们就会挑一些这种大的这些partner。当然就是需要这个服务的公司肯定有很多很多，所以他们服务不过来。对，但是我觉得他们其实也是能提供这样的一个drain的一个能力。",
      "speaker": "发言人5"
    },
    {
      "time": "01:12:17",
      "text": "对我稍微下一下，其实刚刚主要提到非常重要的两点，一个是cost，然后这cost quality trade of，特别是在这这个特别是在enterprise的use case里面特别重要的一点，然后about money。然后第二个就是大家都提到的这个privacy issue。其实这个也不仅仅是在企业中，比如说甚至可能会maybe invisible在to c的这个场景。Maybe如果你算力或者模型或者以后允许的情况下，你可能也会把自己的过往的经验或者什么作为你的你自己用的这个language model的一个corporate。然后它也只会跳在你自己的私有的这种模型上。但是确实privacy和cost这两个可能是觉得是至少让这个fine tuning或者是自动或者customize model有存在的必要性。",
      "speaker": "发言人4"
    },
    {
      "time": "01:13:04",
      "text": "上半部分的内容就是这些，你是不是很意犹未尽？下一期我们会讨论更多AI领域的核心话题，包括多模态模型机器人的具身智能，AI对于SARS落地的影响，两位嘉宾在OpenAI的工作体验，还有那些有些理想主义，有些疯狂，有很有意思的未来畅想，更是精彩不容错过。赶紧关注Amber，不要错过更新了，我们下期见。",
      "speaker": "发言人3"
    },
    {
      "time": "01:13:33",
      "text": "感谢大家的收听。如果你喜欢我们pocus的内容，欢迎你点赞并分享给可能感兴趣的朋友。有任何建议反馈都可以在评论区留言，我们都会很认真的看的。如果你在用apple podcast收听，也希望你花几秒钟给我们打个五星好评，让更多人了解到我们我们下次再见。",
      "speaker": "发言人3"
    }
  ],
  "lab_info": {
    "summary": "本次讨论深入探讨了人工智能（AI）领域的最新进展，重点关注了闭源与开源模型的发展趋势、算力的重要性、人才流动、模型定制化以及隐私和成本问题对AI模型应用的影响。闭源模型在算力和速度上可能占优，但与领先的开源模型之间的差距正在扩大。开源模型的灵活性和适应性为AI应用提供了广阔空间，企业可能需要同时采用闭源前沿模型和领域特定模型。此外，成本和隐私问题在企业采用AI模型时显得尤为重要，定制化模型的需求日益增长。未来讨论将扩展到多模态模型、机器人具身智能、AI对特定行业的影响以及工作体验等核心话题。对话还触及了AI在游戏、软件控制、自然语言处理等领域的应用前景及面临的挑战，展示了AI技术的广阔前景和多方面角色的贡献。",
    "qa_pairs": [
      {
        "question": "大家好，今天我们请来了几位重量级嘉宾。能否先请徐老师做一个自我介绍，并分享一下最近让他觉得有趣的AI相关项目或产品？戴晗俊，能否请你做一个自我介绍，并谈谈你目前的研究方向以及最近让你感兴趣的AI项目是什么？",
        "answer": "谢谢大家。我是徐老师，我在硅谷工作生活了二十多年，主要从事云计算、AI投资和相关公司的工作。最近有趣的AI项目是MetaBob，它利用AI来发现bug，通过prompting和vector database等技术进行创新应用。大家好，我是戴晗俊，在Google DeepMind工作，研究方向主要是生成模型算法及其优化采样方法，包括但不限于语言模型、图像生成模型等。最近引人注意的项目是关于如何对大语言模型进行更高效采样的一系列工作，例如Google Research和DeepMind同时发表的“speculative decoding”，通过利用小模型快速解码后由大模型判断是否接受解码结果，从而实现模型解码速度提升两倍以上。",
        "time": "00:02:50"
      },
      {
        "question": "梦凡，作为英伟达高级AI研究科学家，能否请你分享一下你的背景以及对AI agent的看法？",
        "answer": "我叫梦凡，曾在OpenAI实习并在斯坦福读博士，现在是英伟达的高级AI研究科学家。我对AI agent特别感兴趣，因为它能自主做决策并不断学习和提高。我关注的agent应用有三个方面：软件应用、游戏中的AI以及未来物理世界中的通用机器人技术。",
        "time": "00:08:53"
      },
      {
        "question": "AI agent在软件、游戏和机器人领域的应用有哪些特点？",
        "answer": "在软件应用中，agent可通过编写代码和利用API工具串联完成复杂任务；而在游戏领域，多模态大模型至关重要，它们能感知虚拟或现实世界，并在开放式游戏中自主探索和学习；对于机器人领域，agent将引领通用机器人在未来3到5年或10年内进入家庭和工厂等环境。",
        "time": "00:10:53"
      },
      {
        "question": "AI agent的核心构成要素是什么？从技术和产品角度出发，应具备哪些特点？",
        "answer": "AI agent的核心能力取决于其在虚拟世界或物理世界的应用类型。对于控制软件的agent，主要是通过编程和API调用实现任务；而对于游戏和机器人agent，多模态大模型是关键，不仅处理文本，还需要计算机视觉等多维度信息。总的来说，不论是哪种类型的agent，都需要结合具体应用场景来构建其核心能力。",
        "time": "00:12:41"
      },
      {
        "question": "在训练大语言模型时，机器人领域遇到的主要挑战是什么？",
        "answer": "对于机器人领域来说，训练时遇到的主要挑战在于控制类的数据无法从互联网直接获取，需要通过模拟器或物理实体进行数据采集。目前主流的数据采集方式有两种：一种是通过模拟器（如物理模拟器或游戏模拟器），另一种是购买大量机器人进行操控或自主探索以收集真实世界数据。这两种方式各有优劣，但都比训练大语言模型面临的问题更为困难。",
        "time": "00:15:09"
      },
      {
        "question": "是否有尝试将语言模型或基础模型作为环境来模拟世界并让agent与之交互？",
        "answer": "是的，已经有人开始研究将基础模型如GPT或foundation model作为事件模型，使其能够模拟未来并预测行动后果，从而生成人工数据来训练更好的智能体。然而，由于大语言模型可能存在污染和幻觉问题，其构建的世界模型可能存在不准确性，这也会带来一定的困难。",
        "time": "00:16:15"
      },
      {
        "question": "在企业场景中，对于agent相关的尝试有哪些挑战，以及与当前落地之间的差距是什么？",
        "answer": "目前从落地角度看，agent的应用还存在较大差距。尽管大家普遍看好使用大型语言模型将任务分解为良好步骤并调用API完成工作的方向，但实际上要实现这一目标目前还无法做到。例如，在客服应用场景中，除了回答问题外，还需要进行记录更新等复杂操作，这在当前阶段还不成熟。但随着技术发展，预计未来几年内，基于agent的客服系统可能会更加成熟。",
        "time": "00:16:54"
      },
      {
        "question": "agent在实际应用中面临哪些具体挑战？",
        "answer": "具体挑战包括：1) GPT模型自身调用模型的迭代过程中可能需要大量步骤，这在某些应用场景中会导致延迟问题；2) 评估过程复杂，尤其是中间步骤的反馈和评价，比如让agent订机票的过程中，每一步都需要及时有效的评估；3) 如何安全地处理不可逆的错误和边缘案例，以及如何对agent行为进行有效监管。",
        "time": "00:18:38"
      },
      {
        "question": "在安全性、可靠性和AI落地方面，为什么游戏领域可能是目前最适合的应用场景？",
        "answer": "游戏领域对AI的落地较为友好，因为即使AI出错或产生不合适的内容，在游戏环境中往往被当作特色而非bug。此外，目前AI技术尚不完全成熟，而在游戏中的应用场景允许一定程度的创新尝试，且即使出现错误也不会造成严重后果。随着技术进步，如GPT-5和GPT-6的出现，有望解决现有模型的部分局限性，例如更准确地使用API、支持多模态输入等，这将进一步推动AI在游戏和其他领域的广泛应用。",
        "time": "00:21:03"
      },
      {
        "question": "在大模型中，agent的应用是否意味着我们需要额外的底层模型来实现期望的准确度落地？",
        "answer": "这并不意味着必须采用不同的底层模型。agent的问题在于它涉及到多个步骤的执行，但大模型自身存在无法避免的内在机制。解决这个问题的关键在于确定模型是否知道答案，并在对应情况下给出相应回答，例如通过instruction tuning的方式。",
        "time": "00:27:47"
      },
      {
        "question": "是否可以通过更好的自我训练来降低模型在特定任务上的不确定性（如编程）？",
        "answer": "确实如此，通过强化学习和自我训练，模型可以在遇到错误时进行debugging并不断改进。例如GPT4已经展现出了较强的自我调试能力，可以查看自己写的代码并根据编译器错误信息进行修正。随着GPT5等后续版本的发展，编程能力有望进一步提升。",
        "time": "00:31:03"
      },
      {
        "question": "对于像编程这样要求高精准度的任务，能否有信心实现接近人类工程师编写的代码水平？",
        "answer": "非常有信心实现这一目标，因为GPT4等模型已经展示了强大的自我改进能力，未来随着模型版本的升级和更多高质量数据的积累，写代码的能力将会显著增强。",
        "time": "00:31:03"
      },
      {
        "question": "何时编程人员能通过类似Copilot的功能精准地写出整个文件或大规模代码？",
        "answer": "这需要解决长文本理解与生成问题，目前受限于模型的上下文长度限制。不过，随着更多高质量交互数据的产生，例如通过与Copilot的互动修bug过程，未来几年内有望看到突破，实现编写长代码的能力。",
        "time": "00:33:31"
      },
      {
        "question": "对于agent最终实现形态的看法，特别是与屏幕交互的方式？如果一个基于AI的agent能直接与用户交互并操控屏幕，这对现有APP生态和企业软件有何影响？",
        "answer": "相较于直接控制鼠标和键盘的方式，更看好从语言模型出发，通过生成代码来模拟鼠标点击等操作，这种方式更为灵活且具有更好的扩展性。同时，多模态信息的利用，如将网页渲染为易于理解的配置文件，也是未来发展方向。这种可能性是必然发生的，未来用户可能不再需要通过具体的APP操作，而是通过AI agent完成各种任务，这将彻底改变软件交互方式，甚至可能重塑企业级软件和服务的提供模式。",
        "time": "00:36:56"
      },
      {
        "question": "你认为Copilot在未来企业软件公司中的地位将会如何变化？",
        "answer": "我认为Copilot在未来五年内将成为大多数企业软件公司的主要产品，取代当前需要人工完成的工作流程。比如在Office 365中，未来用户将更多地与Copilot打交道，它会帮助处理很多工作内容，程序员写的代码最终也将是与机器、语言模型进行交互。",
        "time": "00:41:12"
      },
      {
        "question": "对于软件开发者来说，面对Copilot这类工具是否会打击积极性，以及软件如何获利的问题怎么看？",
        "answer": "虽然软件开发者与Copilot等工具打交道，但并不意味着会减少他们与用户的直接接触，而是改变了互动方式。大公司由于控制着生态系统和API，如微软在Windows Copilot上的优势，使得第三方公司在某种程度上受限。不过，像Adobe这样的公司拥有特定API，能够针对专业软件进行微调，这样的模型可能只有这些拥有软件公司自己才能做，并且会成为一个重要的盈利点。",
        "time": "00:44:18"
      },
      {
        "question": "如果agent只能接触到API层面的调用，会带来哪些问题？",
        "answer": "如果agent只能调用API，那么它难以适应复杂多变的需求，例如在获取信息时可能无法灵活地选择最合适的API。此外，反馈循环对于agent学习和改进至关重要，没有足够的反馈，agent可能无法准确知道何时调用哪个API。",
        "time": "00:45:49"
      },
      {
        "question": "目前对agent落地应用的看法是怎样的？",
        "answer": "当前agent的设计大多基于现有工具和流程，很多被认为是智能RPA。但实际上，成功的agent应该具备更强的通用性和适应性，而且像拉马2这样的开源模型在性能上已接近闭源模型，尤其是在推理能力上。开源模型为更多公司提供了定制化的机会，使得各个公司在特定领域进行微调，形成独特的竞争力。",
        "time": "00:48:17"
      },
      {
        "question": "在大模型时代，开源模型和闭源模型之间的差距是否会缩小？开源模型在面对大模型时，是否有机会通过社区的力量来弥补差距？",
        "answer": "我认为开源模型和闭源模型之间的差距不仅不会缩小，反而会越来越大。主要原因在于算力方面的差异，闭源模型背后的公司如OpenAI、Google等在算力投入上具有优势，能够进行更多的创新和优化，而开源社区受限于GPU等资源，更多关注于模型的微调、加速等方面。此外，闭源模型公司拥有专有的研究团队和最新算法，这些积累的信息不对称会进一步加大两者之间的差距。开源模型确实可以通过社区的力量在某些方面进行迭代和实验，积累经验，希望最终能对大模型的发展有所贡献。但大模型因其强大的算力支持和顶尖人才的不断投入，其领先优势可能会持续很长一段时间。不过，随着技术发展和市场扩大，未来可能会出现多个公司在不同细分领域利用开源模型实现商业成功的情况。",
        "time": "01:00:56"
      },
      {
        "question": "开源模型是否有可能在某些特定领域或任务上超越闭源模型？开源模型公司在面对企业客户需求时，是否能够提供针对特定领域的模型优化服务？",
        "answer": "是的，对于一些特定任务，例如企业内部的特定需求（如NER等），开源模型已经足够满足需求，无需依赖前沿模型。而针对某些敏感数据或严格隐私要求的应用场景，企业可能更倾向于使用定制化的domain-specific模型。因此，未来世界可能需要结合使用前沿模型和特定领域模型，形成一个多元化模型组合策略。开源模型公司通常会提供fine-tuning服务，针对企业特定领域的数据进行模型优化，以满足企业内部的需求。同时，这些公司可能也会投资于创业公司，将前沿模型应用于垂直领域，并为大型企业提供定制化的解决方案。虽然他们服务覆盖不了所有需求，但确实能够为部分企业提供专业的fine-tuning服务。",
        "time": "01:08:20"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "软件如何改变世界：AI领域的深入探讨",
        "summary": "Monica和高宁一起探讨了软件，特别是AI技术如何对世界产生影响。他们首先谈到了与两位AI领域的顶尖研究员的对话，这两位研究员都在AI领域拥有深厚的研究和实践经验，特别是在生成式智能代理方面。讨论覆盖了从技术到应用的新进展，以及面临的挑战。此外，还涉及了开源与闭源大语言模型的竞争，展示了AI技术发展的多个维度。接下来的讨论将关注于AI领域的其他核心话题，如多模态大模型、机器人的实际应用、AI对SaaS的影响以及大语言模型的演进历史等。此次对话不仅体现了科技发展的美妙，还体现了深度参与AI研究的必要性。"
      },
      {
        "time": "00:02:39",
        "title": "AI技术革新与应用展望",
        "summary": "讨论集中在AI技术，特别是生成模型、云计算和安全领域的创新与应用。一位发言者分享了在硅谷20年的工作经历，包括参与云计算和AI创业项目，以及AI在程序开发中的应用。另一位则专注于生成模型研究，提及了与Google Cloud合作的产品发布，以及高效采样算法在提升大型语言模型应用性能的潜力。"
      },
      {
        "time": "00:08:02",
        "title": "探讨人工智能（AI）的发展与应用",
        "summary": "在斯坦福大学博士期间，一位学者分享了其对人工智能（AI）特别是AI代理（智能体）的研究兴趣，这些智能体能够自主做出决策并从决策中学习提升。他讨论了AI在软件应用、游戏设计及机器人技术三个领域的未来应用潜力，强调了智能体技术在实现更开放、互动式游戏体验和通用机器人技术进步中的重要性。此外，还提到了对多智能体交互的研究兴趣，这表明了对AI技术复杂性和应用范围深入探索的关注。"
      },
      {
        "time": "00:11:29",
        "title": "探讨AI智能体的发展与挑战",
        "summary": "AI智能体，特别是多智能体系统，展示了巨大的潜力和发展前景。通过引入具有不同人格和背景故事的GPT驱动的AI智能体，创建了一个能够模拟社会互动和日常活动的虚拟小镇，展现了AI在模拟复杂社会交互方面的可能性。此外，讨论了agent在技术和产品角度的核心构成，强调了大语言模型（LM）在实现智能体核心能力中的关键作用，以及在物理世界应用中面临的挑战，如机器人控制数据的采集困难。虚拟世界与物理世界中的智能体虽然有相似之处，但物理世界的应用需要克服更多技术障碍，如通过模拟器或实际机器人群来采集训练数据，这凸显了通用机器人开发中的挑战。"
      },
      {
        "time": "00:15:38",
        "title": "探讨语言模型在Agent和Environment设置中的应用及挑战",
        "summary": "讨论集中在如何将语言模型或基础模型作为环境（Environment）设置，以促进代理（Agent）与环境之间的交互。通过这种方式，基础模型可以作为一种事件模型，预测行动可能带来的后果，从而生成人工数据并训练更智能的代理。然而，当前的大语言模型存在产生幻觉等问题，导致世界模型的准确性受到质疑。尽管如此，参与者仍看好代理方向的发展，认为尽管目前与实际应用存在差距，但通过时间的成熟和技术的进步，未来代理在特定场景（如客服）中的应用是完全可能的。此外，讨论也触及了在企业场景下，代理相关的尝试和面临的挑战，强调了成熟度和实际应用之间的落差。"
      },
      {
        "time": "00:18:38",
        "title": "探讨Auto GPT的挑战与应用",
        "summary": "Auto GPT的能力让模型可以自调用，引发对迭代次数和延迟问题的讨论。特别在客服等应用中，延迟成为一个大问题。此外，讨论了agent在执行任务（如订机票）时的评价挑战，强调了强化学习中中间步骤评价的重要性。还提到了安全和可靠性在企业、机器人或无人驾驶等应用中的重要性，指出目前AI技术在这些方面的成熟度还不够，而在游戏中，AI的不完美反而成为了一种特色。"
      },
      {
        "time": "00:21:46",
        "title": "探讨生成式AI在游戏领域的应用与发展",
        "summary": "近年来，生成式AI，尤其是像Jasper这样的模型，因其创造性的输出而在游戏开发中展现出巨大潜力。这类AI在游戏中的应用不仅仅局限于提供情感陪伴或模拟角色对话，更在于创造全新的游戏体验，如通过AI生成的对话实现游戏情节的多样化。尽管目前大多数游戏尚未利用这些技术进行全面革新，但已有原型游戏展示了基于AI的第一人称游戏体验，例如一个名为病娇女友的游戏，展示了通过聊天机器人技术实现的复杂游戏互动。此外，讨论还触及了生成式AI在实现更长记忆长度和更复杂的决策机制上面临的挑战，以及对未来AI原生游戏模式的期待。尽管目前市场上对于这些新技术的实际应用仍处于初期阶段，但已有一些进展和创新项目正在探索这些领域，展现出对未来游戏模式发展的乐观前景。"
      },
      {
        "time": "00:25:18",
        "title": "探讨GPT模型升级对解决问题能力的影响",
        "summary": "讨论集中在当前GPT模型，特别是GPT-4，虽然表现出色，但在准确性、API使用、多模态处理等方面仍有局限。期待未来版本如GPT-5和GPT-6能显著提升这些能力，解决现有问题，如精准使用API、增强多模态功能，以及通过自我修正提升代码编写准确率。同时，探讨了通过改进自我训练和错误识别来降低模型的幻觉问题，强调了模型在知识更新、安全回答方面的挑战及解决策略。"
      },
      {
        "time": "00:30:13",
        "title": "探讨人工智能在编程中的应用与挑战",
        "summary": "对话中讨论了使用强化学习和知识学习解决编程问题的两种方法，以及人工智能在编程精度上的挑战。讨论者对AI技术，特别是GPT-4在编程领域的应用表示出了极大的信心，认为AI可以通过自我调试来改进代码，其能力已经非常强大，并预计未来版本如GPT-5将进一步增强这种能力。此外，通过模拟人类工程师的编程过程，AI在代码编写方面的表现预计将更加出色。"
      },
      {
        "time": "00:32:00",
        "title": "探讨编程模型的未来及挑战",
        "summary": "对话中讨论了编程人员在编写代码时的能力限制，以及未来技术，特别是AI模型如GPT4在编程领域的应用和挑战。指出了目前的编程模型在处理长代码、理解复杂代码库方面存在不足，但对未来技术的发展持乐观态度。特别强调了数据质量和模型理解上下文长度的能力对于提升编程模型性能的重要性，同时提到了通过各种方法如retrieval-based技术来克服现有挑战的可能性。"
      },
      {
        "time": "00:35:56",
        "title": "探讨Agent实现方式及其优劣",
        "summary": "对话中讨论了Agent技术的不同实现方式，包括直接控制屏幕与通过编写代码扩展API的方法。一种方法是通过观察屏幕像素来控制鼠标和键盘，但此方法受限于强化学习在2016年时的局限性，导致泛化能力差，且对屏幕分辨率有较高要求。另一种更被看好的方法是利用语言模型，通过生成代码来控制浏览器，此方法被认为在鲁棒性和可靠性方面更优。讨论还触及了多模态应用的潜力和鼠标控制可能的益处，以及通过视觉和系统间的互动提升体验。最后，提到了GPT模型在理解图像内容和生成相关HTML代码方面的应用示例。"
      },
      {
        "time": "00:39:26",
        "title": "大语言模型对未来软件生态的影响",
        "summary": "讨论集中在大语言模型（LLM）如何变革软件开发和应用的交互方式，特别是通过实现智能代理（agent）来提高生产力。展望未来，软件开发将更多地依赖于这些模型，改变人类与软件的交互方式，使得用户无需直接与众多应用程序交互，而是通过智能代理完成任务。这可能会重塑应用程序的生态系统，减少用户对单一应用的依赖，并促使企业软件公司围绕这些智能代理开发新产品。同时，讨论也指出，尽管大公司因控制整个生态系统和API而具有明显优势，但对于软件开发商来说，如何在这一变革中保持其软件的相关性和盈利性仍是一个挑战。"
      },
      {
        "time": "00:47:07",
        "title": "探讨AI模型的发展和行业影响",
        "summary": "对话中讨论了AI模型在行业中的应用和发展，特别是开源模型对行业突破的意义。一方面，对于当前AI代理的实用性表示怀疑，认为成熟的AI产品需要时间发展。另一方面，拉玛2（lama 2）的开源可能对软件开发产生重大影响，强调了coding能力的重要性，并讨论了模型在安全性和领域特定适应性上的努力。同时，探讨了开源与闭源模型的竞争，以及企业如何基于开源模型进行定制化开发以获得竞争优势。"
      },
      {
        "time": "00:52:51",
        "title": "拉马2模型对行业生态影响的深度分析",
        "summary": "对话中讨论了拉马2模型刚发布时的初步印象以及随后对其潜在影响力的重新评估。开始时，讲者认为拉马2只是又一个开源模型，但很快意识到它可能对整个行业生态产生重大影响。拉马2的发布激发了工业界对自建模型的兴趣，标志着一个重要的转折点，因为它鼓励了更多的创新和投资。讲者还将拉马2比作PC与大型机的关系，强调了其对推动技术进步和创新生态建立的重要性。此外，提到了开源社区对拉马2模型的积极反馈和优化工作，进一步证明了其在技术和商业上的潜力。最后，讨论了开源与闭源模型之间的差异，以及拉马2如何为个人和公司提供了探索和开发新模型的机会。"
      },
      {
        "time": "00:58:04",
        "title": "大模型生态及未来技术发展探讨",
        "summary": "讨论集中在拉马2模型相较于GPT4的性能差距及其在生态方面的发展潜力。虽然拉马2可能在性能上暂时落后，但通过不断的技术迭代和生态系统的完善，有望缩小与领先模型的差距。特别强调了生态系统的价值，在补足技术漏洞、提供定制化解决方案方面具有重要作用。同时，指出了开源社区在提升基础模型能力方面的潜力和挑战。"
      },
      {
        "time": "01:00:56",
        "title": "开源与闭源模型的未来发展与挑战",
        "summary": "讨论集中于开源与闭源AI模型的差异及未来发展趋势。一方面，闭源模型由于拥有更多的算力资源和先进的算法研究，预计将与开源模型之间的差距不断扩大。另一方面，开源社区受限于硬件资源，更倾向于进行模型优化和轻量化处理，如quantization和尝试将模型运行在iPhone上。尽管闭源模型在短期内可能保持优势，但长期看，随着算力成本的降低和人才的流动，开源模型有潜力缩小与闭源模型之间的差距。此外，讨论也指出，AI领域的创新并非仅局限于少数大公司，文化、集体智慧和商业模式的创新也极为重要。"
      },
      {
        "time": "01:08:20",
        "title": "开源模型与领域特定模型的融合应用",
        "summary": "讨论重点在于企业如何利用开源模型和领域特定模型来满足自身需求。一方面，开源模型提供了广泛适用性和灵活性，能够处理许多基础任务，如命名实体识别等；另一方面，领域特定模型则针对特定行业（如医疗、金融）的需求进行精细化调优，提高任务处理的准确性和效率。讨论指出，企业应采取一种融合策略，利用开源模型的基础能力和领域特定模型的定制化优势，同时考虑到成本、隐私和数据安全等因素，以达到最优的性能与效率。此外，还提到了一些企业通过为特定垂直领域提供定制化模型服务，以及如何在保护隐私和控制成本的前提下，有效利用AI技术进行创新和优化。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [
                    {
                      "children": [],
                      "content": "需要强大的基础模型支持"
                    },
                    {
                      "children": [],
                      "content": "对话中提到的技术模型：GPT-4、AutoGPT、AGPT等"
                    },
                    {
                      "children": [],
                      "content": "存在的挑战：模型准确性、幻觉问题、API调用准确性等"
                    }
                  ],
                  "content": "定义与挑战"
                },
                {
                  "children": [
                    {
                      "children": [],
                      "content": "游戏开发"
                    },
                    {
                      "children": [],
                      "content": "企业应用：客服系统、自动化流程等"
                    },
                    {
                      "children": [],
                      "content": "个人助手：提高生产力，简化任务处理"
                    }
                  ],
                  "content": "应用场景"
                }
              ],
              "content": "Agent技术"
            },
            {
              "children": [
                {
                  "children": [
                    {
                      "children": [],
                      "content": "GPT系列、LLaMA等"
                    },
                    {
                      "children": [],
                      "content": "开源与闭源模型的竞争"
                    },
                    {
                      "children": [],
                      "content": "性能提升：生成能力、多模态支持"
                    }
                  ],
                  "content": "技术进展"
                },
                {
                  "children": [
                    {
                      "children": [],
                      "content": "编程辅助：代码生成、错误修正"
                    },
                    {
                      "children": [],
                      "content": "个性化内容生成"
                    },
                    {
                      "children": [],
                      "content": "企业内部应用：特定领域定制模型"
                    }
                  ],
                  "content": "应用领域"
                }
              ],
              "content": "大语言模型（LLM）"
            }
          ],
          "content": "AI技术与应用"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "大模型的训练成本与资源需求"
                },
                {
                  "children": [],
                  "content": "模型泛化能力与适应性"
                },
                {
                  "children": [],
                  "content": "隐私保护与数据安全"
                }
              ],
              "content": "面临的技术挑战"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "多模态模型的兴起"
                },
                {
                  "children": [],
                  "content": "AI在游戏、娱乐等领域的应用扩展"
                },
                {
                  "children": [],
                  "content": "自动驾驶、机器人技术的进步"
                }
              ],
              "content": "未来技术趋势"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "工作自动化：替代低技能工作，创造高技能需求"
                },
                {
                  "children": [],
                  "content": "教育与培训：AI工具辅助学习与职业发展"
                },
                {
                  "children": [],
                  "content": "法律与伦理问题：数据使用、偏见问题、版权等"
                }
              ],
              "content": "AI的社会影响"
            }
          ],
          "content": "未来展望与挑战"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "社区贡献与改进"
                },
                {
                  "children": [],
                  "content": "开源模型的应用与定制"
                },
                {
                  "children": [],
                  "content": "技术与文化的传播"
                }
              ],
              "content": "开源模型的生态建设"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "企业级服务与支持"
                },
                {
                  "children": [],
                  "content": "定制化需求满足"
                },
                {
                  "children": [],
                  "content": "高级技术支持与优化"
                }
              ],
              "content": "闭源模型的商业化"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "互补性：开源模型提供基础，闭源模型提供高级功能"
                },
                {
                  "children": [],
                  "content": "人才与知识的流动"
                },
                {
                  "children": [],
                  "content": "商业模式的差异与共存"
                }
              ],
              "content": "开源与闭源模型的共生关系"
            }
          ],
          "content": "开源与闭源模型的生态"
        }
      ],
      "content": "对话脑图摘要"
    }
  }
}