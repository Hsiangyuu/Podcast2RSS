{
  "pid": "61cbaac48bb4cd867fcabe22",
  "eid": "646673036752b5f9de7e0beb",
  "title": "EP 32. 【生成式AI专题4】对话微软大模型专家：GPT 能否带领我们通向AGI（通用人工智能）？",
  "task_id": "ro84nrarg3mxqkb3",
  "transcription": [
    {
      "time": "00:00:03",
      "text": "欢迎来到onboard，真实的一线经验，走心的投资思考。我是Monica.",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:09",
      "text": "我是高宁，我们一起聊聊软件如何改变世界。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:16",
      "text": "大家好，我是Monica。今天又是一期关于AI的硬核讨论。对于AI能力的评估和理解一直是这个领域最核心的话题之一，至今都没有标准的答案。而大模型加上hug GPT auto GPT等一系列生成式代理，也就是general intelligence之后，能给各个行业甚至整个社会带来怎样的改变？我们这一期的嘉宾应该算是相当有发言权的这是omber与科技早知道又一期合作节目。我与大家都非常喜欢的硅谷徐老师请来了前段时间刷屏的微软150多页的论文，通用人工智能的火花Sparkle s of AGI的作者之一张译博士，聊聊他们对于GPT4模型的系统深入测试的一些深入发现。我们还邀请到了哈根GPT的作者之一谭旭博士，还有国内AI独角兽的研发总监洪博士，与这些一线的研究者从业者一起聊聊我们离通用人工智能AGI还有多远。相信你听完这一期可以对人工智能有不一样的认识。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:24",
      "text": "长达3个小时的谈话，即使知道短一些的版本也许更容易传播，但是Monica还是想让大家能听到更多原汁原味的讨论，所以还是尽量保留了不少的内容，相信这些干货值得你的时间enjoy。大家好，欢迎大家收听omber与科技早知道合作的这一期节目。我是主持人Monica。我原来在亚马逊云计算负责AI产品北美市场的商业化，现在是真格基金的投资人，也是翁布尔博客的主理人。今天我跟硅谷徐老师邀请到几位人工智能领域最一线的研究者从业者，一起聊聊这段时间AI领域最新的进展，深入探讨技术和商业应用的现状、挑战与未来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:11",
      "text": "我是谭旭，来自微软亚洲研究院。我的主要研究方向是关于语言模型和生成式的人工智能。主要面向的是啊多模态的一些方向的生成，比如说像语音哪音乐，以及像最近关注的虚拟人的生成。以及也最近也在看啊基于大语言模型为基础，然后通过调动各个专家模型来完成更复杂的人工智能的任务。把它作为一种通往AGI的一种路径，这方面的研究。",
      "speaker": "发言人3"
    },
    {
      "time": "00:02:53",
      "text": "我最近关注的一些话题或者是研究项目，主要还是在多模态的AIGC的方向上面。比如说在音频或者音乐语音方向。比如说谷歌在半年前推出的像audio ARM或者music ARM，其实是一些非常受关注的研究项目。就是能够以端到端的方式，大模型的方式，通过大量的数据能够生成非常好的音频或者音乐。",
      "speaker": "发言人3"
    },
    {
      "time": "00:03:32",
      "text": "我是张毅，现在是在微软研究院的总部，总部在西家屯后我现在是c senior research。然后我两年前从普林斯顿毕业，导师是3G8 roa，我以前一直以来的方向是做关于用数学或者是理论基础来解释深度学习中的一些现象或者问题。然后以然后用这些研究的结果来推动深度学习，来开发新的模型。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:06",
      "text": "好，可以分享一个你关注的这个项目和公司。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:10",
      "text": "对，我们要自己把AGI给做出来。我们组现在这个名字很有点奇怪，就是英文叫做physical of AGI，通用人工智能的物理。但是这个物理并不代表说我们是要特征的物理，而是说把它当做一个自然存在。我们现在有大模型，它有显露出来AGI的一些特质，然后我们要把它当做一个自然现象，我们来先制定实验，然后搭建理论框架，寻找其中的规律。我们最后能够真正的迈向人工智能，通用人工智能。然后我们组这个组成也比较的奇怪，就是我们组大部分的人的背景都是做这个理论，计算机，甚至纯数学，包括我自己。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:52",
      "text": "那个红博士。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:56",
      "text": "大家好，我先介绍一下我自己之前研究领域是计算机视觉和数据压缩。其实过去第一波深度学习这么多年，计算机视觉可以认为是发展最快，投入的人和钱最多的一个领域了。现在我的研究兴趣转向了AGI通用人工智能。当你把这个AGI做出来，它其实你的计算机视觉，语言的理解等等很多任务都可以用一种新的方法来解决。",
      "speaker": "发言人4"
    },
    {
      "time": "00:05:38",
      "text": "说一个fun fact，我最近看到的，也是看到有一段时间就deep mind的goto它的原文，paper的原文叫a general agent。我认为这是一个非常富有野心的项目。它真正的用到了多模态的输入和输出，并且通过控制信号把数字世界和物理世界建立了连接。",
      "speaker": "发言人4"
    },
    {
      "time": "00:06:07",
      "text": "今天很高兴能够跟这么多博士一起探讨AI我个人是之前一直做云计算，做操作系统的。然后过去八年开始做AI做人工智能方面的初创公司也好，然后最近几年是在在在硅谷的公司做高管，主管AI的项目。我分享一个最近我看到比较好玩的一个项目，可能也就是最近一两个礼拜刚刚宣布的，或者说看到的。就是在ChatGPT上面也有一个plugging，这个plugging叫code interpreter，就是翻译器可以把它其实它翻译什么呢？就是你可以把一个任任何一个CSV的文件，就是一个表格把它送进去。然后你可以问他有些什么样的特，这个表格里面有些什么值得你注意到的一些insights洞见。这点其实让我蛮震惊的。因为我觉得有了这些东西以后，其实我是觉得很多的那些初级的数据分析师，就应该担心一下他们的工作。并不是说他们应该担心自己的工作没有，而是说应该去学一些更加深或者更加不一样的东西，比如说跟一些domain knowledge去结合或者怎么样。所以说这是我想分享的一个比较有趣的一个一个一个项目。",
      "speaker": "发言人5"
    },
    {
      "time": "00:07:48",
      "text": "AGI就是通用人工智能，是我们今天特别想要去聊的一个话题。而关于这个话题，最近在业界有一篇非常有影响力的论文。就是张译所在的微软的这个研究院，发表了一篇150多页的一个询问。Sparks of artificial general intelligence, 就是AGI通用人工智能的火花，其实是对GPT4的能力做了非常深入的一个研究。我想对于很多还没有来得及深入去读这篇文章的同学或者张译，可以给我们简单的介绍一下这个研究的背景是怎样的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:26",
      "text": "首先这样我可以给大家介绍一下这个研究背景，就是微软在和和OpenAI在这个GPT4的合作大概是在去年的大概8月和9月。那个时候微软内部就大概有可能少数人100到200个人参加这个绝密的项目。我们首先拿到了这个GPT4，然后那个模型那个版本的模型就是比现在的这个public外面大家现在都可以拿得到的那个GPT4还要更强强非常多。然后我们的paper是基于那一个模型，就有很多可能大家看读paper，然后觉得这个例子有用或者好玩，然后自己去试过之后发现没有然后他现在这个模型它没有，它显示不出来这个例子这个功能的话，对这个其实是非常正常的一件事情。对，我也不知道这个模型到底这个内部这个模型到底什么时候能够让大家见到，但是我觉得这是非常值得期待的。因为这个模型比现在外部的这个GP4要强非常多。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:27",
      "text": "就是现在的外面我们看得到的GPT4是弱一点。这个弱一点的原因是因为跟我们人类有了更多的realign nant.",
      "speaker": "发言人5"
    },
    {
      "time": "00:09:38",
      "text": "因为我们也不知道全部的细节。然后我们猜测是因为他最后因为为了让把把它放到产业链里公之于众，加入了很多关于安全性的fine tune微调。就是让他比如说要去掉它一些对人类有害的行为，让他变得更平易近人。然后更上面我觉得是这些微淘是必须的。但是从一个科学的角度来讲，它确实也让这个模型它在这个推理能力，很多各方面能力指标都下降了不少。对我觉得现在一个可能将来一个比较重要的研究就是说我们怎么样能更好的align这个model，但是又不让他损失一些其他方面我们又想保留的能力。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:26",
      "text": "就是加了这些align这些安全的东西，它的推理能力反而下降了？就是怎么理解这个现象？",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:34",
      "text": "对，因为其实并不矛盾对吧？因为首先它这个安全性上面的考量，它跟推理本身是一个可能比较不太相干的一个能力，然后我们把一个能力变强，一般来说对于这些大模型他的其他能力都会变弱，特别是像这种玩相关性不是很强的两个能力？你加上其中一个，另外一个一般来说都会变弱。对，就这也是学术界现在比较关注的一个，到底要怎么样能够微调它，然后又不让他其他能力变差。对，但现在还没有很好解决办法OK回到这个配备本身，我们我们组大部分都是数学家。然后大家可能之前也看过GPT3，当时我们自己没有对这个觉得这个模型特别厉害。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:24",
      "text": "大家觉得这个模型它这个GPT4看起来更fancy，但是它到底能不能代表是智能？就是智能它它可以完成很多任务，但是他有可能只是说在网上他见过这个任务怎么完成，对吧？他学过他就记住了。那现在你现在在问他这些问题的时候，他可能就是背诵出来。所以我们觉得这个并不一定是智能。所以我们当时就在想怎么样能够说服我们自己，这个东西它到底有没有智能，到底是不是一个更好的model。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:54",
      "text": "我们就想了一些task，一些任务，主要是通过一些简单的数学题。然后一开就发现我们因为我们之前研究GPT3，我们其实存了很多很多那种非常刁钻的问题，就是在GPT3一定GP3打不出来的。我们把这些问题在gbt 4上基本上都试了一遍。然后令人震惊的是GBT4基本上完美的解决了我们以前觉得人工智能不太可能能解决的那些问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:20",
      "text": "其实也不难，就是一些很简单的，比如说高中层面的那个组合数学题。比如说你有红一个红色的石头，两个蓝色的石头，然后三个绿色的石头，然后你一共有多少组合这样之类的问题。但GPT3他就没办法他没办法知道。比如说这两个蓝色的石头当你抓取出来的时候，它其实是同一个石头，对吧？它都是蓝色，它都是石头，就很难让GPT他理解这个事情。但GPT是它有这个common sense，它有这个常识。这个事情我们都不需要做太多的prompt的的调整。GPT4好像他直接就把这个题目做对了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:53",
      "text": "然后类似的例子有非常多，我们内部其实也有分歧，一部分人会觉得这个可能也是他在网上见过，另外一部分人就觉得这个网上一定没有。所以我们后来就想了越来越多网上一定不会存在的很奇怪的问题，但是它是可以解决的，只要这个模型能够推理的很好。对然后后来发现这个模型基本上把这些都解决了。所以我们最后就所有人都同意这个东西它确实很厉害，它确实可以称得上它是有智能的。然后它到底是不是AGI呢？到底是不是通用人工智能的，这个值得商榷。因为其实现在学术界对ACI这个词也有一点过敏。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:36",
      "text": "我觉得这个词一般来说不太能提。但是如果我们抠这个字眼，这个artificial general intelligence，那GP4它确实它是artificial，然后他general，然后我们是发现非常的general，就是我们拿到的GPT4版本，它是一个文字版。后来OpenAI说的那个report technical report说他们的GPT4是可以处理这个图片输入的，但是我们拿到的那个只是纯文字版。那我们发现这个纯文字版的GPT4它竟然能够看见。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:08",
      "text": "他看见是指比如说你让他去画一个东西，他可以很他并不一定画的很完美，但是他能给你画出来。特别是如果你要求他在某些地方加上某些细节。比如说一个很有名的例子就是我们让他画了一个uni on独角兽，这小朋友很喜欢，然后他画出来了。首先是很震惊对吧？他从来没有见过独角兽，他可能读到过独角兽，它可能读到过类似的画独角兽代码OK，他现在把它画出来了，但是我们还不满意，他有可能就是备注了这个代码，对不对？我们就又改了一下，我们把那个独角兽代码里这个画头的和画脚的那部分给他去了，然后我让他把头上那个角给他加回去，这个就是考验这个模型他到底知不知道他画的是什么，他到底是不是叫独角兽。它有一个角，而且这个角要长在头上他才叫独角兽，不然的话他只是马，结果发现模型是完全知道他在干什么的，他不仅把这个东西画出来了，他是完全知道我们每一行代码，每一个地方画的是什么东西。对，然后你为什么。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:12",
      "text": "说他在网上没有看到过独角？",
      "speaker": "发言人5"
    },
    {
      "time": "00:15:16",
      "text": "因为他的训练应该是不包含图片的这即使说有文章，只是说把字给扒下来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:22",
      "text": "然后成为他的。因为你们的那一个文章是你们的那个模型是纯文字的对。",
      "speaker": "发言人5"
    },
    {
      "time": "00:15:30",
      "text": "完全没有图片的。但是它对图片的相对位置的感知，然后一堆一些常见物体，它的形状它可以把握。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:38",
      "text": "的非常精确。OpenAI在GPT4那篇论文里边其实提到他们让GPT4去解读一些图片，就这一类的测试，你们在你们那个版本PPT four上有测试过吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:51",
      "text": "对，有，但是形式一定是不一样的。因为我们这个模型它本身它你没办法把一张图输入给他。我们能做的就是说可能我们可以给他一段代码，这个代码能够大概画出这个图的样子，然后让他去读这个代码，一定承认他是可以做这件事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:11",
      "text": "甚至还有网上不是有很多那种叫SK的那个art，就是用那个字符，用什么星昊，等号画一个图，那个东西他也能读。你可以用那个东西摆一个数字出来。问他这是几，他知道这是几对。虽然准确率没那么高，但是他绝对是statistical significant，他确实是知道的，他可能会猜错，但是他并不是说对这个。这个几何关系图片的视觉的concept，对这些东西都是有理解的对这个令我非常震惊。所以这回到AGI的定义对吧？它是人工的，然后它是general的，它能处理图片，能处理文字，甚至还能谱曲，能写代码，然后他能读懂人的心理，他他基本上是无所不能。那当然是general，那他还有没有intelligence呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:01",
      "text": "然后这就回到了什么叫intelligence。这个东西我觉得是很模糊的，这个历史上也没有什么很好的定义。特别是有一点我们在社会里有啊有谈到，就是说可能人类到了现在这个时候才真正有意义来讨论到底什么是intelligence。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:19",
      "text": "之前这个intellect可能在这个哲学家，特别是之前有研究人人工智能的哲学流派，他们会讨论这个事情。但是他们从来都没有想象过这个人工智能到底会以一种什么样的形式出现。所以他们的那个时候对智能的定义，可能现在并不太切合这个大模型本身。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:39",
      "text": "我们现在是真真切切的能够有一个模型，我每天可以跟他互动，然后这个模型它已经展示出了很多跟人非常相似的一种高级的推理能力。这个时候我们才需要好好想一想，我们该如何定义intelligent这个事情。对我们的在配置里我们的做了一个proposal。就是说我们觉得这个东西它可能已经是叫展现了很多AGI的特质。就是他可能不完美，但是他好像是在告诉我们，沿这条路走下去，我们终于能够看到终点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:14",
      "text": "就可能大部分人，包括我自己两年前看到GPT3的时候，我还觉得我这辈子可能都不太能看得到人AGI。然后可能在50年内都不太能看得到GPT4。现在今天的GPT4，但是谁知道呢？对吧？两年内就发生了，而且这只是一个开始，这个只会这个发展速度只会越来越快，这里我先插一句，我刚才里面加入了很多暴论，这个代表我自己的观点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:42",
      "text": "也就是你在网上看到的最常见的就是不一样的这种观点。或者说可能你觉得是一些误解的点在哪？你觉得通常可能是基于什么样的原因呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:54",
      "text": "比如说大家可能很多读者没有花太多的精力读读这个论文本身的时候，他可能觉得我们说的就是他们每天能看得到的GPT4。但其实这是两个很不一样的模型，然后在各种指标上面他们也很不一样。具体的说就是我自己是负责这个模型的写代码能力的评测的。我们当时评测的结果是非常的激震惊，就是在v code上它它是远高于人类的平均水平。然后我觉得这个水平是绝对可以轻松通过大厂的各种面试。如果我们把这个GPT接到电话这一端，让他写代码。对，然后好像这个公开版本的GPT4，它在这个写代码的能力上就下降了非常多。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:40",
      "text": "然后很多推特上的这个博主，他们自己就测试了他们可爱的一些data，然后就测试发现之前的题目都能做的对，但新题就做不对。就说明这个模型只是说他over fit到他原来这个训练集，他并没有说他真的理解怎么写的。他遇到身体他是不会的，不会举一反三。对，这一点我们我们测我们那个模型的时候，包括其实配合你所有的例子，我们都对这个模型到底之前有没有见过类似的数据，这一点非常的敏感。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:10",
      "text": "具体到这个写代码的评测，我们是抓取了e code上面最近的100道题。因为妮寇的他发布题是一个一个每周的叫竞赛，每周发布3到4道题作为他本周的竞赛，然后就把它送到那题库里。所以每一道题你都可以追溯到他哪天发布到网上的。然后当时我们对大部分的题都在网上用beam search h google search给搜了一遍。以我们最大的能力都没有找到类似的听力，所以我们是非常自信。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:44",
      "text": "我们用的这个测试集，它是在网上是不存在。对，这个更更广义的他就关系到我们到底怎么评价这个，到底怎么测评你太的这件这个事情。因为之前的deep link大家都有，这个叫mark有测试集。这个模型好不好？我在这测试集上跑一遍，然后分高就是好，对吧？但这个模型它实在他实在训练数据太大了，他把整个网上所有数据都看遍了，那你再去找网上已经存在的数据集，不是，那基本上就不太可能能真实反映他的能力，所以这也是一个非常大的chAllenge。大家可能也没有意识到这个chAllen，比如说OpenAI他们的paper，他们他跟那个report大部分做的事情就是在已有的这个benchmark上跑了一遍，分很高。但是他们也没有claim说这个东西它的引擎非常的强，因为他有可能就是技术的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:34",
      "text": "然后我们，基本上每一个方向我们测的都是自己手动设计测试的例子。尽量保证在我们已知的范围内，这个测试的例子一定不会在网上被他看到的。对我我。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:49",
      "text": "也可以接着张毅刚刚讲的Sparks of AGI，也谈谈我的一些感受。他对于视觉空间的一些理解。比如它的方位，它的这个形状，即使在这个模型没有见过任何的视觉数据的情况下，他还能够做到比较好的推理。这个对我的震撼是非常大的对我我我的感觉一个猜测就是可能现在因为GPT4它的训练数据已经不再是我们比如在GPT123里边理解的是那种单纯的文字的数据。那现在可能他应该是把互联网上只要以书面的形式能展示出来的数据形式应该都包括进去。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:34",
      "text": "比如说，代码，这个是很很基础的，然后包括它在图像里面展示的这种，我理解应该是the text或者text这种代码的格式。那它应该是在网上也见过大量的这样的数据。可能对于空间位置或者对于这种形状的理解。也许他对于这些比较text的可视化代码和他的一些文本的注释之间应该会有一些关联。所以他对于通过文字和代码建立一些连接。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:03",
      "text": "因为文字本身描述了空间的一些形状的一些几何的理解，所以形成了它来直接通过文字的指令，然后可以生成这个代码来去做这个事情。并且你还可以对它去进行交互。比如你说这个形状有问题，或者你要改一个形状，它可以通过代码和形状的联动，能够去生成正确的指令，去改它相应的形状。对，那因为另外一个点对于音乐的生成，因为我我自己本身也会做就是呃AIGC音乐的生成相关。所以看到这个功能以后，我我我第一反应是非常震惊。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:38",
      "text": "当然现在GP4的音乐生成肯定比不上我们自己的音乐生成的专业模型。所以它在很多方面，可能比如无论是从质量或者diverse，或者是从从这种创造性，然后这个丰富性来讲，都会差一些。但是也依然让我们很吃惊，因为GP4从来没有可能过他们专门要做一个音乐的模型。他只是把互联网上所有的能见到的数据都拿进来训练。然后他就可以能做到和文本比较交互式的音乐的生成或者改进。也就是说可以理解现在GP4它是一个非常全面和通用的，也就是一个超级的大百科全书。但即使他现在在专业的领域里边，可能比各个专家模型，在在很多领域里边都会要差。但可能它的往后的潜力应该是非常大的对这是我我我能感受到GPT4和Spark和AGI这个paper带给我的一些感受。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:31",
      "text": "对你刚才说的那个图片，我们后来发现就是它其实网上是有很多图片的格式，那个图格式叫svg。Svg其实就是把那个图片里的那个点和线用代码的形式写出来。所以很明显open应该是把这个图片，只要是SVG的都加到他的训练语料里去了。所以图片是可以这个模型是可以读得到这个图的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:56",
      "text": "然后另外一点是关于这个音乐，然后我们其实发现我们在配备里只是说秀了这个case。我们自己是不太觉得他那个音乐写得非常好的，就是人不太能听。但是它至少它能生成。所以我觉得这个专家模型比GPT4在这个方面还是要强很多的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:15",
      "text": "所以说回到你前面说的那一个独角兽那个例子，实际上他有可能以前见过独角兽和svg这样的一个形式格式的那个训练数据。能不能这么理解解？",
      "speaker": "发言人5"
    },
    {
      "time": "00:25:32",
      "text": "对他有可能是见过。这是为什么我们后面就是说我们这个测试不只是说让他画一个独角兽出来，对，而是说我们要测试他知不知道他画的这个头，然后独角兽就是头上也有一个角。比如说我问他，我这个拼码是有一匹马换码的代码，你在哪加一行呢？把它变成独角兽对吧？然后他就能做对了，他知道我要加一个角在头上。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:58",
      "text": "是的，我看到这个论文里面对，这个论文里面就提到，就是说不只是画出来。画出来以后我说把这个东西往往左边挪一挪，往右边去挪一挪。他他对这个图其实是有理解的。这个不是。",
      "speaker": "发言人5"
    },
    {
      "time": "00:26:14",
      "text": "这个其实事实上是对人的。比如说这个面试对吧？比如说你作为面试官一开始问一个问题，这个面试者他有可能很很完美的打出来了，但他有可能是背的答案，对吧？所以这个面试需要一个交互的过程。你把这个原题改一改，你问他在这个情况下会怎么样，那个情况下会怎么样，对吧？出一些刁钻的这个例子，然后你就很快就能反映的出来这个面试者到底有没有水平。还是说他在英国学者对我们基本上就对GPT做了这么一件事情，然后发现结果是非常。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:46",
      "text": "令人满意的，但我写那篇文章的主要意义，其实还不是说是GPT，是或者说chat BT有有多好，那当然很好，对吧？我的一个很重要的一个观点是因为我觉得人类其实本身是有很多问题的。我们自我们有很多时候自作聪明，或者说自以为是了很多。因为我们人类可能是很聪明，能够解决很多问题。但是实际上在我们的日常生活当中，对人对事、在工作中，在生活中，其实并没有一个能力去充分发挥我们的一个智商。我是从这个角度去分析，我是觉得因为GPT four它没有太多的感情因素，在做应用题也好，在做任何社交的题目也好，那在因为基于这个原因，我是觉得他已经超过了一个average的人类，或者说是一个平均数字。",
      "speaker": "发言人5"
    },
    {
      "time": "00:27:41",
      "text": "因为我觉得一个人类的平均数是蛮低的，这个平均数蛮低的原因并不是说是我们人类聪明不聪明，人类是肯定是很聪明的。但是人类在遇在在具体的事情上面，具体的生活工作当中，做很多傻事。我觉得这个apple to apple去比较，对吧？你不能说是人类都很聪明的，但是遇到事情不做明智的决定，然后就不去算他，但是一个计算机所能够计算机这个API所能做到的是一个consistency，对吧？一致性就说我今天的跟昨天的，不管是那个股市跌了不跌了，我会给你同样的答案，从这个角度上来讲，我是觉得已经是比人类要厉害了。当然这是从另外一个角度了，我是蛮同意张毅说的，其实你要从从AGI的一个严格的定义来讲，这是一个非常非常难去去去论证的一件事情。",
      "speaker": "发言人5"
    },
    {
      "time": "00:28:44",
      "text": "对我觉得徐老师这个说的特别好。我我们我们自己可能也是同意就是说我们把这个东西称作为一个基本上在人类已知所有领域都能达到一个高中生水平，而且可能还是高中毕业的那个成绩比较优秀的学生的水平，这件事情本身就值得。这个模型被称为AGI，就是人类有数学家。对，然后这个模型他叫AGI但是他做数学他可能不一定有数学家那么强对吧？然后他写代码不一定有人类最强的写代码的那么强，然后他下象棋不一定有这个grandmaster那么强。但是它在人类所有已知领域都是一个高至少是高中生水平。这件事情是一件非常可怕的事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:27",
      "text": "然后张毅刚才其实提到说这一版你们实验的这一版GPT4，其实并没有加入这个多模态的这些训练的数据。他跟我不知道你们内部有没有讨论过？他跟这个ChatGPT可能3或者3.5能够有这么大的一个差异。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:45",
      "text": "对就首先这个模型的细节，包括它的训练的细节，我们是不太知道，只能做猜测。通过跟和open I的人来交流，当然有些绝密的信息，他们也没办法跟我们透露那些他们能说的。就比如说他们觉得用这个RL来alive这个事情非常重要，而不只是说online为了safety的line，而是说有很多东西他在那个推理层面你也可以用它来。比如说你可以写代码的时候用这个对吧？你可以给他人工给到feedback，就是说这个算法题他做对了，他写的这个代码他no work了，对吧？你给他一个reward，然后这个模型可以这么来训练。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:27",
      "text": "他们做了很多关于RI方面的尝试，然后他们告诉我们这方面的尝试就是直接决定了GPT4和3.5之间的差距，当然最直接差距就是GPT4。虽然不知道它参数到底有多少，但是它肯定是比GPT3.5要大好几个数量级的。因为其实GPT3.5它本身不是很大。GP3.5好像这个应该是公开信息了，因为他有那个mixture of the expert，它可能就可能少于100个并列，100个并列对吧？然后一般来说大模型它对GPT3.5应该是比GP3还要小的，GPT4它肯定是比GPT3还要大。至少1到2个数量级。那之后就是可能到一一个training或者到10个training这个区间之内，我们的猜测是这样，但这只限于猜测。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:25",
      "text": "你其实还有我看到这个论文下面，其实大家也提到很经常会提到有一些limitation，就是一些限制。你们看到这限制怎么样？而且包括像house station，就是这种幻觉这些限制。我觉得大家讨论一个点，可能不只是说我现他现在有没有，更多是说我要去解决它，是不是这个要是一个模型层面的一个改动，还是说我们在工厂基于现在的这个架构，我慢慢是可以去通过一些改进或工程上的一些改良去去解决的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:57",
      "text": "我们是比较关注他推理能力上的。然后有一点这个模型很明显的不足就是在于它没有办法做规划。就比如说他没有办法先试错，比如说他一在一开始他要进行一个任务的时候，他一开始不知道怎么办。但是作为人类，我们可以比如说先往前走几步试试看，对吧？不行，我们再退回来。但这个模型它只要把这个字写下去了，它就存在于这个模型它的input你了，对吧？它是没有一个橡皮擦把它擦掉的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:28",
      "text": "然后特别是在他的网上训练的时候，比如说我让这个模型来接来来证明一个数学定理。一般其实顶级数学家来解决一个数学定理的时候，也很少会有一次就能把它证出来，对吧？我们一般会是好几种方法，有些方法大部分人最后肯定都不会能成功，最后OK找到终于找到了一种成功的，然后写了一篇论文。在论文里他只会说我试到这个方法他成功了，他不会提我之前试了100种方法，这一百种都是什么，而是在哪个地方失败。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:01",
      "text": "所以导致这个模型它很容易就是说你当要你问他有数学问题的时候，他先把答案给你吐出来，他连任何步骤都没有。他先把答案告诉你，后面再假装写很多很多步骤。一般来说这个答案如果他一开始吐出来一定是错的，99%都是错的。但是他后面能假装写很多像模像样的步骤来justify说这个答案肯定就是对的。就是很明显他没有他并不是说真的说把是像人类做数学题一样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:31",
      "text": "一步一步的走你觉得这个试错的过程能不能从一个调用GPT API的方式来做的。比如说我去调用的时候，我给不同的prompt对吧？我我我的prompt让他去按照不同的途径可能去做，就等于说试错这一部分是放在调用GPT API之外去做这么一件事情，使得最终一个solution，最终这个解决方案是仍然能够达到这么一个效果的。你觉得这个靠谱吗？",
      "speaker": "发言人5"
    },
    {
      "time": "00:34:04",
      "text": "对，这个是靠谱的。这个是之前陶哲轩他说的，他他说他是陶哲轩这个等级数学家，他说他已经能够用ChatGPT来在他的这个日常的数学研究工作中为他提供灵感。然后对我自己也有亲身经历一些例子，就是说我们当时是想测这个GPT是它的数学能力，然后当时就想直接一步登天，我们测那个IMO。你知道IMO就是那个国际数学竞赛是最难的。但是我让GPT c来写来解这个题，他一定是解不对的。但是他一开始给的那个思路，我发现是非常有用的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:42",
      "text": "就在这个情况下，我自己本身是没有经过IMO训练，它能够帮助我。比如说把去年的题解出来一道到两道，我让他先解，然后我顺着他的思路往下想，然后当我发现他在某一个地方犯了错了之后，OK我就把他的后面那部分去了。我自己在想如果这个地方不犯错，我接下来该怎么做。这样我沿着他的一开始的这个答案往下，我自己写，我发现我能把它做出来。但如果没有GPT4来帮我，我自己肯定是没有办法从头开始把这道题做出来。甚至一开始我连什么工具要用什么定理，这是属于哪个方面的题目我都不知道。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:21",
      "text": "但是GPT4能够很好的给我这个信息。这可能是比如说GP4和人一起进行试错对的一个例子。对我觉得这个是非常有希望。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:31",
      "text": "如果用new bing的话，就是微软说这个bin的话，因为它跟ChatGPT很不一样的一点是，它会给你原来这个来源的这个link，就是那个网页的link是不是说所以这样的话其实是不是可以理解为它在一定程度上，通过加上这个来源的网页链接的这种方式，其实一定程度上去解决了幻觉的这个问题。但其实大家能感受出来，我自己的感觉是，其实newbie的这个推理各方面能力其实比比这个GPT f或者ChatGPT其实还是差挺多的。我好奇这个是不是也是刚才所说的一种取舍？",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:14",
      "text": "对，其实对我们组其实在写这个Sparks of AGI这个paper的期间，最主要的工作就是我们写了一半的那个ubin的meta pro就是那个网上后来被UB上线24小时之后，就在推特上被人给破解了的拔出来。对对对，就被拔出来了。然后我还没想到24小时都没撑到。对，然后你可以看到里面做了一件事情，就是说GPT4它只是决定什么时候要去扩这个search engine的API。然后人类是帮他去扩，真正去扩，然后把这个搜索结果返回给他。对我发现这个确实对他的hello tion这个问题有很大的帮助，但是他还是没有办法完全解决这件事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:59",
      "text": "我们自己有一个很有很很有意思的例子，就好像是问某一个东欧小国最大的人，十座城市以人口，网上你可以找到那个网页，那个网页上面确实有十大城市，十个城市都有，但是限制于这个病的。它的搜索API，我们返回的返回给GPT4的结果，只有五个城市，只有前五。GPT4看到前五他觉得OK够了，然后他就把前五复读了一遍。前五都是对的，没问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:30",
      "text": "但从第六个开始他就自己想象了，但是想象的差的也不多，就是说可能五位数字后面三位两位差差了一点，但是我们觉得这也是hello，就是特别在这种一半一半的情况下，这个问题它有一半的事实，剩下一半的事实，它好像有点模糊的记忆，其实跟人一模一样，人说话可能也就是90%的非常确定的事实，然后再加10%的假话吧？啊，这个问题我们到最后都没有解决的很好。我们觉得这个可能是要以后在这个数据或者在模型训练的层面能解决，而不是说只是说meta prom层面能解决的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:09",
      "text": "关于和人类对比这个hesitation，其实我我我的一个感觉，因为像人其实也一样。因为人比如说我们可以说人认为学习或者认知知识是有几个阶段。我们通常在说就是有有那四个经典的阶段，就是不知道自己不知道。然后第二个阶段就是知道自己不知道，后来要知道自己知道，到最后可能不知道自己知道，那已经顿悟了。其实可能现在GPT第四估计还是处于最早的那个阶段，就是我不知道自己不知道，所以他就自己的天马行空的自己去凭空生成，或者在decoding去去去逐步解码。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:52",
      "text": "那有什么样的机制让他能够知道自己不知道呢？可能就是比如刚刚莫妮卡提的这个就是B如果我有一些grounding的东西，如果我我的任何的知识是只从grounding的这个材料里面来。那如果对我自己产生东西，如果我没有把握，我是不会去说的那可能是一个很很好的机制。但是目前模型它其实对于自己预测错的东西是非常有信心的。就有点像说一本正经的胡说八道。他往往比如说预测错错的东西，他可能那个token的概率也是非常高。所以从单纯模型自身的角度是很难让他知道哪个东西是错的，所以还是可能要进入到人的学习过程。比如说小孩子他可能什么东西都不懂，或者他懂的时候他其实不知道自己，或者不懂，那还是要需要更多的反馈。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:46",
      "text": "我们现在可能GPT4的训练，我觉得可能大部分是一个课本知识，少部分是比如说instructing或者feedback。但你像人类的学习，其实对于课本知识来讲，应该只占到一部分人。更多的学习要在比如在家庭里边，在学校里边，在社会里面去跟其他人互动，通过互动学到很多很多反馈，这样才能逐渐的让自己不知道自己不知道到知道自己不知道这样的过程。可能这个就会涉及到我们新的一些模型训练机制，比如说巨星的人工智能等等等等的方向来去解这样的问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:25",
      "text": "我就这里面一部分是让模型去提高，让模型去意识到或者怎么样，这是有可能的。但另外一部分实际上是就像我前面提到的，整个解决方案去提高。吧？",
      "speaker": "发言人5"
    },
    {
      "time": "00:40:41",
      "text": "因为你拿从gbt拿过来的东西，你可以再去就像那个兵一样，可以去摄取一把，或者说看看网上有没有人这么说，比如说人类其实也经常还如此那群，比如说微信里面经常会有人说，什么事情发生了，某某人过世了，这种事情传摇什么的，这每天都有。那我看到了以后，我就去搜索一把看，这个网上面那么安静，从来没有一个人提到的。十有八九我就是在哈罗斯内训或者说是那个造谣对吧？但是一搜哇塞全网都在说某某人发生了什么事情，某某人过世了。一看我了解了这是一个蛮大的新闻，对吧？所以说我是觉得一个是靠模型本身去提高，另外一个是靠整个解决方案去提高。两个两条路都要走。",
      "speaker": "发言人5"
    },
    {
      "time": "00:41:33",
      "text": "各种各样其他的诈骗，其实也是一种从外界获取信息的手段。然后其实它会更本质的一个解决方案，还是要从模型下手。我举个例子，就比如说从GPT3GPT3.5到GPT4，其实他的这种幻觉的现象是降非常多的。如果我们去做对比的话，那这里面可能有有不同的因素，我觉得第一个可能是模型基本能力其实强了很多的，就是他在普称的阶段能力已经变得很强。然后在ROHF或者最近应该慢慢成熟的技术，还有IOAIF，就让AI能够自己帮助自己来做levent，这些手段其实都是有提升空间的那除此以外其实还有一个技术，就是在我们现在IL的这个训练过程中，实际上这个方法它是还是有比较大的问题的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:42:49",
      "text": "我举个例子，比如说我们现在去回顾IOHF的这个过程的话，他第一步是要基于人工标注的数据来做supervised fine tune对吧？然后第二步的话我们会去训一个reward model，来比较两个答案哪个好哪个坏。然后在第三步再用这个report model去做强化学习的训练。但是我们就看到这里面当模型输出一个人类认为不够完美的答案的时候，我们的反馈只是一个reward。这个reward其实并没有那么准确，或者说没有那么精确。我们只是惩罚一下这个模型，但是并没有告诉他到底我哪错了哪。对，就是在方法上可能还是有非常多可以挖掘的地方。我觉得这也是对于研究的团队最重要的事情，就是从基础模型上来去解决幻觉的问题。",
      "speaker": "发言人4"
    },
    {
      "time": "00:43:57",
      "text": "我非常同意这一点。然后我觉得还有一个跟这个非相关的一个研究领域，到现在就是说可能我听说很多人在做，但是我现在还没有见到任何的结果，可能很快就会大家都会见到。就是怎么检测这个模型它处于一种什么状态。比如说拿不到GP是它内部的一些运算的。比如说它每一层的输入输出我们是拿不到，但假设我们能够拿到，我们先在小模型上做这件事情。如果他是在hello sate的时候，我能不能通过他一些内部运算的结果来我独立的train一个classifier，就classic可以告诉我这个模型现在很有可能在胡说。或者是他在输出一些，比如说他之前记住了关于版那个版权的内容，比如说一些书的章节的时候，这个开始能告诉我这个模型现在很有可能在Violet的copyright，对吧？然后这个我现在还没有看到太多的结果，但是我觉得是非常有意思和很重要的一个领域。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:59",
      "text": "我就刚才我们提到了这个一些限制，我不知道还有哪一些。大家觉得要是最终实现我们所期望这个AGI也好，或者更强的智能也好，大家觉得还有哪些限制？",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:10",
      "text": "比如我们前面其实说了很多AGI或者现在GPT是很好的一面。但可能我们也要再从另外一个角度去看看，比如现在GP4它的一些方法论，然后通向它现在的智能是一个什么样的途径。其实我们都知道像思考快与慢这样的书，它其实因为我看看spx AGI里面也提到经常提到这个概念。可能现在这些模型更多还是做一个数据的频率统计，然后做一个pattern的映射，可能更多像是一个去思考跨语言里面的，比如系统一的方式去解决问题。也就是它中间没有非常强的或者完整的推理过程。当然现在有些机制，比如chain of salt，类似的这种prompting的机制，让他强制去做这种慢思考，然后一个链条，然后把中间的步骤都拿出来。但我觉得本质上现在的模型还是在为数据对是否未来有一个更好的能够实现推理的或者计划，或者是认知的一些逻辑上面的一些技术方法，这个不是特别清楚。这个也可能也是需要我们在思考的，是否GPT4这种暴力的语言模型是通往AGI的最好的途径。",
      "speaker": "发言人3"
    },
    {
      "time": "00:46:28",
      "text": "这个模型他现在犯了很多的错误，都是因为他思考太快。他第一句他第一个词就把答案给吐出来，他都不想过程，那一定是错的对吧？人都做不到这一点。所以对他经常如果你强制让它慢下来，他就会好很多。但是就是问题说这个训练数据它就长长成这个样子。比如说大家在网上看到那些大家讨论对吧？这个文章一定是先把结论告诉你，这样别人才有才才想往下读。除非我们能改大规模的修改这个数据结构，但是我们不知道怎么做。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:00",
      "text": "然后我自己觉得还有一个limitation是我们一定要解决的，就是真正的多模态，就是说不只是说他能够读图，就是O因为open I的版本他们claim他们那个是GPT4已经能够读图了。但是我是觉得读图这个事情是要从他的预训练就开始的。因为我我的想法是这样，比如说思考一个小孩子，就小孩子他通过视觉收集到的信息，其实他这个成长过程中最重要的信息。比如说可能有些盲人的小孩，他要经过这个特殊的训练，他才能赶得上正常小孩的智力发育水平。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:39",
      "text": "然后具体一点，就比如说像我们解数学题的时候，如果旁边有一个图，它不一定要是几何体甚至代数题。有时候你画图，然后给你一个更直观的感觉，也会帮助你解题，就是写代码？做这个代码的面试，你最好也是拿一张纸边边做边边画。所以我觉得最好是要把这个全网的图都用起来，特别是现在GPT4、GPT3.5都已经把全网的所有的文字信息都已经用完了的情况下。就比如说如果我们要建GPT5，我不知道他们在不在建就下一代模型。这个模型当然是要变更大，但是模型变得更大的更多的数据从哪来？",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:23",
      "text": "最大人类最大的数据库就是youtube上面所有的视频，而且很多视频的质量非常之高。特别是那些教比如说教大家怎么写代码的，教基础数学的，然后还有就是关于人生思考。但是视频数据它太贵了。它就是比如ETB你可能都存不了几部电影。但是一TB你基本上好像全网的文字数据也就是在这个十几TB100不到100TB这个数据这个量级上点。所以就怎么样用好这个人类非常高质量的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:58",
      "text": "这个视频视觉信息，然后能够让他帮助这个模型更好的推理。这个事情我们必须得解决。然后现在好像还看不到很明显的能够解决他的办法。",
      "speaker": "发言人2"
    },
    {
      "time": "00:49:15",
      "text": "其实张毅亓前面你提到有一点我觉得挺有意思的。你说之所以这个模型会思考这么快，是因为你给他喂的这个数据，我们是自己人类产生很多数据的结构，导致我好奇你觉得这个是一个数据结构的问题，还是说我要实现刚才谭旭所说的，我要能够让他会慢思考，他其实是要从这个模型结构就要做一个改变的。然后你后面说到我要给他从头preachin开始，就feed这种多模态数据，那这个是一个纯粹数据结构上的变化，还是说它对于模型结构也是需要一个比较根本性的一个改变。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:54",
      "text": "关于第一点，我觉得可能是要模型层面。当然我觉得就是它的这个根在于数据，但是数据我们是没有办法强行的大规模的修改。我们不可能说把全网所有的数据都把它变成慢思考，对吧？这个不现实。所以我们可以在模型上面给它加一些限制，让他更倾向于学到一个慢思考的结果。但具体怎么做我也不知道了，对吧？这就是我们现在在每天讨论的一些事情，但是确实很有难度。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:27",
      "text": "这个可以从强化学习的rewarding里面做得到吗？就是让他们思考。",
      "speaker": "发言人5"
    },
    {
      "time": "00:50:38",
      "text": "我认为这个应该让模型自己学到。马斯克他应该自己能figure out。比如说刚才提到的数据，互联网上可能有很多数据，提完问题马上给出答案，最后再给解释。他自己应该能认识到。",
      "speaker": "发言人4"
    },
    {
      "time": "00:50:54",
      "text": "数据。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:54",
      "text": "就是这种结构的，但并不意味着他就要按照这种结构直接吐出来。如果他直接这样吐出来，说明他还没有真正的理解这个数据产生的过程，他还不够吃。所以这里应该还是从模型上下功夫，是比较本质对个人的一点看法。所以说张毅。",
      "speaker": "发言人4"
    },
    {
      "time": "00:51:17",
      "text": "你是猜想他们那个图，那个GPT four那个认识图，只是做了一个fine tuning。你觉得没有放到free training里面去？",
      "speaker": "发言人5"
    },
    {
      "time": "00:51:29",
      "text": "对，这只是猜想了。因为根据成本的来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:35",
      "text": "这个应该是挺确定的。就是GP four的训练pretend是成本的，然后图像是后面。",
      "speaker": "发言人4"
    },
    {
      "time": "00:51:44",
      "text": "加进去的。所以说他是一个称它是一个multing model的一个模型，是一个是是是有问号。",
      "speaker": "发言人5"
    },
    {
      "time": "00:51:57",
      "text": "的对对，他的这个并不是很本质，而且同样的做法在学术界基本上同一时间就是CMU的那个rush他们组，基本上他们在一个开源的OPT模型上做了同样的事情。他们就是做了你可以翻译TM，把图加上去，所以这个其实不是很难，对，这个东西并不是很难，所以我并不觉得这是GPT4的一个亮点。对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:25",
      "text": "这里我可以解释一下，就是它不只是说把图像拿来放tune，这里面我们说它没有在回春的阶段，加入图像是说文本，也就是说这个base model它的creature还是长的吻的对吧？但是图像的特征表示它有自己的一个预训练的过程，他还是有预训练的，应该是把图像图像文本pair来预训练出来一个图像表征。然后文本就用GPT做一个GPT的Price，然后两个都说完了，再把各自再把图像的表征给粘到这个GPT的model里面来，就应该是这样一个过程。",
      "speaker": "发言人4"
    },
    {
      "time": "00:53:11",
      "text": "你说表征就是embedding，就是把那个图像的embedding放到表征。",
      "speaker": "发言人5"
    },
    {
      "time": "00:53:16",
      "text": "就是你把一张图像变成对，您说的对，变成一个embedding。但是这个embedding要跟文本的embedding能够match，这样我们才能理解用文本来表达这个图像，来描述这个图像。",
      "speaker": "发言人4"
    },
    {
      "time": "00:53:30",
      "text": "还行。",
      "speaker": "发言人5"
    },
    {
      "time": "00:53:32",
      "text": "我之前跟秦博士也聊过这个话题。就是我好奇现在业界有没有人尝试说在free train的阶段，就直接去给他为这些多模态的这些数据。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:45",
      "text": "其实是有的。然后我记得open I在对，open I在做完GPT two以后，马上就做了image GPT，其实那就是一种尝试。但是他当时没有把图像和文本一起做，而是图像单独去做一个pretrail。后来在deep man的工作里面goto去做了一个多模态的输入。但是他那个目标还不是说去做这种我们想要的这种文本跟图像再进行做配置。它更多的是把各种各样的模态的数据拿进来，看我能不能来统一起来来去，更多是一种实验性的。对还没有那么成熟。像刚才张毅张毅想看到的这种，我觉得学术界还没有figure out一种高效的并且有效的方法。",
      "speaker": "发言人4"
    },
    {
      "time": "00:54:47",
      "text": "所以就说你现我们现在这种只是在分tuning阶段去加入这种多模态的方式，其实很难达到1加1大于二的效果，或是大的不明显。对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:58",
      "text": "那看起来是这样。了解就这里可能还是一个我们怎么去定义智能这件事。对，就是你看我们去说这个大语言模型的时候，实际上它是有一些智能在的对吧？但是像GPT four这种方式把图像加进去，它似乎并不是说加了图像就加了智能，而是说智能不变。他把这个单元模型装上了一双眼睛，让他除了看懂文本也能看懂图像，但是他脑子的智商是不变的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:55:36",
      "text": "具体来说的话，其实开源领域有一个论文，就是deep man的flaming go。他已经做了一些图文输入的demo。然后技术我猜测跟GPT four应该是有很大的相似性的那在这个前提下，其实我们需要一个比较严谨的评测基准。比如说在计算机视觉里面，像物体识别的能力，OCR就光学技术识别的能力，还有场景理解的能力。现在其实我们还没有看到一个针对于这种动物太冒痘的很好的一个评测基准。",
      "speaker": "发言人4"
    },
    {
      "time": "00:56:19",
      "text": "未来的话应该是怎么样让多模态信息能够拿来理解世界。举个例子，就是像人是懂语言的，但是猫猫狗狗这些动物们其实并没有一个语言模型。但是他们的视觉、听觉？还有味觉、触觉，可以让他们获得对周围的世界有一个相当丰富的理解。所以这些宝贵的多模态信息，他们更有价值的用途应该是在于增进对世界的理解。这背后其实是有关于智能的一些理论基础的。对。",
      "speaker": "发言人4"
    },
    {
      "time": "00:56:57",
      "text": "好，我们刚才聊了很多AGI这个话题，其实可以聊非常长的时间。但其实今天我们其实还有一个很重要的另外一个话题想要聊的，是为什么请这个谭旭来的原因。谈续是哈根GPT这一篇论文的作者，琮寒冰GPT之后，包括我们看到像auto GPT，还有前段时间完成了几个亿几千万美金融资。这个fixy其实越来越多的公司都在加入我们所谓的intelligent agent的阵营。所以这次也想听韩旭来我给大家介绍一下最近非常火的这个行GPT的，也是这研究的背景。然后它大概一个运作机制，以及我们现在看到的出现了很多类似行行GPT的这一些这些工具。你他们之间的一些主要的一些路径核心的差异在哪？",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:49",
      "text": "对，哈根。",
      "speaker": "发言人4"
    },
    {
      "time": "00:57:50",
      "text": "GPT其实它的核心思想就是觉得现在的语言模型解决复杂任务的能力还不太够。所以他就比如多模态的或者更加长链条的一些任务。所以他利用语言模型来作为一个调度的中心，通过解析用户的请求，把它分解成一个个不同的子任务。比如说用户的任务都很复杂的情况下，我们拆解丸子人物以后就去call或者去调用一些专家的模型来分别执行这个拆解的责任。之后，把它的结果汇总起来，整理成最后的回复，或者是结果返回给这种用户。也就是说相当于一个专家模型作为大脑系统，就是语言模型作为大脑系统。而各个专家模型去干自己的每个子任务的事情，然后形成一个有点像一个复杂的人工智能的解决方案。",
      "speaker": "发言人3"
    },
    {
      "time": "00:58:51",
      "text": "能不能讲一个分享一个，你看到一个非常很不错的应用。",
      "speaker": "发言人5"
    },
    {
      "time": "00:58:56",
      "text": "往往在学术界或者说当前开发的一些系统，它都是面像单个任务的。比如说图像识别，或者是文本的生成，或者是什么检测，或者是语音合成。那往往我们需要的一些能力是一个长链条的，或者很复杂的，而且并且更面向用户的，实际需求的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:15",
      "text": "谈一个最简单的例子，就是比如说我想要输一张，或者是想要让AI去生成一张图片，那它是在在做一个动作，或者他比如他躺在沙发上读一本书，但是我要求这个人他会有某些动作或者姿态，他是要向另外一个人，那另外一个人他其实可能不是在读书，或者他在比如骑一个滑板或别的。那同时我们也需要用一个声音去把这个画出来的图描述出来，它就是一些可能典型的AI任务的复合。这里边如果拆解这个复杂任务，它就需要，比如说我要用那个参考图片，我要去做图像的检测，或者是定位，或者scale的识别，之后我要去调用AI的生成模型去生成这个图片。生成图片以后，我要去对调caption的模型去描述图片，之后调机电视的模型把它合成出来。但这是只是一个我们比较容易理解的AI任务的例子，当然还有很多复杂的场景。只要我们的语言模型植入的强大，它可以把你复杂的用户的需求给它拆解成AI可以实现的任务的方式。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:26",
      "text": "那如如果跟现在另外一个比较红火的auto GPT比起来，这两个概念或者说这两个各有什么什么擅长，有些什么样不同吗？",
      "speaker": "发言人5"
    },
    {
      "time": "01:00:40",
      "text": "我觉得可能本身的思想，我觉得有一点有有一些区别。就是auto GPT它更多是围绕着语言模型为中心去做一些事情。比如说它主要以GPT4为基础，然后通过去构造它的prompt，让让GPT是有反复的去去去迭代调用，完成一些复杂的功能。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:04",
      "text": "因为GPT auto GPT诞生之初，它这个项目可能更多的核心思想是说，能不能让GP4去做商业决策，最后能帮我去赚到。所以他说怎么去优化我的这个商业的一些一些一些11一些策略之类的。所以他核心思想就是说我让GPT去，比如说我用一个文字去去prompt给GP4。GP4他就会帮你去分析说我要做这个任务，我需要去做什么事情。他可能主要有好几个功能，比如他可以访问互联网去搜索和收集的收集信息，然后以及你历史做过什么样的角色或者是对话。他可以用内存去做管理，最后生成的结果，它可以用通过文件存储或者是通过GPT去做sum range。也就是说是偏偏以GPT4为核心为主体的，让GPT4自己可以run起来的一个系统。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:00",
      "text": "而哈根GPT更多是强调GPT4OK或者GPT的这种语言模型，只是一个大脑，它只是负责调度决策或者整个整合。具体执行的任务还是交给更擅长他的专家模型。这个专家模型也可能是语言模型本身，但也有可能是更多广泛的别的模型，就是来形成一个协调的系统，一起来配合完成一些复杂的AI任务。可以说就是auto GPT，它可能会面向一些不是那么或者更泛的一些任务场景。而哈根GPT更强调的是一些复杂的AI任务，可能更加专业的一些问题。我看欧洲GPT.",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:44",
      "text": "上大家分享了很多很有意思demo在网上。比如说我让它自动去完成一个网站，建一个写一个游戏什么的。其实这里边很多是不是ai的工作，不是用AI模型来去完成工作。是不是说对于这些其实用auto GPT就更合适一些？",
      "speaker": "发言人1"
    },
    {
      "time": "01:03:03",
      "text": "对我的理解是这样，他可能会有一些流程化的东西，你说他每个动作有多难，或者有核心的我们AI的能力，可能不一定见得，他也没有那么依赖说我们现在已有的大规模的或者大量的产生的一些AI的专家模型。它就是一些偏流程性的、事务性的或者商业性的，更多的依赖的是GPT4的语言理解能力。",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:27",
      "text": "那它的实现跟这个GPT ChatGPT plugin的这个时间有什么不一样呢？",
      "speaker": "发言人1"
    },
    {
      "time": "01:03:35",
      "text": "就是ChatGPT或者OOA他们自己开源panin生态，是不是更多是一个互补或者说完善它的生态。我我我总会觉得整个这一类型的工作应该都算一个大的核心思想。",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:52",
      "text": "核心思想就是都是让GPT1个API调用，是不能完成有的东西。然后从你的角度，auto GPT是围绕着他，让他尽量把把这个问题完成的越多越好。然后从一个higg GPT的角度来讲，这个GPT只是一个大脑，然后我还有大量的其他事情，大脑之外也在做。",
      "speaker": "发言人5"
    },
    {
      "time": "01:04:19",
      "text": "现在AI的解决方案其实经过了很多不同的方式。比如早期我们有这个专家系统，就是说就是神经网络之前的那个年代。那后面我们有些统计机器学习的方法，到后面我们有深度学习的模型。到这几年我们有foundation的大模型。可能逐渐的我们的能力就变强以后，我们会去踏实更多任务，更复杂任务或者更深度的AGI的能力。也许再往下一代就是基于foundation模型，然后去连接各个自己领域的专家，然后解决更复杂更实用的问题。可能会也就是说我们到了这个转变点，面临就比如说人工智能的一个范式的转变。",
      "speaker": "发言人3"
    },
    {
      "time": "01:05:00",
      "text": "这种思想其实也和我们比如说内部，或者像比如微软本身的一些基因。比如像早期我们做操作系统，其实也不是说把所有的任务全做了，就是开放一个平台。但是很多软件开发者可以基于这个操作系统去完善windows的生态，让我们可以做很复杂的任务，那可能现在也是个仿真性模型，做完以后不见得某我们每个公司或者每个团队都要去做仿真性的模型。你可能基于他去做更丰富的生态，能够让我们解锁，就是让这些工具解锁更多的能力。",
      "speaker": "发言人3"
    },
    {
      "time": "01:05:30",
      "text": "你觉得有必要去自己做一个foundation model吗？还是说一般来说这个foundation model已经足够了，反正你自己翻看一下，基本上也能够完成。你的你想要做的。这一个其实是大家不管是学术界还是在工业界，其实争论蛮多的。想听听你们是怎么想这个问题的。",
      "speaker": "发言人5"
    },
    {
      "time": "01:05:56",
      "text": "我我我的感觉就是说如果我们选择的系统未来是一个一个一个单元模型作为大脑，然后应用每个领域的专家模型作为执行的具体执行的角色的话。我觉得这种范式下面，我们对于每个领域，比如说金融，医疗或者教育等等，他可能更多需要我们对于这个场景下面，大语言模型它的这个决策调度或者任务的拆解等等这个能力。因为每个领域的专家模型，我相信不会有太大的问题。因为现在每个领域都有自己的一些模型，深耕了很久。对于大语言模型本身的来讲，它是否能够迁移到每个领域都能做的这么好。现在大语言模型是否对这些demotion有很好的泛化能力，也就是我们的show能力是不是足够强到这个领域里边。",
      "speaker": "发言人3"
    },
    {
      "time": "01:06:46",
      "text": "其实现在看到的一些现象还是不一定很好。对，因为有些领域它可能对于这些任务的需求的拆解，然后任务的调度执行等等不是那么强的人。所以可能也会涉及到是不是要去对每一个斗门去定制它的大语言模型。作为大脑这个能力也许是不一定是完全从头去训练这个语言模型，但你可能是拿到一个大语言模型，我们去翻听到这个斗门里面来，让他能够更加适应这个斗门里边所涉及到的任务。它对应的需求的理解，任务的拆解、规划执行等等。",
      "speaker": "发言人3"
    },
    {
      "time": "01:07:23",
      "text": "所以你觉得foundation的基础模型的能力还不一定是最最关键的，最最关键可能是拆解问题的能力，可能是对于实际应用可能更有影响。是不是会说我还是啊不要去做方案确定，就去把把这些专有的数据放到预训练里面去可能会更好。",
      "speaker": "发言人5"
    },
    {
      "time": "01:07:49",
      "text": "我觉得现在这个最大的boss like就是在这个地方，最大的瓶颈就是在这个地方。学术界其实也不知道我这个模型训练完了之后，怎么样find tune能够他既学到新的知识又不把旧的忘了。就导致现在find fine tune话，大家得非常的小心，特别是当你这个领域需要非常强的reasoning能力的时候。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:13",
      "text": "基本上facto可能不是一个最好的选项。但是我个人觉得，这只是一个技术层面的问题，就是说它并不我觉得这个问题并不本质。就是随着时间推移，可能一两年等大家用这个模型多了之后，然后发现他的这个经验越来越多，可能会找到一个比较好的办法。对。然后我个人的想法，关于他是不是需要各个领域都需要一个foundation，我我也是觉得不需要的。但是我可能我现在是从一个比如说他的cost和他这个商业角度来考虑。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:50",
      "text": "因为一个大模型，比如说GPT4，我们虽然不知道它具体花了多少钱，但是这个模型训练本身我猜应该是在one billion dollar上下的。因为当时是微软注资了two billion dollar，对吧？一个one billion dollar的现金，然后one million dollar的edit credit。这个是发生在GPT3之后，然后这笔钱肯定是用完了，然后微软还投了新的一钱。就这个程度的投入，并不是说大部分的公司能够承担的，而且这是一个high risk。",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:25",
      "text": "到现在也只有open a一家公司做出来这么厉害的。然后好像是感觉其他公司的模型，虽然有，但是好像还差了一代。甚至现在训练这种大模型都已经到了一种地球上的资源够不够的这种一种程度。就是说GPT是他肯定是在比如说英伟达的A100上训练出来的。然后可能现在这个微软的edge cloud里面是包含了地球上大部分的A1版，但是还是会不够用。然后其他的公司，比如像国内一些大的公司，可能他们会有比如说上千块，甚至比如说1万块。但是这个是也许可以支撑一次非常成功的预训练，但如果这一次失败了，可能就没有机会。再说我进行微调，调整它的have private，我再试一次，可能没有这个机会。对，就是我觉得以人类现在这个资源和这个资金的方面来说的话，不太能支撑一个每个领域都有一个大模型。所以现在我们还是会尽量想办法把这个fine to给做好。",
      "speaker": "发言人2"
    },
    {
      "time": "01:10:33",
      "text": "这以后的硬件也会不断的提高，大家也可能去发现有各种各样的方式方法去优化训练大模型。这么高的要用这么多的价，就是相当于这么多的钱去烧，是一个不会本质上不会在在五年十年内不会改变的吗？还是说现在是这样，显然就几家公司能够afford起，能够训训练的起。但是过个五年、十年，其实这个产业界就会有很多个公司，都能够去有有这个实力去运训练。你觉得这个后面那种可能性有有多大？",
      "speaker": "发言人5"
    },
    {
      "time": "01:11:17",
      "text": "应该是非常大的这个局面应该很快就会改。比如说我们现在看五年前，对吧，五年前2018年，比如说2016年、17年？那个时候可能rest net或者是dance net刚刚出来，那个时候其实我们觉得训练这些模型也很难，那现在的话就感觉好简单，现在这些都是小模型，我觉得这个技术进步是非常快的对，然后还有一点，就是说啊就是open I他到底有没有自己的秘密？他现在显得很有秘密，比如说他paper他都没有说这个模型有多大，到底是怎么训练，这个文件找出来GPT3都说了，但GPT4就一个字都不说。我反而会觉得可能他们是会有很多别人不知道的trick，导致于别的公司的尝试到现在看起来好像都没有他们的强。但是这个take本身可能是很简单的，几句话就能说清楚，这就需要大量的试错。所以当更多的公司去加入到这个里面来的时候，大家试了很多很多次之后，我觉得很有可能就把这个数给找出。所以我觉得a open ADB的并不会存在太长的时间，这是我个人看法。",
      "speaker": "发言人2"
    },
    {
      "time": "01:12:27",
      "text": "想听听谭博士讲讲这个问题。因为他是做海淀GPT，其实你刚才是说，这个东西已经做到极致了，那有这个潜力在哪里？他跟GPT跟那个auto GPT到底成熟了吗？",
      "speaker": "发言人5"
    },
    {
      "time": "01:12:43",
      "text": "其实如果要我们往下继续推进这样的系统，其实就有两个角度。一个角度是本身作为大语言模型，它的理解调度，plum的这些能力的提升，并且在每个抖面都可以做的足够好。第二个角度是本身专家模型它的生态的建立。",
      "speaker": "发言人3"
    },
    {
      "time": "01:13:01",
      "text": "其实我们也看到现在比如说我们哈克GPT推出去以后，有很多奇怪的需求。但是这些需求我觉得他也不奇怪，只是我们以前不常见而已。但是这个需求一直存在，只是被掩盖了，被被压抑了。他们释放出来的需求就是需要很多一些复杂的模型能支持。那我们怎么去在这个抖音里面去支持足够多的干各个事情的模型，其实是现在要解决的。比如说我们现在可能通用的AI的模型还好，比如CVNRP或者语音的模型可能都有很多。但是对于一些短的模型，比如说医疗，或者是营销，教育，或者广告什么的，他可能就需要一些奇奇怪怪的别的一些模型。我觉得这个生态的建立，可能也是对这个系统能推的更加成功是比较关键的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:13:50",
      "text": "然后这里边还是想谈一个问题，就是这个边界的问题。也就是说因为你大语言模型本身也可以做一些相关的任务，然后他也可以去调度。所以有点像既当裁判又当运动员。那我们怎么去找好大语言模型的边界，也就是什么任务就交给语言模型自己做，他也能做了哪些任务一定是要交给专家模型去搞的。可能要去要去可能有一个比较指导或者定义说，哪些模型我是放在一个模型里面，我的我是更经济的那哪些东西任务能力是要拆开来交给专家们。你自己去做专业的事情。",
      "speaker": "发言人3"
    },
    {
      "time": "01:14:27",
      "text": "然后如果有了这样的一个边界，就好比我们说IOS或者安卓的，或者是windows的系统，windows它也不是做所有的软件。比如说我可能微软都做了一些基础的办公软件，或者说基础的一些底层的软件。但是很多软件还是要交给开发者去做的，把这个链条可能守好或者定好是是让我们推动这个事情更加容易一些，我觉得目前比如像跟GPT跟GP还处于很。",
      "speaker": "发言人3"
    },
    {
      "time": "01:14:53",
      "text": "初期的一个过程。所以说哈根GPT要做好，其实还是最好practice是跟专家模型一起做。你刚才是说这个意思吗？",
      "speaker": "发言人5"
    },
    {
      "time": "01:15:06",
      "text": "对，就他需要有专家模型来做支撑，才可能把这个生态转起来。",
      "speaker": "发言人3"
    },
    {
      "time": "01:15:12",
      "text": "那那同时你又说这个还是比较初级阶段，初级在哪里呢？",
      "speaker": "发言人5"
    },
    {
      "time": "01:15:17",
      "text": "我觉得可能初级指的是现实框架还会比较明确一些，可能就欠缺的能力还是两方面，就是本身语言模型在于任务方案调度上面还是需要增强。因为我们现在所能用的API只能是few shot，zero shot没法去调用它，就是给demo station。他现在我们可能试过的一些模型，比如除了ChatGPT或者3.5的系列，GP4的系列，其他模型你看开源出来说，虽然能生成和现代GPT或者GPT3.5这种一样的能力，实际上差很多。在模型的任务的解析调度方面，这个能力上面，其实好好多开源的模型都不太能打。",
      "speaker": "发言人3"
    },
    {
      "time": "01:15:57",
      "text": "那我怀疑这个调度planning的能力，它跟大模型哪一块的能力相关性是更强的。比如说它是不是reasoning的能力越强，像GPT for这样的。它的调度能力应该会越强，还是说它更多的还是取决于fun tuning这个阶段。",
      "speaker": "发言人1"
    },
    {
      "time": "01:16:17",
      "text": "它调度本身可能就两两几个事情，一个是有比较好的contest的长度，有现在GP4已经很好两三万的长度了。所以它能够足够让我们把这个任务描述清楚，我们的demotion or prompt去非常详细的描述这个任务的一些事例。然后我另外一个就是他还是需要有推理，有要有理解，因为他要选择决策，就是我我要做这个事情，我要去了解现在有哪些工具，从工具里面去选择哪些工具来去做。这个可能就是一个涉及到决策的东西，两方面能力都需要。如果我们在能基于大模型去翻看有这样的印刷的数据，它会做的会更好。比如我理解就是后面可能有一个配置叫open AGI还是什么。他好像里面就提到说我们不是优秀的秀的去做planning，而是拿一些示例数据去翻，效果可能。",
      "speaker": "发言人3"
    },
    {
      "time": "01:17:13",
      "text": "会更好。要让这个hony GPT o GPT这种方式就能够被广泛的应用。你觉得除了刚才讲到的planning这个模型层面的这个能力之外，还有哪一些能力可能是需要提升才能让它成为一个所谓的serious应用。",
      "speaker": "发言人1"
    },
    {
      "time": "01:17:34",
      "text": "我觉得如果我们要做成这个事情，还是需要有一个新的平台。这个平台要鼓励大家去接入这样的专家系统专家模型，让让这个供给专家模型的供给能够足够的丰富。这样我们在这样的生态下面才可以选择各种各样的模型去做复杂的任务。可能是一个比较要去构建一个生态的这样的事情去做。",
      "speaker": "发言人3"
    },
    {
      "time": "01:18:05",
      "text": "我好奇秦博洪博士和张译你们俩对这个领域的看法是怎样？",
      "speaker": "发言人1"
    },
    {
      "time": "01:18:13",
      "text": "我我我先发表一下看法。对，其实我觉得a agent这个事情，其实它非常的通用。然后A镜头它其实也是在关于智能intelligence研究中一个非常重要的概念。",
      "speaker": "发言人4"
    },
    {
      "time": "01:18:32",
      "text": "刚才我们聊了很多，其实都是从应用或者我们就要从互联网的视角来看待的那我们先说从互联网的视角，不管是auto GPT，还是啊哈根GPPT，或者是open eye plugin的插件，实际上它都是在去用大元模型，然后调用一个的API。每不管是model还是外部的一个成熟的外部API，其实我们都可以把它看成一个API。其实我们可以从open I的这个plugin的设计里面看到很多很多东西的。在分析之前我们先有一个背景，这个背景就是open I最关心的一定是AGI。他关心的其实并不是说chat BT这个生态或者挣多少钱，他最关心的还是GI当我们有了这个背景之后，再去看拉丁这个事情，就会能看到新的东西。",
      "speaker": "发言人4"
    },
    {
      "time": "01:19:35",
      "text": "我举个例子，比如说刚才我们讨论到，其实现在的GPT在做规划的时候，其实它并不能总是很确定的知道在什么时候我应该调用哪一个API。现在CPT plug in其实也是不知道的。他现在是怎么做的呢？他其实是让用户来指定我要用哪些plug in，然后我告诉他我的任务是什么，这样去做的那这样我们其实可以猜测open I其实是在收集数据，他想让人类替他把这件事儿给做了，给标注好。",
      "speaker": "发言人4"
    },
    {
      "time": "01:20:17",
      "text": "我当我想完成某一个任务的时候，我该调用哪些API。而且这件事情做完之后，他还能拿到一些feedback。这个事情到底有没有完成？这个数据是很宝贵的数据，对未来他去升级自己的GPT是不可或缺的一个数据。这是其中一个视角。",
      "speaker": "发言人4"
    },
    {
      "time": "01:20:42",
      "text": "更恐怖的是说API现在我们看到还只是几十个或者几百个这种外部的API更进一步本地的软件。每个APP其实也可以看这个API操作系统的各种各样的函数接口，也可以看作API更进一步各种各样的硬件。比如说各种各样的传感器，温度传感器，对吧？激光雷达传感器、视觉传感器，还有机器人、机械臂等等。这些东西都可以做一个API来接到这个大脑里面去。所以这是一个很本质的事情，那就是通用智能general intelligence。他就要求你这个agent能够在尽量多的environment环境里面能够成功的执行任务。",
      "speaker": "发言人4"
    },
    {
      "time": "01:21:29",
      "text": "你能够在越多的环境里面生存，你就越intelligent，这是智能很本质的一件事情。所以open I在做plugging这个生态的时候，他已经很他已经想清楚了A进通用A进的这件事，也想清楚了这是通往AGI的一个很重要的路径。就是当我们从不管是互联网视角看，还是从智能这项技术的视角看的是这件事它是能对上的。",
      "speaker": "发言人4"
    },
    {
      "time": "01:22:03",
      "text": "我之前看到一个很有意思idea，就是大家要open source这个build model这个事情本身这个idea就是以后可能这个model并不是说有一家公司来train，甚至也不是有一个人来追，就是每个人可以给他提供一个部件。比如说是一个动漫上的一个X文模型，专家模型，需要一个中心的，可能是OpenAI，可能是别的公司他们来处理。怎么样把这些所有的模型都结合在一起，然后做到1加1大于二的效果。因为我我们现在猜测那个GPT4或者GP3.5，它也本身就在使用一种叫mixture of expert。就是它里面有很多很多的pathway，然后遇到不同的输入，它会调用这个模型中间不同的部分来来处理。所以其实这个事情也很很方便的能够把很多很多看起来不相干的专家模型给联合到一个模型上的一个技术。",
      "speaker": "发言人2"
    },
    {
      "time": "01:23:13",
      "text": "所以这可能未来的模型就不是说一个模型我拿来翻译to或者怎么样。而是说如果我需要这个模型，需要一个功能，我可以自己提供一个专家模型。就像我需要这个github上一个rapper对吧？一个package它有个功能它它OO很好，但就缺一个功能我很需要，那我就可以folk它我folk它之后我自己把这个功能写上去，我还可以要求他们做一个pull request的，把我的企业的这个新功能给放到那个branch里去，对吧？很有可能以后的模型变成这样，然后这个模型它这样迭代的速度会越来越快。",
      "speaker": "发言人2"
    },
    {
      "time": "01:23:50",
      "text": "就是可以把一个小模型给加到大模型里面去，通过连接的方式。对，这个跟final也不一样。对，就是你是改变这个模型本身的架构，不只是参数，甚至架构都在改变。对，其实刚才不是我们一直在说就是fine tune这个事情他不太好做，它会让之前的capability会变差。现在我们是发现现在最好的，就我们没有办法完全处理这件事情。但是我们现在最好的方法就是单独训练一个expert，把它加到现有的MOE里面去。现在看起来这个是working最好的，虽然还没有完全解决，但至少说明单独给他加一个expert是可以做到的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:24:37",
      "text": "这个是说去取代。比如说我可以理解为，那有点像说我比如说基于这个运GPT，然后我可能把好多个专家模型把它做起来，做一个下一代MOE的模型，然后它其实是说不定是取代或者说超越这个GPT的一种方式。",
      "speaker": "发言人1"
    },
    {
      "time": "01:24:56",
      "text": "因为它不只是调API了，因为API还是有限制。他很有可能就是说他可以更灵活的使用这些专家模型里面的一些insight，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "01:25:07",
      "text": "对。",
      "speaker": "发言人1"
    },
    {
      "time": "01:25:07",
      "text": "这个还挺意思。",
      "speaker": "发言人2"
    },
    {
      "time": "01:25:08",
      "text": "这个是从模型的角度，我们刚才很多讲到GPT说的都是从这个应用的角度去聊。其实大家聊到了几个话题在聊多模态，中国尤其在这一块有很多追赶，都是在很努力去追赶。所以我觉得后来就想说到底作为追赶者来说，他是应该是复制前任的路竟还是说还是说他其实应该从我从z one开始，我就要尝试一个不一样的路径。我好奇大家会怎么看未来的这个竞争格局和有可能的颠覆者。要不要鸿博士你们聊一聊。",
      "speaker": "发言人1"
    },
    {
      "time": "01:25:45",
      "text": "我们可以看看美国的这几家公司。Deep mind answer bic和open eyes。当然aspic是从open eye出来的一帮人做的，所以s back跟open I的路线非常的接近。但deep man的其实跟OpenAI路线一直以来还是有不小的差异的。比如说demand会去做很多跟强化学习相关的对，也会去做生命科学，比如alpha fold这样的工作。并且他们并没有真的在大元模型上投入那么多的精力。但是ChatGPT之后我们都看到了，deep mind就是让人紧张的，也开始往这个方向去投更多的精力。",
      "speaker": "发言人4"
    },
    {
      "time": "01:26:35",
      "text": "当然不管是在工业界还是在学术界，都有不少人想去弯道超车的各种各样的路径，都有一些很著名的教授，其实是很diss GPT这一套cos q up的做法的对，他们有自己的一套路线图，想去尝试的，也许会很成功。即使是在工业界，其实也会有人想去做跟GPT不太一样的路线。比如说我纯靠像类似于alpha zero这样的路线图是不是能做出来。还有一些人会去想我一步到位直接去做grounding对吧？比如说我用大规模的智能体，比如机器人来去在现实世界中去掌握智能等等，其实都是路线。",
      "speaker": "发言人4"
    },
    {
      "time": "01:27:25",
      "text": "但是当有很多种路线的时候，最明确的是哪一个？其实还是open I这一套路线图。因为有两个因素了。第一是它已经在很多很多的AGI路线里面，他的实验室最成功的那一个，至少截止到目前为止。第二就是这个领域的一些基础，不管是理论还是一些技术，或者芯片等等各种各样的东西都是相当ready。至少在GP3.5这个level是相当ready的。所以我们如果是你做出AGI的目标来去看这件事儿的话，我认为应该还是相当于大部分这个宝还是要压在GPT这个路线上。这是从形式上的分析，当然我做这样的判断更多的还是基于DBT这背后的一套非常基础的原理。我没有看到特别大的blocker或者说技术层面的破绽。",
      "speaker": "发言人4"
    },
    {
      "time": "01:28:38",
      "text": "我认为这条路是可以继续往下走很远的对，我可以举一些也许可以做的例子，比如说像context lungs对吧？就现在OpenAI的GPT four已经做到了32K但显然人们想要的是更多的。而且你如果真的想抛弃掉fortune的这种路线，实际上你如果能够把context longs变得非常长，很多很多场景你是不太需要find tune的。然后这个问题其实很难，因为现在的技术我们如果想增强这个context lunch的话，你的内存是一个非常大的挑战，你的算力的复杂度也是一个非常大的挑战。其实我们把flash attention，把space transformer，fast attention等等这样的技术全用上，我们也只能做到。而且GPT32K已经是比较成熟的技术里面相当了不起的长度了。但是我觉得这个还需要更多的算法层面的突破，我们要做到更长，集成电路层面，当然HBMHBM的技术应该还有很远的路要走。对，然后这是context Lance，当然还有很多其他。",
      "speaker": "发言人4"
    },
    {
      "time": "01:30:05",
      "text": "的比你有什么预测吗？关于contact length结构等等，就是你觉得是一个能够线性的不断的提高的一个，比如说到他下一代就是128K了，还是你有什么预测吗？",
      "speaker": "发言人5"
    },
    {
      "time": "01:30:25",
      "text": "这个我没有太好的预测，因为这就是一个科学问题，它还不是一个工程问题。如果我们能够把计算的复杂度做成跟输入的长度是线性的关系，我们可以增加非常多。但现在是N方或者是N乘根号N的一个关系，这是一个我们至今为止没有解决的问题。",
      "speaker": "发言人4"
    },
    {
      "time": "01:30:49",
      "text": "Can context length就是提示的输入跟输出这么一个长度，今天能够输入的是有限的，这是为什么？红博士说如果说你能够提示的如果足够多的话，那你也不存在需要去微调了。很多时候但是因为有这么一个限制，我们是不是还必须或者说很勉强的要去做微调？我比较好奇的就是你你你刚才提到你觉得这不是一个工程问题，这主要是一个science问题的难点，或者说怎么能不能能不能再。",
      "speaker": "发言人5"
    },
    {
      "time": "01:31:27",
      "text": "讲一讲我说科学家的问题，实际上是想在给定硬件约束的前提下，我们能不能更好的把context lunch给skill up。对，这是我定义的一个科学问题。但在这里面其实像deep mind等等一些公司也去以前也都做过尝试。就是我们能不能把这种context的输入，也可以认为是一种memory。对我能不能把这种memory来做压缩，就像人一样，其实我刚刚发生的事情可能记得是很清楚的。但是再往前一周以前的、一个月以前的、一年以前的，实际上在我的记忆里面是比较稀疏的。是相当于也是压缩的相当深的一些记忆。类似于这样的事儿是不是也可以在GPT的context lost里面也这样去做对，会有这样的一些就嗑学家里头在做这样的一些尝试。包括最近如果大家注意到的话，也有相关的paper。比如有人去做一个million的token输入。",
      "speaker": "发言人4"
    },
    {
      "time": "01:32:40",
      "text": "其实我我也不知道工程可以做什么，但是我觉得这是最终还是一个性价比的问题，就是说跟cost有很大关系。然后我之所以这么说，是更多的是因为我知道有一家至少有一家大模型的公司。这家公司我们今天这里没提到过，但其实也算是这个大模型的公司的硅谷大模型公司里面的其中之一。他在给企业落地的时候，他就提供128K的那个option。我相信他他之所以能做到这一点，是因为他给人家解决的问题的，能够产生的代价比较高。所以说他有些有些trade off就会就就就会跟我们通常的这些chabot的trade off是不一样的。对，大概是这么一个情况。",
      "speaker": "发言人5"
    },
    {
      "time": "01:33:38",
      "text": "对，这里我可能要提一下，就是我想要的那种很长的country lungs，它不是说增加十倍、100倍，而是说你能不能给我把我一个人一生所看到的数据全部算进去。我一家公司整个历史上的数据全部塞进去，我们想要的是这样的一个loss。",
      "speaker": "发言人4"
    },
    {
      "time": "01:34:00",
      "text": "因为我们组也有一些工作，就是focus在就是stop这个contest next的问题。然后我觉得我非常同意黄博士说的这现在是一个科学问题。因为在学术界里面，我们都没有看到非常promising the work就是触及到这个本质的。比如说之前可能有一阵时间，可能1年到2年，之前有很多关于这个linear time attention to work，大部分来自于google和deep mind。其实我们发现这些东西在真正用到这个language model里面的时候，基本上都是不work。然后他们犯的错误其实比较低级。",
      "speaker": "发言人2"
    },
    {
      "time": "01:34:44",
      "text": "比如说我们发现就是说这个好的大模型，如果你能打开看的话，对吧？开源的模型你把它打开来看，它的在特定输入的时候，它里面那个attention它是有很强的pattern。那就说明可能好的模型，你做这个linear time attention的时候，它需要能够至少capture这些pattern。如果你是pattern都不不能capture的话，那这个indian time approximation可能就不太行。对我就发现学术界在这个方面其实花的精力特别少，很少。就是说把这个模型真正打开看，我们想要加速它，但是我们我们不能毁了这个模型，对吧？我们我们想先看这个模型它到底想要什么。然后我们在确保这个模型能拿到他想要的这个结构的时候，我们能不能做加速。",
      "speaker": "发言人2"
    },
    {
      "time": "01:35:33",
      "text": "我现在还没有看到很多学术界的工作在这方面挖的比较深，就很少会有就打开这些很大的模型看看里面到底发生了什么。然后基于这个我们再来design，就是说这个是space的pattern要长什么样，或者说它到底是不是low rank，或者low rank approximate到底能不能approximate这个attention。对我觉得这个在科学上面都还没有解决，我们需要更了解transformer这个model本身。然后下一步再是我们在工程上怎么更进一步。",
      "speaker": "发言人2"
    },
    {
      "time": "01:36:11",
      "text": "我想如何帮助我们的听众朋友更好的去理解说为什么我要有这么长的context那么重要。的话我就是否比如说二位可以举个例子，就是说因为我们没有这个能力，使得现在大模型的哪一些任务上他可能还做不了，或者说哪些任务上，我比方说像一些企业里边的它的应用的时候，他可能说我我通过用这种embedding的这种方式来去做。那这两种方式它的差别，它有可能的就contest下来的。这个libitina应该怎么去理解？",
      "speaker": "发言人1"
    },
    {
      "time": "01:36:45",
      "text": "我有一个例子，比如说GPT4刚出来早期的时候，好像我不记得是OpenAI还是我们微软做了一个测试，就是他们用了全部的contact，把整个美国的那个叫什么，那个艺考叫smile，还是忘了，就是类似于美国的这个医生执照考试资格考试。他们把整个textbook都放进了context，然后这个模型直接最右下载就sop了所有东西。但是如果不放这个整个textbook的话，他perform.",
      "speaker": "发言人2"
    },
    {
      "time": "01:37:21",
      "text": "其实也他怎么可能把所有的这本书放在放到context里，是因为翻译还是什么？",
      "speaker": "发言人5"
    },
    {
      "time": "01:37:28",
      "text": "不不不不不就就是把这本书给token ize，可能不是所有的章节，他们可能挑选了重要章节。",
      "speaker": "发言人2"
    },
    {
      "time": "01:37:35",
      "text": "就是尽量33。是的，即使是但是即使是重要的是章节也不会32天就购买32K.",
      "speaker": "发言人5"
    },
    {
      "time": "01:37:43",
      "text": "其实挺长的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:37:45",
      "text": "两万多相当于二十多K的单词。",
      "speaker": "发言人5"
    },
    {
      "time": "01:37:49",
      "text": "对，能塞不少东西。对，但是肯定塞不完整本书。因为一般这种考试的test go都非常厚。对。对，他们可能是做了很多那种就是测这个模型，他本身记得什么不记得什么，他们把不记得了以这个text book的形式放进去，然后就基本上一考都是买都是新的艺考题的是吧？",
      "speaker": "发言人2"
    },
    {
      "time": "01:38:11",
      "text": "这个在几十年前，香浓就已经想过这个问题了。你context越长，你对于信息的理解是越充分的。",
      "speaker": "发言人4"
    },
    {
      "time": "01:38:22",
      "text": "如果是个人，你的这个memory，你需要去relay到很久以前的这个事情。如果在很多企业里边，比如说一些分析性的这种workflow性的这种场景里面，那是不是对于这contest要求相对来说没有那么高呢？",
      "speaker": "发言人1"
    },
    {
      "time": "01:38:35",
      "text": "我觉得可能有个很简单例子。比如说就是，现在企业大家都用，比如像team或者slack这种工具对吧？然后有很多channel然后里面有很多人一直在说话，但可能其中有一条是艾特你的。比如说老板要让我做个什么什么事情，然后突然就被所有人的method给淹没了。虽然两我回去找也能找，但是我希望可能会有这个模型，他能提醒我说，你让老板今天早上八点跟你说了，你要干什么，明天早上之前交。这样就需要他把整个channel所有的新都读完，吧？他如果漏掉这一条，你他没有给你提醒，那就完蛋了。",
      "speaker": "发言人2"
    },
    {
      "time": "01:39:11",
      "text": "处理的contest这个长度，你们觉得会是对于模型的本身架构本身就提出一个挑战吗？还是说更多的是科学问题，而不是工程问题。",
      "speaker": "发言人1"
    },
    {
      "time": "01:39:22",
      "text": "得改掉穿梭的这个模型，就是不是说大概当然不是说从另外建造一一座大厦。而说这个attention我们要理解就是为什么attention好。理解了attention好之后，我们再想有什么更以推想办法来做同样的事情。",
      "speaker": "发言人2"
    },
    {
      "time": "01:39:39",
      "text": "另外一个角度就是因为我们谈到contest，这个事情涉及到memory或者说历史的记忆，其实可以参考，对，或者有没有可能就是参考人类的记忆。其实人类记忆不是说把过去一生当中所有的事情都记在脑海里面，他一定有几个特征。一个是随时间衰减，可能最近的事情他记得注意，但是你记不住。第二个是说重要的事情，或者有些提炼性的结论性的事情，或者某个东西美好的瞬间记得住，然后其他一些细节或者别的不重要的事情是忘掉。所以这是人脑记忆的特点。",
      "speaker": "发言人3"
    },
    {
      "time": "01:40:13",
      "text": "而现在我们transformer都是用比如说很长的contest，用attention。Attention是一个什么机制呢？就是我去选择，也就是说我基因一直存在，我是存在那儿的，我要从一个很长的序列里面去选择。而人脑他也许就是说可能我有东西就记不住了，我只是存的时候我已经压缩过了。你在选的时候你可能再去选。所以这个就涉及到一个效率的问题。就比如说我们在transformer模型里面，能把过去历史上的一些重要的信息筛选出来，或者是有些成绩化的存储，让我们在选择的时候不要那么的看那么多，或者计算量那么大。也许是一个可行的方式。因为现在的选择还是一个暴力选择，所以造成了现在N方的这种复杂度，导致我们的你是没法支持这么长的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:41:02",
      "text": "contest能够超越open。它需要从更fundamental的模型架构上。",
      "speaker": "发言人1"
    },
    {
      "time": "01:41:09",
      "text": "他们这个模型它从诞生到今天并没有基本我可以说基本上没有变化，就是会每天都有个新模型。但是你仔细看它可能就是微调了一点点。然后其实也很难说这个微调对最后的performance到底有什么影响。他是它的backbone是没有变过的，特别是往下来看它本身这个东西。所以这个其实是也是非常震让人震惊的一件事情。比如说compare to这个competitive tion，他们这个模型迭代速度是非常快的，就会有新的东西也没加进来。但是transformer可能是因为这个实验的成本实在太高了，并不能支撑大部分的组一直在尝试新的东西。所以导致这个模型本身就形成了非常严重的路径依赖。",
      "speaker": "发言人2"
    },
    {
      "time": "01:41:52",
      "text": "而在这个层面，我个人不太相信说这个模型它本身到底是到底有多好。他很有可能就是说80%的。但如果说我们要真的要突破它的话，还是有很大的空间的。只不过现在没有太多人尝试，至少在这个模型架构的方面。",
      "speaker": "发言人2"
    },
    {
      "time": "01:42:08",
      "text": "然后这里面有一个原因是因为也是eco system，因为大家都在做transformer，即使transformer那个不是最好的，就像你说不管80%还是多少好，因为大家都在朝这方面做，你很难去。你如果去标新立异做了另外一个东西，写了一些数据，也没多少人理你，对吧？所以这个eco system其实是蛮重要的。最终最终一个好的技术被大家吸引，然后再做，决定权不在于这个技术本身。这技术本身有一定原因，但还有一个原因还是一个它的一个eco system，这个生态圈其实蛮重要的，多少人用？",
      "speaker": "发言人5"
    },
    {
      "time": "01:42:55",
      "text": "大家可能知道有一个就是adg现在当然是没人用，但是现在现在大家这个train大模型都是用那个叫adam。对，但是adam的前身就是build on这个l grab，阿拉瓜这个东西，他是我的princeton一个教授，就是我也是我老板的学生之前的学生。然后是他当时这个纯纯理论的，主要是没想说把这个东西用给deep，他就发表这个paper。然后当时有很多第一代的deep能力的frame叫咖啡吧，他们就不知道为什么把这个给写进去了，导致了所有人都觉得阿拉瓜比HGD好，所有人都用阿拉瓜那边配备估计已经有24两三万的section，但是那个paper跟deep能力一毛钱关系都没，然后甚至还影响了到今天的。对，就是如果你被一个library写进去了，对吧？这个事情比本这个技术本身更重要。",
      "speaker": "发言人2"
    },
    {
      "time": "01:43:50",
      "text": "所以我觉得这个也挺有意思的。就是我觉得不只是人工智能这个领域，开发者工具，甚至info很多领域也不是技术最强的那一个产品，最后就赢得这个市场。我好奇大家有没有考虑过，就是说到底怎么样是能够真正打造好所谓的这个生态的？这里面有没有一些best practice可以总结出来。",
      "speaker": "发言人1"
    },
    {
      "time": "01:44:15",
      "text": "我觉得有一点，包括贾扬青他在提到，在我的课堂节目提到易用性很重要。Pyto ch他认为pyto ch之所以能够后来居上，能够现在基本上打败或者超过打败不能这么说，超过那个天色flow的那个有很大的一个原因就是易用性。那你再看其他领域其实也是一样，我是做做网络做了很多年。二十多年前有一个很大的一个比较大的争论，就是应该用TCPIP的这一套，还是用ATM的这一套。ATM这一套其实你从学术界的角度来讲，这个其实有很大的优越性，或者说有一定的优越性。至少但是后来是完败，完败给TCPIP有一个很重要的原因，就是TCPIP很很容易理解对吧？他不管他是是不是optimal，是不是完全最好的，这是另外。但是相对来讲更加容易被理解，这或者说是还有一点是开放性对吧？刚才张毅提到的一个原因也是你看他放到咖啡里面去，相当于就是开放性提高了。",
      "speaker": "发言人5"
    },
    {
      "time": "01:45:27",
      "text": "我觉得易用性、开放性这些我们尤其是我们这些做做可做做技术的人，不一定那么去appreciate，不一定那么觉得这些不都是很很肤浅的东西。但这些肤浅所谓的肤浅的东西，其实是我觉得是决定了很多的技术的发展再走远，可能你们都还没生出来。那时候当年windows打败OS two，那个OS就是IBM的，也不是因为技术上的原因，对吧？所以说这种例子是一代一代的这种，反正我觉得历史是在不断的重演。",
      "speaker": "发言人5"
    },
    {
      "time": "01:46:04",
      "text": "最后一个话题，我们聊的接地气一些，就是具体的这个应用。我们怎么把这个AI的技术应用到我们的日常生活中。因为我们现在看到很多，我们刚才谈到的一些项目研究，他可能都还在都还在一个demo阶段。像泓博士还有hobby，其实都在这个企业界做了很长的时间。就你们现在看到，GPT的这些应用落地的情况是怎么样的那它在这种企业里边能够去落地下，它带来哪些新的机会，同时又有哪一些挑战，要不和你聊聊。",
      "speaker": "发言人1"
    },
    {
      "time": "01:46:43",
      "text": "这个问题太广了。我觉得是这样子的，整个全球不止是这个业内的人，业外的人其实也是在关注ChatGPT，这也是上新闻头条对吧？或者说怎么样，其实也是。但是我觉得最终他在短期内，我说的在短期内可能是一两年内。对一个真正的一个世界500强的公司，或者说全世界最大的2000家公司，这可能更加有代表性一点。如果你把世界上最大的2000个公司去看，他们在今后一年，从现在开始到一年以后这一个阶段，他真正去用用到这个GPT的技术，用到这个大模型。",
      "speaker": "发言人5"
    },
    {
      "time": "01:47:41",
      "text": "不管是用各种各样的方式，有一种方式就是我去用一些新的公司的服务，像jasper，Midjourney这种都是啊我购买一些第三方的服务。这第三方的服务背后可能是一些人工智能的模型，然后来提高我的生产效率，这是一种。另外一种就是我把这些大模型的，不管是概念也好，技术也好，带到我的公司来。",
      "speaker": "发言人5"
    },
    {
      "time": "01:48:07",
      "text": "我觉得其实不多，这为什么说不多？其实每个公司的CEO都在说，或者说都在想，但要把这件事情做成其实不容易的。为什么不容易呢？因为你想这个就像我们刚才说的。最终还是要微调一点，因为我光是靠ChatGPT，它不能告诉我公司我下一步发展应该怎么样，对吧？我下一个我的我应该是在市场部门应该多招三个人还是少招三个人。这些预测也好，帮助我就是做一些商业决定。",
      "speaker": "发言人5"
    },
    {
      "time": "01:48:43",
      "text": "其实我需要有大量的数据去问会给他，对吧？不管是微调还是各种各样，其实有各种各样的方式方法去把把这件事情给做起来，包括你前面提到的embedding，embedding虽然说不解决length的问题，但是能够potentially是能够在32K的这么一个限制下面，能够把最最有效的数据给送进去。所以实际上这件事情是可以做的，但前提是我的我的一个公司的这个数据能够打通，能够是一个数据驱动。然后要有这么一个去去去一个conviction。应该说还要有一定的执行能力去把这件事做做起来。",
      "speaker": "发言人5"
    },
    {
      "time": "01:49:30",
      "text": "其实我看了不少公司，包括我自己，我最近也换了公司，或者说我其实跟很多的大公司都有联系，其实这件事情是一个很难做的一件事情。刚才说的还只是一个痛点，还有痛点我还没说，就是像这种complaints来，或者说是比如说GPT现在能够写code。对，刚才那个张也提到了，写的还不够好，但是其实很多东西是能写的。但绝大多数的财富五百的公司，它是不会让chat PD来给你写code的。为什么他都不知道这个compliance就是合规性，对吧？以后是不是有法律上面会不会有纠纷。所以说大公司，全球的前一千前两千的大公司，其实在这方面，因为我刚才说的这个文化上面的需要改变一些，这个数据上面打通是需要做很多事情。",
      "speaker": "发言人5"
    },
    {
      "time": "01:50:30",
      "text": "然后对于这些这些公司合规，担心他在那边换那个幻觉或者怎么样。其实把这些因素都都加起来，我觉得其实其实要去adopt，其实还是一个蛮长的一件事情。所以说我是觉得从我们消费者的角度来讲，这是已经非常明显的。",
      "speaker": "发言人5"
    },
    {
      "time": "01:50:59",
      "text": "从大公司的角度来讲，我觉得这是一个还是蛮漫长的。但是还有一个我没提到的是应该说是最exciting的，或者相对来讲是最exciting的。其实就是一个相当于是GPT native的，或者说大语言模型原生的公司对吧？这些公司都是这个时代生成的。这些公司我觉得他们会颠覆颠覆很多我们今天知道的那些incumbent意见。",
      "speaker": "发言人5"
    },
    {
      "time": "01:51:30",
      "text": "我们你们可能都知道一个数据，对吧？比如说一个财富五百的公司，它大概每隔二三十年就大约就是轮换，或者说大致就轮换一圈。也就是说30年前的财富五百的公司，其实没几家今天还在财富五百。这个轮换其实是在过去50年、60年，这个速度是越来越快。我觉得在AI这个时代，在这个大模型这个时代，这个轮换可能会更加快。完全有可能过了15年，不需要20年、30年、15年。绝大多数今天我们知道的财富五百的公司，就不在财富五百的里面了，但是对于那些原生的，大模型原生的公司来讲，我觉得他们的执行力应该会快一点。",
      "speaker": "发言人5"
    },
    {
      "time": "01:52:19",
      "text": "这个是不是有点像当年这个，云计算刚起来的时候，也是大家觉得说这我怎么可能把数据放到云上？就说这个大公司都不愿意去尝试，都是一些小公司，这clone native的公司，慢慢的起来。但是然后到了现在，过了时隔了十几年，这些大的公司才开始在慢慢去adobe这个云计算。就现在我们看到了很多不用的理由，是不是随着这个时间的演进，其实慢慢也许未必成为最终的一个阻碍了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:52:49",
      "text": "对我觉得你提到的一个原因，其实每一代我们其实前面也讲到了，其实每一代都是一样的。之前互联网也是一样，对吧？你那个互联网出来了，出现了amazon也出现了，不是出现了一个amazon，但是当时候的在位者是walmart，right? 然后walmart是怎么应对的？Amazon是怎么去去来来用好互联网这个技术的。然后云计算也是对这个事物的发展永远都是差不多的。只有在位者他总会有一堆的，其实是原因，或者说理由，或者借口。不管你怎么说，是是是是比较相对来讲比较难一点，这也是很自然的。",
      "speaker": "发言人5"
    },
    {
      "time": "01:53:34",
      "text": "那你说对于一个要在AI这个领域的一个创业公司来说，那既然像浩伟刚才说的那反正这一些本身这一些财富五百强一千强的公司，你首先也不是本身就不是新技术的early adopter。而且你可能说不定你这个公司未来也要被改变。那是不是对于一个创业公司来说，我应该在这个时候我应该focus在我的用户群，应该是这些愿意接受改变这种中小型的或者全新的公司，而不要太早的去去打这些大公司的主意。",
      "speaker": "发言人1"
    },
    {
      "time": "01:54:08",
      "text": "那肯定是有一定道理的。就像amazon当年AWS亚马逊的云计算部门，它前五年基本上都是或者说绝大多数从数量上来讲，至少他的客户都是start up。到时候可能也就只有两三家公司是稍微体量大一点的。绝大多数的客户都是start up，都是初创公司，其实是一回事情。对，从这个角度上来讲是，但是有一点你也要稍微谨慎一点的，就是startup能够给你带来的价值，除非这个startup是往上走。",
      "speaker": "发言人5"
    },
    {
      "time": "01:54:47",
      "text": "几个硅谷的公司，它它的成长是因为他卖给了uber跟AMBMB。在早年后来uber AMBMB变成大公司，那他也变成大公司了对吧？像对twitter，twitter就是其中的一个example.",
      "speaker": "发言人5"
    },
    {
      "time": "01:55:00",
      "text": "也是跟着LBNB。",
      "speaker": "发言人1"
    },
    {
      "time": "01:55:02",
      "text": "对，觉得你是有可能的。但是并不是说这这是这是一个easy pass。因为也有很多公司就跟着小公司，就是客户都是小公司，其实也没做起来。You have to be careful。",
      "speaker": "发言人5"
    },
    {
      "time": "01:55:17",
      "text": "我也要听听洪博士你的你你的这个看法。",
      "speaker": "发言人1"
    },
    {
      "time": "01:55:20",
      "text": "我还是非常认同徐老师刚才那些观点的对，包括现在虽然大家都在谈论GPT ChatGPTGPT four，但实际上我们去看身边的人，身边的企业，真正把它用在每天的工作和生活里面的，其实还是尝鲜者。然后认识的一些科技公司和AI公司的CEO，其实已经在自己的公司里面去主动去推广。现在t GPT这还有copilot这样的工具了。但是这件事儿对于大部分公司，尤其是传统公司来讲，可能还是一个相对比较复杂和漫长，并且有非常多的考虑因素的一个过程。",
      "speaker": "发言人4"
    },
    {
      "time": "01:56:14",
      "text": "这件事儿就有点像可能20年前大家都在做，叫信息化对吧？就是搞IT那个就大家要做业务流程重构。现在有了AI以后，其实拿着AI其实也是要重新去做一遍AI的业务流程重构的那要做这样的流程重构，实际上你既要理解AI也要理解这个业务流程。所以这个时候其实是需要一个施工队这样的角色存在的。这个施工队就是说他能够既理解AI又去愿意下沉到每一个复杂的业务流程里面去去看我怎么样把类似于GPT的技术，或者是更复杂的一些GPT，加上各种各样的model或者API的技术，做成一个的解决方案。来帮助这些互联网企业或者更加传统的企业来完成AI的业务流程重构。我认为现在应该是一个缺位的机会，就是专门很擅长做这件事儿，并且愿意下沉到一个的企业里面去做这件事儿。",
      "speaker": "发言人4"
    },
    {
      "time": "01:57:36",
      "text": "对，这是一点看法。而企业服务里面实际上要下沉下去，还是挺难的，尤其在中国会有普遍的定制化和私有化的需求存在。那从技术上讲，从在开源模型的基础上去做垂直领域的调优。对于以前那些做AI企业服务的公司来讲，技术门槛和研发成本其实是不算高的这里面最大的风险应该还是在于通用模型的进步，应该会迅速提升在长尾场景的表现。比如说我们看到的从GPT3.5到GPT four发生的事情。在法律或者医疗的一些场景，GPT four直接就超过了以前所有的专用的模型。",
      "speaker": "发言人4"
    },
    {
      "time": "01:58:29",
      "text": "当然话说回来，如果有足够强的数据壁垒，其实还是会保持这种定制化的。目前还是会保持相当长时间的竞争优势的。只是这个市场可能会逐步的会被蚕食。然后最后剩下的主要差异化优势可能就是定制化和根据业务流程重构的过程所做的私有化。",
      "speaker": "发言人4"
    },
    {
      "time": "01:58:56",
      "text": "是不是以后企业都会倾向于自己用一个本地的大的model，可能它是基于某一个开源的模型去改造的。还是说以后大部分的企业都会用一个open I这样的一个这种API的这种形式。",
      "speaker": "发言人1"
    },
    {
      "time": "01:59:13",
      "text": "这里会有一个关键的因素，就是在这个差异化的场景里面，到底有多少是跟智能相关的，跟intelligence是相关的。其实一个更强的foundation model，它相对于一个专用的model，更多的是它的智商更高。那这个智商到底对于这个场景是不是必要的？如果不是必要的那仿真是model就不是必须的。对我是这样来看这个事儿。",
      "speaker": "发言人4"
    },
    {
      "time": "01:59:43",
      "text": "我觉得这个可能需要底层的计算平台或者叫infrastructure要有革命性的提升，我觉得才有可能。因为现在就是现在其实大家谈到这个GPT4，虽然这个。好像所有人都在谈，但是大家这个用的很少。其实对于这个普通用户的话，好像现在还有一个每分钟还是每小时25个query的限制。就导致这个模型其实即使很强，也没有办法现在放到日常生活当中去。即使在微软就是我们的GPU resource就为了支撑包括bean包括open I包括各种GPT model的inference edge那边其实已经非常吃紧了。然后再就是市面上怎么买到更多的A1版或者新的H1版。",
      "speaker": "发言人2"
    },
    {
      "time": "02:00:42",
      "text": "现在所有的这个东西都是based on英伟达一家公司，然后英伟达based on台积电，台积电based这个阿斯迈尔对吧？就是一环扣一环的，想提升产能非常的难。这不是说有钱就能买得到现在这个问题，而且这是中国大陆还面临着A100的禁运，对吧？我不知道这个事情有没有缓和，最近。所以就是大家想用好这个模型，广泛的用的话，我们必须得把它做小，或者是把它做快把它做的更便宜。因为现在已经到了人类的整整个整个地球都拿不出足够的100让所有地球人使用的这么一个奇怪的场景了。一年之前没有人会想得到。",
      "speaker": "发言人2"
    },
    {
      "time": "02:01:26",
      "text": "对，然后之前我听说他们甚至还在让微微软在给那个open a提供他们在建建一个新的data center的时候，他们还在考虑要放在美国的哪个州。因为好像大部分的州的电网并没有办法支持这么一个强大的电缆战略。最近到了一个人类工程能力的问题的层面了。所以对，希望很快就能解决这些问题了。比如说用能不能不用GPU？如果这个模型已经做好了，我们能不能用LPGA，我们不需要改模型的情况下，能不能IPJ这一系列的。对我觉得甚至在这个硬件层面会有一波新的startup，专门就是做这个hardware dedicated to transformers对吧？这个就是为了serve这个model，他并不是用这个model，但是我觉得这个潜力也很大。因为毕竟现在市面上真的只有英伟达这一家公司，AMD也有。对，但是AMD相对份额比较少一点。",
      "speaker": "发言人2"
    },
    {
      "time": "02:02:22",
      "text": "最后一关于这个应用的这个角度，我们现在也看到，其实各种无论是VC的这个hipe，还是start up创业的热情，觉得就感觉很像当年可能像当年的移动互联网开始时候，出现涌现出了无数的公司。尽管他们很多当时看上去都像一个，都还像一个玩具一样。我们听众里面也有很多想要做AI创业，或者正在做AI这一块创业的同学，就是你你会给大家怎样的建议，怎样去在这个时候如何去思考我的这个产品go to market这个壁垒，还有我的这个产品的一个长久的竞争力。浩伟你会给大家怎样的建议？",
      "speaker": "发言人1"
    },
    {
      "time": "02:03:03",
      "text": "莫妮卡同学如果我知道了，明天就自己去做了。我觉得是大概思路我是这么想的，就是我们能够看到的应用，包括那些chat PT plugin的应用，不就是买机票、订饭、送菜对吧？这种可以做的更加方便一点。但我个人认为如果只是这些应用，只是靠增加订饭、送菜饭、买机票的提高这些效率。我其实都不知道我们做这个AI这件事情是利大于弊还是弊大于利。我是比较乐观的，就是AI能够带来的不只是说是一些我们今天看得到的这些事情的效率，那些当然也是需要也是很很不错，而是去改变一些，去去去让我们去改变一些以前认为是mission possible，或者说以前觉得变化很慢的一些事情。",
      "speaker": "发言人5"
    },
    {
      "time": "02:04:00",
      "text": "怎么说呢？也说穿了就是到我们这个IT领域之外去，对吧？不管是医疗也好，mechanical engineering也好，或者说是什么领域也好，到各种各样的领域里面去去去帮助他们，去帮助。",
      "speaker": "发言人5"
    },
    {
      "time": "02:04:16",
      "text": "特别是法律领域。因为我的我的女朋友是律师，就是我发现法律领域其实是一个天然壁垒特别高，但是效率特别低的领域。法律公司倾向于养很多人，但是干很少的活，而且收很高的费。如果有ChatGPT对吧？我开一家法律公司，我找有有牌的律师，但是我只顾大公司，可能10分之1的人，但是我训练我所有的同员工，让他们熟练使用GPT，就是帮他们不用做很fashion的东西，就做比如说日常的这个文件处理，让他们的效率提高十倍，对吧？我觉得是这个可能有可能，然后我们收费很低，这就是一个社会性的变革，这可能会改变这个世界的法律体系。对，可能我想的比较满意了。但是我觉得这可能就是打破这个社会壁垒，是这个新的技术可能对人类最大的价值。",
      "speaker": "发言人2"
    },
    {
      "time": "02:05:13",
      "text": "没有我觉得讲的很好啊，我觉得你想的肯定有拿义务的一点。那是因为就像律师这一行业，IT进去颠覆他这件事情迟迟没有发生，所以说肯定不只是一个技术的原因，对吧？因为如果说是如果说是如果只是技术的原因，那那说老实话，过去20年这个律师行业本来就应该有很大的变化，然后我们今天可以给他新的变化，其实这个行业过去20年没有变化，从这一点你就能够看出来，肯定不只是技术，对吧？但是我我我是非常同意你的，就是要从各种各样的行业，包括你说的这个律师行业。就是我是觉得以前大家认为已经到天花板的那些行业。其实每个行业我们说三百六十行，对吧，每一个行业都觉得这是天花板。我会比较chAllenge的是，每一个行业的天花板是不是都可以是十倍、100倍这么一个去思考，用过去的方式方法去去思考，跟今天的方式方法三百六十行对吧？",
      "speaker": "发言人5"
    },
    {
      "time": "02:06:21",
      "text": "他为什么做做事情演变特别快？它其实有一部分就是它的IT化还比较低，它的数字化还比较低。那对于我们像硅谷，google facebook这些大厂，微软这些大厂，招这些程序员的是感觉是已经是天经地义的一件事情，没什么对吧？但是其实对很多我们IT行业之外的，要找到好的程序员，让他们做事情，让他们把把数字化。其实这件事情不容易的。",
      "speaker": "发言人5"
    },
    {
      "time": "02:06:52",
      "text": "然后我们我们我们同意微软的CEO萨提的一句话，就是大家都在说这个program的job是不是会被程序员马工的工作会不会被替换掉，他觉得不会，他觉得最终我们增加的是对我们这个世界的digital currency是会增加。也就是说我们的所谓的programmer或者说马马工的能力，其实就是把一个物理世界的事情把它给转换成数字化。然后数字化在不断的优化。这些事情在有些公司在就像我说的，在大厂已经是司空见惯的。但是其实除了除了这些IT领域，其实这件事情是以比较低效的缓慢的在往前走。",
      "speaker": "发言人5"
    },
    {
      "time": "02:07:40",
      "text": "举一个例子，自动写代码这一点增加了digital currency，增加了世界上千千万万家公司的digital currency，会不会对他们做事情的效率提升。然后他们做事情效率提升又在他们每一个行业的那个就是本来认为天花板在这里，但是我因为做事情的效率提升了10倍20倍以后，然后我的天花板也在往往上走。这是我觉得是一个比较顺理成章我去能够思考的。包括在生命科学，在在今后若干年之内，AI大致都能够帮我们解决到一定什么程度。我觉得这个还是蛮有希望的。当然了，技术永远不可能解决所有的问题。我相信技术，即使技术解决了我们今天所有知道的病，到时候人类又有新的问题。对我就先说这么点。",
      "speaker": "发言人5"
    },
    {
      "time": "02:08:36",
      "text": "我自己个人其实非常看好poy前面说的一个AI native的organization。就是我觉得我们现在讲很多用AI的这个场景，都还是说我怎么把它去提高效率。就基于现有的组织结构的情况下，我觉得他对我们效率提高之间已经到了一个所谓的基点，或者说这个临界点。因为我我有时候在身边去聊一些这种比较新型的一些比较初创的一些公司，你都能感觉到就是它的这个GPT能够或者AI能够带来的这个效率提升，已经让大家去重新的去思考。",
      "speaker": "发言人1"
    },
    {
      "time": "02:09:12",
      "text": "我下面这个team不只是说我是多招人还是少招人的问题。而是说当我自己我作为一个可能一个team leader，就我有了这个我自己都有了AI这个能力。我一个人就像一支队伍的时候，我下面的人需要的这个素质可能它都是不一样的。从整个组织角度来说，我觉得很多以前的junior的工作，比如张一提到法律这个领域里面很多junior种association的工作，干的就是GPT做的summarized的这些活。那这些人的需求变少了以后，他们的repeat又是怎么样？我们现在整个大的公司体系都是基于一堆junior的人，慢慢怎么培养他们在公司里面的career pass class这个corporate letter，在公司里面爬梯子这样上来一个组织。那以后这整个组织会不会也会变化？因为我们每个人教经过我们的不同的教育。",
      "speaker": "发言人1"
    },
    {
      "time": "02:10:03",
      "text": "可能我出了学校了以后，我的能力也跟现在大学生能力也很不一样了。对，所以我觉得说我自己个人是更乐观派一点，我觉得这个改变会是非常非常fundamental的这个东西。我们最后closing的一个话题，我们还是展望一下未来。对于AI的未来，你们自己个人觉得最让你们觉得兴奋的一个点会在哪？",
      "speaker": "发言人1"
    },
    {
      "time": "02:10:26",
      "text": "我觉得可能对未来比较一个赛季的事情，可能有一个点就是说要有一个理想主义和现实主义的这个区分。我往往在讨论AGI，我觉得更多是在强调理想主义，我们能不能达到完全的人工智能。但是你看现在其实即使GP4这种模型没有完全实现一些，但是它已经解决了大部分的问题。我已经产生了非常大的影响，而且帮到各行各业的提升效率。在在这种情况下，我是是不是达到了AGI，其实已经没有那么大的重要的关系了。只要我能解决好的是提升现在的一些生产流程的效率，我觉得目的已经达到了。",
      "speaker": "发言人3"
    },
    {
      "time": "02:11:15",
      "text": "现在沿着现在大语言模型的方向往下走，应该是能够变得更加的第一个是多模态，第二个是和世界交互，第三个是是是偏向action，或者说机器人或者自身的人工智能。这种方向往下应该会有一个大突破。我们把人的智能，比如说可以做一个拆解。首先是大脑，大脑里边语言又又是一个最核心的能力，是区别于其他动物的一个关键点。现在的语言模型看起来把大脑的，尤其是语言方面的一些能力做的还非常不错的那往下我们就要接入，比如说眼耳鼻、眼睛、耳朵、鼻子嘴巴以及我们的手和脚，还有我们和这个世界的互动。沿着这个方向往下去发展的那一定是能够丰富我们对于AGI的能力的体现。同时也给我们创造了足够多的机会，让我们去去往下去开拓或者去尝试。这是我谈谈对未来的一些讲。",
      "speaker": "发言人3"
    },
    {
      "time": "02:12:25",
      "text": "我们可能关注的问题更学术一点，就是说怎么样更好解决大模型现在的这些问题。如果如果能解决好这些问题之后，应该他能有一个质的飞跃。那个是什么呢？我们现在都不好假设，我们也猜不到那是什么。对，有可能是一个完全不同的，跟现在的大模型完全不同的一个。然后我比较希望想看到就是在未来的很短时间内，大家能够逐渐打开这个大模型训练的黑盒。",
      "speaker": "发言人2"
    },
    {
      "time": "02:12:59",
      "text": "就现在大家对这个训练的各个方面的探索，其实还是处于非常初级的阶段。基本上就是把所有我能够有的数据全扔进去，然后就用所有的卡混在一起训练。训练完了之后微调，然后可能再加上ROHF。但是我觉得有一点非常重要的是，到底什么样的数据我先扔进去，而且有没有顺序。比如说大家口口相传的时候会有一个秘密，就是他们的模型是现在代码上训练，然后再在这个通用的NLP文本上训练，我觉得这个非常make sense。对，到底是不是这样我也不知道，但是就感觉学术界还对这个东西缺乏探索。然后我觉得这个东西如果都摸清楚了，以前我们可能需要好几去年的token可能如果我们浓缩好了数据之后，可能只需要hundred million或者甚至几十B年，然后模型可能也可以变小。对，那个时候的话，大模型可能会变得更有用。然后更多的探索会在更多的公司会加入进来，然后更多人也会愿意使用。我希望可能在未来的一年之内看到的事情。",
      "speaker": "发言人2"
    },
    {
      "time": "02:14:11",
      "text": "非常有意思。inside.",
      "speaker": "发言人1"
    },
    {
      "time": "02:14:12",
      "text": "首先我觉得今天在座应该大家三号不管是从什么路径推导出来，应该对于AGI会到来这件事儿没有太多的怀疑。然后在在中国其实跟美国还是会有一点差异，因为中国起步还是有点晚了，我们还是一个追赶的态度，所以没有太多人去关心一些前沿的研究，或者是一些主要是研究。但实际上在AI领域是有很多很多的前沿科学问题需要研究的。比如说包括模型本身的，比如说数据，刚才张弋也提到了数据到底应该怎么用，相当于语言的数据，我们是先把它去做token ize对吧？Token ize其实本身就是一种压缩。压缩了以后我再用GPT进一步的做压缩，我获得了智能，这是一种用法。那对于图像到底应该怎么用？对于视频我应该怎么去做tokenizer，还有对于其他模态的数据，这个是不知道的。",
      "speaker": "发言人4"
    },
    {
      "time": "02:15:24",
      "text": "然后还有刚才我们聊到的代码数据跟文本数据，其实它都是支持的。代码数据可能是包含了一些任务的解决和逻辑推导等等。就这些数据到底该怎么精细的去用，现在的研究是没有那么深的。因为过去很长的时间里面，以open a为首的公司其实还是在摘那些低垂的果实。到了现在这个时间点上，skill up这件事儿已经变得越来越困难了。",
      "speaker": "发言人4"
    },
    {
      "time": "02:15:56",
      "text": "我们是需要静下心来去看一看这些更加精细的科学问题的那就包括模型本身的数据，也包括算法，有没有比transformer更好的架构，也没有更好的去解决这个长记忆的问题的方法。还有一些很重要的科技实现的研究。我们得知道什么东西是记忆，什么东西是泛化。然后在什么阶段模型会倾向于去记忆，在什么阶段开始去做泛化。然后记忆的水平和泛红的水平，在我们训练的每一个阶段它是怎么变化的。我们得去理解训练好的这个模型。当我们理解了以后，我相信我们会看到很多新的提升的手段。然后再一个是对齐alive，在中国关注可能非常少，但在全球范围内其实讨论是很多很多的。包括一些知名的AI的科学家也在讨论这件事儿。",
      "speaker": "发言人4"
    },
    {
      "time": "02:16:58",
      "text": "怎么样能够让这么模型按照人的旨意来显示，不只是去解决一些幻觉的问题，还有未来可能会出现的一些怎么去控制模型的问题。因为那个基点到达人类智能水平的或者叫认知水平的基点，是很有可能不会花太长的时间就能达到的那超过那个机电以后，我们还能不能控制它，现在其实是一个未知数。不过我们现在就需要去花很大精力做这个事儿。所以我认为在最前沿的科学研究，是需要把可解释性或对齐放在非常高的优先级来做，这是模型本身。然后模型以外也有，比如说我们需要更好的这个存储模型的存储，对吧？",
      "speaker": "发言人4"
    },
    {
      "time": "02:17:50",
      "text": "HBM现在应该到了第三代，那未来chip let的技术有没有可能把摩摩尔定律更快的往前推？然后机器人的技术，我们刚才聊到一些最深的。当我们把GPT的脑子做好以后，怎么样能够有一个最新的机器人来解决各种各样的问题。比如说自动驾驶汽车，比如说家务机器人。",
      "speaker": "发言人4"
    },
    {
      "time": "02:18:12",
      "text": "还有一个很重要的就是AI for science。其实上一次人类的科学家是比较少的，顶尖的科学家就更少。如果一个AI成为科学家的助手，甚至说有超过科学家的一个认知水平，它是否能够快速的推进我们科学的进步。比如说在在生命科学领域，在材料领域等等。目前的一些技术，他就有点像从人类知识里面去做蒸馏，他在学人类的知识，人类在互联网上留下的知识。人类有多少知识，其实它就有多少智能。那怎么样让他能够有获得更多的智能呢？所以就需要人类还是要在科学上有更多的突破，比如说去做更好的观测仪器。",
      "speaker": "发言人4"
    },
    {
      "time": "02:19:02",
      "text": "阿尔法food为什么能做出来？是因为我们人类科学家发明了去观测蛋白质结构的仪器。然后我们知道了一些氨基酸序列怎么就变成了这种蛋白质的折叠。有了这些数据以后，我们才做出来了f fold这样的算法，从而帮助科学家们去预测新的一些蛋白质结构。其实还是很依赖人类的知识在里面的，所以我就非常希望可以有更多的人参与去研究AI或者是把AI用于解决科学问题。这样我们可以拿到人类可能有史以来最大的福利，就是一个可以无限复制的很强的人工智能，从而推动人类文明的进步。这是我个人的一点想法。",
      "speaker": "发言人4"
    },
    {
      "time": "02:19:55",
      "text": "因为我们知道AI无非就是算法算力数据，对吧？刚才张毅博士也说了，那个数据上面不只是一个暴力的丢进去，有可能sequence来，有可能curation各种各样的方式方法，其实有很多潜在的东西要去做。我们今天只是一个冰山上面的一个一个非常非常一个小的角，我们touch了一下，我们触摸了一下，其实还有很多的事情要做。",
      "speaker": "发言人5"
    },
    {
      "time": "02:20:24",
      "text": "从一个算法上面来讲，其实我们刚才也讨论了transformer model这个大大模型其实有很多的可以去提高的。我是我是做做操作系统，做并行处理出身的人从我的角度来看，只是光是从并行处理这个角度来讲，我一看这个transformer这个model，那就应该有很多提升空间了。然后从算力的角度来讲，刚才我们也提到了NVIDIA，它的从V100到A100到现在的H100，每一每一个代每一代的提升都是很显著的。就是我们看到一个不像就有点像90年代的那个看intel的CPU觉得看不到天花板后，但是到后来我们在intel的芯片上面看到天花板了，对吧？那个基本上到了三个gay hts左右，基本上就到顶了。所以说我是觉得未来最让我感到激动人心的一点是啊这个领域没有看到天花板，是是是最大的一个是最大的一个让我激动人心的地方。",
      "speaker": "发言人5"
    },
    {
      "time": "02:21:43",
      "text": "好了，非常感谢几位。今天的时间我们聊了三个多小时，我觉得非常尽兴。今天聊的每个话题都值得专门再去做更深入的探讨，而且都是很多其实也没有答案，也是很希望未来在AI股未来的发展中，能够我们会有更多组织更多这样的讨论。很难想象现在离出来GPT出现出来才不到半年的时间，我们已经发生这么天翻地覆的变化。我相信未来一两年也会有更多有意思的事情发生。",
      "speaker": "发言人1"
    },
    {
      "time": "02:22:14",
      "text": "好，谢谢monk，谢谢大家。",
      "speaker": "发言人5"
    },
    {
      "time": "02:22:17",
      "text": "感谢大家的收听。如果你喜欢我们pocket内容，欢迎你点赞并分享给可能感兴趣的朋友。有任何建议反馈都可以在评论区留言，我们都会很认真的看的。如果你在用apple podcast收听，也希望你花几秒钟给我们打个五星好评，让更多人了解到我们我们下次再见了。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "在这次讨论中，参与者探讨了人工智能（AI）的未来发展，特别是大模型如GPT在提升生产效率、解决科学问题及推动社会变革方面的潜力。讨论聚焦于AI发展的关键方向，包括多模态、世界交互能力及AI的行动偏向，以及确保AI高效可控的可解释性和对齐研究的重要性。数据高效利用、算法优化、硬件进步尤其是GPU技术，和AI在科学研究中的应用被视为推动AI领域发展的关键因素。未来AI发展强调跨学科合作及伦理和对齐问题研究的重要性，以确保技术进步的同时保障人类利益和安全。讨论还涵盖了“通用人工智能”（AGI）的概念，评估AI智能的挑战，以及AI伦理和安全问题。讨论认为，通过优化大语言模型和专家模型的协作，可提高AI的整体性能和适用性。参与者对AI的未来持乐观态度，相信AI将在更多领域发挥重要作用。",
    "qa_pairs": [
      {
        "question": "张译博士，您能否简单介绍一下微软研究院关于GPT4能力研究的背景？你们是如何验证GPT4具备通用人工智能特性的？",
        "answer": "当时微软内部有一项绝密项目，大约有100到200人参与，他们在拿到比现有公开GPT4更强的内部模型后，对其进行了深入研究。尽管目前公众所使用的GPT4版本在安全性等方面进行了微调，但微软的研究更多关注于如何在保持模型强大的同时，尽量减少对其实现通用人工智能能力的影响。我们设计了一系列任务，包括一些非常规但可以通过有效推理解答的问题。即使这些任务中包含了一些网上难以找到的具体信息，GPT4依然能够出色完成它们。此外，我们还发现即使给模型提供纯文字输入，它也能对图片中的物体相对位置有良好的感知，并能识别常见物体的形状，这进一步证明了其通用人工智能的特性。",
        "time": "00:08:26"
      },
      {
        "question": "那么，您如何评价GPT4模型是否代表了真正的智能？",
        "answer": "我们认为GPT4在解决一些看似复杂但实际上需要推理和常识的问题上表现出的能力，确实体现了某种程度的智能。例如，它可以解决高中层面的组合数学题，这表明它具有一定的常识和推理能力。不过，对于是否达到通用人工智能的标准，学术界对此仍有争议，但GPT4展现出的通用性和广泛适用性无疑是显著的。",
        "time": "00:11:54"
      },
      {
        "question": "AGI的定义是什么，它是否具备普遍性和无所不能的能力？",
        "answer": "AGI是指人工通用智能，它能处理多种类型的信息，如图片、文字，并且能进行谱曲、写代码等任务。它能理解并应用到不同的场景中，看似具有无所不能的能力。",
        "time": "00:16:11"
      },
      {
        "question": "目前对于“intelligence”的定义是否清晰？",
        "answer": "“intelligence”的定义在历史上并不清晰，尤其在AI领域，直到现在有了像GPT4这样能够展示高级推理能力的模型，我们才需要重新思考和定义intelligence。",
        "time": "00:17:39"
      },
      {
        "question": "网上流传的GPT4与实际模型有何不同？如何评估GPT4在写代码方面的表现？",
        "answer": "网上常见的是对GPT4的误解，实际上不同的GPT4模型在不同指标上表现差异很大。例如，在写代码的能力评测上，原始的GPT4版本远高于人类平均水平，但在公开版本中，写代码能力大幅下降，说明模型存在过拟合现象。我们使用了独特且未在网上公开的测试集，通过手动设计的例子来评测GPT4的写代码能力，确保测试例子未在网上出现过，以真实反映其能力。",
        "time": "00:18:54"
      },
      {
        "question": "GPT4在视觉空间理解上表现如何？",
        "answer": "GPT4即使未见过特定视觉数据，也能在视觉空间理解方面表现出较好的推理能力，这可能是因为其训练数据中包含了大量以书面形式展示的信息，如代码和文本注释等。",
        "time": "00:21:49"
      },
      {
        "question": "GPT4是否能通过文字指令生成和修改代码或音乐？",
        "answer": "是的，GPT4可以理解并生成相应的代码或音乐，尽管质量可能不如专业模型，但已经能够实现基础的交互式生成和修改功能。",
        "time": "00:23:38"
      },
      {
        "question": "GPT4能否处理特定格式的图片和音乐训练数据？",
        "answer": "GPT4有可能接触到过特定格式的图片（如SVG格式）和音乐训练数据，因此能够识别和生成相应的代码或进行基本操作。",
        "time": "00:24:31"
      },
      {
        "question": "GPT4在解决复杂问题时的表现如何？",
        "answer": "GPT4在解决复杂问题时表现出超过人类平均水平的能力，因为它在所有已知领域都能达到高中生甚至更优秀水平，而无需考虑人类常犯的主观性和非理智决策因素。",
        "time": "00:28:44"
      },
      {
        "question": "在GPT4和3.5之间的差距中，参数量是否是决定性因素？new bing搜索引擎与GPT4相比，在解决幻觉问题上的优势是什么？",
        "answer": "是的，GPT4的参数量肯定远大于GPT3.5，可能至少大1到2个数量级。new bing会在返回结果中提供来源网页链接，一定程度上解决了幻觉问题。但其推理能力仍不如GPT4，可能需要在数据或模型训练层面进一步改进。",
        "time": "00:30:27"
      },
      {
        "question": "对于模型的限制，例如house station等现象，大家如何看待解决这些限制的方式？",
        "answer": "大家讨论的重点不仅是当前是否存在这些限制，更是思考如何解决它们。讨论点包括是否需要在模型层面做出改动，还是通过工厂端的工程改良逐步解决。",
        "time": "00:31:25"
      },
      {
        "question": "GPT模型在推理能力上的明显不足是什么？",
        "answer": "GPT模型的一个主要问题是缺乏规划能力，无法像人类那样进行试错和调整，一旦写下某个词就无法擦除，而在解决复杂任务如数学问题时，它会直接给出答案而非逐步推导过程。",
        "time": "00:31:57"
      },
      {
        "question": "是否可以通过调用GPT API的方式实现试错过程，以改进其解决方案？",
        "answer": "这种想法是可行的。陶哲轩等数学家已经使用ChatGPT在其数学研究工作中获取灵感，并通过多轮调用API、提供不同prompt的方式模拟试错过程，最终得到有效的解决方案。",
        "time": "00:33:31"
      },
      {
        "question": "GPT4在认知知识阶段上处于何种状态？",
        "answer": "目前GPT4可能处于学习认知知识的早期阶段——“我不知道自己不知道”，会凭空生成内容或在解码过程中逐步生成答案，缺乏对错误预测内容的信心调整机制。",
        "time": "00:38:09"
      },
      {
        "question": "如何让模型意识到自己的不足并提高准确性？",
        "answer": "一方面可以通过增加模型本身的训练，使其从更准确的grounding材料中学习；另一方面，整个解决方案的提升也很重要，例如引入更强的环境互动和反馈机制。",
        "time": "00:41:33"
      },
      {
        "question": "从模型训练角度，有哪些方法可以减少幻觉现象？",
        "answer": "除了增强模型的基本能力和利用先进技术如RLHF和IOAIF外，还可以改进训练方法，如在训练过程中给予模型更精确的反馈，以及探索检测模型状态并独立训练分类器来判断模型输出的有效性。",
        "time": "00:42:49"
      },
      {
        "question": "GPT4是否是通往AGI的最佳途径？",
        "answer": "目前还不清楚GPT4这种暴力的语言模型是否是通往AGI的最好途径，需要进一步探讨其推理过程和逻辑认知层面的技术方法。",
        "time": "00:45:10"
      },
      {
        "question": "GPT4在训练过程中为何会犯很多错误？",
        "answer": "GPT4因为思考太快，往往快速给出答案而忽视过程，导致错误。如果强制它放慢速度，表现会更好，但这涉及到训练数据结构的问题，大规模修改该数据结构目前尚无解决方案。",
        "time": "00:46:28"
      },
      {
        "question": "如何解决模型在处理多模态信息时的局限性？",
        "answer": "解决多模态问题的关键在于从预训练阶段就开始引入多模态数据，例如视觉信息，让模型能够更好地推理和理解不同模态的数据。但目前还没有明显的方法来实现这一目标。",
        "time": "00:48:58"
      },
      {
        "question": "是否可以通过模型结构上的改变来解决模型思考过快的问题？",
        "answer": "问题的核心可能在于模型层面，而非单纯的数据结构问题。可以通过在模型上添加限制，使其更倾向于学习慢思考的结果，但具体实现方法仍是一个挑战。",
        "time": "00:49:54"
      },
      {
        "question": "GPT4认识图的能力是否仅限于fine tuning？",
        "answer": "GPT4对图像的认识并非仅通过fine tuning实现，而是基于预训练的图像特征表示与GPT模型结合，将其作为一个multimodal model进行训练。",
        "time": "00:52:25"
      },
      {
        "question": "业界是否有尝试在free train阶段直接加入多模态数据？",
        "answer": "业界确实有尝试在free train阶段加入多模态数据，如OpenAI在GPT-2之后做了image GPT，不过当时并未将图像和文本一起做预训练，而是单独对图像进行预训练。目前学术界还没有找到一种高效且有效的方法来整合多模态数据进行统一训练。",
        "time": "00:53:45"
      },
      {
        "question": "对于未来如何让多模态信息帮助理解世界，有何看法？",
        "answer": "未来应构建严谨的评测基准，以衡量多模态信息对于理解世界的能力提升。同时，要深入研究如何利用多模态信息增进对世界的理解，这背后涉及智能理论基础的研究。",
        "time": "00:56:19"
      },
      {
        "question": "能否分享一个GPT应用的成功案例？GPT与auto GPT在概念上有何异同？",
        "answer": "GPT的核心思想是利用语言模型作为调度中心，解决复杂任务。例如，可以通过解析用户的请求，将其分解成多个子任务，并调用不同的专家模型执行这些任务，最后整合结果形成回复。GPT围绕语言模型构建复杂任务解决方案，而auto GPT更多以GPT4为基础，通过构造prompt让GPT反复迭代调用完成复杂功能，两者思想上存在一定的区别。",
        "time": "00:57:50"
      },
      {
        "question": "GPT auto GPT诞生之初的核心思想是什么？",
        "answer": "GPT auto GPT诞生之初的核心思想是让GPT4能够进行商业决策，通过分析任务需求并采取行动来帮助赚钱。它主要具备访问互联网搜索信息、利用历史角色和对话数据进行记忆管理、生成结果（如文件存储或sum range）等功能，以GPT4为核心主体自行运行。",
        "time": "01:01:04"
      },
      {
        "question": "哈根GPT与GPT auto GPT的主要区别是什么？",
        "answer": "哈根GPT强调的是GPT4或其他语言模型作为大脑进行调度决策和整合，具体执行任务的部分交给更擅长的专家模型，这些专家模型可能是语言模型也可能是其他模型。哈根GPT适用于更复杂、专业的AI任务场景，而GPT auto GPT则更偏向于流程化、事务性和商业性的任务，依赖GPT4的语言理解能力。",
        "time": "01:02:00"
      },
      {
        "question": "GPT auto GPT与GPT自身的成熟度如何？",
        "answer": "GPT auto GPT目前处于初级阶段，主要欠缺大语言模型在任务调度和解析方面的增强，目前很多开源模型在这方面的表现不如GPT系列。未来需要与专家模型结合，共同构建健康发展的生态系统。",
        "time": "01:15:17"
      },
      {
        "question": "AI解决方案的发展历程以及未来趋势如何？",
        "answer": "AI解决方案经历了早期的专家系统、神经网络、统计机器学习、深度学习模型，再到近几年的基础大模型。未来可能会出现基于基础大模型连接各领域专家以解决更复杂实用问题的转变，同时探讨了微软等公司如何构建操作系统平台让开发者基于此开发复杂任务。",
        "time": "01:04:19"
      },
      {
        "question": "是否有必要每个领域都定制一个大语言模型？现在大模型训练面临的主要挑战是什么？",
        "answer": "对于每个领域的专家模型，关键在于大语言模型能否在不同领域迁移得很好，即泛化能力强。目前一些领域的任务需求拆解和调度执行能力可能并不强，因此可能需要针对特定领域微调大语言模型，使其适应该领域的应用场景。目前大模型训练面临的一个主要瓶颈是找到既能学到新知识又不忘记旧知识的方法，尤其是在需要强推理能力的领域。尽管这是一个技术层面的问题，但随着时间推移和技术进步，这个问题有望得到解决。",
        "time": "01:05:56"
      },
      {
        "question": "如何看待每个领域都需要一个自己的大模型这一观点？",
        "answer": "考虑到当前大模型训练所需的高昂资源和风险，不是所有公司都能承担得起，所以并不认为每个领域都需要一个独立的大模型。但随着硬件升级和训练方法优化，未来可能会有更多的公司有能力训练大模型。",
        "time": "01:05:56"
      },
      {
        "question": "我怀疑调度planning的能力与大模型的哪一块能力相关性更强，比如GPT这类模型的reasoning能力还是fun tuning阶段的影响更大？",
        "answer": "调度planning能力可能既依赖于模型的contest长度，如GPT4已达到两三万长度，足够清晰描述任务；同时也需要推理和理解能力以进行决策和选择合适工具。此外，若能结合大规模数据训练，模型表现会更好。除了planning能力外，还需要提升平台层面，构建一个丰富专家模型供给的生态，让用户可以调用各种模型完成复杂任务。",
        "time": "01:16:17"
      },
      {
        "question": "为了让Hony GPT或GPT方式被广泛应用，除了planning模型能力外，还需要哪些能力提升？",
        "answer": "需要构建一个鼓励接入和丰富专家模型的新平台，使得生态内有多种模型供选择执行复杂任务。",
        "time": "01:17:34"
      },
      {
        "question": "是否可以通过构建生态，让每个人提供专家模型部件，实现模型的通用智能和快速迭代？",
        "answer": "是的，未来模型可能不再由单一公司或个人训练，而是由每个人提供特定功能的部件，通过组合这些部件形成强大的联合模型，实现1+1>2的效果。这种模式类似于GitHub上的代码包，可以灵活地将新功能添加到现有模型中，加速模型的迭代速度。",
        "time": "01:22:03"
      },
      {
        "question": "秦博洪博士和张译对通用智能体（agent）的看法是怎样的？",
        "answer": "秦博洪博士认为agent非常通用且是智能研究中的重要概念。从互联网视角看，当前如auto GPT、Qwen等都是调用大模型和API实现任务。OpenAI的插件设计体现了其关注AGI，收集数据以优化GPT模型，并可能通过学习人类如何指定API调用来完成任务来升级自身。",
        "time": "01:18:32"
      },
      {
        "question": "对于复制OpenAI的路线图还是探索不同的路径，作为追赶者应如何选择未来的竞争格局和可能的颠覆者？",
        "answer": "尽管存在多种研究路线，但目前大部分AGI研究仍然基于类似OpenAI的路线图，因为它在该领域取得了显著的成功，并且相关理论和技术已经相当成熟。DeepMind、BIC和OpenAI等公司在不同方向上有所投入，但也有人尝试诸如基于强化学习、生命科学或其他前沿技术的新路径。然而，若以明确和可行的角度看，大多数情况下仍应将重点押在基于GPT的技术发展上。",
        "time": "01:27:25"
      },
      {
        "question": "在企业落地应用时，为什么有公司能提供128K的选项？",
        "answer": "这是因为该大模型公司解决的问题产生的代价较高，使得他们在进行权衡时与其他普通聊天机器人有所不同。",
        "time": "01:32:40"
      },
      {
        "question": "您提到的“很长的country lungs”是指什么？",
        "answer": "我想要的是能够将一个人一生看到的数据或一个公司整个历史上的数据全部计算进去的模型，以获得更全面的上下文信息。",
        "time": "01:33:38"
      },
      {
        "question": "学术界在研究大模型中的时间复杂度问题上取得了哪些进展？",
        "answer": "学术界在这个方向投入的研究较少，很少有人真正打开这些大型模型去深入理解其内部运作，并在此基础上设计更高效的加速方法。",
        "time": "01:34:44"
      },
      {
        "question": "大模型在处理长文本时的优势体现在哪里？",
        "answer": "例如GPT4在早期测试中，当把整个教科书作为上下文输入后，能够直接解答出所有问题，这显示了其在处理长文本和复杂情境上的能力。",
        "time": "01:39:11"
      },
      {
        "question": "对于模型来说，较长的contest长度是否会对其架构构成挑战？",
        "answer": "这既是一个科学问题，也是一个工程问题。目前需要改进对注意力机制的理解，以及探索如何在保证模型性能的同时减少计算复杂度。",
        "time": "01:39:11"
      },
      {
        "question": "是否可以从人类记忆的特点中获取灵感来优化模型架构？",
        "answer": "人类记忆具有随时间衰减和选择性记忆的特点，而当前的transformer模型可通过研究和借鉴这些特性，优化信息筛选和存储机制。",
        "time": "01:39:39"
      },
      {
        "question": "如何打造一个好的技术生态？",
        "answer": "易用性和开放性至关重要，如同PyTorch因易用性打败TensorFlow，TCPIP胜过ATM的例子表明，易用、开放的技术更易被理解和接纳，从而推动整个生态的发展。",
        "time": "01:44:15"
      },
      {
        "question": "GPT等大模型在企业界的应用落地现状如何？",
        "answer": "虽然全球范围内都在关注ChatGPT，但真正广泛应用还需要一段时间，预计在未来一两年内，大型企业可能会开始将其技术应用于实际工作中，带来新的机会和挑战。",
        "time": "01:46:04"
      },
      {
        "question": "在AI领域，大公司和初创公司的发展路径有何不同？对于AI领域的创业公司而言，是否应该首先关注愿意接受新技术改变的中小型或新兴公司，而不是过早地去接触大公司？",
        "answer": "大公司在面对新技术时，由于内部文化、合规性要求及执行力等原因，往往反应较慢，需要经历一个漫长的过程去适应和应用新技术。而初创公司则更具创新性和执行力，更容易接受和利用新技术，如大语言模型，快速构建竞争优势。在AI时代，这种轮换周期可能会比以往更快，初创公司有可能颠覆现有的大型企业格局。有一定道理，初创公司确实可以先聚焦于愿意接受新技术的中小型或全新公司，因为这些公司在采用新技术上的接受度更高。但同时需要注意的是，并非所有服务于初创公司的都能取得成功，也需要警惕市场环境的变化和竞争对手的情况。",
        "time": "01:53:34"
      },
      {
        "question": "AI技术在企业级应用中，尤其是传统企业中推广和应用的难点是什么？",
        "answer": "主要难点包括：1) 员工和企业对于新技术的接受程度不一；2) 将AI技术与现有业务流程进行重构的复杂性和漫长过程；3) 如何在满足定制化和私有化需求的同时，平衡技术门槛和研发成本；4) 基础设施层面，如计算平台的升级以支持更大规模的AI模型运行；5) 随着通用模型的进步，如何保持专用模型的竞争优势。",
        "time": "01:57:36"
      },
      {
        "question": "未来企业更倾向于使用本地的大模型还是开放API的形式获取AI服务？",
        "answer": "这取决于差异化场景中，智能相关部分是否至关重要。如果更强的基础模型智商对于特定场景并非必需，则专用模型仍有其价值。此外，底层计算平台的技术革命性提升将直接影响企业对于本地大模型或通过API获取服务的选择。",
        "time": "01:59:13"
      },
      {
        "question": "在法律领域，你认为新技术如ChatGPT如何能够带来变革？",
        "answer": "如果使用ChatGPT，我可能会开设一家法律公司，聘请有资格的律师但人数更少，然后训练所有员工熟练使用GPT来处理日常文件处理等事务，从而提高工作效率十倍，并降低收费。这可能会引发社会性变革，打破法律行业的传统壁垒，重塑全球法律体系。",
        "time": "02:04:16"
      },
      {
        "question": "律师行业是否容易受到IT和数字化的影响？",
        "answer": "律师行业虽然IT化和数字化进程相对较低，但随着技术发展，像微软这样的大厂也认识到程序员在将物理世界事物转化为数字化方面的价值。尽管在非IT行业推广数字化存在困难，但其效率提升将使原本被认为是天花板的行业得以突破。",
        "time": "02:05:13"
      },
      {
        "question": "AI是否会替代程序员的工作，以及它如何增加digital currency？",
        "answer": "微软CEO萨提认为AI不会完全取代程序员，而是通过转换物理世界的事情为数字化并优化流程来增加digital currency。AI不仅在IT行业，在其他领域也能够显著提升效率，打破行业天花板。",
        "time": "02:06:52"
      },
      {
        "question": "AI是否会对组织结构产生影响？",
        "answer": "AI native organization是一个趋势，当AI技术能带来显著效率提升时，现有的组织结构将面临挑战。例如，在法律行业，AI能够完成许多初级工作，使得组织内部需求发生变化，可能需要重新思考职业发展路径和团队配置。",
        "time": "02:08:36"
      },
      {
        "question": "对未来AI发展的最兴奋点是什么？",
        "answer": "对未来AI发展的兴奋点在于理想主义与现实主义的结合。即使目前尚未实现完全的人工智能（AGI），但在解决实际问题、提升生产流程效率上已有很大进展。未来AI将朝着多模态、交互性和行动导向发展，有望丰富AGI的表现形式，并带来大量探索机会。",
        "time": "02:10:26"
      },
      {
        "question": "如何更好地解决大模型训练中的问题并期待的突破点？",
        "answer": "期待在短期内能够逐渐揭开大模型训练的黑盒，探索数据选择、顺序等关键问题，以便更有效地利用数据和减小模型大小。同时，深入研究模型本身及其算法架构，解决长记忆问题，理解模型在不同阶段的记忆与泛化能力，以及对齐alignment问题，确保模型按人类旨意运行。此外，还期待AI在科学领域的应用，如作为科学家助手加速科研进程。",
        "time": "02:15:56"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探讨AI变革：从GPT到通用人工智能",
        "summary": "本期节目聚焦于人工智能，特别是AI能力的评估与理解，及其对社会和各行业的潜在影响。随着大模型和生成式代理如GPT的进展，通用人工智能(AGI)的实现似乎更加接近。通过与一线研究者和从业者的对话，探讨了对GPT4模型的深入测试发现，以及离实现AGI还有多远。"
      },
      {
        "time": "00:01:24",
        "title": "探索人工智能领域的最新进展和技术挑战",
        "summary": "本次节目中，来自科技领域的一线研究者和从业者齐聚一堂，共同探讨了人工智能领域的最新进展、技术现状、商业应用的挑战及未来发展方向。讨论涵盖了语言模型、生成式人工智能、多模态方向的生成技术，如语音、音乐及虚拟人生成等。特别关注了通过大语言模型和专家模型完成复杂人工智能任务的研究，及其作为通往通用人工智能（AGI）的路径。此外，还讨论了深度学习的理论基础、计算机视觉、数据压缩等领域，并分享了有趣的AI项目，如能从CSV文件中提取洞见的code interpreter插件。这些讨论不仅展示了人工智能技术的广泛应用和潜力，也指出了该领域内面临的主要挑战和未来的研究方向。"
      },
      {
        "time": "00:07:46",
        "title": "探讨AGI及GPT4的智能能力",
        "summary": "微软研究院与OpenAI合作，基于GPT4的模型，进行了一项深入研究，评估其通用人工智能（AGI）的能力。这项研究揭示了GPT4在解决复杂数学问题方面的卓越表现，这些问题是GPT3无法解决的。研究人员通过提出一些刁钻的问题来测试GPT4，发现它能够利用常识和推理能力来正确解答，这在某种程度上证明了其智能水平。然而，关于GPT4是否达到AGI的标准仍存在争议，学术界对AGI的定义也存在不同的见解。此外，讨论还触及了模型在加入安全性微调后，其推理能力可能下降的问题，强调了寻找既能确保模型安全又不损失其能力的平衡点的重要性。"
      },
      {
        "time": "00:13:36",
        "title": "探讨GPT-4的AGI特质及其对智能定义的影响",
        "summary": "讨论集中在GPT-4展现的通用人工智能（AGI）特质，及其如何处理图片、文字、谱曲和代码等多方面能力。通过实例，如要求GPT-4画出独角兽并加入特定细节，展示了其高级推理能力。此外，讨论还触及了智能的定义及其随着人工智能技术进步而变化的历史背景。特别指出，GPT-4的出现可能标志着向实现AGI迈出了重要一步，同时也提出了如何定义智能的新问题。"
      },
      {
        "time": "00:18:40",
        "title": "GPT-4模型评测与应用潜力分析",
        "summary": "GPT-4模型在代码编写能力方面展现出超过人类平均水平的能力，但公开版本在写代码能力上有所下降。模型对新题目的处理能力不足，显示出其可能过度拟合训练数据而缺乏泛化能力。评测采用的题目均未在互联网上找到，以确保测试的公正性。此外，GPT-4在理解视觉空间关系、音乐生成等方面也显示出了潜在的能力，虽然在特定领域可能不及专业模型，但其全面性和通用性预示着巨大的发展潜力。"
      },
      {
        "time": "00:24:30",
        "title": "探讨人工智能模型在图像识别与生成中的能力",
        "summary": "对话集中在分析人工智能模型，特别是专家模型在处理SVG格式图像和音乐生成方面的表现。指出专家模型在这些方面优于GPT-4，能有效读取和生成SVG图像，且在修改图像（如添加独角兽角）和理解音乐方面展现出的能力。此外，通过将AI模型与人类表现进行比较，强调了AI在一致性、逻辑推理方面的优势，尽管存在对AGI（通用人工智能）定义的讨论，但普遍认可AI在多个领域的应用已经超越了平均人类水平，显示出对人工智能能力边界的深入探索和思考。"
      },
      {
        "time": "00:29:25",
        "title": "探讨GPT-4的进展与限制",
        "summary": "讨论集中于GPT-4与先前版本GPT-3.5之间的显著差异，特别强调了GPT-4在不包含多模态训练数据情况下的表现提升，及其在推理、代码编写、解决数学问题等方面的能力和限制。对话中提及，通过与OpenAI的交流了解到，利用RL（强化学习）是GPT-4改进的关键，且GPT-4的参数量远超GPT-3.5。此外，还讨论了模型在规划、试错能力上的不足，并通过实例说明了如何利用GPT-4为数学研究提供灵感和辅助，提出了通过外部调用API以实现试错过程的可能性。"
      },
      {
        "time": "00:35:30",
        "title": "探讨人工智能模型的局限与未来发展",
        "summary": "讨论重点在于分析New Bing与ChatGPT等人工智能模型的差异，特别是New Bing通过提供信息来源链接来降低信息幻觉问题的能力。尽管如此，这些模型在推理和知识准确性方面仍存在局限，例如无法完全解决信息的准确性问题，特别是在处理具体事实与模糊记忆方面。讨论也涉及了模型自我认知的缺乏，以及通过外部反馈和互动学习提升模型性能的可能途径。强调了模型训练机制的改进和综合解决方案的开发对于解决这些问题的重要性。"
      },
      {
        "time": "00:41:32",
        "title": "解决AI幻觉问题和提升模型准确性的探讨",
        "summary": "对话中讨论了AI模型，特别是从GPT-3到GPT-4，幻觉现象的减少与模型基本能力的增强。提到了ROHF和IOAIF技术能够提升AI的自我修正能力，但指出目前的训练方法，如IL训练过程中存在缺陷，需要更精确的反馈机制。此外，还探讨了通过模型内部运算结果来检测模型状态，如是否处于胡说或侵犯版权状态的研究方向，认为这是个重要且有趣的领域。"
      },
      {
        "time": "00:44:58",
        "title": "探讨AGI实现的限制与未来方向",
        "summary": "讨论集中于实现AGI的当前限制，特别是GPT模型虽表现出显著智能但仍存在的问题。指出当前模型主要基于数据频率统计和模式映射，缺乏完整的推理过程，尽管有chain of thought等机制尝试弥补。强调了未来AGI研究需要解决的两大限制：数据结构的修改和真正的多模态理解，特别是利用视觉信息来增强模型的推理能力。最后，提出利用全网视频资料作为训练数据的潜在方向，但同时也指出了视频数据处理的挑战。"
      },
      {
        "time": "00:49:12",
        "title": "探讨语言模型的多模态融合与智能表现",
        "summary": "对话中讨论了语言模型如何通过数据结构和模型结构的变化实现更复杂的思考，强调了向模型中加入图像等多模态数据的重要性。讨论指出，简单地在模型上添加图像处理并不能显著提升模型的智能水平，需要在模型结构上做出根本性改变。同时，探讨了现有技术如GPT-4在多模态处理方面的局限性，以及学术界对于多模态信息融合的研究现状。提出为了更好地理解世界，未来的研究应着重于如何有效整合多模态信息，以促进人工智能模型的智能表现。"
      },
      {
        "time": "00:56:57",
        "title": "探讨行GPT及其在智能代理领域的影响",
        "summary": "行GPT作为最近非常热门的研究成果，其研究背景在于当前语言模型在解决复杂任务方面的能力尚显不足。行GPT提出利用语言模型作为调度中心，通过分解用户请求并调用专家模型执行子任务，最终整合结果回应用户。这种方法将语言模型视作核心系统，通过与各专长模型的协同工作，解决了长链条或多模态的复杂任务。以生成一张特定情境下的图片为例，展示了如何将一个复杂的用户需求拆解为多个AI可执行的任务，并通过调用不同模型来实现。这种智能代理的构建方式不仅提高了模型处理复杂任务的能力，也更加贴近用户的实际需求。"
      },
      {
        "time": "01:00:25",
        "title": "AutoGPT与哈根GPT的区别与应用",
        "summary": "对话中讨论了AutoGPT和哈根GPT的区别，强调两者虽然都基于GPT技术，但侧重点不同。AutoGPT主要围绕语言模型为中心，利用GPT-4通过构造prompt反复迭代调用，完成复杂功能，旨在通过GPT进行商业决策优化。而哈根GPT则强调GPT作为决策或整合中心，将具体执行任务交给更擅长的专家模型，形成协同系统完成复杂AI任务。AutoGPT更适合解决泛任务场景，而哈根GPT则针对更为专业的复杂问题。此外，还提到了AutoGPT在实现自动化任务，如网站构建或游戏开发方面的应用潜力，展示了其在流程性、事务性或商业性任务上的优势。"
      },
      {
        "time": "01:03:27",
        "title": "探讨GPT技术及其生态的发展与未来",
        "summary": "讨论重点在于GPT及其相关技术如Auto GPT和OOA在AI领域内的应用与发展。GPT被视为解决复杂问题的“大脑”，而技术的不断进步，从专家系统到深度学习，再到当前的大型预训练模型，标志着AI能力的显著提升。未来，基于基础模型的专门化应用和领域专家的结合被认为是解决更复杂问题的关键。同时，讨论还提到了生态构建的重要性，类比操作系统如何通过开放平台促进软件生态的丰富，强调了基于现有大型模型开发更广泛应用和工具的潜力。"
      },
      {
        "time": "01:05:29",
        "title": "大模型的泛化能力与领域适应性讨论",
        "summary": "对话中讨论了大语言模型（如GPT4）在不同领域应用中的泛化能力和适应性问题，以及是否需要为每个领域定制专门的大模型。指出当前大模型可能无法完全满足特定领域的需求，比如金融、医疗或教育等，因为这些领域的任务需求复杂，可能需要模型具备更强的任务拆解和调度执行能力。同时，考虑到训练大模型的成本极高，并且存在资源和资金的限制，大部分公司可能无法承担为每个领域单独训练大模型的费用。虽然技术进步可能会降低训练成本，但目前看来，找到让大模型在各个领域都表现优秀的解决方案仍然具有挑战性。"
      },
      {
        "time": "01:12:25",
        "title": "探讨GPT技术的未来发展与生态建设",
        "summary": "讨论重点在于GPT技术，特别是海淀GPT的未来发展潜力，及其在大语言模型和专家模型生态建立两个方面的进步。指出了目前对于多样化需求的模型支持不足，强调了满足特定领域（如医疗、营销、教育和广告）需求的重要性。此外，还提及了对于复杂模型支持的必要性，以应对各种未被满足的需求。"
      },
      {
        "time": "01:13:50",
        "title": "大语言模型的边界与专家模型的合作模式",
        "summary": "讨论集中在如何界定大语言模型的能力边界，以及这些模型何时应该独立完成任务，何时需要专家模型的支持。强调了目前大语言模型在任务调度和规划方面的能力还有待提升，尤其是在决策和推理方面。指出为了促进大模型的有效应用，需要构建一个平台，鼓励专家系统的接入，以丰富模型选择，满足复杂任务的需求。同时，提到了一些技术细节，如模型的context长度和利用示例数据改善性能的可能性。整体而言，对话揭示了大语言模型发展的初期阶段特征，并探讨了未来改进和应用的可能方向。"
      },
      {
        "time": "01:18:02",
        "title": "探讨通用智能与模型的未来发展",
        "summary": "对话中提出，Agent的概念及其在智能研究中的重要性，强调了从互联网视角看，现有技术如GPT等主要通过调用API来实现功能。讨论了OpenAI对于AGI的重视，以及通过插件生态收集数据来优化模型的方法。同时，指出了模型的未来可能发展方向，包括多模态技术的追赶和通过集成专家模型来增强模型能力，提出了模型共享和迭代的新模式。此外，还探讨了竞争格局和可能的颠覆者，强调了探索不同路径的重要性。"
      },
      {
        "time": "01:25:44",
        "title": "探讨AGI路线图和GPT未来发展方向",
        "summary": "对话集中在分析当前人工智能领域内几家公司（DeepMind、OpenAI等）的发展路径及其差异，特别是GPT模型的进展和影响。一方面，DeepMind因AlphaFold等项目在生命科学和强化学习领域有显著成就，但其对大模型的投入相对有限。另一方面，OpenAI的GPT模型，尤其是GPT-3.5，展示了强大的文本生成能力，引领了AGI（通用人工智能）研究的方向。讨论还涉及了技术挑战，如如何延长模型的context length（上下文长度）以支持更复杂的对话和任务，以及未来技术发展的可能方向，包括在硬件和算法上的进一步突破。此外，还讨论了关于是否可以通过模仿人类记忆的压缩方式来优化模型的context length，以及这在科学与工程领域内仍是一个挑战性问题。"
      },
      {
        "time": "01:33:37",
        "title": "探讨大模型的长期记忆与上下文理解",
        "summary": "对话集中在如何使人工智能模型能够处理超长序列数据，以实现更深层次的上下文理解。讨论了现有模型在处理长期记忆时的限制，强调了对模型内部机制更深入理解的需要。提到了学术界在此领域的研究不足，以及对于模型架构的挑战，探讨了在不破坏模型性能的前提下加速处理过程的可能性。同时，通过实例说明了在实际应用中，如企业工作流程管理中，长序列理解的重要性。"
      },
      {
        "time": "01:39:22",
        "title": "探讨Transformer模型的局限与未来发展",
        "summary": "对话内容涉及Transformer模型的当前局限，特别是其在处理长序列时的效率问题和路径依赖问题。讨论指出，尽管Transformer在自然语言处理等领域取得了显著成功，但其模型结构自推出以来基本未变，缺乏根本性的创新。同时，提出了对于模型改进的思考，如借鉴人类记忆的特性来优化注意力机制，减少计算复杂度。此外，还探讨了技术生态系统对模型发展的影响，强调了易用性和开放性在技术推广中的重要性。最后，通过历史上的技术竞争例子，说明了即使技术并非最优，也有可能因为生态系统的支持而胜出。"
      },
      {
        "time": "01:46:04",
        "title": "探讨GPT技术在企业中的应用及其挑战",
        "summary": "GPT技术当前正处于Demo阶段，但其在企业界的落地应用引起广泛关注。短期内，大型企业可能会通过第三方服务集成AI模型以提升生产效率，但直接引入GPT技术面临挑战，如数据调整、合规性问题及企业文化改变等。同时，出现了基于GPT技术的原生公司，它们有可能颠覆传统行业，反映出AI时代公司轮换的加速。创业者应聚焦于接受新技术的中小型企业，而非一开始就追求大型企业客户，同时需谨慎评估与初创公司的合作价值。"
      },
      {
        "time": "01:55:20",
        "title": "探讨GPT技术对企业服务的影响与挑战",
        "summary": "GPT技术，特别是GPT-4，正在引起科技行业和AI企业界的广泛关注。尽管如此，实际应用中，大多数企业和个人仍处于尝试阶段，其普及和实际应用面临诸多挑战。一些科技公司和AI公司的CEO已经开始在企业内部推广使用GPT技术，但对传统企业而言，AI的业务流程重构是一项复杂而漫长的过程，需要深入理解AI技术与具体业务流程的结合。市场上对能同时理解AI和具体业务流程的“施工队”角色存在明显需求，这为专门提供此类服务的企业创造了机会。此外，讨论还涉及了技术调优、私有化需求、硬件限制及市场应用等方面的问题，强调了在推进GPT技术应用时需要解决的实际挑战。同时，对于创业者而言，如何利用GPT技术在竞争中脱颖而出，保持产品竞争力，成为了亟待解决的问题。"
      },
      {
        "time": "02:03:02",
        "title": "探讨AI技术对各行业的影响与未来展望",
        "summary": "对话者认为，尽管目前AI技术在诸如订餐、买机票等日常应用中的效用显著，但其真正潜力在于打破传统行业壁垒，实现效率的大幅提升。特别是对于法律行业，AI技术有潜力降低服务成本，从而实现社会性变革。此外，还强调了技术与行业的数字化转型之间的关系，认为许多行业的所谓天花板可以通过技术手段被打破，从而提高效率，带来新的商业模式和社会结构的变化。"
      },
      {
        "time": "02:08:35",
        "title": "AI技术对未来组织和工作效率的影响",
        "summary": "对话内容聚焦于AI技术，尤其是像GPT这样的大语言模型，如何在提高工作效率和改变组织结构方面发挥关键作用。讨论强调了AI不仅能够显著提升个人和团队的效率，还可能改变对员工素质的要求，以及对初级职位需求的影响。此外，对话还展望了AI技术未来的发展方向，包括多模态能力、与世界的交互以及更加偏向行动的能力，这些进步将为实现更高级别的人工智能（AGI）奠定基础，并为各行各业带来效率的大幅提升。"
      },
      {
        "time": "02:12:22",
        "title": "探讨大模型的未来：挑战与突破",
        "summary": "讨论重点在于如何有效解决当前大模型面临的挑战，包括训练数据的优化选择与顺序，模型结构的创新，以及如何提升模型的泛化能力和对齐问题。特别强调了探索数据应用的新方法、寻找比Transformer更优秀的架构、理解和提升模型的记忆与泛化能力，以及重视模型的可解释性和对齐。还提到了硬件技术的进步，如HBM和chiplet技术，对未来大模型发展的重要性，以及将AI技术应用于机器人等领域的潜力。"
      },
      {
        "time": "02:18:11",
        "title": "AI技术在科学领域的应用与展望",
        "summary": "讨论集中在如何利用人工智能（AI）技术加速科学进步，特别是在生命科学和材料科学等领域。AI可以通过学习人类在互联网上留下的知识，提升其认知水平，从而作为科学家的助手，甚至超越人类科学家的认知能力。强调了高质量数据、算法和算力对于AI进步的重要性，以及未来AI领域的无限可能和挑战。此外，也提到了硬件技术，如NVIDIA的GPU，对于推动AI发展的关键作用。整体上，讨论展现了一种乐观的态度，认为通过AI可以为人类带来前所未有的福利，并且鼓励更多人参与AI的研究，以解决科学问题。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "研究进展：基于大模型的进展，如GPT4和专家模型的结合。"
                },
                {
                  "children": [],
                  "content": "技术挑战：模型推理能力、多模态数据处理、长记忆（context length）问题等。"
                },
                {
                  "children": [],
                  "content": "科学问题探索：模型结构优化、数据利用效率、对齐（alignment）问题等。"
                }
              ],
              "content": "AGI（通用人工智能）"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "应用潜力：图像、语音等多模态信息处理。"
                },
                {
                  "children": [],
                  "content": "技术难点：模态间信息融合、模态特定任务能力限制等。"
                }
              ],
              "content": "多模态模型"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "数据科学：高效数据利用、非结构化数据处理。"
                },
                {
                  "children": [],
                  "content": "算法研究：超越Transformer的模型结构、优化计算复杂度等。"
                },
                {
                  "children": [],
                  "content": "硬件技术：提升算力、降低成本、AI专用芯片开发等。"
                }
              ],
              "content": "AI基础研究"
            }
          ],
          "content": "AI技术发展趋势"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "挑战：技术适应、定制化需求、数据安全与合规性。"
                },
                {
                  "children": [],
                  "content": "机遇：提高效率、优化决策流程、AI原生公司可能颠覆传统行业。"
                }
              ],
              "content": "企业服务"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "潜力：AI辅助的科学发现、加速材料科学、生命科学研究。"
                },
                {
                  "children": [],
                  "content": "需求：跨学科合作、科研数据的高效管理与分析。"
                }
              ],
              "content": "科学研究"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "教育与学习：个性化学习路径、辅助教学工具。"
                },
                {
                  "children": [],
                  "content": "法律行业：文档自动化处理、法律咨询辅助。"
                },
                {
                  "children": [],
                  "content": "医疗健康：病例分析、药物研发加速。"
                },
                {
                  "children": [
                    {
                      "children": [],
                      "content": "数据隐私：确保用户数据安全与隐私保护。"
                    },
                    {
                      "children": [],
                      "content": "偏见与公平：模型训练数据的多样性处理、避免偏见输出。"
                    },
                    {
                      "children": [],
                      "content": "透明度与可解释性：提升AI决策的透明度，便于用户理解与接受。"
                    }
                  ],
                  "content": "人工智能伦理与安全"
                }
              ],
              "content": "社会影响"
            }
          ],
          "content": "AI在各领域的应用与影响"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "算法创新：寻找更高效、更通用的模型架构。"
                },
                {
                  "children": [],
                  "content": "硬件优化：提升计算效率，降低能耗。"
                },
                {
                  "children": [],
                  "content": "多模态融合：实现模态间更高效的协同工作。"
                }
              ],
              "content": "技术革新"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI与就业：AI技术的发展对就业市场的影响。"
                },
                {
                  "children": [],
                  "content": "AI伦理：建立伦理准则，确保技术应用的正向价值。"
                },
                {
                  "children": [],
                  "content": "数据伦理：数据收集、使用与保护的伦理考量。"
                }
              ],
              "content": "社会与伦理问题"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "商业模式创新：寻找AI技术与传统行业的结合点。"
                },
                {
                  "children": [],
                  "content": "产品化挑战：将AI技术转化为可实际应用的产品。"
                },
                {
                  "children": [],
                  "content": "用户接受度：提升用户对AI技术的理解与信任。"
                }
              ],
              "content": "应用落地"
            }
          ],
          "content": "AI技术的未来发展与挑战"
        }
      ],
      "content": "AI技术及其应用讨论脑图摘要"
    }
  }
}