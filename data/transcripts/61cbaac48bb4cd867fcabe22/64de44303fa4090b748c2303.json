{
  "pid": "61cbaac48bb4cd867fcabe22",
  "eid": "64de44303fa4090b748c2303",
  "title": "EP 37. 对话Deepmind, 英伟达大语言模型专家（下）：多模态大模型解读，亲历OpenAI，AI的挑战与未来",
  "task_id": "gpjbqkmdbweknk2a",
  "transcription": [
    {
      "time": "00:00:03",
      "text": "欢迎来到onboard，真实的一线经验，走心的投资思考。我是Monica.",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:09",
      "text": "我是高宁。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:09",
      "text": "我们一起聊聊软件如何改变世界。",
      "speaker": "发言人3"
    },
    {
      "time": "00:00:16",
      "text": "大家好，我是莫妮卡。咱们这么快又见面了，近3个小时的与硅谷AI大牛的现场讨论，我们上下集都在同一周发布给大家。如果你还没有听过上一期，那么再简单介绍一下这次莫妮卡期待已久的超级重磅的嘉宾组合。其中两位嘉宾都曾经在OpenAI工作过，包括英伟达资深研究员均范，除了对生成式agent和机器人的具身智能有深度研究外，他的twitter连jeff VS都关注，是AI领域的顶尖KOL，还有戴晗俊，google deep mind的资深研究员，也是google新一代大语言模型german I的深度参与者。兼任主持和嘉宾的硅谷上市公司华人高管郝伟硅谷徐老师每次来欧布串台都会大受好评。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:11",
      "text": "这次是3个小时播客的第二部分，上期的内容我们深入讨论了最近AI领域最火的话题generative agents生成式代理。这一期更是精彩纷呈。我们讨论更多AI领域的核心话题，包括多模态大模型的研究进展，具备具身智能即embody AI的机器人，如何打造AI对SaaS行业的影响，我们对未来AI商业和社会影响的畅想等等。真的是非常非常尽兴，你也可以拿起笔记本做做笔记了。最后几位嘉宾都是长期在美国工作生活夹杂英文在所难免，我们不接受抱怨。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:54",
      "text": "enjoy. 很多人看到妈妈吐的时候，觉得那还是一个大语言模型。但是jim其实在拉拉兔发布了以后，你的一个twitter上面，我觉得你提的挺有意思一个点。你说其实拉拉兔对于这个multimodal就是多模态的，还有robotics，我想也是你很关注的。这两块其实有很会带来很大的一个一个推动可以进来跟大家解释一下为什么你会这样去看拉模二的作用。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:20",
      "text": "我觉得多模态是一个非常有意思的问题。我觉得现在基本上大语言模型总的一个recipe已经都定下来，就可能预训练，然后后面就find 22F等等。但我觉得其实现在多模态这一块，整个pipeline其实还非常的不确定。而且我觉得其实学术圈也好，可能工业界也不断在探索多模态有几类做法。",
      "speaker": "发言人4"
    },
    {
      "time": "00:02:39",
      "text": "然后其中有一类就是基于一个已有的大语言模型，然后把别的模态给像插件一样接入进去。比如说我在英伟达带了一个in turn，我们大概几个月前做了一个项目叫PRSMR。其实想法非常简单，就是比如说把一个图片，然后先用一些计算机视觉的一些模块来处理一下。比如说分析一下它的这个里面的物体这种segmentation，或者就是分析这个深度depth，然后CD一些信息，然后再把这信息融合到一个大语言模型的一个backroom上面去就像一个插件一样。然后通过这个方法，现在世界里面就这种视觉信息它就能够理解。然后我觉得当时我们用的那语言模型就比较差，但是现在lama 2出来的话，我觉得它是可以作为一个非常好的一个这种推理，或者这种语义的理解的一个引擎。然后把这个别的模态接进去，我觉得可以在相对少一些的计算量的情况下，就能够做到一个还不错的，就是在开源模型里面还不错的一个多模态的效果。所以这是为什么我在推特上提到了这一点。",
      "speaker": "发言人4"
    },
    {
      "time": "00:03:42",
      "text": "然后另外的话就是做机器人这一块，就比如说这些机器人要做规划，然后还有就是他要输出一些那个机器人就控制了一些command。然后其实也是可以通过一个插件的方式。只不过这次这个插件是一个输出的插件，它输出的不再是下一个单词，它输出的是一个机械手的一个控制的一条指令。然后这个的话也是可以这种多模态的模型，也是可以通过llama 2这样一个很强的一个backroom来提升它的这个效果，所以这是一点。另外我也想稍微buck off一下，然后讨论一下多模态这整个包括它未来，还有现在这个情况。",
      "speaker": "发言人4"
    },
    {
      "time": "00:04:19",
      "text": "然后我觉得多模态很有意思，就是因为首先模态是什么对吧？我觉得那个GPT4说多模态，但其GP4就是他把文本和图片输入，然后它输出文本，它是一个非常特定的一个多模态，但是其实就还有别的模态，比如说有视频，视频就是一大堆图片，对吧，就在一个时间轴上面展开，然后还有音频，然后甚至还有三维。然后三维这一块的这个格式可能还有各种不同的格式。然后还有就输出的话有不同的模态，比如说这个机器人的控制，甚至鼠标和键盘也是一种模态。所以我觉得动物态的话就是可能性非常的多。",
      "speaker": "发言人4"
    },
    {
      "time": "00:04:56",
      "text": "然后现在包括就在应用上面，我觉得大家还在探索中。因为就GP4的这个多模态的这个API，现在大家还不能用。但是比如说我可以想象到可以通过截屏，然后这样的话这个GPT它就能够理解这个网页里面的东西。然后他可能做一些刚刚说的一些智能体的一些操，或者说是可以借助机器人等等。如果的麦这边，因为我知道gina其实也是一个多模态的模型，所以这块就是不少。韩俊怎么看？",
      "speaker": "发言人4"
    },
    {
      "time": "00:05:23",
      "text": "对我非常同意。东方它也是一个是一个future，以及现在可能有两种方式去approach它。像一方面像jim说的，如果现在可能已经有一个demo它的模型，那我想办法把其他的模块作为插件给poking进去。比如说要生成image的话，这样其实还是defusing model，还是会比这种AUX model，或者至少它更cost effective或者是quality更好。那diffusion就和现在的这种auto press language model本身就不太一样。所以如果在这做一个插件进去，肯定是让你的text instruction，然后去用division model再去做的话。其实是一个我觉得是一个walk around。但是这个我觉得是一个非常不错。",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:00",
      "text": "但是另外一个direction，我觉得是啊我们之前像image上也有很多tokens zed这些work就是把一个连续空间的image转化成离散空间的一些token，就是把它当做text来处理，这是其实我们最近也是在i clear也做过一些类似的工作。怎么去用diversion model把把这个tags和因为tocom ized image给unified在这个space，然后用一个就去做生成模型。这个可能是一个更native的做法。比如说车爆胎了，然后我要怎么换备胎这件事情如果你网上去看攻略，可能看了半天可能有些看不太懂。但是如果就一个短短的几秒钟的youtube video，就是直接跟你电话下，就是把这个先定你怎么用一下，然后就是非常容易去跟你评论的K对对对，所以怎么。",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:46",
      "text": "理解这两个approach，这个核心的区别会带来什么样的变化呢？就听起来的确第二种更加的native，那是说他会有一个更高的intelligence，可以做一些前一种做法做不了的事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:00",
      "text": "一方面是说如果前一种可能大概率情况下的这个base model可能会比如说freeze就不动了。然后你包括像D盘之前有一些类似的工作，是把这个language model部分给freeze掉。然后我接上音乐这部分，然后再去只调音面这部分。所以就会带来一部分是你因为这是完全去往language model那边靠，但是language model其实他自己那部分没有去take into，the fact就是它会consume image这边的input，是GPT four.",
      "speaker": "发言人3"
    },
    {
      "time": "00:07:26",
      "text": "就是这么一个做法。具体怎么做不是。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:29",
      "text": "但我确定他们应该是在在pressure的时候，就把这个image和tax的希望可能就是在更原生的层面去把它。",
      "speaker": "发言人3"
    },
    {
      "time": "00:07:37",
      "text": "你觉得它是更加原生的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:39",
      "text": "更加多彩。对对对，因为他们完全有这个能力去做这件事情，以及这样可能会更更自然一点。其实对我好奇。",
      "speaker": "发言人3"
    },
    {
      "time": "00:07:46",
      "text": "就是大家对于多模态的一个期待，是说大家很明显想到他能够enable更多新的场景，这个robotics等等。大家会期望多模态对于它这个foundation model，这个智能本身会带来一个大的提升。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:02",
      "text": "我觉得这是一个可能偏哲学一点的问题，我是那么理解这个事情的，当然就是欢迎大家一起来debate。对我的理解是就现在的文本是我们这个多模态世界在一维上的投影。然后有一个很有意思的一个实验，就是GPT4其实它能够理解颜色。但是就比如说你把颜色用RGB那个hex code作为一个文本输进去，然后你可以跟他你可以问他哪个颜色比另外一个颜色更暖色调，哪个颜色比另外一个颜色更热情，然后他其实会回答的是对的。并且他有一些泛化的能力，我觉得就是因为吉利意思，他看过大量的这样的数据，然后其实在网上可能大家在讨论这些东西的时候会提到这些。比如说你在做网站设计，你可以在讨论这几个RGB的颜色。从这里面GPD4其实它是在这个一维的投影上来理解我们这个非常高维度的这个世界。",
      "speaker": "发言人4"
    },
    {
      "time": "00:08:54",
      "text": "但这样的话就有几个问题，就是说第一它肯定是一个它的效率很低，因为你要大量的这个数据来补充这。但是第二的话，我觉得也可以argue，就是文本作为一个智能的一部分，可能是最重要的一部分。因为我觉得文本的理解就是语言的理解，是我们人和动物的区动物的视觉系统非常的强我举个例子，前两天就是我看到youtube上面有一个很有意思的实验，是他们让一个大猩猩来玩minecraft，它能够理解里面各种不同的东西，还能够敲这个墙什么的，这他都能理解。但是可以大家想想这件事情是多少的不自然。因为对于大猩猩来说，这个mine craft的视觉上的他的texture等等，还包括craft里面的物理，所有的这些东西和自然世界里。非常的不一样，看上去非常不像。然后这个大猩猩他自己以及他所有的他的祖先都从来没有见过my craft的这样的一个视觉的一个情况。但是他几天训练下来，他全都懂它里面这个三维什么他都能理解。",
      "speaker": "发言人4"
    },
    {
      "time": "00:09:53",
      "text": "然后我觉得大猩猩视觉系统已经超过我们现在最强的计算机视觉的算法。所以我觉得这个是一个叫做morphic的一个悖论。就是说我们人觉得简单的东西对于机器觉得很难。我们人觉得很难东西或者很牛逼的东西在算法里实现反而不是那么难。然后我们一直觉得这个语言是一个智能的最强的东西。然后像人的话推理什么都不是一件简单的事情。但是我们拆GPT先到了GPT4，几乎已经是就快要到了那一步了。但是我们人或甚至星星都能做的事情。",
      "speaker": "发言人4"
    },
    {
      "time": "00:10:25",
      "text": "现在没有一个计算机视觉的模型能够不在minecraft上面训练，就能够one my craft根本做不到。因为这个有一个巨大的一个抖音感，他这个泛化能力非常的弱。就是有一本书上面他说就是说人其实大脑的70%的大脑皮层其实都是处理视觉信息。我们这个神经元的单位很多是在处理其实视频的信息。对，就大量的这样一个视频进来，然后我们再试图在理解这个世界，然后剩下的语言什么部分就只占了剩下的30%。",
      "speaker": "发言人4"
    },
    {
      "time": "00:10:54",
      "text": "所以这也是一个很有意思的自然演化，就是不断的进化。最后我们人的大脑是这样一个结构。所以我要处理视频信息这一块可能就是必须的必须。但是路也很长，就可能从计算的角度来说也是远高于文本。",
      "speaker": "发言人4"
    },
    {
      "time": "00:11:10",
      "text": "你这让我想到我们在讨论AGI的时候，经常会去拿这一些人类的智商测试来去测大模型，来去讨论它是否达到AG。就像你说如果说本来这个对一个事情的难易程度对他就不一样，说也许我们在讨论一个大模型的intelligence的时候，其实也不应该用人类的这种测试的方式。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:30",
      "text": "对特别echo这一点，以及包括像比如说现在有很多工作做，让大模型去做数学定理的证明。然后会他发现大模型在某一类数学问题上，比如说组合这种类型问题上，它其实定理证明可能比人类的这种数学家可能会证明的会更好一点。但是像绝大多数还是远低于人类。所以就是说他在擅长的地方和人类擅长的地方可能确实有一个miss lemon，或者说我们自己哪怕是理解微积分的时候，我们也会通过这种，比如说面积这些怎么把这个东西切割成小块这些方式去理解。然后忽然发现这个抽象的概念就会会更深刻的理解。但是这个建立在这个基础上，就是说人类的视觉系统会可能会比现在的machine的视觉性能强大很多，以至于他会去更容易去帮助他。如果说回到multi modality model，如果这个视觉本身需要消耗它很大一部分模型的capacity的话，它是不是值得吹到？我觉得短期内来说，它是运动中让我believing这个还是会互相multi benefit。",
      "speaker": "发言人3"
    },
    {
      "time": "00:12:33",
      "text": "Al对我的理解是从应用的角度，就刚才讲一些哲学的角度。但我觉得从应用的角度来说，多模态最大的未来的应用就是机器人。因为我就要解决机器人一定要解决多模态的问题，而机器人其实比多模态更难一些。因为还有一个输出就是你要就比如说control，假设有五个手指的这样一个机械手，要就控制他做一些人这个五个手指的手能够做的事情，其实非常难。所以这一块其实也是比大猩猩要差了很多的。甚至我觉得狗和猫它们的运动能力都远高于现在波顺动力的那些机器狗。",
      "speaker": "发言人4"
    },
    {
      "time": "00:13:05",
      "text": "然后我觉得解决多模态只是解决机器人的第一步，但是他解决的是先解决输入的问题，他能够理解这个世界。然后输出的话可能还要通过别的方式来解决。所以我觉得长远来说这是最大的应用。然后我也觉得下一个就是ChatGPT之后，下一个最大的AI革命其实就是机器人。如何让机器人普及，机器人成为每家每户就像iphone 1样的存在，让我觉得这可能是下一个工业革命。对但现在我们距离那个还差了，我觉得。",
      "speaker": "发言人4"
    },
    {
      "time": "00:13:32",
      "text": "好几个突破。其实当时我记得GPT4他自己也有release这种对比，就是说GPT for ways的那个vision部分enabled或者是text only的GPT4它在一些benchmark上对比，其实它有一些在甚至在做题方面它会有提升，这个是一个很明显的。Sega就是说他如果能够理解一些文本的，比如说可能一些问题里面本身就包含对一些图片的问题，比如说数学证明这种他确实我觉得是一个很明显就是说它会帮助。然后有一些地方可能你不得不去理解这个图片，像抽象，像jm说的这个robotics的，或者说像可能一开始提到的你在做web navigation，就是网流量网页的时候，它的渲染出来的CSS渲染出来了之后的这个网页会比直接原生的那个HDMI代码会更容易理解，至少对人来说可能是这样。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:26",
      "text": "但是可能这中间有个主要的gap是vision的很多信息是冗余的。包括就是你看到这么多个pixel，就是它的dimension，它的维度远高于你的text的它真正的有信息量的一部分。所以其实image可以被压缩的很大，还有就是压缩的比例很大。但是像文本的话，它是一个更concise的方式去表达信息。所以这方面如果说能够让它的表达的效率能够对齐的话。因为这时候可能一开始提到，为什么不一定要把image作为原生的pixel level去表达，而是说在一个encoded space去表达会更容易去align with其他的modality。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:06",
      "text": "对我再补充一下，我觉得从数据的角度来说，视频是一个巨大的金矿。然后现在感觉大家还没有完全开发这一个巨大的金矿。我们可以想象视频有多少，视频对tiktok youtube上面每天有，我都估计不出来。但是这些视频其实生成的这个数据量其实远高于我们现在那么多芯片能够处理的量。而且视频里面有大量的这种信息，不仅是人的一些日常的一些活动的一些信息，有这种语义的信息。然后它还有物理，就我们称之为叫intuitive physics，就这种直观的物理。就可能比如说我现在把这个杯子从这个桌上推下去，我就知道它会打碎。但我可能不一定知道这个碎片到底是怎么样一个精确的一个地方，这我不知道，但是我是会估计出这是会发生的事情，所以这叫做intuitive physics。",
      "speaker": "发言人4"
    },
    {
      "time": "00:15:53",
      "text": "然后我觉得大量这个视频里面其实能够有很多很多这样的信息，还包括风吹过来这个树叶会动等等。其实这些东西我们不是从单张图片里面理解的，是从大量的视频里面理解。对于人来说也是这样。其实我们人每天大部分情况下我们在处理的是视频。少部分情况下我们在聊天，我们在处理文本。大量的情况下，其实视频如果从人工智能角度来说的话，视频是一个很好的切入点。但现在还没有我觉得还没有一个学术圈工业界一个统一的一个算法来来来处理视频。这个视频的GPT到底长什么样，我这个还有待讨论。",
      "speaker": "发言人4"
    },
    {
      "time": "00:16:31",
      "text": "所以这个会带来说不定下一个涌现能力。你刚提到这个还没有一个共识。那现在要能够处理这些多模态的数据作为一个training data的话，核心的几个难点在哪？",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:45",
      "text": "看一开始提到的，比如说像image或者video，video可能是个更高维的一个数据表达，就是可能短短几分钟视频可能就占了好几个G的空间，但很大部分是容易的。所以其实如果能够如何把这个信息用更方式去表达，我觉得是会帮助去你后面去理解，去生成。对，其实最近很大一个trend，在学术界就是把这个视频也把它给token ize使的。是你能够把它像语言一样处理这种离散的一个单词，这样一个表达形式。然后这个方面有做很多像视频生成，包括之前google的一个像菲拉克这样的一个text to video这样一个模型，以及最近有很多这种给你一个一开始的图片，然后让你把这个图片让它给动起来，很多模型都是会基于这样一个技术。",
      "speaker": "发言人3"
    },
    {
      "time": "00:17:35",
      "text": "我觉得有有好几个点，一个是说你把它偷回来之后，你可以利用像现在的蓝规，你们的学到了很多这种技巧，把它给同样做生成栏位的方式去生成视频。但以前是指如果直接在视频的空间是做是做不到。因为它的对面生态维度太高，就一每一帧可能就已经有上几百万几千万个像素，不太可能去在那个lever去做。但是另外一方面，之后它也会让很多冗余信息被filter掉，使得它能够更efficient去表达。至少短期来说是在现有的算力和算法这个能力的基础上，是一个非常不错的trade off。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:12",
      "text": "其实我们刚才讲了很多模型本身，算法，还有哲学层面的东西。我们聊个具体的就是工具。大家看到就是说现在大模型，大家真正在无论是在training还是在应用的这个过程中，还有哪一些你觉得从工具层面需要弥补的一些gap。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:30",
      "text": "对，其实我觉得工具和之前我们聊了很多的agent是非常相关的一个话题。我们可能对因为你的agent的要能够去跟外界去做反馈或者是做decision，其实还是会leverage的很多工具，然后也会对外界产生影响。但是我可能更想说的一点是，工具也分好多种。那有些是像比如说generally的去做一个搜索引擎，或者是用一下派送一些已经有的library。但是其实我我更care的是说，他能不能去adapt出一个新的工具。比如说用一个a apply一个大模型在一个企业的。应用场景中，因为这个企业他自己有自己的一套工具量。所以这套工具量或者是他自己的dm specific language，这些东西是你在大模型的训练什么这都不会见到的那些工具，但是你要能够让他去adapt到这个具体的应用场景，我觉得这是一个非常有意思的问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:19:24",
      "text": "包括最近其实有一个比较两三个月之前，一个就是纯用procedure generation去做video generation的那个lab，也是当时做ImageNet那个lab出来的一个工作。对，但他那个是纯粹是靠graphics去生成这些video。所以如果你要说如何让language model能够去用这个工具，如果能够用上的话，那他就可以直接去原生的去做到text to video这样一个事情。",
      "speaker": "发言人3"
    },
    {
      "time": "00:19:48",
      "text": "好，我们剩下两个问题，我们快速的讨论一下。我觉得第一个就给jm跟韩俊，二位都在OpenAI工作过，算是也是在几年前了。你们觉得open a有哪些让你们自己印象特别深刻的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:01",
      "text": "就是我16年那个时候是欧文牙第一次有英特尔欧莱雅，差不多在15年的时候成立的。所以16年那个暑假的时候，OpenAI还是在一个探索的状态。其实大家都在喊AGI，我觉得AGI16年时候open I就是一个口号了，大家都是希望能够达到HR但大家都不知道去HR路应该怎么走。其实当时OpenAI universe就是一开始我提到的就是训练AR来控制鼠标和键盘那个项目。其实我觉得当年open I觉得是最直接的走向AGI，因为没有比这更通用的一个界面了，对吧？就是至少在这个数字世界里面没有比这更通用的。但是后来发现就是用强化学习的方法，这个泛化能力什么都不行。所以其实那个项目最后欧巴也就下down了那个项目。",
      "speaker": "发言人4"
    },
    {
      "time": "00:20:47",
      "text": "然后在同期的时候，OpenAI也在做游戏，那个时候open I是有一个grand chAllenge，就是要赢dota，要在dota上面赢过人类的世界冠军的团队。16年那个时候已经刚开始搭了，然后可能韩军在的时候就开始慢慢达到一个巅峰的状态。然后同期还有一个机器人的项目。对，然后欧班牙当时做了一个机械手，机械手是能够解魔方，然后就是五个手指一个机械手。对，所以这是另外一个项目。当时他们也觉得可能机器人也是通向AGR的一个必经之路，然后还有在同期有一个小哥，然后他在那边在redit的数据上面训练chabot。但那个时候还没有transformer，他当时用的是一个更旧的一个模型叫LSTM，就一个回馈式的神经网络。对，然后他的名字叫alec radford。当时我觉得至少我没有理解为什么要训练一个char p lt对，但他当时其实就是用这个回馈神经网络来预测下一个单词。",
      "speaker": "发言人4"
    },
    {
      "time": "00:21:46",
      "text": "其实16年的时候就有这个影子，只不过那个时候没有穿梭面，效果不是很好。而且大家也没有想到要scale up，也没有想到要堆更多的算力。但是那个其实是GPT，可以说GPT0，就最早的GPT的影子16年的时候就有了。但是说实话我觉得那个项目当时在open I里面并不是一个很高优先级的项目。我刚提到的open universe dota，还有那个机器人，可能是前三名的项目。但那个时候还是一个探索阶段。",
      "speaker": "发言人4"
    },
    {
      "time": "00:22:13",
      "text": "对我觉得进入这个建议非常好。这是我18年进去的时候，我excel能看到当时的那些演化到18年是个什么状态。对，首先18年的时候确实那些project还在，然后当时他们推出那个robot hand怎么去玩一个魔方以及dota team。当时那个夏天是至少打进那个，反正top player还是能对对还是有来有回的。虽然不是最顶尖的，但是已经我要about average。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:38",
      "text": "然后我当时在实习的也是叫games team，其实当时也是有心跟周淑曼实习。我们那个games可能更像是在那种说你让你玩几个游戏之后，给你一个新的游戏，你能不能更快的去在熟悉那个游戏。当时觉得人类跟机器当时的机器比起来，人类的这个sample efficiency是要高很多。你可能只要少量的样本，你就可以学到新的知识，新的能力。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:04",
      "text": "然后关于说到的这个GPT领域的事情，我当时应该是已经差不多GPT two，可能他们交了一篇paper，就是可能是maybe GPT2，然后交到news还是那个conference，然后被reveal拒了。当时在毛体们就在那个组会上，跟大家把这个review非常harsh的评论给大家念出来。当然目的是说你看我们在achieve AJ的道路上，只能有这些不识相的人，总有这部戏让人但就绝对不会阻碍我们的决心。对，当时我其实没有太放在心上。现在回过头来看，他们其实当时就是非常dedicated，就是这个direction了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:40",
      "text": "已经就是18年的时候，以及我觉得非常佩服三毛地方或者他们整个管理团队的这个vision。虽然中间也是很走了很多弯路，其实像game这些，其实现在不玩game了。然后robotics他们也deprecate，但是至少说他们有这个考试是让大家尝试不同的方向。Identify一个可能普遍社会正确的方向之后，即使有外界很多的这种反对的声音，他们也会put effort to的。所以我觉得这是我对在OI那段经历，我觉得给我最大的lesson。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:12",
      "text": "对浩宇你作为旁观者有什么补充吗？你也算见证了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:17",
      "text": "那个时候我就讲一个，我觉得2015年OpenAI成立的时候，他们就是想做AGI。但是就像杰米说的，怎么个做，怎么录，其实没人知道。但我当时的estimate大概就是一个达到今天或者说是ChatGPT这个moment，我估计大概是一个2030年的事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:37",
      "text": "但是我我我的那个观点，我在大概2020年的时候我就开始改变了。因为2020年GPT3出来以后，那个emerges capability in context learning都是我觉得要好几年以后。当然我并不知道这个encounter learning是怎么样，但是这么大的一个跳跃，我觉得是我没想到的。到2020年的时候，我就我当时会想几年之内会能够出现ChatGPT。所以说ChatGPT出来对我个人没有surprise。对我最大的surprise应该是GPT3出来。然后ChatGPT出来我相信是让google的不少的人觉得是不管是surprise也好，或者说是郁闷也好，或者怎么样也好，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:20",
      "text": "因为我有一个朋友，他是google的一个高管，正好在欧洲度假。他说12月3号星期六开一个会，讲怎么去对待这个chat GB的。因为显然这是一个很大的事情，他记得很清楚。我比较好奇，对你个人，你看了ChatGPT这么一个你个人是什么想法？",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:40",
      "text": "当时对量变引起质变这件事情有了更深的理解。因为我知道他可能就是maybe更大的模型，以及更多的训练数据，然后可能fundamentally还是transformer，还是那些还是这样一个aggressive model。就是我自己试了几下，然后就觉得真的是一个非常让人惊讶的一个东西。如果把lambda给release to the public，我觉得大家可能会对后来的chat VT可能没有那么惊讶。毕竟有一个心理准备台阶以及如果你开始真的能够release这个chat，good拉姆达这些to the public的话，你至少能收获一大波数据。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:16",
      "text": "量变引起质变，这一个有更深的认识。另外一个你是觉得这个还是有一些配对对吧？就是lda没有，至少是能够有一个跟他差没那么太大的一个毛病，先让大家先试一下。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:31",
      "text": "对，可能只是按当时那个时间点来说，可能当时拉姆达可能确实不一定有chat VT那样quality。但是毕竟两个模型最近都evo了很多，也就是一直在进步。包括ChatGPT本身也不是去年的那个ChatGPT了，对这个迭代的速度是非常的impressed。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:47",
      "text": "所以这是你的想法。Jim你？",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:49",
      "text": "我觉得当时就是open a几个早期的项目里面，其实可以看到open AA他们今天很多决策和今天他们成就了很多影子。举个例子，比如说当时就是他们在red上训练的chabot对吧？GP0后来就那个skill up变成了今天的这些GPT。然后还有当时做这个游戏这一块，其实就是一个强化学习的一个他们内部一个强化学习有一个很强的infrastructure。然后他们算法上面也做了，强化学习上也有很多探索，然后后面就直接变成了2 traf。之后就chat BT要跟那个人做alignment的时候，其实强化学习也就是我觉得从当时的影子过来的，然后还有包括当时open universe就是AI用这个软件，这个其实就今天的chat VT的up store login，我其实就类似有当时这样的一个灵感在。",
      "speaker": "发言人4"
    },
    {
      "time": "00:27:34",
      "text": "然后第二个我一直在关注，就从16年开始一直在关注follow opening，基本上每一篇论文我都会读。对，然后我觉得跟皓月老师一样，就是我当时最大的震撼是GPT3，第二大的震撼其实是科普和达利。对，这个像克里普和达利大家说的不多。但是我觉得GPT3克和达利，我觉得他们是开创了一个新纪元，是一个新的一个思维模式，是一个新的范式。就是第一scare up，第二open world对吧？Scalp就堆更多的算力。Open world就是我们把整个互联网数据全都能全都把它下载下来，然后作为我们训练的数据。",
      "speaker": "发言人4"
    },
    {
      "time": "00:28:14",
      "text": "但其实当时这两件事情现在听上去好像很理所应当，但那个时候一点都不obvious。因为那时候学术圈里面的想法是这样的，是我有一个固定的一个训练集，一个固定的测试集，大家所有人在上面benchmark。比如说AMANIETA magnet，就是一个有120万张图片的一个数据集。然后当时所有做计算视觉的人都是在MG net上训练完，然后imac net还有那么几十万张的这图片做个测试，汇报一个数字。然后如果你不这样做，学术圈里评审人会喷你，因为你这个东西跟别人不能比较。所以其实当时学术圈里面根本没有这样子一个open world，要在英特网上，互联网上把所有的这个数据就一起下来下载下来做训练的这样的一个思维模式，学术圈是完全没有的，然后更加不要谈这个算了这事，学术圈根本就没有这个资源。然后我觉得就是贫穷限制的想象，学术圈里面没几张卡，真的就是那怎么办？",
      "speaker": "发言人4"
    },
    {
      "time": "00:29:08",
      "text": "未来我们未来这不是更贫穷了吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:10",
      "text": "但是我觉得芬兰打开了我们想象力。欧佩兰现在就至少告诉大家，当你有当年他们有一两千张卡的时候，你能做什么。他们一旦告诉了大家以后，现在大家全都跟风就过去了。但那时候真的是限制了想象力。",
      "speaker": "发言人4"
    },
    {
      "time": "00:29:23",
      "text": "然后我觉得那个GPT3就是在文本上的scale up open world。然后clip跟大家介绍一下，它是一个图片和文本的一个对齐的模型。我觉得当时对于计算机视觉就是一个巨大的震撼。当时clip他那篇文章应该没有投任何的会议。但我觉得要投的话就是务必是当年CVPR的最佳论文。务必的那那年CVPR我觉得都没有任何别的论文值得读。那天club就是一个地震级的一个东西，海啸级的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:29:49",
      "text": "然后还有就是大力，然后大力的话其实从纹身图这个领域已经做了十几年了。从deep landing前就开始做deep playing之后的话也有很多纹身图的工作。其实就是我在斯坦福的这个组里面也有很多学长，Andrew capacity什么的，他们自己之前也做过这种图层纹，但是没有通过这种一个简单的算法。然后靠算力，靠这种大量的open word的数据，他们就没有走这条路。然后他们就做了很多engineering什么的，但这样这个pipeline就非常的复杂，但是大理是一个很简单的算法，一个很简洁的算法，但是他把它up。所以我觉得那个是在算法上，从这个思维模式上一个巨大的震撼。",
      "speaker": "发言人4"
    },
    {
      "time": "00:30:28",
      "text": "然后我看到chat BT，我觉得是一个小震撼，比起前面那个，因为我觉得chat BT是一个工程上的一个奇迹。就是他们把那么多标注，就整个标注的pipeline，然后还有更多的数据，还有这个RY trip是怎么怎么调参的等等这些事情他们都做的都特别的好。还有包括最后deploy，叉GPT就是一上来就什么前五天里面就有100万用户。那就意味着他们后端的这个工程做得非常好。就有多少APP能够做到这样一个下面还没有大规模卡机。对，就至少从欧派作为一个公司来说，就工程能力非常的强对但其实我觉得从算法上面，GP3是一个更大的震撼。然后当然后面GP4也肯定是个震撼，就说他的这个能力，写代码能力也就远强于GP3.5。",
      "speaker": "发言人4"
    },
    {
      "time": "00:31:16",
      "text": "对，然后之后的话听众肯定就比较熟悉了。但我觉得当年那个时候，在大家没有讨论大语言模型的时候，那几件事情其实我觉得在学术圈里面震撼是非常大的。GB3发生的时候，我大概是斯坦福应该是第三年博士。然后那个时候LP的组他们就召开了一个紧急会议，有点像刚才韩军说的谷歌的紧急会议。我觉得NOP组也是有一个紧急会议，他们就在讨论，就觉得NOPL完蛋了，就觉得在学校里面做NOP已经没有什么值得做的了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:31:45",
      "text": "所以后来为什么斯坦福发了一篇文章名字叫foundation model？因为那时候斯坦福已经感到了巨大的压力。就是一旦我们这些NOP的这些教授几十年的过去，这些什么语言学，什么这些经验他都要过时了。然后如果我们不跟着时代的脚步的话，就要被时代淘汰。所以其实斯坦福提出了这个foundation model这个名字。然后现在搞了一个foundation model的center，包括最后pursue等等，斯坦福的教授做了奥帕卡什么等等的。其实他们当时也是有一个巨大的一个转变，对他们这些资深的教授来说也是一个很大的冲击。更别提我们当时这些片区的学生。",
      "speaker": "发言人4"
    },
    {
      "time": "00:32:19",
      "text": "斯坦福其实这件事情做的非常强烈了。也就是最近开始最近一年我觉得很多的顶尖的大学开始重新在思考。前两天我跟一个朋友在聊，他知道的一所大学是他说2024年毕业的那个论文就让他们就写完。2024年以后毕业的要重新reset他的论文方向，就是也许你写的东西根本就没有任何价值。我觉得斯坦福能够在2020年就开始思考这件事情，已经走在蛮前面了。对，刚才你们两位写的就是ChatGPT moment的想法。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:55",
      "text": "从我的角度上来讲，它的model的performance性能上来讲，我没有觉得惊讶。但是那么多人开始用，这就让我看到API跟UI的区别。因为3.0出来的时候，或者说GPT3出来的时候，它只是API这API只是码农对吧？能够用，但是真正出圈还是需要有一个漂亮的UI，当然不只是一个UI就像jm刚才说的是这个infrastructure基础建设要做的比较scalable，这是我的第一反应。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:26",
      "text": "第二反应，其实我当时跟绝大多数人的想法不是很一样的。因为我不知道Monica或者jm记得吗？当时候大多数人都说google要完蛋了，对吧？那个设计要完蛋了。我觉得社区完蛋这件事情还很漫长，也有可能以后也会完蛋。但是我觉得这是很漫长的一件事情。最大的震撼我觉得是一个云计算会分着metal来改变。以前的云计算主要是storage computing，现在以后更多的是一个AI native的这些API。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:53",
      "text": "我们刚才说的SARS会议建筑在新的AI native的python上面。前面大概一个月，我的这个想法可能是属于非非共识的。但是我觉得最近几个月应该已经算是属于比较共识了。你说要去颠覆google，也许可能对吧？但是这个搜索这是一个很漫长的一件事情。但是其他的那些写B2B software，肯定会在今后的两年、三年会写，会非常不一样。你觉得最被。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:21",
      "text": "大家高估的和最被大家低估的做大语言模型的挑战是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:26",
      "text": "这个难度上来说是其实它是一个真的是一个botnet。包括我一开始说到auto GPT这件事情，我包括在企业用户中用的时候，其实可能大家觉得一些很多花式prompting，或者是mult调用这个language model让他去完成一个task这件事情，但觉得可能就解决了。但是其实在真的企业用应用场景中，很难去接受你一个response，我也需要调用十次或者20次language model可能等个一分钟才能回复这件事情。这件事情可能是现在很多包括做prompt engineer这些research方面，以及和真正应用上面会一个mismatch，或者是一个被低估的一个问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:35:08",
      "text": "这个我就来讲讲低估的东西。我觉得一个是我感觉业界还是有点低估了机器人的难度。我其实这次去SMO的时候，感觉就是很多可能不在直接做机器人领域的研究的同学们，都是在问，这个机器人改进的很快了，现在动态也有了。然后谷歌那边还有2T12T2那些模型，感觉是不是这个机器人会特别快了。而且伊朗马斯一直在喊那个tesla bot什么的，有些炫酷的一些demo。然后现在包括有一些创业公司，初创公司，比如说figure，one x什么，也都是打着通用机器的旗号。",
      "speaker": "发言人4"
    },
    {
      "time": "00:35:42",
      "text": "但是我觉得还是这个事情的难度我觉得是被低估了。因为我觉得机器人第一有一个硬件，就不仅是算法，还有硬件的问题，还有产能的问题，一系列的问题。然后算法这边就是刚提到的这个数据不够，然后可能我们现在就连这个输入处理的都不是很好，更加不要说它输出那一块，输出肯定比输入更难一些。因为输出就是控制这个机器人的身体，比输入更难。但现在输入也没有解决，就是刚才提到的，尽管我们现在解决了语言，不代表我们的这个视觉系统就能够在短期内能够超过狗和猫和大猩猩。我觉得这两件事情是脱钩的。然后哪怕解决了这个世界，也不代表我们就能够有大猩猩或者最后是到人的这样子一个肢体的灵活度，这是一个。",
      "speaker": "发言人4"
    },
    {
      "time": "00:36:28",
      "text": "第二个被低估的是，如果现在要做一个foundation model的公司，或者说是大公司想做function model，自己来创一个新的一个东西。我觉得可能组织能力说不定比这个技术要更难一些。因为我觉得刚才今天podcast也提到了，就是说有大量的算力需要资本的运转。然后还有包括需要落地，就是说这个东西怎么去justify花那么多钱，如果不落地，所以还要需要同时要想好这个商业的这个。然后还有就是要吸引大量的人才怎么样就是从可能那些最好的那些地方，挖到足够好的人。还有就是推动的整个agenda。所以我觉得组织能力可能在这个大语言模型的这个时代里面非常的重要。",
      "speaker": "发言人4"
    },
    {
      "time": "00:37:15",
      "text": "因为我觉得曾经就是要做一些AR的突破什么的，就几个PHD，然后大家就是那个对吧三个月哈克桑，然后我觉得就能够做出一个新的文章，一个新的突破。现在我觉得类似这种越来越难了。可能fine tuning还可以。但是我觉得一些本质上一些大的一些突破，需要一个很强的一个领导一个一个领导者。来把这所有的这些资源什么的都放在一起。这是一个巨大的拼图，就不再只是一个算法。但是要拼图的每一块都要在一起，让它才能整个齿轮才能运转。",
      "speaker": "发言人4"
    },
    {
      "time": "00:37:44",
      "text": "我觉得低估的可能还有一个点就是evaluation，就包括做那个ChatGPT moment，我们刚才聊到对吧？对，不管是谷歌还是很多人都是非常惊艳。但你想其实有那么多聪明的人，不管是在google还是不在google，其实都已经能够非常能够做做模型，做的很好了。但他们以前optimize的那个是一些benchmark对吧，就是那个academic的benchmark或怎么样。所以说它的evaluation，它的measured是走了相当于是走了另外一条路，吧。你从今天的角度来讲是一个错的路，但当时候就是所有的人都在走的路，那这是measured。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:23",
      "text": "今天如果是从工业界来讲，你怎么去measure你的copilot是算是好的，算是成功的。怎么去automate这些evaluation automation ate的这些measurement的，我觉得都是蛮大的挑战。我我我大概两个月1两个月前写了一篇很短的文章，因为大家都在写什么whatever is all you need，right, 我就写了一篇。我说但是我觉得最终是measured is all you need。如果你能够measure好了，一旦这个方向对了，然后慢慢的就会做我们前面提到的那个next token prediction，变成AGI这个方向对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:59",
      "text": "那也就是一个把loss function，把一个objective function，把一个目标函数给做好了，接下去慢慢的做吧，但是一开始没人相信这个目标函数是可以potentially达到AGI的对，所以说我觉得这件事情是属于我觉得有点低估。另外一个我觉得这跟evaluation有关。人喜欢去evaluate说这个hello的人们从来没自己去evaluate自己hello。有的时候因为各种各样的原因，用另外一个角度去看halos，ation其实还是蛮多的。所以说我觉得光是去judge这个model说，你这个有的时候不是很公平。我觉得对我觉得有一个点，我前面提到的GPU算力，长期来讲我不觉得算力是一个bottle neck。因为就像我前面说的，任何一个东西只要有mass production，价格就会无限下降。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:54",
      "text": "我另外一个问题是说，你觉得大宇模型或者人工智能在未来一年和未来十年，觉得最让你期待的事情是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:02",
      "text": "我觉得未来一年的话，就刚才提到的一些coding的模型，我觉得肯定会越来越强。可能1到3年，我觉得有一些最基本的一些软件工程，还有包括D报警什么的。我觉得GP5或者可能之后出gina什么的，很多这一块都能被自动化。然后还有就是1到3年的话，会有一些多模态的模型出来，估计还没有完全解决这些问题。就刚刚提到的这个真的要达到这个动物一直到人的视觉这个系统，我觉得可能1到3年都有点勉强，但是至少这些多模态模型会出来。目前为止翻tier模型里面还没有一个是大家真的能用上多模态的。但这个的话肯定就是未来1至3年会有一些开放的API。对，GP5可能不仅是能够处理图片，可能还能生成图片，这具体我就不知道了，但是我觉得就这些API会慢慢的开放，这是未来1到3一定会发生的事儿。",
      "speaker": "发言人4"
    },
    {
      "time": "00:40:54",
      "text": "然后可能还要落地上面的话也会有更多的。我们看到比如说企业什么的，就等会儿这个浩宇老师肯定就会更有经验，但是我觉得就是落地会更多，然后拉满二出来，可能拉满三还会出来coding，说不定也很强。然后对于一些企业的他自己的这个drain里面的一些能力，我觉得也会增强很多。尽管它不是一个frontier模型，但它也不需要一个frontier模型。我觉得未来十年这个事儿就非常难说了。",
      "speaker": "发言人4"
    },
    {
      "time": "00:41:20",
      "text": "我就那么说吧，现在是2023年，然后我自己就是进AI是2012年的时候，然后一二年的时候，那时候我还是本科生。一二年是深度学习元年，一二年刚有alex net出来，然后那个时候我看Alice net就对神经网络特别的感兴趣。对然后一二年那个alix net其实是相比于今天是一个非常弱的一个模型。但是这过去十年这个变化，我觉得简直是我不敢想象的。如果你问一二年，当时我就说你十年以后大概会怎么样，对吧？我可能说十年以后，我们估计在MCN上面的这个准确率能再上个十个点就还是贫穷限制的想象。那个时候觉得就是看到这个AI这圈资源，包括资源那时候其实也没有那么的多。所以我觉得那一块至少一二年的时候是很难预测十年以后的。",
      "speaker": "发言人4"
    },
    {
      "time": "00:42:11",
      "text": "所以我觉得现在也同样让让我想象未来十年的话，首先我觉得10年到15年我们会看到机器人。大家可以打个赌，我们十年以后，吧？我们四个再回来再做一个podcast，看十年前我们当时讲的对不对。我觉得10到15年的话，会有机器人的落地，通用机器人算法的实现，以及可能一个很强的一些机器人的那些硬件的出现。因为现在我觉得很多白领的一些工作，其实已经一点一点的可以至少被半自动化，甚至全自动化在未来3到5年。",
      "speaker": "发言人4"
    },
    {
      "time": "00:42:45",
      "text": "但是其实就是物理世界里面的，比如说做饭、做家务所有这些事情，工厂里面的一些体力活，其实现在还是需要人力，因为这个事情对于机器人来说太难了。但如果未来10到15年有通用机器人出现，比如说就像你训练一个人的工人一样，你告诉他这个零件要这样装，或者我家里面这些餐具的摆放是要那么放。你就给他一个prompt，你就prom他一次，然后包括我这个饭，我就喜欢那么做，我口味就是这样。你给他一个这样一个多模态的一个prompt，然后这机器人就立马能够学会这个技能，并且每家每户里面这个机器人用的方法还不一样。其实我们就可以想象一下，现在ChatGPT就是每家每户prompt的不一样，每个公司也用的就能够用出各种各样的花样。然后如果这个机器人的通用模型也能够用种pro的方式玩出各种花样的话，我觉得这个就是人类文明的一个巨大的进步。对，也是一个绝对是工业革命级别的一个东西。",
      "speaker": "发言人4"
    },
    {
      "time": "00:43:40",
      "text": "然后第二个我想说的就是我觉得未来10到15年的时候，比如说纯语言模型这种推理的模型可能已经超越人的智能了。然后我的意思就是他可能比如说是爱因斯坦级别的智商，就可能现在就是大家，那个普通人的智商可能现在GPT4都没有完全达到。但我觉得10到15年的时候，他可能是人类顶级科学家的智商。然后他能够推理，能够看到数据里面的一些这种hidden the pattern。",
      "speaker": "发言人4"
    },
    {
      "time": "00:44:08",
      "text": "其实我们想一下，科学家、艺术家大概就是这种创作这个过程是一个什么样的过程？其实也是基于前人有很多灵感，然后把这灵感串起来，发现他的这个second order或者更高这个order之间的这种联系。然后把这个东西融合在一起，再加点自己新的东西，这就是其实人的创新的过程。像gbt 4还做不太到，但我觉得十年以后务必能够做到。",
      "speaker": "发言人4"
    },
    {
      "time": "00:44:32",
      "text": "这样的话意味着什么？意味着AI for science这一块也会有一个很大的一个突破。就是人类的科学家可能会和GPT科学家一起合作，来研发一些下一代的一些科技。所以那个时候我觉得可能比如说什么室温超导，什么核聚变，这些事情可能是我们跟着AI科学家一起发现的。因为他们不像人的这个PHD学生，我们不能24期一直在里面工作。但是AR他也不觉得累，他永远都不会喊累。然后他就247，而且他能够可能一天就读一万篇论文，然后没有人类能够做到，他甚至能够去自己去做实验，去做分析。",
      "speaker": "发言人4"
    },
    {
      "time": "00:45:14",
      "text": "假设机器人已经有的话，那就不需要人去做那些比如说生物的实验。一个GPT的一个科学家的大脑，它可以去控制一个机器人，去帮他做一些生物的实验，一些化学的实验。然后这样的话，现在LK99就不是靠人来炼金术一点点练出来的。是可能1000个机器人在里面没日没夜的练agent没日没夜的去练这个材料，然后反馈给AI的大脑，让AI大脑再告诉你，根据今天的实验结果，明天的实验应该怎么做，我们就可以大规模scale up科研的进展。然后大家可以想象这件事情，我觉得是非常又激动人心又恐怖的。因为其实就是这种物理世界上面这些规律，材料科学这种科技上的发展也能靠AI来加速。",
      "speaker": "发言人4"
    },
    {
      "time": "00:45:58",
      "text": "对，他们到时候就不需要写论文了，有什么发现直接在agent之间share knowledge就可以了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:05",
      "text": "对，然后最后跟我们汇报一下就行了。就说我们今天又发现了一个新的发明。",
      "speaker": "发言人4"
    },
    {
      "time": "00:46:10",
      "text": "我本来是想这个问题最后问的，但是因为你讲到这一点，我就顺便问一下，我不知道这是不是你最后一个问题。那从这个角度上来讲，你觉得不管是你或者你周围的人，或者说我们的下一代，应该怎么prepare for这种时代的到来？因为我个人是非常同意你的一个十年的assessment，就像你说的，非常令人激动，但是又是可能是令人恐惧，不管你喜欢不喜欢我觉得这个时代会到来。在这种前提下面，不管是你个人还是你的你你对你的朋友，你对今天正在读大学的，或者甚至于下一代，他们怎么去学习，他们怎么去准备这个时代，你是怎么想的这是一个很好的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:53",
      "text": "对我觉得就是现在可能最前沿的这些AI什么科技什么，还有包括做研究什么的，我觉。这些目前为止还是要人来驱动的，我觉得现在GPT只是一个工具。当然我这个回答肯定非常BIOS ed的。就是我觉得可能现在就是做一些科研，就是静下心来学习一下现在最新的这个东西，然后就是keep一个open mind。比如说有些新的技术过来，然后就立马就能够很快的能够学习，能很快的抛弃可能曾经的一些旧的思维模式，然后迅速的，适应一种新的思维模式。我觉得这个可能是大家都需要有一个能力。",
      "speaker": "发言人4"
    },
    {
      "time": "00:47:28",
      "text": "其实我觉得对我来说，我自己也在不断培养自己的真能力。每天开打开推特就觉得又有一些新的想法。新的这些东西可能跟我两三个月前做的做研究时候的一些思维模式都已经有一些不太一样的地方了。所以我现在就是逼着自己每天就接受这些新的思想。尽管有些时候就觉得跟上这个脚步，就是不断的跟上这样一个科技的脚步，其实还挺累的。但我觉得这个是一个有必要的一个这种mental exercise。",
      "speaker": "发言人4"
    },
    {
      "time": "00:47:56",
      "text": "我能不能chAllenge一下？我觉得这个好像还不够颠覆。我们我们就说假设你现在是读大学一年级，你觉得你会做什么样的事情？因为今后十年的发展你会很不一样。比如说你仍然会按部就班的学这些课程，然后找份工作对吧？或者读PHD，还是说你会有有哪些想法，你会觉得你会想要颠覆自己的学习或者说工作的历程的吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:23",
      "text": "我是觉得这种critical thinking这样的一个技能，它也不是跟着现在这个科技改变而改变的。我觉得每个人都需要有thinking。其实我觉得甚至如果我们不谈AI只是谈教育的话，很多人就说大学无用论，对吧？你说大学里面学的什么这种物理，微积分什么的。如果之后比如说出来就是你当的是一个basis manager。为什么要懂微积分呢？我觉得其实是一样的这个道理就是它培养一种是推理，然后一种就是那种思维模式。",
      "speaker": "发言人4"
    },
    {
      "time": "00:48:54",
      "text": "Critical inking的模式其实有有点像我觉得有点像这个GBT的训练，对吧？然后我还发现如果GPT训练在写代码的数据上面，它推理能力会更强。尽管你最后用GPT做的事情并不擅长写代码。所以我觉得同样的，我觉得对于人来说，其实我们就是在pretend这些思维模式，不一定是我们学的这个化学或者物理的某一个某一块知识之后就一定会有用。甚至我觉得以后问GPT，GPT知道的比我们更多，都不需要去问专家。但我觉得这一块其实培养了就像大学教育一样，培养这种critical thinking，培养的是一种creativity。就是怎么样去思考这些问题，对怎么样应对change也是一种ability。而且我觉得这个东西是跟着教育的越多，然后这样的这个能力其实是会变得越强，这是我对教育的理解。",
      "speaker": "发言人4"
    },
    {
      "time": "00:49:45",
      "text": "然后另外一方面，我觉得如果10到15年以后，真的是像我们刚才说的这样，有一个进入一个科幻的这样一个世界。那我觉得可能绝大部分人，甚至包括AI的研究员都会失业，对吧？因为AR他能够自己研究他下一代的自己了，并不需要我们有多少大的介入。",
      "speaker": "发言人4"
    },
    {
      "time": "00:50:02",
      "text": "然后我觉得那个时候是社会和人类文明本质上的一些变化。那个时候比如说工厂里面都是机器人的那些工人在里面生产，然后所有的餐厅里面机器人在帮我们做饭，还有包括可能农业收割什么的，都是机器人一条龙服务，那我们就不需要工作了。然后那个时候我觉得可能人类社会会达到一种尽管大家都失业，但是大家生活很富足。然后大家就可以pursue他们自己想要追求的东西，就是他们真正内心喜欢的东西。之前那个心理学家muscle，然后他有一个金字塔，人类需求的金字塔，金字塔越越往下就是越趋近于生理的需求，越往上是越精神的需求。然后可能最底层就是先要基本的温饱，然后在上吧？比如说有稳定的工作，然后再上面就是赋予了这个时候，然后最最上面叫做自我实现。",
      "speaker": "发言人4"
    },
    {
      "time": "00:50:55",
      "text": "在上面是写做波克尔。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:59",
      "text": "但是这个金字塔的顶端就是自我实现，自我价值的实现。就当你这个物质的生活已经完全不用去愁，也不用去跟别人抢资源这个时候，最上层就是自我价值，然后自我价值对每个人都不一样。可能那个时候没journey对吧？已经版本20了，然后他已经能够做所有的这个人的这艺术上能够做的事情了。然后那个时候我们在学画画，就不是为了靠这个为生，而是我就是喜欢这个画，我就是喜欢用笔在纸上画出这些我心中这个图案的这个desire。对，而不是我我要靠卖画为生。然后我觉得那个时候这个社会会很不一样。",
      "speaker": "发言人4"
    },
    {
      "time": "00:51:37",
      "text": "我非常同意这一点。就是你在practice，你在大学里面学的是更多的是practice about your thinking。当然我觉得很很知识这部分，很多fundamental部分可能还不会变。像华为之前也提到很多computer science里面的philosophy，包括有一些最基本的一些complexity的是比如说排序算法，它的这个如果基于比较的话，理论下界杂度是多少，就这些或者是有很多像停机问题，generally它不是一个decide able的问题。对这些fundamental东西我觉得不会变。以及你得知可能这些知识会教教你说你的帮助在哪里。或者是在在现在这个体系里面哪些是可能做的，哪些是不可能做的。以及你要对比如说最基本的算力或者是复杂度，我觉得还是需要学习的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:52:23",
      "text": "当然另外一方面我觉得可能做个类比，就像是我觉得大学也是相当于是一个你在去做prompt，你自己做future能力的ability。这个prompt本身更像是你会看到过去的经历，有方法A然后后来大家第三个方法B你可能学的不是方法一或者方法B本身，而是这个improvement怎么做。觉得这个量，反正我觉得fundamental的知识以及improvement的这种critical thinking，还是得就是再再college会靠过来的事情。",
      "speaker": "发言人3"
    },
    {
      "time": "00:52:52",
      "text": "我个人觉得短期内我觉得language model会enable这种real time的一些application。比如说像这些自动驾驶那些汽车，他们自己每每辆汽车自己会有一个on device的GPU或者这样就是他他不会说把这个service跑到云端，为的也是real time。如果你能做到real time这件事情，它会unlock很多这种新的possibility。包括在问答情况下，或者是做decision making的时候，特别是不有些时候真的是time sensitive decision making。就是我我觉得real time这件事情可能在1到3年应该会能够做到一个程度。包括算力，或者是包括模型几10比0或者几百比例这种规模可能已经能够做到这样的real time的事情。",
      "speaker": "发言人3"
    },
    {
      "time": "00:53:38",
      "text": "然后十年老店我也回想一下我自己十年前在在做啥，以及我刚刚开始读PHD的时候，我们当时虽然已经有了depending这件事情，但是我们当时做topic，我不知道大家有没有听过叫kernel methods，这可能是比较classical的machine learning的一些方法。然后我们当时在做了一个topic，是怎么让clonal method跑的比迪弗兰尼更好。然后是一个相当于是一个against current的这样一个strategy。虽然有点不甘心，但是确实我的PH第一年都在做一些这样事情，然后发现确实干不过。然后十年前我觉得这类比下来，放到今天的话，我觉得你现在看十年后得是一个至少是ride the wave或者follow的这个current这样一个往往前布置的一个事情。对然后具体的形态的话，十年之后可能一开始提到一些VV像personalized的这种language mode，以及可以personal individual。如果到时候算力已经这种平民化了，这种情况下的话，我觉得反倒是这个customer ation，或者是是individual自己也会有一个personalize的这种language model这样的一个scenario，肯定也不一定是language model的那时候反正某一种放了一首model.",
      "speaker": "发言人3"
    },
    {
      "time": "00:54:58",
      "text": "我觉得是一年之内大家其实都已经看得到对吧？会有google，会有games model？OpenAI，会有GPT five。然后任何一个公司，包括我自己的公司，我们会有自己的model出来，自己的code的，自己的assistant这些AI base的，我觉得这些都会出来。两三年之内我觉得大量的企业软件都会不能算是重新写一遍，但是会大规模的被重新思考。",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:27",
      "text": "但我觉得十年这十年我觉得是一个蛮蛮大的一个改变。因为十年我觉得那个时候觉得每个人，每个公司都有大量的agent，大量的system，大量的corporate。就是说我做很多事情不需要跟我今天所做的很多事情不需要跟人，不需要跟salesforce，不需要跟我今天打交道的那些entity或者人打交道，我都只要跟agent打交道，到了那个时候不代表我就没事情做了，我相信我有更多的对吧？那个马斯洛的那个东西，到当时候，有当时候的definition的不同的需求。我觉得从技术上来讲，如果说我们AI只是做了一些让我们做的事情更加efficient的。比如说salesforce，今天我需要follow一个world floor，但是明天十年以后这些事情奥特曼的我觉得如果只是做到这些东西，我觉得是一个big failure of the AI。因为我觉得AI这只是做了一个incremental的一个efficiency的提高。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:25",
      "text": "我觉得AI如果说十年以后真正要真的起到作用，有一部分就像James说的，就是说他要对跨领域要做到很大的一个。今天跨领域你看做mechanics吧啊，o robotics超导，或者不管怎么样，其实都有巨大的borrow neck对吧。他的borrow neck是因为他的人不够，然后看paper的速度不够，所以iteration迭代的速度不够，我觉得要用AI的这个不管是agent也好，或者怎么样去去使得它的迭代速度提高。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:57",
      "text": "我经常跟一些企业的老板说，我说你要想象，假设你今天有几个program，你觉得再大的一个很大的公司有可能有200个、500个program。当然google、facebook不算，就是说绝大多数世界上的公司有几百个program。但假设你有1万个10万个program，almost for free in your company, what are you going to do right?",
      "speaker": "发言人2"
    },
    {
      "time": "00:57:17",
      "text": "我觉得10年以后，你就是在这么一个状态，有UFT要去改变一些很多跨领域的、跨学科的一些非常foundation。他们进展的速度，我相信十年能够会看到很多类似的这些的progress。所以说只是我订饭那个买东西那个recommendation更好。我觉得这个太那个了，太浪费资源了。我觉得有没有说老实话，对我不是那么一个那么重要的。但是对我们人类的foundation的technology提高，我觉得是十年以后我们会看到，jm刚才说的这些事情，至少是以有板有眼，能够我看到能够agent的去帮助这些，我觉得是能够看到。",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:00",
      "text": "然后另外一个问题，我问那个建前面提到过，所以对你如果说十年前你会怎么样？我这个问题其实是我非常想探索再探索，但我没有一个很好的答案。今天jim他给了他一个答案是我首先是一个仍然需要一个critical thinking，对吧？但我觉得这个可能还不够，我觉得可能教育上面会有比较大的方面提高。刚才你提到那个教育本身其实就是一个retraining，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:29",
      "text": "对，但我今天已经有很好的pretending我这个retraining出来的model是我能够推荐出来的。十倍、100倍甚至1万倍好的时候，我为什么要花大量的时间精力去，我可能要做的事情是怎么去interact，怎么去跟这些model去去交互，但然后我自己的unique，我自己的价值在哪里，我能够想到的一点，就是我觉得是leadership，就有点像今天所有的人，不是所有的大多数的马工，他有可能是individual contribute。我觉得应该要想象的就是我每个人都那份工作都已经没有了。到十年以后，你有的工作就是tech lead的manager或者director，甚至于VP的工作。那个时候是有你你怎么去做那份工作，怎么去劝对吧？这是一个我最近在思考，我没有一个很好的答案。我是非常不管是听众还是我周围的朋友啊，如果说能够分享一些，能够贡献一些，大家去cross sw一些，怎么去迎接未来十年，我觉得是一个很好的话题。今天我们。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:34",
      "text": "已经聊了两个多三个差不多3个小时的时间，真的是非常的非常的尽兴。最后如果还要再加一两句话的话，大家还有什么想要跟听众说的？",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:45",
      "text": "我最后有一个问题问jam，当亚马逊的创始人jeff vessons follow你的twitter的时候，你心里是在想什么？能不能跟我们分享一下？",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:56",
      "text": "他当时follow我的时候，我还没follow他，我在我的时候我不知道他follow，所以还挺尴尬的，后来赶紧follow back。对。",
      "speaker": "发言人4"
    },
    {
      "time": "01:00:05",
      "text": "那就是有没有给他发私信，不敢。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:09",
      "text": "就这么点。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:11",
      "text": "对，但我觉得就是现在确实在推特上什么的有很多noise，就是感觉有很多happy，然后还有包括杂七杂八的这些信息特别多。我希望自己为这个社区做出的一个贡献，就是能够提高一些这种signal to noise的这个ratio，能够给大家多create一些比较高质量的，比较有价值的一些一些内容。有些时候我也会提一些自己对一些最新工作一些看法，当然也不一定对，但是我觉得就至少能够让大家可以开始一些debate，开始一些conversation。",
      "speaker": "发言人4"
    },
    {
      "time": "01:00:45",
      "text": "对，我们把这个GF的这个twitter的handle放在show note里面。如果你还没有关注的话，就反省一下，然后赶紧去关注。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:55",
      "text": "连首富都在关注了，你还有什么理由不关注？",
      "speaker": "发言人2"
    },
    {
      "time": "01:01:00",
      "text": "对，最后大家聊一聊，就是一两句话做一个clothing也聊一聊。以后还想要再再多讨论的话。",
      "speaker": "发言人1"
    },
    {
      "time": "01:01:08",
      "text": "对我觉得就是sofa。大家也看到很多学术界、工业界在兰科是魔头上的一些成果，然后也大家其实热情非常高涨的。但是其实很多DTL的问题，就包括落地的时候会碰到很多DTL的问题，这些还没有其实真的大家静下心来去解决。所以我觉得希望这个之后也可以更关注的这些更底层这些包括哪怕只是用好一个two这样一件事情，就有很多话题可以聊。我觉得怎么去把它真的make is useful，这个话题我觉得特别期待之后能够再deep dive。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:44",
      "text": "好的，下一期播客已经安排上了。",
      "speaker": "发言人1"
    },
    {
      "time": "01:01:48",
      "text": "对我我个人是很相信这个技术里面的这个exponential growth，就这种指数级的增长。如果我们看过去的话，刚刚也提到Alice net，但其实在alex之前就是AI已经整个领域已经做了很久很久了几十年。其实就第一篇那个卷积神经网络就是一个阿里斯的前身，差不多在一九七几年的时候做的叫neo cot内容。然后那个工作能做的就是区分一些手写的数字，比如说12345这样区分3和5，然后alex net其实就是那个升级版，然后区分的不是数字，是狗和猫和飞机对吧？不同的这些类别。然后从区分3和5到区分狗和猫，这整个领域花了33年的时间。然后从区分狗和猫到gbt死活了十年的时间。",
      "speaker": "发言人4"
    },
    {
      "time": "01:02:37",
      "text": "所以这个是我觉得是一个很直观的一个技术的指数增长的这样子一个案例。所以我觉得刚才提到未来10到15年，可能刚才讲的有点像科幻。但是可能到那个时候我没有觉得也是理所应当的这件事情。对所以我对未来还是充满了一个很乐观的一个态度。但是我觉得未来乐观就意味着我们今天要更加的努力。",
      "speaker": "发言人4"
    },
    {
      "time": "01:02:59",
      "text": "对，所以就是我也就是希望所有的听众，你们对AI感兴趣的话，也一起加入这个浪潮。然后现在网上有很多的这种教程、资源，还有开源的代码。我觉得学习AI最好的方法就自己动手，亲自去用一下这个模型，亲自去感受一下。",
      "speaker": "发言人4"
    },
    {
      "time": "01:03:18",
      "text": "我觉得jm提到的就是怎么去准备，我觉得这是一个他刚才提了一个方案，但是这是一个很大的未知数，就是到底是怎么去追加。如果说十年以后回过头去看我觉得我们会觉得今天大学生应该做这件，做那件，有一些我们今天没看到的，这是一个我觉得我非常passionate会去思考的一些一些问题。刚才杰米也提到另外一个signal to ratio。",
      "speaker": "发言人2"
    },
    {
      "time": "01:03:49",
      "text": "非常不幸的是我觉得今后十年，我觉得人类看到的质量更低的信息可能是那个比率可能是越来越大，而不是越来越小讲。因为有大量的信息是机器可以生成，对吧？今天可能人生存机器生成还能比1比，再过不久其实是绝大多数的信息都是机器生成的。所以说趁大家还有人类生成的信息，包括我们做的这期播客的时候要多听。",
      "speaker": "发言人2"
    },
    {
      "time": "01:04:19",
      "text": "没有，那是开玩笑。但是确实是我觉得那是一个非常重要的就是你怎么决定要去学习什么样的东西，然后学习什么样的技能。在今后十年是非常非常过去几十年已经是一个定，就是说大家就沿着一条路，反正你就是这条路，基本上就可以成功或者怎么样。我觉得今后十年要走什么样的路，其实是一个需要大家都去思考的，对很多人来讲，这其实是一个蛮大的挑战。但对我来讲，或者说我一直跟周围的人说，this is the best time to live, 非常的开心，living this moment，这是人类历史上最好的生活的时刻。就是我认我这么认为。",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:00",
      "text": "华伟这个总结太好了。我也非常有幸在这个最好的时刻跟几位来进行了一次。我觉得这是最美好的很长一段时间内最尽兴也是最有收获的一次谈话。然后再次感谢几位的这个时间在加州非常一个非常lovely的一个周末的上午，花了那么长时间来探讨人工智能这个话题，感谢大家时间，谢谢谢谢。",
      "speaker": "发言人1"
    },
    {
      "time": "01:05:23",
      "text": "谢谢感谢。",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:24",
      "text": "大家的收听。如果你喜欢我们pocus内容，欢迎你点赞并分享给可能感兴趣的朋友。有任何建议反馈都可以在评论区留言，我们都会很认真的看的。如果你在用apple podcast收听，也希望你花几秒钟给我们打个五星好评，让更多人了解到我们我们下次再见。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "本次对话汇聚了多位行业专家和学者，共同探讨了人工智能（AI）领域内生成式代理、多模态大模型、具身智能机器人以及AI对SaaS行业影响的核心话题。讨论强调了数据科学与技术落地过程中遇到的问题及其解决方案的重要性，以及深入探索现有技术（如深度学习）的潜力和通过实际操作模型学习人工智能的价值。嘉宾们指出，虽然AI技术在过去几年取得了显著进展，如大语言模型在自然语言处理和生成方面的应用，但仍面临如何更好地理解和处理多模态数据、如何使AI系统具备具身智能以及如何有效应用于实际场景等挑战。讨论也触及了AI未来可能带来的社会和商业影响，强调了持续学习和适应技术变化的重要性，尤其是在教育领域培养批判性思维和跨领域能力的必要性。最后，对话鼓励听众关注高质量内容，积极参与AI领域的讨论和研究，共同推动AI技术的发展和社会的正面变革。",
    "qa_pairs": [
      {
        "question": "在AI领域中，为什么您会在Twitter上提到拉拉兔（Llama）对于多模态和机器人领域的重要性？",
        "answer": "我觉得多模态是一个非常有趣且具有挑战性的问题。目前大语言模型的基本框架已相对固定，但在多模态这一块，整个处理流程还很不确定。拉拉兔作为基于现有大语言模型（如lama 2）接入其他模态信息的插件式方法，可以在较少计算量的情况下实现不错的多模态效果，比如将视觉信息融合到语言模型中，提升模型对多模态的理解能力。",
        "time": "00:02:39"
      },
      {
        "question": "多模态在机器人控制方面如何应用？",
        "answer": "在机器人领域，可以通过类似的方式将控制命令这一种“输出插件”接入多模态模型中，让机器人能够根据视觉、听觉等多种输入信息输出机械手控制指令或其他操作指令，从而提高机器人智能水平。",
        "time": "00:03:42"
      },
      {
        "question": "对于多模态模型的发展现状和未来展望，您有什么看法？这两种多模态处理方式的核心区别是什么？",
        "answer": "我非常同意jim的观点，多模态是未来发展方向，并且目前有两种主要的探索方式：一种是将其他模态作为插件接入已有的大模型中；另一种是尝试将连续空间的模态转化为离散空间的token进行统一处理，例如使用扩散模型处理图像和文本，这可能是一种更为原生且高效的多模态处理方法。第一种方法可能会冻结基础模型的部分参数，仅调整特定模态的部分；而第二种方法更原生地整合不同模态信息，在处理过程中可能表现出更高的智能水平，能够完成前一种方法难以实现的任务。",
        "time": "00:04:19"
      },
      {
        "question": "多模态对于提升AI智能的整体期望是什么？",
        "answer": "大家普遍期望多模态能够使AI模型更好地理解和处理多种类型的数据，从而开启更多新的应用场景，特别是对机器人技术产生重大影响。然而，对于多模态是否能显著提升基础模型的智能本身，则是一个值得哲学思考的问题。",
        "time": "00:07:46"
      },
      {
        "question": "解决多模态问题对于机器人的意义是什么？",
        "answer": "解决多模态问题是机器人技术进步的重要一步，它解决了输入理解的问题，让机器人能够理解世界。但输出仍需通过其他方式解决。长远来看，这一突破对未来AI革命具有重要意义，尤其是当机器人普及到每家每户如同iPhone 1一样存在时，将会带来下一轮工业革命。",
        "time": "00:13:05"
      },
      {
        "question": "GPT4在处理多模态数据方面的表现如何？",
        "answer": "GPT4在vision部分和text only版本上都有所提升，特别是在一些基准测试和解决包含图片问题的任务上表现出明显优势，比如数学证明和网页渲染后的CSS理解等场景。",
        "time": "00:13:32"
      },
      {
        "question": "当前多模态数据处理存在哪些主要难点？",
        "answer": "主要难点在于如何有效表达和利用冗余的视觉信息，以及如何在现有算力和算法基础上更高效地处理高维度的视频数据。目前学术界正在尝试将视频tokenize并转化为语言般的离散表达形式以进行处理。",
        "time": "00:16:45"
      },
      {
        "question": "在大模型训练和应用过程中，有哪些工具层面需要弥补的gap？",
        "answer": "需要开发新的适应具体应用场景的工具，如将大模型应用于企业自有工具量或特定领域语言。此外，如何让语言模型适应并利用已有的工具（例如通过procedure generation）以实现更高效的任务执行，如text to video生成。",
        "time": "00:18:30"
      },
      {
        "question": "在OpenAI工作期间，有哪些项目或进展给说话人留下深刻印象？",
        "answer": "在OpenAI早期阶段，训练AI控制鼠标和键盘的项目以及在Dota游戏中战胜人类世界冠军的团队等项目让人印象深刻。同时，16年时就开始探索AGI方向，如机械手解魔方项目和基于LSTM模型的文本生成实验，这些都为后续GPT的发展奠定了基础。",
        "time": "00:20:01"
      },
      {
        "question": "Jim，你认为当时拉姆达模型是否比chat GPT质量差？",
        "answer": "当时拉姆达可能在质量上不一定优于chat GPT，但随着时间推移，两者都有显著进步，包括ChatGPT本身也在不断迭代升级。",
        "time": "00:26:31"
      },
      {
        "question": "你能否举个例子说明OpenAI早期项目的影响？",
        "answer": "当时OpenAI在Reddit上训练的chatbot（GPT-0）后来发展成为今天的GPT系列。此外，他们还拥有强大的内部强化学习基础设施，并在算法上进行了大量探索，比如将强化学习应用于GPT-2，以及创建了类似今天的Chat GPT应用商店登录功能的早期版本。",
        "time": "00:26:49"
      },
      {
        "question": "GPT-3和Cryp和Dalila的工作对你的影响如何？",
        "answer": "GPT-3和Cryp-Dalila的工作开创了一个全新的思维模式和范式，即scale up（堆叠更多算力）和open world（利用互联网数据进行训练）。这在当时是前所未有的创新，颠覆了学术界固定训练集和测试集的传统观念。",
        "time": "00:27:34"
      },
      {
        "question": "OpenAI在GPT-3、Clip和DALL-E等项目上的突破是什么？",
        "answer": "这些项目展示了对计算机视觉和文本领域巨大的震撼，尤其是GPT-3在文本上的scale up和Clip在图片与文本对齐模型上的贡献，以及DALL-E在处理纹身图等领域的简单算法与大量open world数据结合的应用，都是算法和思维模式上的重大突破。",
        "time": "00:29:49"
      },
      {
        "question": "ChatGPT出现时对学术圈和业界带来了哪些冲击？",
        "answer": "ChatGPT不仅在工程上是一个奇迹，拥有出色的API设计和用户增长速度，而且从算法层面也带来巨大震撼，尤其是GPT-4展现出的强大写代码能力。斯坦福等学术机构感受到了压力，开始转向foundation model的研究，并成立了相关中心。",
        "time": "00:30:28"
      },
      {
        "question": "对于大语言模型的发展，业界存在哪些误解或低估的问题？",
        "answer": "业界可能低估了机器人技术在硬件、产能、算法以及商业落地等方面的挑战；同时，组织能力对于创建和维护foundation model公司的重要性也被忽视了；此外，在模型评估和度量标准方面，业界也存在一定的误解，因为以往学术界常用的benchmark可能并不完全适用于工业界的实际应用场景。",
        "time": "00:36:28"
      },
      {
        "question": "你认为现在人工智能目标函数的潜力和当前对它的低估体现在哪些方面？",
        "answer": "现在的人工智能目标函数虽然被一些人低估，但实际上它有可能实现AGI（通用人工智能）。此外，在评估和评价模型时，人们往往缺乏自我evaluate的能力，以及对不同视角下模型表现的理解，这也导致了对模型能力的不准确判断。同时，我认为GPU算力在未来并非瓶颈，因为随着技术进步和mass production，价格会不断下降。",
        "time": "00:38:59"
      },
      {
        "question": "在未来一年和未来十年，你对大宇模型或人工智能最期待的事情是什么？",
        "answer": "在未来一年内，我期待看到更强大的编码模型以及软件工程自动化方面的进展，例如报警系统的优化。而在接下来1到3年内，多模态模型将出现，并逐步开放API，如GP5不仅可能处理图片还能生成图片。对于企业应用层面，会有更多落地案例，同时也会有更多针对开发者能力提升的产品出现。",
        "time": "00:40:02"
      },
      {
        "question": "对于未来十年，你有什么预测？",
        "answer": "未来10到15年内，预计会出现通用机器人算法的实现和强大的硬件支持，许多白领工作有望被半自动化或全自动化。此外，纯语言模型推理模型可能达到甚至超越人的智能级别，成为类似爱因斯坦级别的科学家。这一时期，AI将助力科学领域取得重大突破，比如通过AI科学家与人类科学家协作加速科技研发进程，甚至可能发现室温超导、核聚变等重大科学发现。",
        "time": "00:43:40"
      },
      {
        "question": "面对未来科技发展，个人和下一代应该如何准备？",
        "answer": "目前前沿的AI科技仍需人来驱动，所以最重要的是保持开放思维，快速学习接纳新技术，并摆脱旧有的思维模式。培养批判性思维和创造力是关键，因为这些能力在未来社会中依然重要，无论科技如何发展。同时，随着AI研究者可能普遍失业，社会将面临根本性的变革，届时物质生活富足，人们可以追求真正的自我价值实现和个人兴趣所在。",
        "time": "00:46:53"
      },
      {
        "question": "在大学阶段学习的计算机科学知识和技能，哪些是不变的，哪些可能会随着技术发展而变化？",
        "answer": "大学阶段学习的计算机科学知识中，一些fundamental的部分如算法复杂度理论下界（例如基于比较的排序算法的下界）、停机问题等是不会变的。但学习如何运用这些基础知识去解决问题以及了解技术体系中的可能性和限制将会随着技术进步而变化。",
        "time": "00:51:37"
      },
      {
        "question": "大学教育的核心目标是什么？",
        "answer": "大学教育更像是一种prompt能力的培养，即学习如何基于过去的经验和已有的方法进行改进和创新。重点在于理解和掌握如何提高和改进现有技术或方法的能力。",
        "time": "00:52:23"
      },
      {
        "question": "对于未来一到三年内AI技术的发展趋势有何预测？",
        "answer": "预计语言模型将在一到三年内实现实时应用，比如在自动驾驶领域，每辆汽车可能配备本地GPU以实现实时处理。同时，AI将帮助企业软件重新思考和重构，大量企业软件将在两三年内经历大规模改造。",
        "time": "00:52:52"
      },
      {
        "question": "十年后的AI技术会有怎样的改变？如果十年前的自己能知道未来AI的发展情况，会有什么启示？",
        "answer": "十年后的AI技术将带来巨大变革，每个人和公司都将拥有大量的智能代理，许多任务将由AI代理完成，这将极大地改变工作方式。那时，AI不仅提升效率，还会跨越不同领域，解决当前因人力和信息处理速度限制而存在的瓶颈。十年前的自己需要保持开放和批判性思维，同时也意识到教育的重要性。尽管AI技术在未来会极大地改变工作方式，但人的独特价值可能体现在领导力、人际交往等方面，如何适应和利用AI技术提升自身价值是一个值得深思的问题。",
        "time": "00:56:25"
      },
      {
        "question": "对于未来十年，教育领域需要做出怎样的调整？",
        "answer": "教育在未来十年应注重培养批判性思维能力，并且随着AI的发展，教育体系需要重新设计，以培养能与高质量AI模型互动和协同工作的能力。此外，还需要关注如何提高信息质量与噪音比例，促进高质量对话和辩论。",
        "time": "00:55:27"
      },
      {
        "question": "十年后个人在职场上的角色应该如何定位？",
        "answer": "十年后，个人的主要角色可能转变为技术领导、团队经理或高层管理者，负责与AI协作并指导团队如何有效利用AI技术提高工作效率和创新。",
        "time": "00:58:29"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "软件如何改变世界：AI领域的深度探讨",
        "summary": "在这次对话中，我们深入探讨了AI领域最火热的话题，包括生成式代理、多模态大模型的研究进展、具身智能的机器人以及AI对SaaS行业的影响。此外，还对未来AI的商业和社会影响进行了展望。参与讨论的嘉宾包括在OpenAI工作过的专家和来自英伟达、Google DeepMind的资深研究员，以及硅谷上市公司的华人高管。他们分享了对AI领域核心话题的见解，并讨论了AI如何能够改变世界。"
      },
      {
        "time": "00:01:54",
        "title": "多模态模型及其在机器人控制中的应用",
        "summary": "讨论集中在多模态模型的潜力及其在机器人控制等领域的应用。首先，多模态模型允许将不同模态的信息（如文本、图像、视频、音频等）融合到一起，提高模型的综合理解能力。讨论者提到通过将计算机视觉处理后的图片信息，作为插件接入到大语言模型中，使得模型能理解视觉信息，这种方法在计算量相对较小的情况下，实现了多模态的效果。此外，机器人控制也被认为是多模态模型的一个重要应用领域，通过将多模态模型作为强大的后端，可以输出机械手的控制指令，显著提升机器人的性能和效率。讨论还触及了多模态模型在未来的广泛应用可能性，以及目前学术界和工业界在多模态领域探索的现状。"
      },
      {
        "time": "00:05:23",
        "title": "多模态模型的未来与挑战",
        "summary": "讨论集中在如何使多模态模型更高效地处理图像生成等任务，以及将连续空间的图像转化为离散空间的token的潜在价值。一方面，通过将现有模型作为基础，插入其他模块来扩展功能，如通过扩散模型生成图像，被视为一种成本效益高且质量好的方法。另一方面，讨论了将图像直接转化为文本进行处理的原生方法，这种方法被认为能够更好地统一标签和图像，进而提升生成模型的质量。此外，还探讨了多模态模型在理解和处理视觉信息方面的能力，及其与人类智能的比较，强调了视觉系统在人类大脑中占据重要地位，以及多模态模型在模仿人类智能时面临的挑战。最后，指出了多模态模型在实际应用中的潜力，如在机器人等领域开启新的场景，并对未来多模态模型的发展持乐观态度。"
      },
      {
        "time": "00:12:33",
        "title": "多模态技术在机器人领域的应用前景",
        "summary": "多模态技术被认为是机器人领域未来发展的关键技术，因为它能解决机器人理解复杂环境和执行精细动作的问题。讨论指出，机器人技术面临的挑战不仅包括对多模态信息的理解，还要解决如何精准控制机器人执行类似人类的复杂动作。尽管目前机器人在某些方面还无法与动物的运动能力相媲美，但通过解决多模态问题，机器人能够更好地理解世界，为实现机器人普及奠定基础。此外，视频数据被看作是人工智能发展的一大资源，蕴含丰富的信息，但在有效利用这一资源上，目前还缺乏有效的算法和技术。因此，未来的工作需要探索如何高效地处理和利用视频数据，以及如何进一步提高机器人理解和交互的能力。"
      },
      {
        "time": "00:16:31",
        "title": "多模态数据处理与模型应用挑战",
        "summary": "讨论重点在于如何有效处理和利用多模态数据，特别是高维数据如视频，作为训练数据的挑战。视频数据因其高维性和庞大的数据量带来处理难度，但通过将其tokenize，可以像处理文本一样简化处理过程，从而实现视频生成等应用。此外，还提到了工具和模型在实际应用中的差距，尤其是对于特定行业应用场景的适应和工具的定制化需求，强调了模型需要能够适应不同领域的具体工具和语言。最后，提到了利用程序生成来实现视频生成的研究，指出了将语言模型直接应用于生成视频的潜力。"
      },
      {
        "time": "00:19:48",
        "title": "OpenAI的早期探索与发展历程",
        "summary": "从2016年开始，OpenAI在追求AGI（通用人工智能）的路上进行了多项探索，包括通过训练AR控制鼠标和键盘、挑战Dota游戏以及开发能解魔方的机器人等项目。其中，尽管强化学习方法的泛化能力有限，OpenAI仍不断尝试并调整方向。此外，OpenAI早期也涉猎了利用LSTM模型训练的聊天机器人，这一工作可看作是GPT系列的前身。随着时间的发展，尽管面临外界质疑，OpenAI仍坚持其研究方向，不断尝试和修正，展现了其在人工智能领域探索的决心和远见。"
      },
      {
        "time": "00:24:12",
        "title": "从GPT-3到ChatGPT：AI技术的飞跃与影响",
        "summary": "对话中讨论了OpenAI自2015年成立以来的目标是实现AGI，以及随着时间的推移，特别是GPT-3的发布，对于AI技术进步的预期发生了改变。GPT-3的能力展示让讲话者对AI的快速发展感到惊讶，并预测ChatGPT的出现。ChatGPT的推出并未让讲话者感到意外，反而让其对量变引起质变有了更深的理解。此外，也提到了与谷歌等竞争对手的互动，以及对AI模型迭代速度的赞叹。"
      },
      {
        "time": "00:26:47",
        "title": "OpenAI的创新历程和技术成就",
        "summary": "从早期项目开始，OpenAI通过不断的探索和创新，在人工智能领域取得了一系列重大成就。其中包括在red上训练的chabot、GPT的进展、强化学习的基础设施建设、以及在计算机视觉领域的突破。特别提到了GPT-3、CLIP和DALL·E的发布，它们分别在文本处理、图像与文本对齐、以及生成艺术图像方面开创了新的纪元。这些成就不仅推动了技术的发展，也改变了学术界和业界对AI能力的认知和期待。"
      },
      {
        "time": "00:30:28",
        "title": "ChatGPT的影响与学术界的反应",
        "summary": "对话中讨论了ChatGPT及其背后的技术突破，强调了它在工程和算法上的成就，特别是在标注pipeline、数据处理、参数调整和部署等方面。ChatGPT的迅速普及展示了其强大的后端工程能力。进一步，讨论了斯坦福大学对于大语言模型带来的学术挑战的反应，包括召开紧急会议和提出“基础模型”的概念，以及如何适应这一技术变革。最后，探讨了ChatGPT对社区和云计算的潜在影响，认为虽然对传统搜索引擎的颠覆是一个长期过程，但它将显著改变B2B软件开发。"
      },
      {
        "time": "00:34:21",
        "title": "大语言模型面临的挑战及被低估的问题",
        "summary": "大语言模型在实际企业应用中遇到的挑战不仅仅是通过复杂的prompting或多次调用模型来解决问题，更重要的是模型响应速度及效率问题，这些实际应用与研究领域之间存在脱节。同时，机器人技术的复杂性被低估，其涉及到硬件、产能、算法和数据等多个方面的问题，尤其是输出控制的困难度比输入处理更大。此外，创建基础模型的公司面临的挑战不仅是技术层面，还包括组织能力、资本运作、人才吸引以及商业落地等。大语言模型的发展需要强大的组织协调能力，远超单一算法的突破，需要将各种资源有效整合。"
      },
      {
        "time": "00:37:44",
        "title": "人工智能模型的评价与未来发展",
        "summary": "讨论集中在人工智能模型的评价机制、算力问题以及未来一年到十年的期待上。首先，提出对于人工智能模型的评价不应该仅仅局限于学术基准，而应该寻找更符合实际应用的评价方法。接着，对未来一年内编码模型的强化、多模态模型的出现以及API的开放表示期待，认为这些技术进步将大大促进AI的实用化。对于未来十年的展望，通过回顾过去十年AI的发展历程，表达了对于AI技术未来巨大变革的期待，同时也强调了预测未来技术发展的困难。"
      },
      {
        "time": "00:42:11",
        "title": "未来十年机器人与AI科技展望",
        "summary": "在未来十年到十五年，预计将见证机器人技术的重大突破，包括通用机器人算法的实现和先进硬件的开发，使得机器人能执行复杂任务，如家务和工厂体力劳动，实现物理世界中的自动化。此外，纯语言模型的推理能力有望超越人类智能，达到顶级科学家的水平，从而在科学领域实现重大突破，如室温超导和核聚变等。AI科学家与人类合作，通过分析大量数据和进行实验，将加速科研进展，改变发现新知识的方式。"
      },
      {
        "time": "00:46:09",
        "title": "应对未来科技时代的准备与教育思考",
        "summary": "在讨论如何为即将到来的时代做准备时，强调了无论个人还是下一代，都需保持开放心态，学习最新科技，尤其是AI领域。指出学习和科研需与时俱进，放弃旧思维模式，迅速适应新技术。同时，提出大学教育不仅在于传授知识，更在于培养批判性思维和创造力，以及应对变化的能力。预见未来社会可能因AI技术进步而产生巨大变革，人类将更多追求精神层面的满足。强调即便在科技迅速发展的背景下，基础的科学哲学和复杂性理论等根本知识仍不可或缺，且应着重培养解决问题和创新思维的能力。"
      },
      {
        "time": "00:52:52",
        "title": "语言模型的未来及其对实时应用的影响",
        "summary": "短期内，语言模型将推动实时应用的发展，如自动驾驶汽车等，这些应用不需要依赖云端服务，而是采用设备上的GPU实现实时处理。这种实时能力将开启新的可能性，特别是在问答、决策制定等需要时间敏感性决策的场景。回顾过去十年，从经典的机器学习方法到现今对实时性能的追求，技术的发展经历了显著变化。展望未来十年，个性化语言模型和AI代理将成为常态，彻底改变企业软件和个人工作方式。AI不仅仅是为了提升效率，而是要解决跨领域的基础问题，促进技术和社会的进步。同时，教育和个人技能的提升，特别是批判性思维和领导力，将变得更加重要，以适应未来AI驱动的社会。"
      },
      {
        "time": "00:59:34",
        "title": "探讨人工智能的现状与未来",
        "summary": "在本次对话中，讨论重点放在了人工智能（AI）技术的快速发展上，特别是强调了AI领域的指数级增长，如从AlexNet区分图像到更复杂的模型仅用了十年时间。参与者分享了对于AI学习的见解，鼓励大家亲自实践和学习AI技术，以应对未来社会的挑战。同时，也讨论了社交媒体上信息噪音问题及未来技术发展的乐观态度。整个对话充满对当前AI领域成就的自豪和对未来发展的期待。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "多模态模型"
                },
                {
                  "children": [],
                  "content": "具身智能（embody AI）与机器人技术"
                },
                {
                  "children": [],
                  "content": "大语言模型（LLM）的发展"
                }
              ],
              "content": "AI研究进展"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "通用机器人算法的实现"
                },
                {
                  "children": [],
                  "content": "机器人在家庭、工业等领域的应用"
                },
                {
                  "children": [],
                  "content": "机器人与AI的未来融合"
                }
              ],
              "content": "机器人应用"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI对未来教育的影响"
                },
                {
                  "children": [],
                  "content": "AI在科学发现中的作用"
                },
                {
                  "children": [],
                  "content": "AI促进的工业革命"
                }
              ],
              "content": "AI技术的社会影响"
            }
          ],
          "content": "人工智能与机器人技术"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "critical thinking（批判性思维）"
                },
                {
                  "children": [],
                  "content": "适应性学习能力"
                },
                {
                  "children": [],
                  "content": "leadership（领导力）"
                }
              ],
              "content": "个人技能的转变"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "工作岗位的消失与新职位的产生"
                },
                {
                  "children": [],
                  "content": "教育体系的变革"
                },
                {
                  "children": [],
                  "content": "社会需求层次的变化"
                }
              ],
              "content": "社会结构的改变"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "个人与技术的交互方式"
                },
                {
                  "children": [],
                  "content": "个体独特价值的寻找"
                },
                {
                  "children": [],
                  "content": "技术进步与人类幸福感"
                }
              ],
              "content": "技术与人类价值"
            }
          ],
          "content": "个人与社会准备"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "编码模型的加强"
                },
                {
                  "children": [],
                  "content": "多模态API的开放"
                },
                {
                  "children": [],
                  "content": "自动化软件工程的进展"
                }
              ],
              "content": "短期技术展望（1-3年）"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "通用机器人的普及"
                },
                {
                  "children": [],
                  "content": "AI在科学研究中的应用"
                },
                {
                  "children": [],
                  "content": "AI对于人类生活方式的彻底改变"
                }
              ],
              "content": "长期技术展望（10-15年）"
            }
          ],
          "content": "技术展望"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "大学教育的未来"
                },
                {
                  "children": [],
                  "content": "技术对教育内容的影响"
                }
              ],
              "content": "传统教育的挑战"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "通过实践学习AI"
                },
                {
                  "children": [],
                  "content": "利用在线资源和开源代码"
                }
              ],
              "content": "新型学习方式"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "对于critical thinking的重视"
                },
                {
                  "children": [],
                  "content": "面对技术变革的适应能力"
                }
              ],
              "content": "未来技能的培养"
            }
          ],
          "content": "教育与学习"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "技术的指数级增长"
                },
                {
                  "children": [],
                  "content": "人类与技术的共生关系"
                }
              ],
              "content": "对AI发展的乐观态度"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "思维能力的培养"
                },
                {
                  "children": [],
                  "content": "个人价值的探索"
                }
              ],
              "content": "面对未来的关键技能"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "对于即将到来变革的准备"
                },
                {
                  "children": [],
                  "content": "接受并利用技术进步带来的机遇"
                }
              ],
              "content": "社会与个人的适应策略"
            }
          ],
          "content": "个人见解与建议"
        },
        {
          "children": [
            {
              "children": [],
              "content": "AI技术的发展将深刻影响个人、教育和社会结构"
            },
            {
              "children": [],
              "content": "面对未来，培养适应性技能和个人价值的探索至关重要"
            },
            {
              "children": [],
              "content": "社会和个人需共同适应技术进步带来的挑战与机遇"
            }
          ],
          "content": "结论"
        }
      ],
      "content": "对话脑图摘要"
    }
  }
}