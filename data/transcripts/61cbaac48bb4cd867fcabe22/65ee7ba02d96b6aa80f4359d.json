{
  "pid": "61cbaac48bb4cd867fcabe22",
  "eid": "65ee7ba02d96b6aa80f4359d",
  "title": "EP 48. 对话Lepton AI创始人贾扬清：AI需要怎样的基础设施，模型与应用未来格局",
  "task_id": "47z39vd5rmkr9edg",
  "transcription": [
    {
      "time": "00:00:00",
      "text": "亲爱的on board听众们，千呼万唤始出来，on board终于要成立听友群了。今年我们有各种新动作，加入on board听友群，你不仅能结识到高质量的听友们，我们还会组织线下主题聚会，邀请部分听友实时旁听我们的播客录制，直接跟嘉宾提问等有趣的互动。当然你也可以在第一时间看到节目更新。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:19",
      "text": "添加小助手微信onboard 666，是不是很好记omber 666，发送你的姓名、公司和职位，就可以获得进群链接了，期待你来。欢迎来到onboard，真实的一线经验，走心的投资思考。我是Monica.",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:36",
      "text": "我是高宁，我们一起聊聊软件如何改变世界。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:44",
      "text": "大家好，欢迎来到omber，我是Monica。好久没有做一对一的专访了，这一次嘉宾绝对重磅。贾扬清老师是2023年成立的AI创业公司lepton AI的创始人。熟悉AI领域的同学应该都听过他的鼎鼎大名，他在berkeley博士期间就创立了深度学习框架咖啡，很快成为了行业事实标准。贾青老师先后在google brain、facebook AI等从事最前沿的AI研究，随后又回国担任了阿里巴巴的技术副总裁，领导大数据计算平台。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:18",
      "text": "作为AI和info行业的领军人物，杨青老师是如何思考自己的AI创业方向的？他如何理解未来AI对于基础设施的需求，跟云计算这么多年的发展有哪些异同的地方？这一年来回到世界AI创新中心的硅谷，他对于AI创业的理解，开发者工具和应用的价值，开源闭源模型等关键话题的思考又有怎样的迭代？我们不知不觉又聊了两个多小时。杨青老师聊天绝对是干货满满，你也能体会到他条理清晰、观点犀利又温文儒雅，实在是太令人享受谈话了。这大概就是博客的魅力，让我们在文字之外感受到更加真实鲜活的人。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:00",
      "text": "这次也邀请到一位嘉宾主持欧博的老朋友，真格基金管理合伙人戴雨森。在AI和投资领域，宇森一直给我很多启发，他也给这次访谈贡献了非常精彩的问题，大家就enjoy。节目开始请雨森给大家先做个自我介绍，然后就可以进入到跟杨青老师的对谈中了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:20",
      "text": "大家好，我是整个基金的戴宇森，然后也经常跟在王博的上跟孟达一起和大家交流。之前跟杨欣也认识很多年了，在学术上、创业上、管理这方面我们有很多的交流。最近AI的热潮随着soa这些的发布也达到了一个新的高度。在这个过程中，杨青作为在AI领域学术大牛，然后在大厂管理过很大规模的AI团队，然后现在也在做AI的创业，他有哪些对AI的思考判断，有哪些是我们现在还没有注意到，但是可能成为未来趋势的方向，有哪些是现在可能已经过热需要冷静思考的地方。所以今天就很期待和杨青有一个交流和学习。其实这个杨青。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:10",
      "text": "老师也是鼎鼎大名了，但是还是对于不是那么了解的这个同学，也可以请杨青青老师给大家简单一下，介绍一下你自己的经历，然后是如何进入AI的。照例我们有一个fun fact，就是最近你发现的一个比较有意思的一个AI的产品，也可以是一篇你觉得比较有比较重要的一篇paper。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:31",
      "text": "好，谢谢管理卡邀请了，很高兴来到朗博尔和大家聊一聊跟AI相关的一些事情。我是杨青。然后我基本上从读PHD当年在伯克利开始，就一直在AI和AI系统这一块来做工作。本身其实我是做计算机视觉研究的。后来因为当时deep 30刚刚开始，所以对于他的整个软件层都比较的缺失。所以我们从birke开始，而且还是一个比较偏系统的地方。我们就开始做AI的run time，ai和GPU计算异构计算的结合，以及后来更多的开始做AI info。在前面几年当中，就在google、在facebook、在阿里都一直在做这方面的工作和业务。",
      "speaker": "发言人3"
    },
    {
      "time": "00:04:10",
      "text": "去年4月份开始，我们在硅谷做一个小的start up叫做lepton AI，也是在一脉相承的从AI加系统加应用的这个角度来帮大家能够在应用AI到自己的实际的业务当中的时候，变得更加的高效快捷。一个方fact的话挺有意思的，可能稍微稍微违反一下主持人的要求。我们和MIT的韩松老师他们一块儿合作做了一篇paper叫做distribution。Distribution是通过多个GPU来加速stable diffusion的计算。今天stable diffusion on可能大家觉得已经算是比较快了，但是刚兴起的比如像video等等，也都是比较大的计算量的工作。所以我们其实一定程度上我喜欢它的原因，是因为它一脉相承的体现出了分布式一个系统对于AI当中的一个作用。2014年的时候，alex给写篇文章叫做one weird trick to speed of conclusion internets。那个时候是他通过这个分布式的CPU来实现这样或者说是全年阶层的加速。",
      "speaker": "发言人3"
    },
    {
      "time": "00:05:12",
      "text": "2017年的时候，facebook当时发表了一篇文章叫做training in internet in an hour，是通过多个GPU，多个机器分布式的训练，以及对于分布式训练算法的调优，来实现把饮水train从当年最开始的时候的一个星期缩短到1个小时。所以今天我们其实是说在新的AIGC这个领域，这种分布式计算和高性能计算的想法，其实对于新的算法也在不断的起到非常fundamental的作用。这也是我们比较喜欢的一篇文章，当然就有幸和韩松老师，包括和摩托车的作者天乐，他在princeton一块大家合作，这是一个很开心的事儿。我们代码开源的。所以说我觉得就是对于大家怎么样来提升自己的，无论是训练还是推理的速度，应用的速度，希望能够起到一定的借鉴作用。",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:00",
      "text": "好，非常感谢杨青老师这个自我介绍paper的这个链接也会放在我们的show note里面。杨青老师虽然提到自己现在做一家AI创业公司，也可以跟大家介绍一下，你的创业公司left in的AI是做什么的。然后我看到在一个你在一篇linking里面形容这是一个AI class company。那什么是一个AI class company？可以跟大家分享一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:22",
      "text": "我大概说一下我们对于AI cloud这一块的一个理解。首先其实在cloud出现之前，我们说IT这个领域一直都有的。那么从1970年代开始，基本上因为高性能计算的这样的一个需求的不断的持续。所以大家都有叫supercomputing，或者说high performance computation，或者说叫scientific computation这一块的一个领域。大家说用非常多的机器把它互联起来，在上面跑大规模的。比如说像气象模拟，物理学的模拟等等这一类的工作。这些工作当时还是属于我们在每一个公司或者说每一个科研院所自己有一个IDC这样的一个状态下面。比如说以前我们所听到过的create super computer，像国内的银河等等，都是这领域的一个工作。",
      "speaker": "发言人3"
    },
    {
      "time": "00:07:10",
      "text": "后来互联网崛起之后，其实有一个非常典型的workload，非常典型的一个负载，就是把各种各样的数据搬来搬去，对吧？Web服务意思就是说是我把外部的各种各样的数据，HTML, 图片，文字等等搬来搬去。所以这个时候为了更加有效的搬这些内容，更加有效的能够来服务scalable的用户。那么cloud就开始越来越多的作为一种标准的infrastructure的崛起起来了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:07:37",
      "text": "2008年的时候，David elson他们当时提出一个概念叫data center the computer。在这个上面，亚马逊ads开始成为全球第一朵云。它的名字其实不叫am the cloud，叫做IT am the web services。所以那么多年其实云是为了web service以及所相应带来的，比如说大量的数据库，数据分析，数据处理等等这一系列的工作所建立起来。",
      "speaker": "发言人3"
    },
    {
      "time": "00:08:02",
      "text": "AI来的时候，我们发现一个很有意思的一个状态，就是AI不光光是把一堆数据搬来搬去，还带有非常重的计算。以前的时候，比如说我们做数据分析等等，每一次绊一次数据，其实在上面的计算并不多，对吧？今天我们说AI带来所所使用的计算量可能并不大可能几个T或者最多几个P这样的一个状态。但是在这个上面所需要的计算，尤其是我们说加减乘除是非常大量的。因此我们会发现说，比如说像GPU等等这一系列的高性能计算的需求就又开始崭露头角起来了。因此的话，我们就在开始考虑说传统的云架构为了外部服务和为了数据计算这种方式所构建的infrastructure，和今天我们为了AI的计算大量的high performance amErica competition这样的一个计算有没有什么区别。同时是否会需要我们在整个的从底层的harder infrastructure到中层的平台，到上层的应用之间有一个更加打通的一个设计。这是我们的I希望来进一步的帮助用户来解决的问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:09:04",
      "text": "从最小的一个点来说，今天我们说我们要来管GPU的机器，我们要来用GPU的机器，对吧？以前的说CPU是一个批发转零售的模式，大家在上面在云上面开一个虚拟机就够了，然后完了之后云会去解决供应链，去解决这个CPU调度等等这样的一个问题。今天GPU非常贵，然后同时又不好拿到。然后同时拿到的时候我们就要想说，怎么样把它跑得更快，第一个是怎么样来更好的管理和使用GPU的资源。第二个是怎么样来在上面做更加高性能的。无论是LM还是IGC的计算，这个都变成今天在AI这个大的背景下面，我们对于云的一个新的一个需求。这也是我们的在这个领域里面把我们做了一个完整的全功能的平台。能够让用户在上面来focus在他的AI的计算，包括find，包括推理上面。然后同时AI阶段所需要的周边的一些infrastructure，我们以一种非常简便，同时高速高性能的方式提供给他。这是我们简单的来说，就是正在做的事情。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:02",
      "text": "当时您是怎么想到要成立left AI当时的？市场状况是怎么样？因为我们知道AI这个领域真是日新月异。我们听众中有很多想要创业的朋友，我觉得可以给大家分享一下你当时的一个思考的过程。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:17",
      "text": "我们是二三年4月成立的，所以基本上我们的结构方也是一直以来在AI和cloud这个领域做了非常多的工作，尤其是开源的工作的人。我们的想法其实比较简单，今天其实我们看见了以large language model为代表，虽然当时的时候其实OpenAI的h GPT还没有出来。我们更多的其实是看见说各种各样的AIPN。我们自己在阿里当时的时候做也看见，就是应该怎么来描述？就是我们在前面的那段时间当中看到说大家对于AI和high performance competition需求越来越旺盛。然后同时我们也看见说在云的基础之上，对吧，就云的云原生的基础之上，其实有非常多的为了AI来build infrastructure的这样的一个机会，当然这个时候大家就会发现有两条路，一条是我们来做算法。",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:07",
      "text": "但我记得当时的时候，国内虽然新的这一批AIGC的IOM的公司还没有起来。但是有比如说像兰州科技，微软的周明老师等等，大家做的已经开始在AI大语言模型和其他的一些AI应用上面开始做探索。他们已经开始做有比较大的一个AI的一些应用兴趣等等。这是我们觉得说值得对吧？我们几个创始人其实本身也都没有大厂情结。在我们以前的时候也都在小厂待过，也都在不应该说有的校长发给我，我们以前就也都在开源的社区做过，然后我们也就是run过，我也写过代码，我们也让过社区，我们也做过小的项目，大的项目，所以说对我们来说其实是一个非常灵活的状态。",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:50",
      "text": "建林当时在去年年初的时候，有一篇文章我觉得特别有意思。就您刚也提到就是说这个AI的计算不同于我们传统上说的云计算。你那篇文章里面提到是说，其实这个更接近于高性能计算，就是HPC。可以跟大家延展来聊一聊，为AI设计这个计算的时候，它到底有什么不一样？要实现这个转变，它的难点又在哪？那为什么云厂商他们可能这一块也未必能够走的那么那么快的？",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:19",
      "text": "对，好，这个问题我们可能稍微往技术一点的聊一聊吧，就是云厂商在外部服务的这样的一个需求下面，其实它最主要的是在解决两个问题。第一个是供应链，第二个是更加容易的安装跟部署软件。那如果展开来说的话，第一个供应链作为一个站长来说，我要serve我的这个外部的服务。我的外部服务，第一个我有可能白天多一点，晚上少一点。另外比如说我可能这个月做的有1万个用户，下个月突然爆发性增长了有10万个用户。所以我需要有比较灵活的机器，尤其是CPU机器的这样一个供电。有人说我帮你把供应链的运维来，而这些事情都解了，而且可以非常的弹性以后，我就能够给你拉起来，这是第一个需求。",
      "speaker": "发言人3"
    },
    {
      "time": "00:13:05",
      "text": "第二个需求是一旦要做一个网站的话，那不光光是说我要做一个网站的server这个APP对吧？同时我还需要有一堆各种各样其他的零零碎碎的软件。我需要一个消息的中间件，我需要一个数据库，我需要一个文件的存储，我需要一个其他的像负载均衡，网关等等，防火墙等等这一系列的工具。这个工具，对于这个云上的用户，或者说就是说对于这个web development来说，它是一个很麻烦的一个事儿。如果说我自己要装一遍，那这事儿没完了，然后云说没关系，你来这儿装，我都可以非常标准这样的方式提供给你。因此在web service的这个角度，怎么样来standardize的用一种standardize的方式来获取安装和部署这些软件就变得非常的容易。所以因此云在这个web service的这个领域的话，就给大家带来了供应链的便利性以及软件的便利性。",
      "speaker": "发言人3"
    },
    {
      "time": "00:13:56",
      "text": "当然有人会说一个premium，说你看在我这个上面买一个CPU的机器，对吧？这个我会圈的比较多的premium。前一段时间大家在媒体上面听到说我要下云，很多时候很多人说我要下云，也是因为在性价比等这方面大家都有不同的争论。但是云带来的benefit实打实的有这两条。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:15",
      "text": "然后AI来了。AI来了之后，大家发现说第一个供应链其实在无论是在做research，还是在AI不足的时候。因为我的单个GPU的价格是如此的昂贵，所以大家不由自主的可以更加仔细的去做自己的supply chain的管理跟预估的。因此在这种情况下面，其实很多的AI的公司，其实我们会发现的一点是说，至少在今天这个阶段上面，大家其实没有太强的对于弹性的需求。而且同时因为整体的这个市场的缘故，今天的GPU整体的弹性在全球上面都是比较小的。所以因此的话就是说传统的语言所带来的弹性，这个benefit会变得比较小。第二个是啊对于安装软件。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:55",
      "text": "软件这一块，传统以前的时候其实更加云，提供了一系列的中间件的，没得玩。但是AI今天它的应用的形态其实相对比较简单。比如说我就做一个图片视频，我就是一个图像进一个传出，或者说做LOM就是一句话进一句话出。除了标准的open API这样的一个interface之外的话，其实更多的需求其实都是focus在我怎么样把这些计算跑得更快。比如说像拍touch，以及像test flow，像老的这些框架以及新的各种各样的工具。比如说像fast tension，包括像classroom AI的那个，我都忘了他们项目名字了。Class AI做的工作等等。其实很多时候都是在帮助大家focus在把AI的这个软件，AI的这个应用跑得更快。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:33",
      "text": "这和云的软件是不太一样的。因此，就是说说云在这方面所传统的云在这方面软件这方面的优势也开始逐渐的变小。所以这些云也在做一个转型。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:43",
      "text": "如果我们看AI整体的需求的话，它的使用不是说我要把数据搬来搬去，而是说我要把这些GPU单个的或者说是说多一台多台GPU非常好的跑起来。它的CPU的利用率一般都在80%以上，相比较的话，外部服务的CP率大概在20%或者以下。所以因此它的计算这块就是high performance competition的high performance这块就是它的这个计算的利用率非常的高，80%以上。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:10",
      "text": "如果说是多台机器的话，它中间的互联要变得非常的快。A8而言，大家今天听到说infinite band，像几百G的网络互联等等，都是因为这些机器在计算的时候，一方面他要算的很快，另一方面他们要把结果迅速的communicate起来，尤其是在训练的时候。因此这个计算pattern和传统的外部服务很不一样，反而和典型的高性能计算HPC这块变得很像。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:34",
      "text": "如果说我要做一个大规模气象模拟的话，每一台机器都在吭哧吭哧的算一个他自己local一个区域的信息。机器之间他算完了，他就告诉同一个系统下面的这台机器说，我这边的这个风我simulate完了之后，这个风吹北风要吹到你那块儿去了。所以训练不抱歉。计算的这个utilization非常的高，然后网络的通信的latency跟slop的要求也非常的高。这个的话其实AI和scientist competition就会变得更像，因此的话，在这种情况下，我觉得就是云也在做转型。微软云其实应该是在整个的转型当中，你们算是做的最成功的一个。",
      "speaker": "发言人3"
    },
    {
      "time": "00:17:11",
      "text": "之前以前在阿里云的时候，就阿里云你大家可能注意到一个产品叫做林俊。这个产品其实从，18年开始，就大家在酝酿跟迭代当中。其实也是是说看到AI的这种competition pattern之后，我们所做的对于传统的云的架构上面的重新的思考跟升级。",
      "speaker": "发言人3"
    },
    {
      "time": "00:17:31",
      "text": "就像您说的，以前也有这个HPC，对，就是云厂商也有HPC，这也有一些独立的HPC厂商。我可以直接利用这些HPC厂商的这些资源。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:41",
      "text": "这是个好问题。我觉得其实这个领域就有点大家螺旋前进的这样的一个状态。云关注在外部服务，所以说在高性能计算的这个时候，也许没有太好的符合用户的需求。HBC关注在高性能计算机方面，但是传统的HPC有两个弱点。第一个弱点是他对预估计算的知识不太好，当时很多H都还是基于CPU的，这个GPU其实还是云和AI用起来的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:04",
      "text": "第二个的话，传统的HPC的软件栈是基于很早的linux包括像slam等等这一系列的古老的软件栈的。在今天软件已经非常的突飞猛进的情况下面，它还留在一个相对比较早的水平上面。因此我们其实今天看见的是说HPC的需求和云的技术相结合那么一种方式。有一种新的高性能计算的形态，用云原生的cop IS等等这样的软件栈。以及AI的这样的一个workload和异构计算等等这样的硬件和传统的HPC的这样一些philosophe相结合做的一个东西。它并不像传统的HPC，他也不像传统的云，而是说在AI的这个需求基础上面，把以前的philosophy重新思考和升级之后做出来的产品。其实我觉得传统HBC的需求其实和GPU所能提供的能力也是有点像的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:53",
      "text": "我们知道说有一个领域叫做AI for science，对吧？就是也有非常多的scientific科研的这块的领域。大家在来使用GPU等等来做传统HPC做的东西。HPC因为它是一个非常传统经典的一个领域，因此就是GPU的渗透，还是最近几年的事情。",
      "speaker": "发言人3"
    },
    {
      "time": "00:19:14",
      "text": "Speaking从workload的角度来讲，其实HPC跟GPU是一个天生的一段。只不过是因为古早的年代也没有那什么也没有GPU在那。因此的话就HPC架构以前都是基于CPU，甚至是去比如说其中比较经典的，比如像power等等这样一些架构的CPU来来实现的。但本质上面它和它和GPU并不冲突，它的这个workload AI的这个workload今天也是一样的，就是说非常契合这种对于处理器的utilization要求非常高，对于网络的质量要求非常高。",
      "speaker": "发言人3"
    },
    {
      "time": "00:19:45",
      "text": "那么一个状就是我们刚一直在讲用计算这个事情，的确不论是训练还是推理的，对计算的这个需求的也是在AI这波最大的一个推动。这里面其实大家看到过去一年推理的成本其实下降的下降非常快。我觉得open I的这个API动辄一降价，就是降了百分之七八十八九十两个问题。一个就是这个训练环节和这个推理环节，它对于这个计算的，尤其作为info提供计算的基础设施的要求有什么不一样。那为什么我们可以看到这么这么大的一个推理成本的下降？在短短的一年内，就我们对未来这个推理成本下降应该有怎么样的一个预期？",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:28",
      "text": "对我觉得咱们先说训练和推理这一块，训练和推理稍微会有点不太一样，但是本质上从软件层倒是也比较像。首先训练的话，一般而言我们会需要有比较高性能的网络，除了这个之外，其他的这个机器等等设置都是差不多的。训练非常强调的会在是说整个的分布式的计算的调度上面。我怎么样把计算的这部分跟网络通讯的这部分比较好的overlap起来，使得网络通信的人，所以叫网络通信的overhead可以藏在计算的好啊，推理这块相对比较简单，说很多时候，尤其我们都是这个单台机器，甚至单台机组卡就可以，所以对于网络的要求会低一点。除此之外，训练跟推理都其实需要有比较好的GPU的这个implementation，GPU的实现。尤其是比如说像当年是卷积，现在更多的像transformer里头的话，怎么样来做更好的这矩阵乘积以及矩阵乘积，以及相应的带来的一些更小，但是可能也比较critical的engages，这也是为什么我们今天看见说库的这个生态依然很强大的缘故。就是今天哭的能够让我在上面非常迅速的来做计算的，来做开发，做调优等等这块的事情。",
      "speaker": "发言人3"
    },
    {
      "time": "00:21:41",
      "text": "然后第二个问题是说，为什么推理的性能我们会发现有那么大的提升？这个基本上还是因为就是软件上迅速迭代的这样一个过程。因为以前的时候，大家关注训练关注多一点。因为像这个AI在科研这个领域的话，大家主要先做训练，找到更好的算法。训练的时候，其实我们并不太关注退役时候的效率的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:02",
      "text": "在前面两年当中，我觉得非常迅速的出现了一点说大家发现说这事儿开始有用，不光光是写赔本写paper我就把模型训出来就行了。推理的在在科研领域推理的workload的可能就是训练的10分之1左右的样子，我验证一下就行。一旦到应用之后，推理的workload推理的体量会迅速的涨到训练的十倍甚至百倍。那这种时候大家发现说，我该优化很多的各种各样的方式就都能搞起来了，就比如像在LM优化里面，我会看见说第一个动态的fashion dynamic fashion，在前面一年非常迅速的被被大家所采用起来。第二个是做量化quantization，第三个是比如说一种用小模型来预测跟模拟大模型的行为等等。这种比如像modus所谓叫speculate这种叠加起来之后，的确就是说很容易能够使得推理的性能增加十倍百倍以上的样子。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:53",
      "text": "我觉得前面两年我们就在见证那么一个过程。我们把以前推理当中没有用到，但是可以用到的一些技术都用起来。所以有一个非常迅速的一个性能红利。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:05",
      "text": "大家一般觉得说这块我们推理的性能可能在前面两年快了，有大概10倍到30倍左右的样子。我觉得后面还有可能会有十倍左右的这样一个破产数可发，更多100。为什么就说说不准？因为的确我们也做的这个整个的社区做的非常的好在推理这一块上面。所以我觉得这给我们带来的一个信心是说，今天大家一般而言不太需要担心推理所带来的成本。因为软件件应用的协同设计叠加起来之后，能够给我们带来超越摩尔定律的一个性能和性价比的提升。所以对我们来说，其实怎么样找到用点更加重要。成本这事儿不是特别的需要担心。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:46",
      "text": "刚才杨青老师讲到一点，我觉得特别有意思。就是您说其实过去一年的推理成本上的一个提升，其实是在以前我们这个行业里面的很多积累，只是当时无用武之地。那在过去一年的这个用起来，那那我还就比如说说要是像您刚才所说，要是再需要再把下降成本再降十倍，再降十倍的话，您会觉得说还需要有哪一些突破？",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:09",
      "text": "对我觉得这是个好问题。我个人的感觉是前面几个，前面一段时间其实我们用到了很多的本身在现在的软硬件硬件站上面的所有的红利。接下去的话，我觉得我们可能还能够同样的，你如果说完全所有的技术都不变，我觉得我们可以以同样的这个加速的速度再再跑1到2年左右的样子。那后面其实就会涉及到更加深水区的，比如说怎么样来设计和推理更加就对于推理更加合适的硬件。无论是比如说GPU本身，还是整个的这个整个的系统，怎么样来配比这个memory跟计算等等这块，这是第一部分。第二部分是就是说是怎么样来探索更新的硬件？眉笔有一些新的硬件能够出来。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:52",
      "text": "然后第三个的话是就软件站这一块不断的一个优化。以前的时候其实大家开玩笑说的是开拓者方便是方便，但是性能其实还是有很多的水分可以挖的那我觉得进一步的积水分其实也是一个不断发生的过程。开拓者最近的话把那个恐怕要做成朋友给非常非常怎么说呢？成熟的推起来了，包括有一个叫做GPU fast的patch left的这个团队做的一个GPU fast那么一个demo来show case说在前面一年当中，其实pyto ge即使你只用python，它也能带来很大的性能的提升。所以这些我觉得软件上的优化还会继续再往前走。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:27",
      "text": "现在也有很多除了云厂商之外，而且还有很多这些提供GPU计算的平台可以去选择。我们现在也能够看到很多benchmark的leader board也选的很厉害这个性能。所以你就对于一个开发者来说，他应该怎么去选择呢？除了完全根据这些榜单上的这些数据阿姨，你觉得还需要哪些考虑呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:49",
      "text": "我觉得这个问题其实在今天很难回答。我们首先说later word，因为lead board这个事情其实不奇怪，就是说因为每个领域都有lead board，lead board大家非常迅速的都会采取就两种方式，一种叫打榜，就说是我就烧一堆钱，我就一看说？这个测试的来了，我给他加到我的最premium的记忆上去。另外一个就是说是索性就算了，不管了，我们还是做产品。我们在上个月的时候，应该是就说是其实这个是vial analysis咋的呢？刚起来的时候，我们其实也就是无意当中被被他们测试了一把，所以我们的性能都是最不错的，我们也挺开心。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:23",
      "text": "然后完了之后同时我们也解释了我们背后的思考，就是到底做API生意，从攻击者的角度来讲，我是要持续的提供非常高性能的顶级性能，同时又是白菜价的这么一个API，还是从一个长线的business来说，我应该找到一个更好的baLance。所以我们当时我写这个推特说，我们不会继续在那为了打榜而在那儿烧钱的。我们还是采取是对于用户来说也更加sustainable的那么一种，就是不需要是一切都非常高的performance，但是性价比比较好，稳定性比较好那么一个那么一个那么一个那么一个服务。API对我们来说更多的其实是让用户来更加容易的用到我们的产品，尝试我们的产品的那么一个渠道。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:07",
      "text": "然后第二个，从用户的角度，我觉得今天既然有非常多的人在烧VC的钱提供API。It's not a bad thing. 对用户来说，API是一个非常标准的一个存在。在这种情况下面的话，其实我觉得就是大家找到趁手的，找到标准的，然后在那儿用的就可以。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:22",
      "text": "一般而言这个决策其实就是最开始做做exception的时候，没有太多的需要来做决策，说我到底要用哪家API，因为反正都是OpenAI done的那么一个状态，到了有serious的流量之后的话，其实更多的是要开始做capacity planning，就是我需要多大的流量，我需要多大的速度。因此我希望我我希望他在多少的成本之下能够支撑。那这块其实我们作为非常专业的团队，是能够和用户一块来做这种passive planning。然后给他找到一个可能性价比更好的一个方案，real business其实永远都不是说i want the fast speed，或者说i want the lowest Price。其实更多的是我要找到一个对于我自己的现在的业务和我的我的和我的这个流量最make sense的一个方案。我们其实和我们的客户做过这planning，以及如果说他需要迅速的bw的话，因为我们本身平台能力比较强，所以我们能够非常迅速的支撑它，往上扩容等这一系列的事情。对我觉得这个其实是比API更加重要的部分。如果说今天大家在尝试用API的话，用一个标准的API就用的就行了。比如说他不管价格还是挺便宜的，然后完了之后你就在那用着，就显得不用特别担心后续的一些乱七八糟的事儿。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:35",
      "text": "其实这一块的话，就传统的云计算的这个服务有点类似的地方。就不是说谁有最多的计算集群就好。其实云厂商也做了很多像这种这些这些planning，就资源这种资源调度的工作。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:48",
      "text": "对的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:49",
      "text": "是前面您也提到就是提升训练或推理效率这个事情，它是一个很综合的工作。软件软件有软件有硬件的这个工作。您觉得这个算力的紧缺会持续下去，可能越来越多的算力可能需要在推理这一侧听听你所说，好像就是从软件层面，它仍然也有很多很大的下降的空间。那这个对于我们对于这个硬件的要求会有怎样的影响？",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:16",
      "text": "对我觉得供应链这一块儿还有可能在跌下去的一段时间之内，还会处于一个比较紧缺的一个状态。所以之前的时候我们在朋友圈提到说GPU今天是一个套利市场，或者英文所谓叫arbitral h market arbitrage market。其实严格的来说不应该翻译成叫套利，更多的他是说说今天是一个没有特别大的库存，然后买卖双方其实非常都是贴着库存那边在那卖的那么一个状态。优化我觉得会继续做，这个GPU的紧缺一定程上在接下去的半年到一年当中会缓和一下。但是因为整个市场整个需求还是在不断的上升，所以说我觉得他不会一下子成为一个非常遍地唾手可得的资源。",
      "speaker": "发言人3"
    },
    {
      "time": "00:29:59",
      "text": "您看到现在在在推理这块有开始在使用除了NVIDIA之外的一些一些芯片。您有看到一些新的厂商进来一个趋势，你就会有新的，就专门可能他专门针对推理的一些芯片出来，会对这个行业有怎样的影响？",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:14",
      "text": "对，我觉得会有，但是不多。目前看起来的话，目前基本上还是MA比较多。大家对于AMD其实都寄予了希望，但是还要看今年MMD的表现。最近可能最著名的一个公司就是grow，他其实是在2016年就已经签订。这个公司很早了，它的创始人是谷歌的TPU的核心团队的成员。",
      "speaker": "发言人3"
    },
    {
      "time": "00:30:36",
      "text": "他们以前的时候，其实一直遇到的挑战是说这个芯片的可编程性不太好，这个其实也不是他们的问题，就是说任何一个和和AI相关的，或者和高清资源相关的芯片，都会遇到这样的一个问题，就是哭的非常好编程，但是这些芯片都很难编程。因此当时在LM还没有出来之前，他们其实一直就也折服了很多年了。然后出来之后大家发现说，今天我很多用户就要一个API他说我就自己索性把整个都包了，我就最后给他一个API，他们做的这个还挺不错，所以出圈力它是常见的。就是不是能够在第一个是性能，第二个是对于开发都不光是说独立开发者对吧？对于是说任何一个芯片的客户在上面二次开发的能力，二次开发的容易程度等等这方面都还没有一个clear的winner出来。所以我觉得整体而言还是在我们还在静观其变的状态。这是为什么？就是说NV其实那么多年了，就是说他们的投入，从投入来讲的话，就是they deserving devaluation是的确是属于一直做的非常靠前的一个靠前的一家。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:42",
      "text": "对我看到您在这个朋友圈，那在在glock出来最火的时候，其实也点也也点评一下。就像您说的，他其实也做了挺长时间的，而且他在其实在创始人离开的时候，那个时候其实TPU才也才刚开始，对吧？现在的TPU的这个价，我跟他离开那时候也有挺难，这个不一样的。您怎么看待就是说rock它它号称的能够实现这个性能上的一个一一个提升，它会很快的被标行业里边其他的这些厂商来，也是应用成为新的标准。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:13",
      "text": "我觉得不太会grap今天其实大家所能够看见的还只是API，硬件包括软件其实都有点类似的这样的一个状态。是就是所谓有一个不可能三角，美国所谓叫做我那个卖车的，卖车的不可能参加fast cheap，good快好和便宜这三个玩意。或者说fast cheap safe的那个那个是卖车的时候说，但是我们基本上就是说fast，cheap and good这三个是一个很难逾越的三角。如果要跑得快，然后同时又要个是开发容易，一切都很方便，那就是英伟达，但是it's not cheap对吧？今天是block说你看说他我fast，但是我也不太开发，我也不不太容易cheap。他号称说i am cheap，那maybe就是fast and cheap。在这种情况下面，它的user finding其实还是比较麻烦。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:02",
      "text": "AMD今天说我要听的那个AMD新的这个芯片，他说我的性能其实不错，所以prety fast。然后在各的这个方面，他说你看我和会展能够做兼容，就这么extend。然后chip他说我的价格，反正这个肯定可以比这个MVA他的claim是说我肯定能够比原来性价比更高一些。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:19",
      "text": "对，就大家可以看见的是每家都在做这三个不可能三角上面的一个平衡。然后找到一个也许能够对用户更加批评的那么一个平衡点。目前独立芯片公司，这话说的可能会有点戳人，对吧？我应该的风格独立分公司。我们目前没有看到一个能够真的和和NVANVA打的前面有那么多的公司对吧？来来去去每个号称都很不错。但是说实话，冰冻三尺非一日产，还是很难说上来就可以叫板。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:47",
      "text": "MV刚才聊了很多跟这个底层的算力相关的事情。那可能也知道所有云厂商或者说我们投资人过去几年也很关注过这个所谓的MLOS的这个赛道。可以跟大家讲一讲就是除了计算外搭所谓的AI APP还需要哪一些工具？这个跟我们之前所说的这些ML ops的工具又有什么不一样的地方？",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:08",
      "text": "对这个地方我可能有一个相对比较controversial观点，就是there is no m展开说说。对，因为你想是我们首先要从一个需求的角度来讲，就是说是AI究竟在做什么事情，吧？我们在做那么几个事情，第一个是大规模的训练。大规模的训练这个东西其实就是以前我们做离线计算offline jobs或者叫batch compute，或者在这个数据叫做ETL。就是说我对于时效性没有那么的高要求，但是我需要跑起来之后，我需要对于资源的利用率高，对吧？我需要把这些计算什么做的尽量的快。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:43",
      "text": "第二个是做online seven或者叫influence。Influence其实那service的话，我就得保证说这有足够的稳定性，有足够的latency，足够的好等等这一系列的事儿。我们怎么样来monitor它呢？我们要做logging login完了之后，我们要把它放到一个可观测的一个平台上去。这个可观测的平台在外部服务的年代叫premiers，叫good pana。今天在AI了，需不需要重新建一套呢？不需要，有一些小的工具，比如说像微信bias，但是eventually我需要有一个报表页面，我需要来看我的这个服务到底up time是多少，我的服务的QPS是多少，我的服务的latency是多少。这些从general的软件工程的这个角度来讲，it's the same.",
      "speaker": "发言人3"
    },
    {
      "time": "00:35:20",
      "text": "There's nothing different. 因此我觉得m ops这一块之前的时候，在最热的时候，他努力的想在这种在sno difference的情况下面来找到一些difference。于是他说你看i can do ML experimental management。但这个人其实并不是一个真正的需求。所以我觉得there's no MO ops as we defined m ops in the last few years。",
      "speaker": "发言人3"
    },
    {
      "time": "00:35:44",
      "text": "前面几年的m ops是一个伪命题。然后我觉得真正的m offs在什么地方呢？就说是说how to actually go into the workload and make them more efficient？就是我觉得m ops并还不如我们把它叫做ML depth，就是m helping我到底怎么样把我的这个AI的计算做的更快把推理做的更快。AI有一些其他新的一些需求出来，比如说像stable diffusion，我有啊这个就比如说在C站上面有成千上万的各种各样的lora对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:36:15",
      "text": "以前你想就说是说我要是做一些计算的话，就比如说像做一个推理，比如说拉玛吉推拉玛吉B的推理。那我就那个PPP的一个模型，它是一个是一个闭环的一个世界。我load一把这个模型，然后完了之后我就可以跑。如果说我要做stable division，成千上万的各种各样的模型，我今天用这个，明天用那个，不同的用户要用这个东西。如果要搭一个推理服务的话，我得有非常强的flexibility。这个flexibility怎么样来实现呢？我一方面是GPU的计算，另一方面是我要做多层的cat是我怎么样在GPU上做一层看使用最热的模型，最冷的我要从C端去漏的，中间我怎么样用SSD，怎么样来用这个object store呢？这些其实是就AI的新的workload需要来解的问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:36:53",
      "text": "他不会被传统的我们说我们来管一管实验这种apple ops的解决方案所解决。但是他是其实存在的一个事儿。所以我觉得今天我有点会避免他的MOOS这个概念，因为这个概念已经被前面几年的这个定义所定义的太太乱了，带偏了。对，带偏了。所以我们就觉得说我要essentially今天就说是说我们是how to run faster compute，how to walk to strate these faster compute in the cloud native way and then how to basically like combines es after I just address problems that are actually not emerging as new competition baLance. 我觉得这个可能是今天我们重新思考m off的时候，需要想的一些点就是从应用出发，从需求出发来看说到底要解什么问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:37:39",
      "text": "您觉得这个变化是否是跟这个AI模型的能力的变化也有关系？以前的因为它都是一些小模型，你不得不用一些这些一些很多工具来去做一些调油。要去做这种像这个实验，所以才需要那些工具。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:57",
      "text": "不是，就是honest speak是说传统的这些m ops的工具，我稍微说的controversial，就是传统这次就前面的这一波ML ops they have made zero contribution to AI development。Maybe that's one contribution which is waiting BIOS. 我觉得ways BIOS提供了非常好的一个logging的工具，让我们来是更加容易的来看说what is going on inside these training procedures。但是其他的什么任务管理等等的。While applaud every company has that to. 每一个公司基本上都会需要有那么一套工具，但是它对业界有什么深远的影响，其实没有太多。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:30",
      "text": "我知道你的意思其实都是都变成一些管理工具，而不是真正能够把你的这个APP做的更好。对，是的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:36",
      "text": "但是log也是很有用的。对我觉得我觉得就这样，就是说所谓的可观测性是很有用的。以前的时候大家一跑实验两眼一抹黑，对吧？那现在有这个logging，游客观测等等之后，至少就是we know whether are being good or not。然后同时我们可以看出在训练的时候，包括在推理的时候，就更加有迹可循了。我觉得这个是其实这个软件工程给AI带来的挺不错的一个fact。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:01",
      "text": "另外一点就是其实你有提到东西能力提升也使得还有包括像你们这样做，平台这公司这些出现，使得我开发一个AI应用的这个门槛其实降低了很多。可能几百几百几百行代码就可以开发应用。那那我们怎么看待这个时候这个AI应用的价值？如果每个人都那么容易可以开发这些AI应用的话，那么他们的这个价值的壁垒又在哪？",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:23",
      "text": "我觉得其实这是一个好事儿，比如说像我们投钱的时候，这个开源left time search这一块的话，我们其实想给大家展示的一个点是说，adopting AI今天不是一个特别难的一个事情。最关键的其实到最后还是回到应用上面。就是说今天我对一个应用场景的了解，对于这个应用需求的了解，能够让我更好的来思考说，那我应该怎么样把AI用进来，然后完了之后使得我的效率能够更好的提升起来。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:50",
      "text": "现在如果说我们看AI应用的话，基本上就是两大应用。一大应用是陪伴做一下，或者说就说是说entertainment对吧？对各种chat part，各种纹身图等等，这是一种。第二类应用就是productivity，怎么样来做更加容易的知识的检索，怎么样来做更加好的创作者工具。比如说像今天已经有点就被人忘记了。Jasper er可能其实更多是在帮创作者提升productivity那些。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:13",
      "text": "其实这个虽然我自己在AI里头的，但是我想说的一个事情是说，今天我们没有看见一个新的AI原生应用。而更多的是说以前的很多的传统应用，再加上AI的能力，就是没有一个说AI一来之后，我们发现说，以前从来没有过这个应用，突然出现了一个AI的一个应用。都是大家说我们今天我要做搜索加个AI我要做聊天的工具，加个AI对吧？我要做创作加个I，这个我觉得是加个AI是个今天我们我们我们见到的一个大趋势，不是什么坏事儿。说明就是说说今天谁都训我。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:50",
      "text": "你那你觉得什么是一个真正的AI原生应用，就像比方说像property这样算吗？或者character ai算。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:59",
      "text": "但是他的需求其实还是就和以前的差不多，就是搜索的，我的意思是这样没有创造新的场景。对，就比如说就如我来说这样一个类比，云今天并没有产生新的应用，对吧？我妈妈今天不会过来说，杨千我要用个云，没有的对对吧？它是传统的应用，传统的业务加上云AI我觉得是同样的那么一个状态。就说是说中最终的用户他所其实所需要的是entertainment是对吧？就是说是说是实时创作，是各种各样的应用。就是说是AI，像云阳是在背后帮助这些可以联系他们来那什么来就是来提升它的效率，或者说来来加强他的能力的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:40",
      "text": "最近看到比如像有很多用AI来做帮助开发的一些公司，包括最近就有一家，我觉得这个噱头非常大的这个magic death ray，就是号称要能够做一个不止cop coworker。那您现在看到AI这个能力，它对于我们的软件开发，还有对于我们管理info现在有什么帮助？或者您就您期待他未来会有样的帮助吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:59",
      "text": "我觉得是他能帮我们提升他activity，这是肯定的对吧？就是说今天比如说像get pilot，基本上非常多的AI开发者，其实大家都在用它了。就是说写代码成本的确快，而且效率高，对吧？因此我觉得没有什么特别magic的地方，就是说它能够帮助现在的各种各行各业的从业者们提升productivity。",
      "speaker": "发言人3"
    },
    {
      "time": "00:42:23",
      "text": "您还是你觉得说现在AI能力还很难看到说他对我们软件开发的范式会有一个比较大的一个变化。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:30",
      "text": "对，但是这句话说起来好像稍微有点悲观的样子，但是我是我是一种非常乐观的态度来来看待这个事情。为啥呢？我们办公室有一个有一张海报，是当年微软的开发者杂志上面的一页东西，2004年的海报。然后非常有意思，它上面讲说2004年的时候新的应用是什么，我给你读一下，就是他说第一个叫expand communication，他说有一个叫做conference in server那么一个概念，这就是this zoom，对吧？然后他说你看instant message we are changing我我微软说我可以用exchange来change your chat styles。这个就是我们今天说钉钉，企微等等这种对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:13",
      "text": "然后他当时提出说VVA boot camp用visual basic来做book，develop your first APP, 这就是今天的vers l note JS对吧？然后他说exchange and the net create web services，然后说public folders，这个怎么样用public folder来做sharing，这就是drab x，包括什么钉盘，云盘等等，对吧？Everything is the same.",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:38",
      "text": "从2004年到今天，20年过去了。我们今天一看就conference service，我们还在做一样的事情，吧？所以需求不变这件事情我觉得说起来的时候其实没有那么的negative。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:49",
      "text": "而很有意思的一点是说，20年过去了，我们在比如说conferences这个角度已经和20年前有了翻天覆地的变化。为什么呢？是因为我们的技术提升了，对吧？就比如说像今年AI出来之后，他能够给我们做更好的这个conference insistence。它可能这种就是如果我个人的一个positive的感觉是说，如果今天我们发现说AI已经在这一系列的boring but essential的应用当中占有一席之地了，那是真的是我们比我们的AI到了一个真正可用的一个状态，能用的东西都是很薄弱的对吧？所以我想澄清一下，我我我不是一种非常悲观的态度在说这件事情，我是一个非常乐观的态度在说这件事情。",
      "speaker": "发言人3"
    },
    {
      "time": "00:44:30",
      "text": "很有意思，但是很难想象那个是2004年，而且是微软提出的。看来微软的确还是很有远见的公司。虽然最后第一个做出来的不是他，但现在最大的还是他。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:41",
      "text": "真的对，我觉得他们对于需求的把握还是非常的精准的。我回头把那个图发给你。",
      "speaker": "发言人3"
    },
    {
      "time": "00:44:46",
      "text": "挺有意思。刚刚追问一下这个AI native的一些问题。我们讲AI native产品之外，公司的这个做法上会不会也有一些在AI时代能够他有的特点。所以AI native的组织，比如说现在随着AI的工具的进步，也有一些说法说是不是未来的公司人会很少，对吧？比如说赛马上的好像也说过，可能会出现一个人的bad company。对，因为杨杨青肯定是一个非常AI native的人。就好奇你在创业的时候，这个组织打造上面有没有什么思考。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:18",
      "text": "对我其实挺同意这个说法，就是说说今天会出现越来越多的更加精干的所谓的design house。这个东西其实在游戏开发领域也挺像的。它就是经常会有一些，尤其是在欧洲有一些非常小的游戏制作组。他们可能人十几个人，不超过50个人，对吧？但是他们能够做出非常好的游戏来。",
      "speaker": "发言人3"
    },
    {
      "time": "00:45:38",
      "text": "因此我觉得AI这块可能也会是有非常多的有意思的集团house出来。他们能够做非常创新的产品，而且迅速的走到市场。同时传统的这些行业怎么样来做to b的marketing，怎么样做to b的推广等等。以及像那种希望成为的公司一样，是说以大规模的系统来支持这样的创新的话，这些公司其实我觉得依然也都会在。也就是说我们会出现一个非常有意思的的组合，就是小的小型的design house，或者说小型的design save group。他们来创作非常有意思的新的产品，同时通过新的AI native的system infrastructure来帮助他们更快的走向市场。我觉得这个一定程度也有可能会打破说这个大公司垄断的这种状态。应该怎么说呢？就是说今天的话就是创新能力开始变得越来越重要，而不是说比如说像现有的渠道，现有的市场的这样一个能力。",
      "speaker": "发言人3"
    },
    {
      "time": "00:46:35",
      "text": "这个非常好。韩宇森。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:37",
      "text": "不没有，刚刚一方面说的是这个小公司对吧？比如在AI时代肯定也会有，或者我们至少相信会有新的巨头。历史上来看，比如互联网时代，移动互联网时代新的巨头。比如说当时的google，后来的字节，包括拼多多，包括你之前工作阿里、facebook.",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:57",
      "text": "其实每一家新巨头它往往都带来了一些很独特的文化。这包括说对于组织建设的考虑，或者说对于技术在技术思路上的一些考虑，这方面我不知道对未来的巨头会有什么可能的。这个a native的特点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:15",
      "text": "对我觉得可能这点上有一个类似的这样一种情况，就是现在google所处的一个呃所所所所处的一个窘境，对吧？就是goole今天的话应该已经不是第一次了。Google在最开始鲍尔的发布的时候就翻了一次车。他们非常担心这个鲍尔的有幻觉，于是他们非常仔细的准备了开发，准备了这个发布会。于是在发布会上成功的出现了幻觉，germany的文身服务发布的时候，他们非常担心这个突显种族歧视的问题。于是他们仔细的准备了发布会，然后成功的在发布之后反向种族歧视，里巴又被骂了一通了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:47:49",
      "text": "所以我觉得大公司其实在大公司的好处就是说它针对大兵团作战，很多时候就是非一旦有决心之后，可以平推很多的竞争对手。大公司的坏处其实就是说他的他所需要的做的决策过程非常的复杂，而且也不是他们的错，对吧？就是说说这个事情一旦大公司走错一步，那这个风险是很大。所以我觉得有可能会出现的就是从那种以前我们我们开玩笑说，从战略舰的这种角度，把一艘舰什么都有到更多的有点像航母战斗群的这种角度，就说是大公司有自己的主营业务，但是他可能会开始逐渐的思考说以什么样的一个更加灵活的方式来来孵化新的应用，孵化新的一些技术。然后完了之后再以一种相对比较有机的方式整合起来。我自己也不是这方面的专家，这个我觉得我觉得就很有意思。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:37",
      "text": "就是现在至少我们看见了很多的小的公司在崭露头角。他们和大公司之间以什么样的一个方式合作，以什么样的一个方式以什么样的一个方式建立新的竞合关系，这事儿其实大家都在瞄准，最典型的可能就是微软看到OpenAI了，对吧？你说今天OpenAI做了一个还算比较小的一个小公司，整个叫能够让微软愿意和他们来做深度的合作这些方面。另一方面，微软其实用他自己非常强烈的商务能力和他们的这个业务能力，一定程度上也在蚕食或者说威胁OpenAI的存在。他们之间的关系今天是一种很微妙的，同时是同事，是朋友，同时有竞争这么一个关系。未来会怎么发展，我们我们也不知道，但是灵活性看起来是变得越来越重要的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:49:21",
      "text": "企业组织的问题。正好我前段时间跟一个跟一个朋友跟一个朋友聊的是，一方面我们以后因为AI使得很多人少的公司可以变更大。他说。但是如果你回顾过往所有这些能够出现了新的提升生产力的这些技术之后，我们看到的永远是更大的组织，就更大的巨头。以前我们说一个人的管理半径是多少，这个其实限制了你这个组织总体大小。那你们觉得说以后会不会使得虽然小的公司可以创造更多价值，那同时也会让更大的巨头出现，或者说让巨头变得更大呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:55",
      "text": "这个事儿我倒不是公司治理的专家，但是我觉得很有意思一点是，公司我觉得跟人一样，就是说生老病死也是一个规律。所以我当时其实会期待说有更多的更新的公司不断的出来。当然百年老店的焕发青春这个事情其实还是经常出现的。微软你说也已经好久了所以我觉得很多时候其实还是看人，我觉得人可能是最重要的因素。有了AI之后，管理的效率，管理半径等等的可能会更大一些。但是eventually我觉得人与人之间build很多的就是大家的工作的效率，工作的关系什么的。不光光是因为因为效率所带来的，很多时候还有人与人间交流的互相的信任感等等这种。",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:41",
      "text": "小公司天生有一个优势是说大家谁都认识谁，而且公司的目标和人的目标是更加一致的对吧？比如说十个人的小公司，公司跨的谁都挂，对吧？公司好的大家都好。如果说是一个几十万人的公司，那很多时候大家就觉得说作为一个中层管理者，尤其是我为什么要跟公司共存亡呢？我能够最好的尽早的晋升，然后晋升完了之后，不管公司好或者坏，反正公司发展还是有它自己的步调的。我先拿到我自己的一笔，然后大不了他跳槽呗。",
      "speaker": "发言人3"
    },
    {
      "time": "00:51:05",
      "text": "这件事情其实我觉得是应该说比较难改变的这也是为什么大公司比较稳定，小公司死的快。但是同时小公司带来更大的机遇，大公司更多的有一点躺平这种状态。我觉得可能是啊不由技术所左右的一种智慧规律。",
      "speaker": "发言人3"
    },
    {
      "time": "00:51:19",
      "text": "我觉得绝对人数规模倒不一定，因为它毕竟是个科技产业，对吧？就是那人数最多的公司，应该也不是现在市值最高的公司。但是我确实认为新的技术是要能够去组织起来更强大的生产力的，他其实是一个两头扩张的过程，一头是让个人变得非常强大，超级个体，其实我们现在每个人都是超级个体，吧？我经常感叹30年前的美国总统也没有我们现在一个普通人能干的事儿多。但另外一方面也是能够让组织，比如说更加的使沟通变得更加通畅，然后他的调动资源，使用资源的能力会更强。所以我觉得他希望是一个往下往上的，可能都会有组织的scaling law。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:05",
      "text": "比如说在现代的这些通信技术出现之前，大家可能也很难想象在全世界各地有有大概上百个office，然后有10万人的一个科技公司怎么去运行，对吧？要跨不同的时区。比如说在以前可能一个很大的问题是语言问题。我听说字节比如说开会他有很多同声传译，但是我们可以非常明确的想到，可能在非常近的现在，可能同声传译就不太需要了，对吧？你可以管理几十个国家几十种语言的团队。然后比如开视频会议，每个人听到的都是自己的native language，对吧？你你你不再需要翻译了，那这肯定会让管理变得能力强很多，吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:40",
      "text": "这是一个非常具体的例子，比如包括以后可能你tedy Operation，那这真的是telepresence，你可以出现在别人的一个虚拟空间里面。所以这样可能都不用很多时候都不用去出差，去开个会，然后就回来了这种情况。所以我觉得组织上会有很多的新的挑战，然后正好我开始有个问题想问杨青。就是最近骚扰出来之后，大家也觉得，你看原来大家觉得open I可能对这方面不是那么在意，所以有做这种视频生成模型的创业公司。但是现在好像发现，虽然OpenAI可能那个团队有十几个人，但是做这个sora就非常的震撼。这种就是属于OI顺手就把你灭了的情况，会不会对很多创业公司是一个很大的挑战，对吧？那咱们当然我们做的事情我们还不一定会做，但肯定也会有人或者也会想这个问题，就怎么思考这个问题的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:28",
      "text": "对我觉得首先我不应该发布sorry是个好事儿。因为他们的所有的技术细节也都不太清楚，所以我们就不讨论细节的事儿了。我觉得他带来的一件事情是说，他证明了这个市场游戏这个比较现实的说的话，前一段时间我相信大家其实都有这种感觉，就是我们看见了一堆的文章视频的公司出来，当然效果多都还可以。但是honestly speaking，这个离真正实用距离那实在还是太大了，对吧？就是说生成十个图片，十个视频，可能有一个差不多还能看。于是大家其实一方面觉得说不错，但另一方面其实心里面也会担心说这玩意儿到底真的能不能够，这个能能不能用，还是说是说一直会是这样一种状态。",
      "speaker": "发言人3"
    },
    {
      "time": "00:54:06",
      "text": "从二一出来之后，大家一看说有戏，至少天花板比我们想象的要高很多。那就能干，就是有一群聪明的人就能够干得起来。我在书上给大家带来的最好的我觉我觉得最positive的一点是说，让大家发现是这事儿其实是可以干干得出来的那创业公司那就大家就做就行，愿赌服输。如果做不出来，那也是记不住人，不是说说这方面没法做。然后我觉得市场的市场足够大我倒是相信说只要大家有一个信心在，肯定会有多个player出来。GPT3.5出来，GPT4出来的时候，他也觉得说这事儿没戏了，肯定会被YY干死。但是现在比如说像anthropic，像尤其是像ml最近它的效果也都非常的不错。所以我觉得还是有非常大的空间在那。",
      "speaker": "发言人3"
    },
    {
      "time": "00:54:49",
      "text": "讲到讲讲到这个OpenAI。我们就正好可以聊到这个大模型里边大家经常会讨论的一个问题就是这个。开源跟闭源的模型。杨青老师开源这个领域有很深的经验，至少也host了很多这些开源的模型。您怎么看待这个开源跟闭源模型能力的差距和未来追赶或者说越来越逼近的这个可能性。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:14",
      "text": "对我觉得闭源肯定在长期之内都还是会有几家一家或者几家最好的闭源的公司在做闭源的模型和闭源的应用。同时我觉得开源从一个开箱即用的这个角度来讲，开源肯定会比梨园要稍微往稍微靠后一点。除非有一天就说是我们就说世界大同，大家都开源对吧？否则的话开源可能会闭源，会要稍微落后一点。",
      "speaker": "发言人3"
    },
    {
      "time": "00:55:35",
      "text": "这事情其实在整个的这个技术领域都能看见，比如说像搜索对吧？这个谷歌搜索它本身是必源的，它比其他搜索都好。比如说像即使我们做办公软件，我们有open office，有liberal office，但是它比微软等等这些office软件还是要差一点。我觉得在这个的基础上面，开源不会比开闭源这个离的就差距拉得太开。因为AI这个行业从几十年前开始，其实一个好的一个点就是说是它的交通，他他的他的沟通交流什么的都非常的广泛。因此的话就是这个没有什么秘密是能够长非常非常长期的保持住的。大家都会会就说这个社区里头大家互相的交流，可能很快会让很多的知识什么的变得更加为人所知，所以差距不会特别大。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:22",
      "text": "然后第三个，我觉得开源其实能够放在班子里带来的一些好处，是可以让大家能够更加强的做定制化。虽然现在也有一个argument说，这个将来就不是多种specialized的或者翻译的模型的天下，而是一个非常大非常牛的oracle模型的天下。我其实不太相信这一点，我会我相信说后面其实还会有大量的垂直领域的专用的模型出现的。那么这些专业模型怎么样来构建呢？一两家少的闭源的厂商，其实很难把这个市场都给吃下来。其实更多的是会我我会我会预计说是啊在每个领域里头，他自己的领头羊或者里面非常优秀的企业。他们利用开源的技术在上面进一步的通过find tuna，通过各种各样的方式来build他们自己的AI的模型和体系。那这个时候他们就会需要有infact，他们需要去就会需要有系统的支持。这也是我们现在觉得说接下去就无论叫AI cloud，还是说下一下一个阶段的AI的系统，这一侧会有的很大的一个市场空间。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:20",
      "text": "我就很喜欢跟蒋青老师聊，就是我觉得您总是这个判断说非常的明确，从来不打太极。我觉得这样聊也不要看非常好决策的，对吧？刚你讲到其实很关键的一个两点，就是以后是不是会one model rules all right。然后另外一个就是说看一看闭源，其实还是有相当一部分人觉得说这个最头部的两个课程是一个闭源模型的能力会长期比拉开很大的差距。您觉得您会有不同的判断，您觉得主要的这个假设是有什么不一样的？",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:46",
      "text": "等一下这个我觉得就是说咱们都同意的一点是说，这个头部的一两家或者说少数几家闭源模型肯定会和开源模型有有一定的差距，对吧？他们肯定会领先，这是一个。我们说可能大家观点不一致的说这个差距会有多大，是天差地别的差距还是？我觉得我觉得这个差距不会可能就是说大家都对，就是说这个事情我觉得是这样的，就像咱们拿搜索举例子的话，全我的搜索google，google跟微软，和其他的今天都已经不再存在其他的这种太多的搜索的公司，就是他们之间的这个差距的确有点天差地别的样子，就像大模型在一个通用领域里头需要有一个什么都能聊一把，什么都能够回答的差不多的这种。其实我觉得差距的确会相对比较大一点。",
      "speaker": "发言人3"
    },
    {
      "time": "00:58:33",
      "text": "但是回到大家今天所比较关注的垂直的领域，无论是比如像entertainment，还是说垂直领域，比如像co generation等等的。我不觉得这些闭源的模型，这几家闭源的模型会比开源模型会差非常大的距离。这就有点像就比如说像讲这个必然的模型，就像是一个哈佛MIT，北大清华、斯坦福武廖博士，然后同时又钢琴十级又是这个全国全国二级运动员，他可以非常的多才多艺。但是essentially你总会在垂直领域能够有更加更加更加focused。一些模型在你看一些专家在，所以我觉得这个通用领域差距会大一点。但是专用领域差距还是会小，甚至是开源在领先那么一个状态。",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:19",
      "text": "就大家在这种专业领域，就是他选择用一个所谓的专门领域的这个模型，而不是说用比如说闭源模型有多少是一个有多少是一个成本的问题。就假设更多left这样的公司，是的这个闭源模型的推理也跟这个开源模型也差不多。然后你觉得这个会对这个生态有影响吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:40",
      "text": "这个事情从技术的角度就比较难argue，而且是说技术处理太多，所以说其实我们谁也不知道。但是我是基于这样一个比较朴素的这样一个想法你觉得一个武廖博士去做菜是一个合适的选择吗？从社会的角度来讲，我要不是说没关系，我学习能力超强，我肯定能做。而且我炒菜可以炒的非常快，能干死那些厨师们。但你还是会觉得说，yeah now where is IT？就是术业有专攻这个事情，我觉得我我不觉得它是一个纯靠技术就能解决的一个问题。也30年最后总会有一个就是我我们在计算机领域一直以来都在一个做一个梦想大一统的梦想，是说今天有一个神奇的东西就可以解决一切了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:23",
      "text": "CPU也是一样的，对吧？CPU说你看那樱桃到今天还在坚持说CPU可以解决一切计算问题，你根本不需要GPU。GPU说不让我告诉你看看，对吧？于是安伟达英伟达出来了。所以我觉得阿依彤其实是一个很难的一个事情。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:36",
      "text": "任何一个seriously大家开始就说是说做应用，开始看看效果，看效率。这个时候总会有一些vertical ized，这vertical的这样一些设计出来，这也是一个平衡，对吧？就是说CPU你看通用计算其实也非常通用的，但是总会有一些需要来算出来自的地方。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:56",
      "text": "AI的领域的开源跟以前我们过去更多看到的是这个data info，对吧？大数据领域的开源，比如说数据库这个数据库中间件等等，这开源的这种，不同领域这些开源，你觉得他们这个生态会有会有什么不一样的这个地方。你比如说我们看到像数据库里边，虽然说后来有很多这种开源的开源的这些公司。那比方说他去开源商业化这个模式会AIG公司模型开源公司它的商业化模式会有什么不一样？而且我们其实也看到，比如说数据库，虽然说有很多开源的数据库，但是最大头的就是这个市场。至少从收入角度上来说，其实oracle还是非常投入的。",
      "speaker": "发言人1"
    },
    {
      "time": "01:01:35",
      "text": "对我觉得开源商业化这个事情的确一直以来都是一个挺大的一个问题。AI开源商业化其实和传统的企业的开源商业化差别不是特别的大的。就是大家都在讨论，说我开源其实相当于说是做流量。做完流量之后，我到底要以什么样的一个方式来赚钱。以前的时候传统的这些开源软件，比如说像像那个像克拉德拉等，就是我就不知道。这个还是在不断的变化当中。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:01",
      "text": "传统的这些软件开源公司，它商业化的这个逻辑基本上就是说你看开源软件在放哪儿了。如果说你要来用那些软件，你还是得自己去做部署、运维等等。你买我的部署运维企业化、规模化这些事儿我就帮你做了，这是他们的by position。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:18",
      "text": "今天开源模型就是没有出现的那么一种状态，就是说他这可能有两种方式。第一种方式就是说你看用户如果你要做specialization，你要做fan等等，这种我能帮你做。这是一种就和传统的开源软件商业化是一项类似的这样一种方式。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:31",
      "text": "另外一个，我们今天也看见就是说很多的开源，尤其是开源模型商业化的公司，他其实在做这样的一个情。就是我发布一个小一点的开源模型，我来做市场。做完市场之后，我说你看用户如果你想感兴趣更加powerful。我有一个闭源的模型，你来买我的PI模型。就是模型可以分规格，小的开源，大的闭源。把这个小的完全作为一种市场手段，然后再来引流到大的这边来。所以这个business model上会有一点小区别。同时的话就是这个开源闭源之间，就是从一公司的角度来讲，什么开源什么不开源之间，也持续的在有了这种有着这种去baLance.",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:08",
      "text": "要追赶最头部的闭源模型的能力。您觉得大家通常会低估或者高估的难度在哪？",
      "speaker": "发言人1"
    },
    {
      "time": "01:03:19",
      "text": "我觉得大家可能会高估效果的差别。其实很多时候的话就说。我觉得一些开源的模型效果，像mix tro等等，效果真的还是非常不错的。可能没有到像GBT4等等这样万事通的这种角度。但是他的尤其是对于comprehension等等这些对于理解归纳、总结等这些的任务已经持平，或者说是超过XGVT3.5的这样的一个效果。所以我觉得大家一定程度上高估了闭源模型所所有的壁垒和优势。",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:47",
      "text": "然后我觉得大家低估的可能是，比如说像这个怎么样来更好的orchestrate data，以及怎么样来更好的是说无论是生产还是利用高质量的数据的能力。比如像sora对吧？Sora今天我们也不知道不知道他用的什么样的一些数据。但是显然就是说大家从各个蛛丝马迹上看出来的是说这个OpenAI的大量就OpenAI非常成熟的使用数据，创造数据跟那个什么跟在这个数据上面来做高性能训练，高效高效果训练的这个能力是很强。我觉得可能大家低估的就是说是date time engineering，以及这整体的这个工程工程体系的能力。",
      "speaker": "发言人3"
    },
    {
      "time": "01:04:24",
      "text": "刚才聊了很多AI的事情，我们换一个角度来聊聊杨青老师创业的一个感受。就是从原来这个大厂这个技术专家高管，然后现在转到创业的这个身份。你觉得最大的这个收获是什么？跟原来你预期的有哪些相同和不同的地方？",
      "speaker": "发言人1"
    },
    {
      "time": "01:04:41",
      "text": "我这个回答可能会比较薄弱，因为我知道很多大家创业的时候就会开始讲，好像天天上有地下没的，或者说是开始的一定要死了等等这样的就是一定要很惨才能够体现出价值。我的感觉是这样的，没有太大的差别。但就说说大厂你会摸的更慢一些，就是更稳妥一些，更多的在做管理什么的，创业之后更加开心。第一个是一线的做做工程，做产品。然后同时也需要去handle更多的，比如说像customer relationship，business relationship.",
      "speaker": "发言人3"
    },
    {
      "time": "01:05:07",
      "text": "但是我觉得fundamentally是我们所看见的技术趋势，以及我们在布局的一些技术能力等等，还是在按照我们的计划稳步的再往前推进的。所以这点是我觉得还是挺挺一致的。其他有哪些感觉到不一样的地方呢？我们这群人其实以前在大厂的时候也不太典型的大厂。其实在阿里里头跟我合作过的人，大家经常有的时候说的一句话，说杨青都不像个屁之一，我也不说场面话，我这个怼人大家也知道，就我这个说说话也很直，对吧？这些事儿使得我倒是没有太觉得说从大厂出来到创业公司有什么太大的变化。就everything is .",
      "speaker": "发言人3"
    },
    {
      "time": "01:05:48",
      "text": "expected这么一个状态。也是去年年初，您讲写过一篇文章，叫做三个基础假设。有如果还没有看过的这个朋友跟大家讲下这三个。当时您做这三个基础假设是说开源会降低门槛。然后第二个说应用为王，模型为辅。然后第三个是说企业市场需要新的平台服务。现在一年下来您回顾一下，您觉得说这些判断哪一就是跟您的预计相比，哪一些您觉得是对的，哪一些是有一些偏差的。",
      "speaker": "发言人1"
    },
    {
      "time": "01:06:15",
      "text": "我觉得都挺一致的对吧？你看就说是说这个开源今天在非常好的发展，除了去年的时候，我们也大家就觉得现在比如说像这个mix tro已经基本上在在很多的应用里面，大家至少都会提一提试一试了。然后第二个应用为王，模型为辅。你想就今天大家都开始，尤其是在中国的文化圈里面开始讲说super APP，一三十几基本就是说大家都想说首先找到应用，然后第三个的话是需要新的服务的。我觉得今天我们发现说无论在国内还是海外，其实AI infrastructure包括AI所带来的，比如像软件硬这个软件层，包括新的硬件等等，都在非常稳定的往前发展。我觉得可能这个变化的速度或者发展的速度比我想象的要快，但是这三个基本假设我觉得都还是hold的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:06:58",
      "text": "但是您说比如说刚才讲到这个应用为王，就好像你前面提到的，就是过去一年我看到模型能力不停的提升，这个应用好像似乎跟大家的预期有所差别。我不知道是不是您的这个，我也不知道这个跟您的观察是不是一样的话，您觉得是为什么？",
      "speaker": "发言人1"
    },
    {
      "time": "01:07:13",
      "text": "我觉得可能就是说是当时的时候大家高估了模型的能力。媒体现在非常强烈的要把事情说得惊天动地一些。而今天应用没有像我们文章所写的那么惊天动地，我觉得是一个比较现实的一个状态。就是模型还是很多时候它还处于一种80%可用的状态，所以探索不错。但是到应用落地还有非常多的info的对接，翻译，效果提升的等等这些的工作要做。我觉得是一个会是一个比较缓慢，但是是一个非常确定性的一个过程。",
      "speaker": "发言人3"
    },
    {
      "time": "01:07:47",
      "text": "所以您觉得说其实并不是不是本身本身这个模型和应用的发展低于我们学校说可能原来我们的预期就没有设。",
      "speaker": "发言人1"
    },
    {
      "time": "01:07:55",
      "text": "对，是啊，对。",
      "speaker": "发言人3"
    },
    {
      "time": "01:07:56",
      "text": "那那您对未来未来几年的一个预期是怎样？从刚才说的那几点，模型能力，还有这个应用市场和这个平台的角度来说，您希望发生什么样的一些变化？",
      "speaker": "发言人1"
    },
    {
      "time": "01:08:09",
      "text": "我会希望说因为上层应用这块因为它也不断的在发生变化，我觉得是新的应用，而且是说更加就是我从productivity跟creativity这两个角度，我觉得我会希望说一年之内我觉得可能还是会延续这样的一个过程。然后5年到10年的话，我觉得他很有可能应该会反问自己的改变。",
      "speaker": "发言人3"
    },
    {
      "time": "01:08:29",
      "text": "我们就说是说这个沟通交流等等的一些方式。就像手机来的时候，我们发现有很多时候就模糊已经成为今天我们take for granted这件事情。英法这块我其实会更加熟悉一些。我个人感觉说在五年的这样的一个判断里头的话，cloud就以web service为中心的cloud的这个info会有一个非常大的一个转型，让大家更多的把HPC加cloud这两个需求更好的整合在一起。这个时候从云服务的这个角度来讲，我觉得也有一个attention类型。的一个风险或者机会。就是谁今天能够迅速的adapt到是AI所带来的新的这一批competition pattern，所需要的inflight，那谁其实可能能够是改变今天web service这块已经把有点尘埃落尽了的这样一个竞争的格局。就举个例子，比如说从北美的角度来讲的话，微软爱上云其实在AI这块发力的非常的好不，虽然在算法上面说的比较领先，但是google cloud其实一定程度是没有抓住这一部分这次的机会的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:09:28",
      "text": "然后另外，oracle cloud其实在是算力云这个概念崭露头角的这种情况下面，其实他们在底层也做了非常好的布局，甚至action的一部分计算什么的是offload到RC上去做的。所以说因为整个的需求的市场开始发生了相对比较大的变化。所以我觉得新的机会点跟新的player其实会出来，这个竞争会在这是最近几年肯定还会在在一个不断波动的状态。但是在五年左右的时间之内，我觉得我们会看见一个新的市场的格局。",
      "speaker": "发言人3"
    },
    {
      "time": "01:10:01",
      "text": "刚才您提到说我们过去高估了这个模型的能力，那您觉得有哪些是被大家为在低估的事情？",
      "speaker": "发言人1"
    },
    {
      "time": "01:10:10",
      "text": "我觉得低估的是传统软件印出来的能力。咱们举例什么，这个我吐槽一下complexity，对吧？就是说这个当然非常成功的公司，产品也非常不错。我也挺喜欢他们的产品experience，他们的创始人什么的，跟我们以前在facebook，在break也有认识，但是projective在做的有一件事情，我觉得是非常不靠谱的。就是说他在说说我们我们要放the mentally重建设施。Perplex在底层用了google search或者bean search，但是同时他又说我要find the change search，这个事情是不对的对吧？就是我们低估了在AI的整个的应用当中，传统的info或者传统的software在当中起到重要的作用。",
      "speaker": "发言人3"
    },
    {
      "time": "01:10:49",
      "text": "我们做的ten search其实一方面是说是贴近更加贴近这个开发者。另一方面其实也是是说就向大家展示一个系统化的思考。就是说今天一个成功的应用是要把传统的conventional wisdom核心的AI的技术相结合起来的。在一个reg base的search，尤其是在公寓的这样一种conversation设置的角度，这是有非常大的一部分质量的来源。",
      "speaker": "发言人3"
    },
    {
      "time": "01:11:12",
      "text": "是因为google bing等等这些的测试CPI，他利用了大量的传统information retrieved等等这样一些方式来给我们提供了首先比较不错的，在浩瀚的internet的这个基础上，给我们提供了30个搜索结果。然后我们可以通过AI把以前相对比较糙的30个1个列表变成一个更加自然的交互的方式。你说AI是不是带来了翻天覆地的变化？",
      "speaker": "发言人3"
    },
    {
      "time": "01:11:38",
      "text": "对，是的，就说是我们用户就不需要去看列表了。用户是有一个人就像是有一个人来帮你整理资料，给你回答，这是一个非常翻天覆地变化。但是为了实现这个效果，传统的搜索有没有起到fundamental的作用？是有的。所以我觉得这个地方的话，一定程度上就是我们低估的。其实是。在今天AI要走向应用的时候，传统software，传统info或者说传统的application在其中起到的价值。所以这也是我觉得是一个大家相互尊重，相互学习的过程。",
      "speaker": "发言人3"
    },
    {
      "time": "01:12:07",
      "text": "对，我觉得您说这点特别好，大家总觉得说AI起来是不是又对什么info什么颠覆。然后我们发现其实AI起来了以后，像这些传统的所有的data informed公司都长得非常好。MongoDB elastics其实都都长得很好，是因为很多我们都讲vector b但是你会发现很多这些传统的这些DB很快就上了这个veto search的对于这个功能。对，那你觉得这个是个短期的事情，这个短期我没有别的选择的，我只能用这些老的方案。你觉得长期这些会有变化。",
      "speaker": "发言人1"
    },
    {
      "time": "01:12:38",
      "text": "我觉得长期也不会。就是我觉得这个soft这个market其实的确就是一个大家一起玩的这样的一个过程，对吧？我举一个例子，比如说如果我是做AI的，咱们的FDB做正举。举例子我是做AI的，我也不想去管数据包括什么。如果说一旦要开始上产品的话，我的数据的什么ACID等等这一系列的property对吧？我为什么要管呢？如果说数据库已经帮我管好了，那做的挺好的，那我就接一下他就行。就是我觉得这是一个非常在IT领域非常成熟的那么一个思一个思维逻辑。",
      "speaker": "发言人3"
    },
    {
      "time": "01:13:08",
      "text": "就是说是我把我自己的这块做好，然后我们以标准化的方式接起来，就像比如说CPU对吧？咱们说CPU，CPU说你看我要不要做内存。如果我能够把内存放在我CPU里头，那分区肯定会更快。但是一般大家说说，你看你打开一个机箱之后，里面有CPU，有内存，有硬盘什么的，这个达到一个相互协同，达到一个性价比和效率最高的方案。这个永远是是一个prefer的，而不是说上来说你看我有AIG把刀，我要把所有人全给砍死，那最后自己也可能很累。",
      "speaker": "发言人3"
    },
    {
      "time": "01:13:38",
      "text": "另外一个你提到的是说我们对于这个AI模型能力的一个高估。就未来五年你会希望那个时候可能有哪些我们现在这个模型完成不了的东西，那个时候可以完成的有哪些可能在五年以后这个模型仍然很难完成的任务。",
      "speaker": "发言人1"
    },
    {
      "time": "01:13:52",
      "text": "我最希望能够解决的问题其实就是halcon ation就是怎么样让AI并不是说让AI模型来完全的抛掉和donation的。那就是说有一种更加principle的方式来让AI模型自己来自己来意识到，或者说自己来输出。说哪些是我确定性的知识，哪些是我从我之前的知识库里面或者我的训练数据里面所得到的知识，哪些是我推理出来的知识。然后这样的话能够让我们对于就是对于以前的时候，我们在party的时候做过一些研究叫grounding semantics。所以说对于AI这些输出的内容，我们可以更好的来做grounding。哪些是真的，哪些是推理的，哪些有可能是假的，这个我觉得在实际应用当中会变得越来越重要。今天其实很多时候我们队员还处于一种将信将疑的一个状态。所以如果能够解决掉pollution的问题，一种相对比较principle的方式来解决这个牌，我觉得其实会是一个很有帮助的事情。",
      "speaker": "发言人3"
    },
    {
      "time": "01:14:51",
      "text": "您说比较principal的方式是可能这个transformer这个模型架构的一个改变吗？还是。",
      "speaker": "发言人1"
    },
    {
      "time": "01:14:57",
      "text": "这个我倒是我就不考虑架构了，无论是是不是选什么也好，都无所谓。如果说AI的输出能够告诉用户说，这个地方这个是我确定性的知道的，这个是我猜的。你想我们人之间是交流的时候，其实是这样的，就是说人会告有些时候人会告诉你说，其实我真不太知道，但是我猜怎么样。因为今天有两种模式，一种不会告诉你，一种就告诉你说非常confident，告诉你说自己就这样。所以我觉得说是说怎么样来做这个，因为还有一个词语叫做reflection，对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "01:15:24",
      "text": "就是怎么样来做reflection这个事情其实是在在是AI实际应用当中其实会比较有帮助的一事儿。就比如像google测试，goole测试，今天它其实是说我就不帮你解决对错与否的事儿了。我只是告诉你说那边有一堆网站，那边那那边网站那有你所就你所想要的信息，到底他说的对不对什么的，那我不管，你自己去那网站上看，对吧？这是今天给我搜索的这样的一个这样这样这样子这样的一个这样的一个agreement。",
      "speaker": "发言人3"
    },
    {
      "time": "01:15:48",
      "text": "AI比如说很多时候AI问答，你问ChatGPT等等，说今天他的意思就是说你看我反正给你一个非常confident的回答，到底对不对？你自己去想我们希望能够更加，就比如说像比如说我去看看医生对吧？医生不会告诉你说，你看我这儿有个诊断对不对，我们就不管对吧？医生会告诉你说，那至少说有多少的概率是对的，有多少概率是错的，有有哪些是大概，有哪些是确定性的是对的等等。就是今天AI其实很少能够给你一个guarantee，甚至是一个probability。这个事情我觉得这个在应用当中，其实很多人他会是他会需要我。",
      "speaker": "发言人3"
    },
    {
      "time": "01:16:23",
      "text": "我个人觉得从这个投资或创业的角度来去看，应用创业者来说，可能也是一个优秀的挑战，也是个机会。就是我我觉得我们永远不可能等到模型能力完美了，然后我们才开始做创业。可能很多时候就是在前期，可能就是得在一个变化的这个很变化的底座能力上，然后去去探索这个PMF，然后随时做好这个变化的准备。对，是的。觉得过去可能一年多，市场上你就有什么比较大的一些更共识上的变化，有没有什么让你觉得比较surprise的地方？",
      "speaker": "发言人1"
    },
    {
      "time": "01:16:54",
      "text": "没有太surprise，我觉得整体而言都还比较正常。",
      "speaker": "发言人3"
    },
    {
      "time": "01:16:59",
      "text": "我们一般最后一个会有一个快问快答的环节，让陈老师可以用比如说一分钟左右的这个时间来给我们快速的回答一下。好，那我们就开始。那那第一个问题就是因为你你自己是做这个AI服，那你自己在生活工作中你会如何使用这个会如何使用AI除了ChatGPT之外，你还会有哪些AI工具？",
      "speaker": "发言人1"
    },
    {
      "time": "01:17:19",
      "text": "现在的话在这边用的最多，然后完了说copilot get go pint用的最多。然后其他的其实whisper等等这种是用来帮助来整理什么整理这个语音的内容，开会的内容，以及是来做一些总结action的这种的，就我们自己拿拿自己的图来做的用的比较多，其他的用的还比较少。最近一个很有意思的应用是我们家小朋友要画海报，然后我们就拿chat PT，然后让他说你帮我们出点海报的主意等等。然后完了说因为chat PT现在能够画画了，就是说这个还挺有用的，就是他画一些样例，然后我说这个点子不错，那个点子不错，作为一种exploration的方式，我觉得这个还挺还还挺方便的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:17:59",
      "text": "我好奇你会跟AI聊天吗？或者说用它做吗？或者说用它做brainstorming之类的。",
      "speaker": "发言人1"
    },
    {
      "time": "01:18:06",
      "text": "会吗？Bring stm就是会，尤其是有些时候做一些research的时候。但这个的话可能就是用比如说像这个search，因为我们自己的search，咱们用proxy，咱们这个的用的比较多一些。实还是比较方便。就是说在一些不需要exactly accurate，但是需要非常迅速的来了解文献等等的时候，其实有像plex，像left测试中这样一个总结，其实还挺方便的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:18:28",
      "text": "我其实用proactive就是追新闻用的还挺多的。它非常适合你想要把一个新闻来龙去脉搞清楚，还有一些周边的一些信息。对，然后另外一个就更加意思就是就像刚才大家可能也体会到杨青老师这个对方新人的这个观点。而且时常在这个朋友圈这些AI的话题发表非常犀利的点评，一方面我们非常受益，然后另一方面我也很好奇，你会担心得罪人吗？",
      "speaker": "发言人1"
    },
    {
      "time": "01:18:53",
      "text": "这个事儿担心肯定得肯定是担心的，我觉得这个而且肯定也得罪过人，对吧？就是说得罪了就跟他说抱歉。我的我的想法是这样的，就是这事儿有的时候这个人比较直白，这事儿这个性格也改不了。反正我的朋友圈就保持观点真诚，聊完了之后无论对不对什么的，如果说可能和我这个相对比较熟的人，大家都知道我可能是一个很直的人，对吧？同时我也不太会记仇等等这些事儿，大家都就事论事，这样反而相处的时候什么都会比较简单，对吧？如果说有天比如说我说错话了，那那我就说句抱歉，就是没有什么恶意，所以还是保持那么一个状态。",
      "speaker": "发言人3"
    },
    {
      "time": "01:19:29",
      "text": "我会发现在国外的这个媒体上，不论是podcast、video什么，你经常会看到很多很多大佬也会发表。有时候就挺犀利的一些点评，好像大家更不在意会得罪人这个事儿。然后在国内的这个舆论环境下，感觉大家相对来说就特别担心这个事情。",
      "speaker": "发言人1"
    },
    {
      "time": "01:19:46",
      "text": "对，这个可能也是文化相关。就比如说大家如果说对于这种文化感兴趣的话，有一本书叫菊与刀，d crm and carta。这是以前当时二战结束之后，美国的比较文化研究的一个学者叫rose benedet。他当时就是分析不是中国，是分析日本的这个文化的时候，所以你就他那本书写讲的很有意思的，就是说是讲说美国人的社会逻辑或者西方人的社会逻辑是怎么样的，日本人的社会逻辑是怎么样的，这个东西就没有对错，就更多的是说大家以一种是comparison或者说相互印证的这种方式来看说各个地方的文化以及它所带来的大家的这种社会交往的模式等等，会有什么样的一个区别。Both are right，but is interesting to compare. 大家有跨文化的交往，能够互相看见，说it's interesting，what do they think about stuff? 这个时候其实会有一些很有意思的enlightenment出来。",
      "speaker": "发言人3"
    },
    {
      "time": "01:20:45",
      "text": "你觉得这一年来有什么自己之前非常坚定的观点被证明是错的或者不及预期的吗？",
      "speaker": "发言人1"
    },
    {
      "time": "01:20:55",
      "text": "还好，可能我觉得至少从这个专业的这个角度来，但是没有太多。对，因为我有的时候我的观点也没有那么的坚定，对吧？其实基本上很多时候都是在观察，然后观察做归纳，做总结。然后完了之后有新的数据进来了就做新的总结。所以我可能是一个是不是带有特别强烈的belief，那么一个就是更多的偏daily追问女性。",
      "speaker": "发言人3"
    },
    {
      "time": "01:21:20",
      "text": "interesting。然后另外一个我觉得OK好，下一个话题就是创业。我想虽然说刚才杨青老师说的很云淡风轻，但是关于创业这个事情，我好奇就创业有没有觉得压力压力特别大的时候，你一般会如何缓解压力？",
      "speaker": "发言人1"
    },
    {
      "time": "01:21:37",
      "text": "有啊，这个基本上就创业就属于那种我第一天说we are great，第二天说we're答应的，第三天说we are shit，然后最后一天说we're great那么一个状态，这还是很常见的。然后排解的话，我之前可能在朋友圈提到过，比如说我做面包等等这种，这个是这个是反正是自我排解的一种手段。现在反正就是现在在硅谷之后，反正平时的时候时间非常少，我们家领导肯定不觉得，肯定觉得我在扯谎。但是平时的时候，比如陪陪玩什么的，也是一种baLance的一种方式。",
      "speaker": "发言人3"
    },
    {
      "time": "01:22:07",
      "text": "你前面说的做面包。",
      "speaker": "发言人1"
    },
    {
      "time": "01:22:09",
      "text": "对。",
      "speaker": "发言人3"
    },
    {
      "time": "01:22:09",
      "text": "是你最擅长。",
      "speaker": "发言人1"
    },
    {
      "time": "01:22:12",
      "text": "对OK你可以理解一下为什么咱们来咱们八卦一下这个事儿。作业包为什么是一个非常有意思的一个事儿呢？就是搞IT我们搞AI等等的，天天都在那？我们要更快、更高、更强对吧？",
      "speaker": "发言人3"
    },
    {
      "time": "01:22:23",
      "text": "然后你遇到了面包，面包你你你就是把面粉、水、把什么把酵母等等放一块儿，你得让他去发面对吧？发面你没法告诉他说，我给你个GPU，你给我快一点。酵母不行，酵母说反正我就得俩小时慢慢发展。对你要是捶我，我死给你看，对吧？所以就是它是一个很好的一个心态上的一个平衡。",
      "speaker": "发言人3"
    },
    {
      "time": "01:22:45",
      "text": "Interesting，就是因为你平时做这些自己可控的事情太多了，所以往往在缓解压力地方就是要换一个让你不可控，逼着你慢下来。",
      "speaker": "发言人1"
    },
    {
      "time": "01:22:54",
      "text": "这个很有意思，就是AMBNB的那个创始人brian chesty，他也喜欢做烘焙。上次看他一个访问视频，就现场做做那个muffin。",
      "speaker": "发言人2"
    },
    {
      "time": "01:23:03",
      "text": "对，是因为我觉得很有意思的一点是就是做computer science，我们就是上帝，对吧？我们告诉电脑做什么他就做什么。但是比如说像做面包烘焙等的这种，就是你会发现说我不是我们能够控制所有的事情的。你必须follow一些natural的规则，然后你才能够做出来。所以这个是我觉得是两种无论是工作模式或者思维模式当中的很好的一个baLance.",
      "speaker": "发言人3"
    },
    {
      "time": "01:23:28",
      "text": "很有意思。我这啥时候啥时候觉得自己做太快的时候，也可以去学一学这个烘焙很棒。",
      "speaker": "发言人1"
    },
    {
      "time": "01:23:36",
      "text": "对我当时的时候。",
      "speaker": "发言人3"
    },
    {
      "time": "01:23:37",
      "text": "那那我这个那那我就再问一次。好好，那那下一个问题就是您最经常向别人推荐的一本书是什么？为什么？",
      "speaker": "发言人1"
    },
    {
      "time": "01:23:46",
      "text": "之前是在阿里的时候，其实我也经常向大家推荐一本书，就是卡内基写的人性的弱点。这本书的标题非常的标题党，他的他的这个英文版的名字其实更加的平实一些，叫做friendship and influence people。我觉得好处是他在对我来说，他在是技术上，就是我我对于电脑是上帝的这种技术观点之外，其实打开你打开了一扇门，就是说怎么样和人交往，怎么样和人合作，怎么样以一种说making friendship and win together的这种方式去去去build relationship。所以这个其实对于做技术的同学来说，应该还是一个挺有帮助的一本书。",
      "speaker": "发言人3"
    },
    {
      "time": "01:24:26",
      "text": "我们最后一个问题就是问的有点科幻。然后宇森给我的这个问题说，如果你现在冬眠五年，五年之后醒来，你问的第一个与AI相关的问题会是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "01:24:36",
      "text": "其实这个问题主要是想知道你对AI有近未来进展什么是最关心的，你会关心什么？",
      "speaker": "发言人2"
    },
    {
      "time": "01:24:45",
      "text": "对，那我有可能会是说最关心的一个问题，也是咱们刚才可能也讨论到的一个问题。我会想问AI说今天正确性的这个问题解决了吗？就是我稍微展开讲一下，就是说AI其实一直以来就有那么一个一方面就是说我们说通过逻辑推理的方式，专家系统这种方式来做。另外一种是通过神经网络的方式来做一个黑盒啪出来一个结果，逻辑推理都能够保证正确性，但是它的效果不好。神经网络这块能够能够提供效果，但是它的正确性其实很难保证。所以今天我其实就会很好奇的问题，就是说是AI的学习能力到达了一个可以自己来判断自己的正确性，或者自己反思自己的这个能力了吗？",
      "speaker": "发言人3"
    },
    {
      "time": "01:25:26",
      "text": "我们今天也是不知不觉又录了差不多2个小时，也非常感谢杨青老师的这个时间，我觉得非常的有收获。也很感谢宇森在整个邀请来杨青老师，然后也给了很多非常好的问题跟一些host的这个节目。",
      "speaker": "发言人1"
    },
    {
      "time": "01:25:41",
      "text": "好，谢谢。",
      "speaker": "发言人3"
    },
    {
      "time": "01:25:42",
      "text": "好的，非常感谢二位的时间，非常感谢。好好，那我就不想把这个关上，然后面我会把这个以上就是本次播客的全部内容，感谢大家的收听，希望对你有所启发。如果你喜欢我们博客的内容，欢迎你点赞分享，在评论区写下你的心得。另外onboard也有听众群了，添加小助手微信ID on board 666。再说一次，非常好记欧波666，加入听众群了解更多互动机会。另外如果有喜欢两位主播用爱发电，也可以在小宇宙给我们打赏，请我们喝个咖啡。如果你在用apple podcast收听，也希望你能花几秒钟给我们打个分，打个五星好评，让更多人可以了解到我们我们下期再见，继续更多干货。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "在这次播客中，讨论者深入探讨了人工智能（AI）的发展、应用及商业化问题，涵盖了GPU、英伟达、垂直化设计、CPU通用计算、AI领域的开源、大数据、模型效果、数据管理和工程体系能力等多个方面。贾扬清，作为AI创业公司lepton AI的创始人，分享了他基于深厚经验洞察行业需求，开创AI创业之路的历程。他强调了AI领域需要持续的技术创新和跨领域合作，以及面对激烈竞争和快速技术迭代的挑战。贾扬清展望了AI如何更好地服务于人类社会，与云计算等基础设施结合，推动产业升级，并认为AI领域的创业虽然充满挑战，但也蕴藏着巨大机遇。播客鼓励听众持续关注AI领域进展，思考如何应用AI技术，共同探索AI如何让世界变得更美好。",
    "qa_pairs": [
      {
        "question": "杨青老师能否简单介绍一下自己以及如何进入AI领域的？杨青老师最近觉得比较有意思的一个AI产品或一篇重要论文是什么？",
        "answer": "我是杨青，自读博士学位时就在伯克利开始专注于AI和AI系统的研究，从计算机视觉研究起步，后来因Deep 30的出现而深入到AI软件层的构建，涉及AI与GPU计算、异构计算的结合，以及AI信息等方面的工作。在Google、Facebook、阿里等公司积累了多年经验后，于去年4月在硅谷创立了AI创业公司lepton AI，致力于通过AI、系统和应用的整合帮助用户更高效便捷地应用AI技术。我们最近与MIT韩松老师合作的一篇论文叫做\"Distributed Stable Diffusion for AI加速\"，它探讨了通过多个GPU实现稳定扩散计算的加速。此外，2014年AlexNet通过分布式CPU实现模型加速的文章，以及2017年Facebook提出的通过分布式的GPU和机器进行训练优化，将模型训练时间从一个星期缩短到1小时的文章，都对当前AI领域尤其是AIGC新领域的高性能计算想法产生了深远影响。我们的论文代码开源，希望对大家在训练和推理速度提升上有所帮助。",
        "time": "00:03:31"
      },
      {
        "question": "杨青老师的创业公司lepton AI是做什么的？",
        "answer": "lepton AI是一家专注于AI云计算的公司，我们观察到AI计算需求不同于传统的IT负载，不仅涉及大量数据搬运，更需要高性能计算能力，尤其是GPU等高性能计算资源。因此，我们致力于构建一个更高效、易用且具有全功能的平台，让用户能够专注于AI模型的训练、推理以及AI所需周边基础设施，以简便、高速和高性能的方式提供服务。",
        "time": "00:08:02"
      },
      {
        "question": "当时您是怎么想到成立lepton AI的？当时的市场状况如何？",
        "answer": "我们在2023年4月成立lepton AI，当时意识到以大型语言模型为代表的AI需求日益旺盛，同时云服务商在基础设施层面已开始为AI计算提供专门支持。我们看到的是，一方面有大量针对AI优化的算法研究，另一方面市场上对于高性能计算资源的需求也在增长。基于我们在开源社区、小项目和大项目实施中的丰富经验，我们决定成立lepton AI，专注于为AI计算打造灵活、弹性且高效的云基础设施。",
        "time": "00:10:17"
      },
      {
        "question": "AI计算与传统云计算有何不同，AI计算面临的难点是什么？",
        "answer": "AI计算相比于传统云计算更接近于高性能计算（HPC）。在设计AI计算时，需要考虑如何根据不同工作负载灵活调度和管理GPU资源，以实现高性能的模型训练和推理。云厂商在提供AI计算服务时面临的难点包括供应链的灵活性和高效部署软件，确保服务能满足瞬息万变的用户需求和计算需求的爆发性增长。",
        "time": "00:11:50"
      },
      {
        "question": "在web service领域，云是如何解决软件安装和部署的问题，带来便利性的？",
        "answer": "在web service领域，云提供了标准化的方式来安装和部署各种所需的软件组件，如消息中间件、数据库、文件存储、负载均衡等，用户无需自行安装，只需轻松获取并使用，极大地简化了供应链管理和软件安装过程。",
        "time": "00:13:05"
      },
      {
        "question": "AI对云计算需求的影响是什么？",
        "answer": "AI的到来改变了云计算需求，首先在供应链管理上，由于GPU价格昂贵，促使用户更加注重成本和效率，对弹性需求减少；其次，在软件方面，AI应用形态相对简单，更注重计算速度和结果通信，而非中间件复杂性，这使得传统云服务在软件方面的优势逐渐减弱，云服务商开始转型以适应AI需求。",
        "time": "00:15:33"
      },
      {
        "question": "云服务在性价比方面有哪些显著优势？",
        "answer": "云服务在性价比上有两大优势：一是提供了灵活便捷的资源按需分配机制，用户可以根据需求快速调整计算资源；二是通过高效的资源利用率（例如GPU利用率可高达80%以上），降低了用户的总体拥有成本。",
        "time": "00:15:43"
      },
      {
        "question": "AI与传统高性能计算（HPC）有何异同点？",
        "answer": "AI与HPC在计算利用率和网络通信上有相似之处，如高计算利用率（AI可达80%以上，HPC也较高）和对低 latency、高带宽网络互联的要求。不同之处在于，AI更侧重于单个或多个GPU的高效运行，而HPC则关注整体架构和预估计算知识，且传统HPC软件栈较老旧，无法充分利用GPU等异构计算资源。",
        "time": "00:18:04"
      },
      {
        "question": "如何看待AI for science领域的兴起以及GPU对HPC领域的影响？",
        "answer": "AI for science领域推动了GPU在科研领域的应用，其工作负载与HPC有很好的契合度，尤其是GPU在处理高处理器利用率和网络质量要求的工作负载时表现出的优势。GPU通过软件生态系统的迭代和创新，迅速提升了推理性能，降低了推理成本，并有望在未来继续通过硬件设计优化和软件协同进步，实现超越摩尔定律的性能提升。",
        "time": "00:18:53"
      },
      {
        "question": "在面对lead board时，API服务应该如何应对以保持竞争力？",
        "answer": "对于API服务来说，关键在于找到一个长期稳定的平衡点，而不是单纯为了打榜而烧钱提升性能。我们应该提供性价比高、稳定性好且能满足用户需求的API服务，让用户更容易使用并尝试我们的产品。",
        "time": "00:26:23"
      },
      {
        "question": "用户在众多VC支持的API中如何做出选择？",
        "answer": "用户可以选择标准且易于使用的API，不必过于纠结于价格或性能，重要的是找到适合自己业务和流量需求的最佳方案。",
        "time": "00:27:07"
      },
      {
        "question": "算力紧缺现象会持续多久？对硬件要求有何影响？GPT-4推出的新型芯片能否迅速成为行业标准？",
        "answer": "算力紧缺可能会持续一段时间，尤其是在GPU领域。目前市场中GPU供应紧缺，价格较高，但随着优化和技术进步，未来可能会有所缓解，但整体需求仍在增长，因此不会变得唾手可得。GPT-4的新型芯片要成为行业标准还需要时间，因为硬件和软件优化是一个复杂的过程，需要平衡速度、成本和性能。目前各家公司都在努力在这个三角区寻找更优解，而GPT-4的芯片在性价比和易用性方面可能面临挑战。",
        "time": "00:29:16"
      },
      {
        "question": "是否有新的芯片厂商进入推理市场，并对行业产生影响？",
        "answer": "有新的芯片厂商开始涉足推理市场，如AMD和Growth等，但目前主要以NVIDIA为主导。尽管AMD等公司在尝试提高芯片的可编程性以适应AI需求，但在性能、开发易用性和性价比等方面尚未出现明显的赢家。",
        "time": "00:29:59"
      },
      {
        "question": "AI APP除了计算之外，还需要哪些工具？与传统的ML ops工具有何不同？",
        "answer": "AI APP除了计算外，还需要监控、 logging、可观测性平台等工具来管理服务的稳定性和性能。虽然有人提出ML ops的概念，但实际上针对AI工作负载优化效率的工具更为重要。传统ML ops工具并未对AI发展产生深远影响，未来更应关注如何更高效地运行AI计算和如何解决AI工作负载特有的问题。",
        "time": "00:33:47"
      },
      {
        "question": "在AI应用的价值方面，如果每个人都很容易开发这些AI应用，那么他们的价值的壁垒在哪里？",
        "answer": "这是一个好事儿。关键在于对应用场景的理解和应用需求的把握，这决定了如何更好地将AI融入其中以提升效率。虽然现在更多的是传统应用加上AI能力，但AI确实帮助提升了各行各业从业者的生产力。",
        "time": "00:39:01"
      },
      {
        "question": "您认为什么是一个真正的AI原生应用？",
        "answer": "真正的AI原生应用应该创造新的场景和需求，而非仅是传统应用简单地增加AI功能。例如，像Jasper这类帮助创作者提升生产力的应用，其需求本质上与AI技术密切相关，形成了新的应用场景。",
        "time": "00:40:59"
      },
      {
        "question": "AI对于软件开发和管理领域目前有什么帮助，或您期待它未来会有怎样的帮助？",
        "answer": "AI能显著提升开发活动的生产力，如通过AI辅助编写代码等工具提高工作效率。尽管目前尚未看到AI对软件开发范式产生重大影响，但随着技术进步，AI将在更多领域发挥关键作用，如AI native的应用中。",
        "time": "00:42:23"
      },
      {
        "question": "AI时代下，公司的组织形式是否会有所变化，比如出现更精干的设计工作室？",
        "answer": "是的，随着AI工具的进步，会出现越来越多小型精干的设计工作室，它们能够创新并迅速推出新产品。同时，传统大公司也会调整策略，寻求更灵活的方式来孵化新技术和应用，形成新的竞合关系。",
        "time": "00:45:38"
      },
      {
        "question": "AI是否会使得小公司能够创造更多价值，同时也让大巨头变得更强大？",
        "answer": "AI可能会促使出现更多创新型小公司，同时也会增强现有大公司的实力。公司治理、人际关系以及工作效率等因素将共同塑造未来的组织形态，而AI有望扩大人的管理半径，但最终组织成功仍取决于人与人之间的协作与信任。",
        "time": "00:49:55"
      },
      {
        "question": "在科技产业中，人数规模和技术发展之间的关系是什么？",
        "answer": "人数规模并不是决定一家公司价值的唯一因素，尤其是在科技产业中。新的技术能够组织起更强大的生产力，实现个体能力和组织能力的两头扩张。例如，现代通信技术使得跨国公司能够跨越时区、语言障碍进行高效沟通和资源调动，大大提升了管理能力。",
        "time": "00:51:19"
      },
      {
        "question": "最近OpenAI的技术进展是否对创业公司构成重大挑战？",
        "answer": "OpenAI等头部公司的技术突破确实让市场意识到AI技术的实用性和潜力远超预期，但同时也给创业公司带来压力。不过，这并不意味着所有创业公司都无法与之竞争，因为市场足够大，且随着技术发展，多个玩家有机会脱颖而出。",
        "time": "00:54:06"
      },
      {
        "question": "对于开源和闭源模型的能力差距以及未来发展的看法是怎样的？",
        "answer": "闭源模型在短期内可能仍会有领先优势，但开源模型在开箱即用的便利性和社区交流的广泛性上有其价值。两者差距不会过于悬殊，随着AI领域的广泛交流和知识传播，开源模型将逐渐逼近甚至赶超闭源模型。同时，开源技术可以更好地支持定制化需求，在垂直领域中，开源模型与闭源模型之间差距会更小，且在特定场景下开源模型可能更具优势。",
        "time": "00:54:49"
      },
      {
        "question": "开源模型与闭源模型在垂直领域的表现是否会有显著差异，以及这种差异对生态的影响？",
        "answer": "在垂直领域中，开源模型与闭源模型的表现可能不会出现天差地别的差距，专业领域的专用模型往往在特定领域内表现出更强的能力。用户选择开源还是闭源模型不仅取决于技术层面，还与成本、适应特定需求等因素有关。这会对生态产生一定影响，但具体程度还需根据实际情况分析。",
        "time": "00:59:19"
      },
      {
        "question": "大家对于开源模型效果的预期是否过高？",
        "answer": "我觉得大家可能高估了闭源模型与开源模型效果差距。实际上，像mix tro等开源模型在理解归纳、总结等任务上的表现已经非常不错，甚至在某些方面持平或超越了XGVT3.5的效果。",
        "time": "01:03:19"
      },
      {
        "question": "大家是否低估了开源模型在数据 orchestrate 和高效利用数据方面的能力？",
        "answer": "是的，大家可能低估了开源模型团队在如何更好地组织、利用高质量数据以及高效训练模型方面的能力，例如OpenAI在这方面表现出的成熟数据处理和创新数据利用能力。",
        "time": "01:03:47"
      },
      {
        "question": "从大厂技术专家高管转为创业者的最大收获是什么？与预期有何相同与不同之处？",
        "answer": "最大的收获是一线参与产品工程和客户关系管理等工作，虽然角色转变带来更多的挑战与喜悦，但所见技术趋势和布局的技术能力仍在稳步前进，与预期较为一致。",
        "time": "01:04:24"
      },
      {
        "question": "过去一年中，您提出的开源降低门槛、应用为王、模型为辅以及企业市场需要新的平台服务这三大基础假设是否得到了验证？",
        "answer": "这些基础假设都得到了一定程度的验证，开源进展顺利，模型能力不断提升，而企业市场确实需要新的平台服务来支撑。",
        "time": "01:05:48"
      },
      {
        "question": "对于过去一年模型能力和应用发展的现状，是否符合大家的预期？",
        "answer": "大家可能高估了模型能力，目前模型在很多应用场景中还处于80%可用的状态，落地应用还需要大量工作，如信息对接、翻译和效果提升等，这是一个缓慢且确定性较强的过程。",
        "time": "01:07:13"
      },
      {
        "question": "对未来几年模型能力、应用市场和平台有何预期变化？",
        "answer": "希望未来一年内新的应用不断涌现，从productivity和creativity角度会有延续；5至10年内，市场格局可能会发生显著变化，尤其是云服务将经历转型，新的竞争格局将出现。",
        "time": "01:08:09"
      },
      {
        "question": "是否认为在AI发展中低估了传统软件和信息的作用？",
        "answer": "是的，大家确实低估了传统软件和信息在AI应用中的重要作用。以搜索为例，虽然AI带来了翻天覆地的变化，但传统搜索技术在信息检索和组织方面起到了关键作用，两者应相互尊重、学习并结合来推动应用的成功。",
        "time": "01:11:38"
      },
      {
        "question": "对于未来五年AI模型无法完成或难以完成的任务有哪些预测？",
        "answer": "希望未来能够解决AI模型输出内容的信任度问题，即让模型能区分确定性知识和非确定性推理知识，实现更精准的内容 grounding 和真实性的判断。",
        "time": "01:13:52"
      },
      {
        "question": "在AI实际应用中，如何理解 reflection 这个概念？",
        "answer": "Reflection在AI实际应用中指的是AI不再直接给出对错答案，而是提供一系列可能的信息来源，让用户自行判断。例如Google搜索不再确保搜索结果的正确性，而是展示一堆网站及其内容，让用户自行辨别信息的真实性。",
        "time": "01:15:24"
      },
      {
        "question": "AI在问答方面的角色是怎样的？",
        "answer": "现在的AI如ChatGPT等会给出非常 confident 的回答，但并不保证绝对正确。与医生不同，AI往往不能提供确定性的答案或概率，而是基于模型给出一个模糊的回答。",
        "time": "01:15:48"
      },
      {
        "question": "AI在投资或创业领域的应用挑战是什么？在过去一年多里，市场上有没有出现让人感到意外的重大共识变化？",
        "answer": "挑战在于我们不能等待模型能力完美才开始创业，而应在变化中探索PMF（产品市场契合），并随时做好适应变化的准备。没有特别意外的变化，整体而言市场发展还比较正常。",
        "time": "01:16:23"
      },
      {
        "question": "除了ChatGPT之外，您在生活中工作中还使用哪些AI工具？",
        "answer": "除了ChatGPT，我最常用的是Copilot和GPT，以及用于整理语音内容、会议总结的工具，例如whisper等。最近还尝试用ChatGPT为小朋友设计海报提供创意。",
        "time": "01:17:19"
      },
      {
        "question": "您会用AI进行 brainstorming 或者做research 吗？",
        "answer": "会使用AI进行研究和快速了解文献，比如使用自定义的搜索引擎和总结工具，以及追新闻和获取新闻背景信息。",
        "time": "01:18:28"
      },
      {
        "question": "您是否担心在朋友圈发表犀利观点会得罪人？",
        "answer": "当然会担心，但始终保持真诚并接受错误和批评，认为直率的性格不易改变，重要的是相处时保持简单和事论事的态度。",
        "time": "01:18:53"
      },
      {
        "question": "这一年来，您是否有过之前坚定的观点被证明错误或不及预期的情况？",
        "answer": "没有特别强烈的、坚定的观点被推翻，因为我的观点通常基于观察和归纳，随着新数据的出现会不断调整总结。",
        "time": "01:20:55"
      },
      {
        "question": "创业过程中，您如何缓解压力？",
        "answer": "创业过程中的压力很大，状态时常波动。我通过面包烘焙等方式自我排解压力，同时也会陪家人做平衡的生活活动。",
        "time": "01:21:20"
      },
      {
        "question": "您最常向别人推荐的一本书是什么？",
        "answer": "我会推荐《人性的弱点》这本书，因为它不仅在技术角度上提供帮助，还教会如何与人交往、建立关系，对做技术的同学尤其有帮助。",
        "time": "01:23:46"
      },
      {
        "question": "如果冬眠五年醒来，您会首先问AI什么问题？",
        "answer": "我会非常好奇AI是否达到了自我判断正确性和反思自身能力的程度，即AI是否能解决正确性的判断问题。",
        "time": "01:24:45"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "Onboard播客：探索AI的未来与创业之路",
        "summary": "本期Onboard播客聚焦AI行业的最新动态和创业方向，邀请到了AI领域的领军人物贾扬清老师，探讨他如何思考AI创业方向，对AI未来基础设施需求的理解，以及AI与云计算发展的异同。此外，还讨论了AI在硅谷的创新，开发者工具和应用的价值，开源与闭源模型等关键话题。贾扬清老师以其清晰的思路、犀利的观点和温文儒雅的谈吐，为我们带来了一场充满干货的对谈。节目还特别邀请了真格基金的管理合伙人戴雨森，为访谈贡献了精彩问题，共同探讨AI和投资领域的深刻洞察。"
      },
      {
        "time": "00:02:20",
        "title": "探讨AI领域的未来趋势和创业机会",
        "summary": "在最近的AI热潮中，尤其是随着某些关键技术的发布，AI领域达到了新的高度。本次对话中，杨青分享了自己在AI领域的经历，以及对AI未来趋势的见解。杨青从伯克利开始研究计算机视觉，后在多家大厂管理AI团队，并最终创立了专注于AI系统和应用的公司。此外，他还提到了与MIT合作的关于分布式GPU加速稳定扩散计算的论文，强调了分布式计算在AI领域的持续重要性。杨青的创业公司，Lepton AI，致力于提供高效的AI应用解决方案，反映出对当前AI领域过热现象的冷静思考，以及对如何高效应用AI的深入探索。"
      },
      {
        "time": "00:06:21",
        "title": "AI时代下的云计算转型与发展",
        "summary": "自1970年代高性能计算需求驱动下，IT领域经历了从超级计算到云计算的转变。云计算起初为满足Web服务和数据处理需求而兴起，随后随着AI技术的发展，对高性能计算的需求再次凸显，特别是在GPU资源管理和高效计算方面。AI应用不仅涉及大量数据处理，更需要复杂的计算任务，这促使云服务提供商重新考虑从硬件基础设施到平台及应用的全方位设计，以满足AI计算的特殊需求。"
      },
      {
        "time": "00:10:02",
        "title": "创立Left AI的灵感与市场观察",
        "summary": "在2023年4月成立Left AI的背景下，AI领域快速演进，特别是开源社区在AI和云计算方面的工作。创立Left AI的初衷简单，着眼于AI和高性能计算需求的增长，以及云原生基础设施为AI构建带来的机遇。虽然当时OpenAI的GPT尚未推出，但已预见大语言模型的潜力和AI应用的广泛兴趣。Left AI的创始人来自不同背景，拥有在大厂和小厂工作的经验，并活跃于开源社区。他们注意到AI计算与传统云计算不同，更接近高性能计算（HPC），为AI设计计算的难点包括技术转变和云厂商的适应速度。"
      },
      {
        "time": "00:12:19",
        "title": "云计算在AI时代的技术转型与挑战",
        "summary": "在云计算领域，服务商主要解决供应链的弹性和软件的快速安装部署两大问题。随着AI技术的发展，云服务在供应链管理和软件安装方面的传统优势面临挑战。AI的计算需求对于GPU资源的高成本和弹性需求小，使得云服务的弹性优势减小。同时，AI应用形态简单，更多关注于提升计算效率，而非复杂的软件安装和部署。因此，云计算提供商需要适应这些变化，进行技术和服务上的转型。"
      },
      {
        "time": "00:15:42",
        "title": "AI计算需求与云计算转型",
        "summary": "AI的计算需求特征在于高度利用GPU和CPU资源，通常利用率在80%以上，与传统的外部服务形成鲜明对比。AI应用需要高效的计算性能和快速的网络互联，如infinite band技术，以确保在训练过程中数据的快速通信。这种计算模式与高性能计算(HPC)非常相似，特别是在进行大规模气象模拟等复杂计算任务时。面对AI的这些特殊需求，云计算服务提供商正在经历转型，以适应AI计算的高性能要求。微软云在这一转型中表现出色，而阿里云自2018年开始，通过其产品‘林俊’，对传统云架构进行重新思考和升级，以满足AI领域的特定需求。"
      },
      {
        "time": "00:17:30",
        "title": "云计算与高性能计算（HPC）的融合与发展",
        "summary": "随着技术的进步，传统的高性能计算（HPC）面临两大挑战：对GPU计算能力的忽视以及使用过时的软件栈。云技术和HPC的结合为高性能计算领域带来了新的变革，通过利用云原生的技术栈和AI工作负载，以及异构计算的硬件，形成了一种新型的高性能计算形态。这种结合不仅优化了对处理器的高效利用和网络质量的要求，还特别适用于科学研究领域的GPU计算，促进了AI for science的发展。这种新型HPC突破了传统HPC和云服务的局限，为科学计算提供了更强大的计算能力和支持。"
      },
      {
        "time": "00:19:45",
        "title": "AI推理成本下降与技术优化",
        "summary": "AI领域内，推理成本的快速下降成为一大推动因素。这种成本降低得益于软件的迅速迭代和技术优化，特别是对于推理过程的优化。与训练过程相比，推理通常对网络要求较低，且可通过动态调整、量化和使用小模型模拟大模型行为等技术手段大幅提高性能，实现成本效益的提升。社区在推理技术上的共同进步，预示着未来推理性能和性价比将继续超越摩尔定律，为AI应用的普及和深化提供了强有力的支持。"
      },
      {
        "time": "00:23:44",
        "title": "推理成本提升及未来技术突破方向",
        "summary": "过去一年推理成本的提升得益于行业积累，但要实现成本的进一步降低，需探索适合推理的硬件设计、新型硬件和软件优化。目前，技术红利允许一定程度的成本降低，但未来需要深入研究硬件与软件的优化，如GPU及系统的memory配比，探索新硬件，以及软件性能的挖掘，例如通过优化框架和利用特定技术（如GPU fast）来提高性能。"
      },
      {
        "time": "00:25:26",
        "title": "选择GPU计算平台的考量因素",
        "summary": "在面对众多GPU计算平台和云服务商时，开发者在选择时不应仅依赖benchmark榜单上的性能数据。榜单存在两种应对策略：一是通过投入大量资源来提升排名，二是专注于产品本身而非竞逐榜单。一个平台的性价比、稳定性以及是否能满足用户的长期需求是更重要的考虑因素。对于用户而言，找到一个适合自己当前业务和流量需求的解决方案是关键，而不是盲目追求最低的价格或最快的速度。专业的团队可以帮助用户进行容量规划，找到性价比更高的方案，并根据需要迅速调整资源。"
      },
      {
        "time": "00:28:49",
        "title": "探讨算力紧缺、GPU市场及AI芯片发展趋势",
        "summary": "对话中讨论了算力紧缺的情况及其对软硬件要求的影响，预测GPU紧缺状况短期内将持续，但市场需求持续上升。同时，观察到除NVIDIA外，有新厂商进入市场，特别是一些针对推理优化的芯片，尽管目前市场上还没有明显的领先者。特别提到了AMD的期待和Google TPU团队成员创立的公司，以及各家公司在性能、开发便利性和成本之间的平衡尝试。"
      },
      {
        "time": "00:33:47",
        "title": "重新思考MLOps：从需求出发解决AI效率问题",
        "summary": "在讨论中提到，近年来云厂商和投资者对MLOps赛道高度关注，尤其是在AI应用的背景下。AI应用不仅仅涉及计算，还需要一系列工具支持，如实验管理、模型推理等。观点认为，传统的MLOps定义已经不足以应对现代AI工作负载的需求，特别是对于模型的高效训练和推理，以及对稳定性和延迟性的要求。提出真正的MLOps应更关注如何使AI计算和推理更加高效，而非仅局限于管理实验。此外，强调了面对如稳定扩散等新兴工作负载时，需要有高度的灵活性来适应不同模型的使用需求，这包括优化GPU使用、缓存策略等方面。最终，建议重新评估MLOps的定义和实施方式，从应用和需求出发，解决实际问题，以适应云原生环境下的快速计算挑战。"
      },
      {
        "time": "00:37:37",
        "title": "AI模型能力提升与应用开发门槛降低的影响",
        "summary": "随着AI模型能力的提升和开发工具的进步，开发AI应用的门槛显著降低，使得更多人能够参与到AI应用的开发中。这种变化不仅促进了AI技术的普及，还提高了AI应用的多样性和可用性。然而，这也引发了对AI应用价值壁垒的质疑。讨论指出，尽管开发变得容易，但真正的挑战在于如何深入理解应用场景和需求，以及如何有效地结合AI技术以提升应用的效率和功能。当前AI应用主要集中在增强型应用，如娱乐和生产力工具，尚未出现完全基于AI的全新应用形态。此外，讨论还强调了可观测性（如日志记录）在理解AI模型运行中的重要性，以及传统ML ops工具在AI发展中作用的争议。"
      },
      {
        "time": "00:40:50",
        "title": "探讨AI技术对软件开发与应用的潜在影响",
        "summary": "对话中讨论了真正的AI原生应用与现有技术（如云技术）的区别，强调AI应当在背后提升应用的效率和能力，而不仅仅是改变传统的业务模式。通过提及Magic Death Ray等公司，展示了AI在软件开发领域的潜力，特别是对于提升生产效率的贡献。同时，通过回顾2004年微软杂志对未来的预测，表达了对于技术进步和AI应用的乐观态度，认为尽管需求未变，技术的提升已经带来了巨大的变化。"
      },
      {
        "time": "00:44:46",
        "title": "探讨AI时代下的公司组织与创新",
        "summary": "在AI时代，随着技术的进步，有人认为未来可能会出现只有极少人数的公司，这种组织结构能够快速响应市场，开发创新产品。这种小型的、精干的组织形式，能够在特定领域内迅速取得成功，类似的现象在游戏开发领域已经有所体现。此外，随着AI技术的发展，传统的大公司与新兴的小型创业团队之间的合作与竞争关系变得更加复杂。大公司可能采取更加灵活的方式，通过内部孵化或与小型创新团队合作，来保持竞争力和创新能力。同时，AI技术的广泛应用也让创新能力变得更加重要，可能打破大公司垄断的局面，使得市场更加多元化。"
      },
      {
        "time": "00:49:20",
        "title": "探讨AI对未来企业组织的影响",
        "summary": "讨论集中在AI技术如何使小公司创造更多价值的同时，也可能导致大公司变得更加庞大。观点认为，尽管技术提升了个人和组织的生产力，但公司大小和治理仍然受到人类因素的强烈影响。小公司凭借紧密的团队合作和目标一致性拥有天然优势，而大公司则倾向于稳定但可能缺乏创新动力。AI技术如语言处理和虚拟操作可能改变管理和沟通方式，提高效率，但同时对创业公司提出了新的挑战。最后，提出观点认为，市场足够大，即使面临巨头的竞争，仍有多个玩家能够共存和发展。"
      },
      {
        "time": "00:54:49",
        "title": "开源与闭源模型的未来趋势与能力差距讨论",
        "summary": "在讨论中，开源和闭源模型的差距及未来趋势成为焦点。一方面，闭源模型因其专有性可能在一段时间内保持领先，特别是在通用领域；而开源模型虽然可能在初期略显落后，但依靠社区的协作和共享，能够在特定领域快速追上甚至超越闭源模型。此外，开源模型的优势在于能够更好地适应定制化需求，促进了在特定垂直领域的创新和应用。未来，随着技术的交流和共享，开源与闭源模型之间的差距有望缩小，同时，专业领域的模型将展现出其独特价值，预示着在AI领域内开源技术和闭源技术将并存发展，各自在不同场景下发挥优势。"
      },
      {
        "time": "00:59:18",
        "title": "开源模型与闭源模型在AI领域的生态影响及商业化模式比较",
        "summary": "对话探讨了在AI领域，选择开源模型而非闭源模型的考量不仅限于成本问题。讨论指出，尽管技术角度难以直接比较开源与闭源模型的优劣，但从社会角度考虑，专业化分工更为合理。同时，对话触及了计算机领域对于通用解决方案的追求与现实中垂直化解决方案的必要性，以及开源模型在AI领域与传统数据库领域的生态差异和商业化模式的潜在不同。"
      },
      {
        "time": "01:01:35",
        "title": "开源模型商业化及创业体验分享",
        "summary": "开源模型商业化途径和挑战、对开源与闭源模型效果的评估，以及从大厂到创业的转变体验。开源模型的商业化策略包括提供特殊服务和发布小型开源模型以引导至大型闭源模型的销售。杨青老师分享了从技术专家到创业者的转变，强调了虽然环境有变，但对技术趋势和计划的坚持未变，同时指出了创业过程中更多的直接参与工程和处理外部关系的工作。"
      },
      {
        "time": "01:05:48",
        "title": "回顾去年提出的三个基础假设",
        "summary": "去年年初提出的三个基础假设包括：开源降低门槛、应用为王模型为辅、企业市场需要新的平台服务。经过一年的观察，这些判断与预期大致一致，开源发展良好，模型能力提升但应用落地仍需努力。媒体可能高估了模型的能力，实际应用发展虽缓慢但确定。"
      },
      {
        "time": "01:07:56",
        "title": "未来几年科技发展趋势预测",
        "summary": "预计未来一年内，科技发展将继续当前的趋势，侧重于提高生产力和创造力。而在5到10年内，可能会看到交流沟通方式的根本性改变，类似手机革命带来的影响。特别是在云服务领域，预计将经历向以Web服务为中心的云信息转型，强调HPC与云服务的更好整合。AI的发展将为Web服务带来新的竞争模式，谁能快速适应AI带来的变化，谁就有可能改变当前市场格局。微软和Oracle在这一领域做出了显著的布局，而Google在一定程度上错失了机会。未来几年，市场将会出现新的竞争格局。"
      },
      {
        "time": "01:10:00",
        "title": "低估传统软件在AI应用中的价值",
        "summary": "在讨论AI技术的应用和未来方向时，指出了一个普遍的误解，即高估了AI模型的能力，而低估了传统软件和信息在AI技术中的重要作用。以搜索引擎为例，讨论了尽管AI技术可以极大地改善用户体验，但传统的信息检索技术仍然是AI应用不可或缺的基础。强调了在AI快速发展的同时，传统软件和数据信息公司仍然保持增长，展示了传统技术与AI技术结合的重要性。此外，通过类比CPU和内存的关系，说明了专业分工和协同工作在技术领域的必要性，强调了AI不是要完全取代传统技术，而是与之互补，共同提升效率和性能。"
      },
      {
        "time": "01:13:37",
        "title": "探讨AI模型的不确定性及未来发展方向",
        "summary": "对话聚焦于AI模型当前存在的不确定性问题，希望未来AI能明确区分确定性知识、推理知识与不确定知识。讨论强调AI应当能够自反映，告知用户其知识的来源和可靠性，以改进决策支持和应用效果。同时，指出了市场上对于AI能力的高估现象，对于未来AI模型的发展持开放态度，不局限于特定模型架构，强调在不断变化的技术基础上探索产品的市场契合度（PMF）。"
      },
      {
        "time": "01:16:58",
        "title": "探讨AI应用与文化差异对交流的影响",
        "summary": "讨论重点在于如何在生活和工作中运用AI技术，包括使用AI工具辅助创意工作、信息整理及进行文化比较分析。特别提到了利用AI进行脑暴、新闻追踪和文化研究的重要性，同时也讨论了公开发言可能带来的社交影响及跨文化交流的见解。"
      },
      {
        "time": "01:21:18",
        "title": "创业压力与缓解方法",
        "summary": "讨论主要围绕创业过程中遇到的压力以及如何缓解这些压力。创业被描述为情绪波动极大的过程，创业者通过从事无法完全控制的活动，如烘焙，来平衡心态和缓解压力。烘焙不仅是一种技能，也被看作是一种让创业者从快节奏、高度控制的IT和AI工作中抽离出来，学会接受自然规则和慢慢来的生活态度。"
      },
      {
        "time": "01:23:37",
        "title": "探讨人性弱点与未来AI的发展",
        "summary": "对话中推荐了卡内基的《人性的弱点》，强调了它在人际关系和合作中的价值，尤其是对技术背景的人来说。随后，转向了一个关于AI的科幻问题，询问如果冬眠五年醒来，对AI最关心的进展是什么，特别关注AI的正确性问题以及其自我判断和反思的能力。讨论反映了对技术进步和人性理解的双重关注。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "AI创业方向"
                },
                {
                  "children": [],
                  "content": "AI基础设施需求"
                },
                {
                  "children": [],
                  "content": "AI在云计算发展中的异同"
                }
              ],
              "content": "AI的未来"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "杨青老师的AI创业动机"
                },
                {
                  "children": [],
                  "content": "市场状况与机遇"
                },
                {
                  "children": [],
                  "content": "从大厂到创业的转变"
                }
              ],
              "content": "创业经历"
            }
          ],
          "content": "AI与创业"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "算力紧缺与解决方案"
                },
                {
                  "children": [],
                  "content": "GPU计算平台的选择"
                },
                {
                  "children": [],
                  "content": "HPC与云的关系"
                }
              ],
              "content": "算力与GPU"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "开源与闭源模型"
                },
                {
                  "children": [],
                  "content": "大模型与小模型的优劣"
                },
                {
                  "children": [],
                  "content": "模型训练与推理的效率"
                }
              ],
              "content": "AI模型"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI在不同领域的应用"
                },
                {
                  "children": [],
                  "content": "AI工具在日常生活中的应用"
                },
                {
                  "children": [],
                  "content": "AI对未来工作方式的改变"
                }
              ],
              "content": "AI应用"
            }
          ],
          "content": "技术讨论"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "对AI模型能力的高估"
                },
                {
                  "children": [],
                  "content": "低估传统软件的作用"
                }
              ],
              "content": "高估与低估"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI模型的正确性问题"
                },
                {
                  "children": [],
                  "content": "反思与自我修正能力"
                }
              ],
              "content": "未来AI的挑战"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI在协作与决策中的角色"
                },
                {
                  "children": [],
                  "content": "AI对未来社会的影响"
                }
              ],
              "content": "AI与人类关系"
            }
          ],
          "content": "AI技术趋势与展望"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "AI创业的观察"
                },
                {
                  "children": [],
                  "content": "对AI技术发展的看法"
                }
              ],
              "content": "杨青老师的观点"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "工作与生活的平衡"
                },
                {
                  "children": [],
                  "content": "烘焙作为减压方式"
                }
              ],
              "content": "面对压力的方法"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "《人性的弱点》及其影响"
                }
              ],
              "content": "推荐书籍"
            }
          ],
          "content": "个人见解与经验分享"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "加入听众群的方法"
                },
                {
                  "children": [],
                  "content": "听众群的互动机会"
                }
              ],
              "content": "听众群的建立"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "如何给予节目支持"
                },
                {
                  "children": [],
                  "content": "提出问题与反馈的方式"
                }
              ],
              "content": "支持与反馈"
            }
          ],
          "content": "互动与社区"
        }
      ],
      "content": "播客对话总结"
    }
  }
}