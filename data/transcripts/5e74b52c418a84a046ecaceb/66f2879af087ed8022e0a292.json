{
  "pid": "5e74b52c418a84a046ecaceb",
  "eid": "66f2879af087ed8022e0a292",
  "title": "AI 破局教育行业的「不可能三角」：高质量、大规模和个性化如何平衡？｜S8E19",
  "task_id": "g34dn8eve6xlnwjz",
  "transcription": [
    {
      "time": "00:00:00",
      "text": "用声音。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:01",
      "text": "碰撞世界。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:03",
      "text": "生动活泼。欢迎来到我是next科技早知道第八季，和全球创新第一时间同步。Hello, 大家好，欢迎来到我们今天的what nex科技早知道，我是丁娇改晏。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:20",
      "text": "最近其实我们聊AI落地应用还是聊到蛮多的那上周我们其实是在香港举办了一场AI和创作者这样跨界的一个闭门论坛。上周我们其实没有聊到的是个open I发布了一个特别重磅的一个新的产品，是代号叫草莓的这样的一个新的模型。然后他发布了一个叫做o one preview，然后另外一个是o one mini。O one不一样的地方，它其实是在推理能力上面有很大的提升，在处理多步骤复杂的问题上面是非常的强。它其实也通过了美国数学邀请赛，它的准确率达到了83%，比之前其实还是提升了不少。我们其实如果要聊到数学的话，数学一直是AI领域的皇冠上的名著，是非常难解决的一个问题。所以我们今天就请来了两位嘉宾，一起来聊这个AI在教育领域方面的一些应用。所以今天我们的两位嘉宾，一个是好未来的CTO田蜜田老师大家好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:14",
      "text": "我是好的甜蜜。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:15",
      "text": "然后另外一位是百度集团副总裁侯震宇，侯老师大家好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:18",
      "text": "我是百度的侯震宇。百度在过去的十几年一直在致力于人工智能的研究和应用。我们在从去年和好未来一起，我们在整个教育的AI的这个领域上，双方一起合作也做了很大的成绩。今天主要是跟大家交流一下这方面的内容。",
      "speaker": "发言人3"
    },
    {
      "time": "00:01:36",
      "text": "其实我觉得其实我们聊硅谷的一些内容是聊的比较多。然后我也看到像是OpenAI其实很早是跟c academy可汗学院是做过一个AI的产品，叫做mego。但是在国内其实我们是有好未来跟百度这样的一个基于AI的一个教育大模型，特别是九章大模型，是完全是基于数学的训练的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:56",
      "text": "九章大模型它其实是全科的，但他数学是能力比较突出，所以就把它叫酒庄算数的。这个命名叫叫酒壮胆模型。它的英文名叫MathGPT，所以大家认为。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:05",
      "text": "它就是偏数学。对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:07",
      "text": "因为名字叫mac但是它其实是全科的对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:10",
      "text": "明白咱们两边的合作开始的这个起源是什么样的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:14",
      "text": "是这样，因为是22年10月底，这个GDP出来，当时大家所有人都很焦虑，大家所有人都说你们教育行业为咱们这个颠覆了，然后我们也很焦虑。然后我们各种学习研究，然后到二三年3月份，我们老板决定说我们不行，我们要自建教育大模型。当时这个任务就交给我，但是我其实也是当时也是两眼墨黑眼眸，我也不知达摩型是啥。然后那时我们说我要做的大模型首先要算力，得有人教我们怎么去模型，教我们自己做推理。然后我们一看了看整个中国募，也就只有百度说我推了文心发布会，我也参加了，就是国内第一个大模型。所以我们想百度自己训过这个大模型，然后也都是何老师这边支持的那我就说这样百度在算力方面，在训练推理的优化方面都有很多的经验。所以我们就希望跟百度云去合作，把这个事情定下来。所以说我们主动去找百度把这个合作谈下来，然后越合作越深。我们的这个算力逐步的加大，我们的训练框架优化，推理速度的优化，都是百度帮我们来完成的。所以就越来越深度的绑定。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:12",
      "text": "其实我们跟田老师也认识很久了，百度跟好未来的这个接触也有几年的时间。但是在去年就是二三年的时候，大模型在年初的时候变得非常的火，这时候百度跟好未来的这种天然的联系就变得更紧密了。为什么说是天然的联系呢？特别是在一些教育领域，因为教育领域是一个知识非常密集的一个行业。在教育领域上好未来是一个领军的这么一个企业，大量的这种领域内的这知识。而百度我们也是做AI做了很多年，在AI的各个层面上其实积累都很多。但是跟好未来相对来说的话，我们在基础算力层面上其实能够帮好未来做的更多一些。所以在去年年初的时候，我们就是碰面了几次之后。",
      "speaker": "发言人3"
    },
    {
      "time": "00:03:55",
      "text": "我们就确定合作了。对，因为我之前看到好像咱们之前其实他也用过像是bird这样子的一种模型，稍微就是transformer早期的这样的一些模型。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:05",
      "text": "现在技术大模型可以说所有的原来范式都被改变了。你认为现在无论是LP语音图像基本上都是transformer的。因为它的泛化性吧其实也证明了自己的能力。而且就是只要你不断的对数据，对算力，它的性能却是直线上升的。所以这个其实不光是教育行业，我理解所有的行业的大模型都是已经被吹的风全部给重构了。就以前老的这种辈儿的这种这些犯罪一般就被推翻了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:28",
      "text": "用不下去了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:29",
      "text": "但是他们能活到哪一天呢？这也不好说，也许过了5到10年，估计大概也不是他了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:35",
      "text": "说一个题外话，您试了那个o one吗？您觉得怎么样？对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:39",
      "text": "特别数学这一块是这样。我觉得OKI每次发一个产品，我们朋友圈就会被刷屏一次。而且有无数的朋友啊或者投资人或者客户来说，你们还好吗？你们是不是又要被颠覆了？",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:50",
      "text": "当时CCPSO出来的时候，当时有个视频估计大家都看过。就是看看demy的创始人教他儿子学一个几何题。是然后当时就是基于所有的一个AI tutor，跟他很好的去教，他就说我这个教授是不是失业了，这个老师都是不是要失业了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:06",
      "text": "当时已经被问了很多遍了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:05:07",
      "text": "数遍了对问了无数遍。所以这次O一发布之后，我们是第一时间去测。因为当时他API没出来，但是他基于那个人账号是可以测的。我们测下来，不谦虚的说法就是在中国的K12，就是小学高的这个数学题的解题帧率上，我们是不比他差的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:25",
      "text": "因为他最大的改进是加了强化，对吧？因为他原来这个做预训练的，其实在算力数据上也到了一个瓶颈了。强化的话可以不依赖于这个数据，然后只要自己self play它左右互补，他就不断去找到这个新的规律，自己去反馈学习。其实在半年前我们就已经在做强化学习了。当时也是我们会发现说数学题的话，因为这样训练的语料会很少。虽然我们自己也有也构造的语料，但是数量还是不够。所以我们就让一个AI自己去不断的探索它，可以扩展十几步，然后每一步我们老师给他打分，所以每一步骤做数据的标注，然后来做强化训练训练。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:00",
      "text": "其实大家还是在同样的起跑线上，并没有说是差距太远。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:04",
      "text": "但是这么说，OE它肯定在整个全场景的泛化性肯定是比我们强很多的。但是落到单一的一个教育场景下的话，我们是我们的一个行业大模型或者叫教育大模型。跟他们通常去在特定的specific的场景下比的话是不逊色。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:17",
      "text": "它比如说是在数学领域的话，其实最难的还是它这个长逻辑是吧？就这一块怎么样？",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:22",
      "text": "数学听，比如说我们的小学题已经解到95%以上了，就是都能做对。初中可能80%多，高中就要到60%多，因为什么呢？因为高中一个题目它可能要大要推理十几步，因为每一步出错的概率大约可能是5%出错概率但累积起来它可能退完十几步之后，他可能就百分之三四十就容易出错了。这是整个大于模型这个是很难被打破的一个目前是很难理解的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:45",
      "text": "其实OE的原理很简单，就是说我试多次，每步骤我都可能把十几个可能路径全部遍历一遍。原来他叫快思考，你问了他马上立刻回答。现在慢思考，他可能消耗甚至几分钟十几分钟去思考，把所有的可能性都过一遍，总能找一个相对最好的结果。咱们人也一样，叫深思熟虑。其实他本来就这么个回事。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:05",
      "text": "明白。所以咱们从去年8月份浪直到现在，然后现在基本上是一个是数学，然后也有这个作文。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:12",
      "text": "对，也是是个全科的。其实主要是分为我们后面是我们是一个MOE架构，多专家这样搞。后面主要是三个模型，一个是语文，一个是英语，还有一个是理综。理综是包含数学的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:24",
      "text": "你这很有意思，就是你会发现跟人类一样，就是一个人的语文好，他可能数学不行。他可能英语很擅长，但他可能物理化学不行。所以它这个东西是一个大语言模型，它其实天然是在语言上是很擅长的。所以他一开始在语文和应用上表现都很好。但是在偏reasoning的方面，就是数学它是相对是比较弱的。其实我们做做了大量工作，都是补齐大于模型的一些在推理方面的一些缺陷。这是我们的一直在追求的目标。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:50",
      "text": "田老师，咱们这个AI大模型的产品，现在就是放在咱们什么样的产品里面应用，咱们用户是什么样的一个状况呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:57",
      "text": "其实现在说实话，大模型的落地应用是一个全球的一个难题。让大家看看全球很多公司，买了那么多算力，投了训练那么大模型。但真正能现在看到的kid APP还是非常少的。可以说除了chat board之外，应该没有很多被验证过的这种产品的形态。那好未来从做大鹏平台第一天开始就在思考这个问题，我们到底能用大米在教育行业做些什么应用，有什么落地？",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:20",
      "text": "其实我觉得我们现在大模型的话，目前已经比较成熟的话，我总结大概有五个能力。第一个能力是叫解题，一个题目来把它解出来。这个意义在什么呢？意义在说原来很多题目的生产，它的答案解析是需要人类来写的。现在大量去通过大模型直接给解决了。所以它的成本是原来任老师的可能就是1%这样的一个量级。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:40",
      "text": "然后第二个能力，我们是叫讲题。过去很多我们的辅导老师会花大量的功夫和孩子去讲这个题子。他不懂这个题目怎么说，讲明白在这个讲题的模型，你就完全可以代替张老师去把这个事讲明白了，这是第二点。第三点就是批改，批改也是非常刚需和痛点的一个需求。就是过去你无论是中文的英文的作文批改也好，还是数学的口算和那种应用题的答题批改也好，其他方面都很好的很好的完成，这个可以给老师批改节约大量的时间。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:06",
      "text": "然后第四个的话，我们是叫英语的口语对话练习，这个相对比较好理解对吧？就是通过口语练习来做学习英语的口语。然后第五个的话，我们是做搞大模型的，做个性化的推荐。过去的话就是根据知识的这个图谱和这些诊断来给你推荐你要练习的一题。现有大模型之后，这个推荐的准确度会进一步提升。因为原来推荐只能到这个题目级别，就可以到题目的步骤级别，可以做的会更加的细致。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:31",
      "text": "那5G的能力的话，用在我们我理解现在场景上，我们大约有三个场景。第一个场景是学习机。其实你会发现现在的中国的用户，他很难去为单独的一个软件去付费。但是他愿意为了搭载了很多软件功能的一个硬件去付费。现在我们的学而思的学习机，学习机卖的是非常的好的。我们在高端的学习市场上，我占了50%以上的份额，然后上面搭载了大量的我们的AI工具。刚刚说说所有的这种批改、解题，然后答案，还有对话，全部都在这个学习上可以找到，这是第一个已经被验证过的用户，是愿意为了一个加上AI的硬件买单的，这第一点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:08",
      "text": "第二点的话，其实我们也做了很多独立的一些APP，对吧？比如像我们刚才说的一些随时问，一些批改这种up但是坦率的说，APP目前的话其实它都是免费的。但是它用户的这个增长还不错。但是它的想用户为了买单的话，其实还是我感觉还有很长路要走。因为他本来在中国就很少。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:27",
      "text": "还是移动互联网时代一个freeman模式。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:30",
      "text": "我们还在早期，是的，很早期的对。但是第三块的话，我们也是把我们的能力通过APISDK对外输出。不光输出了内部的各个业务。比如说我们学子培优学习网校，他们都用了很多我们的作文批的能力，用了很多的数学解题讲题能力都用了。然后我们也在对外很多厂商，比如像一些手机厂商、PC厂商、pad厂商，都在用我们的这个API在做他们自己的一些产品。很有意思的时候。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:53",
      "text": "还有一个这还蛮有意思。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:55",
      "text": "的这一块还有意思是一个某家新能源车厂找我们合作，说希望接入我们的那个能力。我当时想车上为什么要接呢？他说家长觉得与其让孩子在车上看动画片，不如让他跟AI要讲讲题，就是把孩子时间充分利用上，这是很有意思的。我估计这种需求只有中国的这个场景能想出来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:18",
      "text": "我想知道咱们好未来在教育领域其实也是有很多年的积累经验了。然后可能在给学生的这个数据反馈上面，这些是咱们的护城河。就比起如果是现在我要做一个AI教育公司，我跟侯总这边合作，咱们的护城河是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:33",
      "text": "我觉得说的非常对。其实大家都知道AI还是三要素，数据、算力和算法。数据的话确实是我们花未来最大的核心的优势。我们过去有21年的积累，我们积累的数据到了题库，可能几千万的这种教辅讲义、试卷对吧？还有几百万的视频，还有数据去调的这种学生的反馈数据，这都是我们的询大模型最核心的优势？然后算力方面就是和百度云合作，百度云这个白给我们提供了各种异构这种算力，算力是完全是依赖于百度的。然后算法的话，我们也是借助了很多开源模型的力量，让他下面做了很多改进。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:04",
      "text": "但其实AI大模型在教育领域一直是还是大家争议很多的。其实一开始很多大学就说我不愿意让学生他是一种作弊，所以就对然后包括我是上周看了一个沃顿的一个论文，他出来，但我觉得后来发现我再仔细再往下看的时候，觉得他其实有很多地方是不经不起推敲的。他说用GPT培训出来的学生，其实对我考试成绩没有不用GPT的这个学生要优秀。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:30",
      "text": "但我看了下去，首先有几点，他一个是用ChatGPT四做的，而去年秋天做的，肯定它的准确率是非常低。对我看他的这个基础的错误大概是在8%，有一些基本的运算都是错的。然后可能是还有40%多，他就是还错的挺离谱的对，然后它是只有四个session，然后大概是90分钟的这样子一个训练，然后是三组学生。对，然后一组是就用GPT，一种是用AI这种tutor就是教学的，然后另外一种就对照。对，然后发现他们还是在土耳其做的一个实验。对，反正我看下来就觉得这个paper可能有参考价值，但是我们不能说是AI没用。我不知道您看了没看过这一篇我。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:10",
      "text": "没看这篇论文。但其实去年在P刚出来的时候，确实我知道很多像美国，还有英国、欧洲一些大学确实是不禁止学生用GGP的。但是好像很快回来也就撤销了。因为这个事情我觉得这个事记不住，就好像当年我们我们上代可能用算盘，现在不让他们用计算器吗？或者不让我们有电脑，这个事情我觉得因为这个BGA是个工具，对吧？其实东西你说你禁用它这个事情，我觉得本质上是我们下代孩子可能就比较他们就是AI原生的，他们从一出生或者很小就去接触到AI工具，就算是用的很天然。比如说像我家娃，他其实他已经不愿意打字了，他永远都是拿手机直接语音输入，他觉得很天然，所以你说难道就是不行，你必须不能语音输入，只能跟我敲字吗？我觉得这个东西其实已经是不是。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:54",
      "text": "一个对未来人机互动的范式，其实是我们现在可能还没有没有摸索出来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:00",
      "text": "我们看来AI一直来说，它首先是一个工具，它能够大幅度的提升人们的这些能力，或者是提升我们整个的效率。至于说是去年open I变得特别火了之后，就很多的教育圈说不能用那个G去查一下这样资料或写论文什么的。其实某种层面上教育是让人们学习知识，掌握能力的，如果你直接给答案，那显然是不好的那就跟抄作业一样，那是作弊。但是他在过程中，我们可以帮助老师，帮助学生能够更好的更快的学到一些知识。我觉得其实这就是在刚才田老师说的这是不可逆的在改变我们整个的教育行业。我觉得这个AI其实某种层面上聊更多的话，AI首先就是一个工具，它不会去取代某一个工种，某一个我们人类的一些能力。所以大家都应该更加善用到这些工具。你用了更好的这些工具，更好的用的这些工具，都能够大幅度的提升你自身的这个能力。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:55",
      "text": "对，就可能在我们比如说企业里面，我们不会禁止员工去用AI的一些提效的东西。对，我们鼓励大家去使用。老师也是一样的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:04",
      "text": "像百度在过去的其实也不只是在GPT或去年的大模型出来之后，我们本来就有这种自动辅助生成代码这样的工具。在去大模型变得特别火了之后，这工具在我们内部也会更加的重视。现在当然我们也会做成一个百度智能云的一个产品往外去推。实际上现在百度内部得有30%多的这些代码，就是由我们这个软件自动生成的，在打互动的，提升了我们整个的效率。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:29",
      "text": "感觉其实现在在海外大家也开始在反过来在思考。因为我们现在所有的范式都是基于教育的资源的稀缺性。我们做了很多的，比如说考试层层选拔这样的东西。未来其实完全就可能会有一个新的这样的一种模式在进行这个教育。我要学习，我目的不是为了考试，我是为了其他的事情。对，我们可以后面再再展开再聊这一块。对对对，接着刚刚振宇老师讲的，我们怎么样用AI来引导学习，不是直接给答案。这块是不是能够田老师再帮我们多讲一讲。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:02",
      "text": "到了今天AI这种它这种chatbot这种一些多轮对话交互的方式的话，我不给答案。我是把分成一步步给你讲，而且每步是设问说这步是用什么，你明白了吗？或者你知道什么什么，比如说1元2次方程应该是先怎么合并同类项什么之类的吗？就问学生，他回答说会还是不会？他不会的话可能去展开去讲，或者他有别的，比如他上市不会前置时间，不会的话也会去展开讲。他会变成说真的想跟老师要给你不断的去对话，然后根据你的不同的学习画像去给你做针对性的讲解和补充，最后还可以给你做总结和举一反三。他目标是能把那个题给你讲会，而不是直接把答案给你。但这个在没有当兵之前的话，其实是很难做到的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:41",
      "text": "但咱们一般是怎么样设计这个流程，比如说是你要分几步骤，然后这个东西我觉得还挺难把它设计出来的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:47",
      "text": "因为我们日常攒了大量的数据，就是一个题怎么把它讲得更明白，我们是有很多经验的，而且可能不同老师有不同的想法，或者一个题有不同的解法。这个都和你孩子的当前的我们叫学习画像。他对不同质量的我的情况就说你是我会针对你的这个知识掌握情况，去针对性的去补这个薄弱的地方。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:05",
      "text": "对于孩子来说，他学习起来跟AI老师交互的话是没有任何压力的。因为我是家长，就是给孩子孩子几岁了？我孩子现在上小学三年级。对，然后有时候跟他讲一个题目，他第三遍听不懂的时候，我可能就控制不了我的情绪，可能就要开始咆哮了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:19",
      "text": "对，但A老师他讲上一百遍他还是会很耐心，而且孩子会觉得这是一个工具。他可能没有老师那种敬畏，他可能就是会很随意的会跟他去聊，他会很放松。他也敢反问这个AI你想他什么时候反问老师的？但是他跟他沟通就非常的平等，其实培养他的自信心。而且他觉得他不懂的话，他就是问我就是我就是不懂，你给我讲一遍，他不会有任何心理负担。如果老师跟你讲的可能老差别，被老师骂笨蛋，所以这个事情就是会变得很多工作，而且其实也是会在培养一些他的我们叫critical thinking的这个能力。他敢于跟他去讨论或者甚至反驳，但是对于甄老师来说他是不敢的对，所以我真的觉得AI老师的出现，真的会让很多孩子其实在培养自己的自学能力，培养自信心和刚才说的这个批判性思维上面，会有很多的一些过去做不到的事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:05",
      "text": "其实AI教育来说的话，完全可以做到给我们的学生一对一的这种定制化的这种设计，个性化对对，个性化的设计也不会再出现像以前说的，就是您遇到的这个问题。就是老某个老师虽然说是一对一的对，但是我忘了这一上一次给你讲到比如说第几页。因为我觉得在接下来的这个AI对应的这样的教育工具上，我觉得都能行，或者田老师你们已经实现了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:28",
      "text": "对，是这样，就是我们教育行业有一个叫不可能三角理论。一个高质量的大规模的个性化的教育是很难做到的。我们现在想做的AI老师，他是真的希望能够在大规模和高转基础之上把个性化加进来。个性化只能考研，因为人类老师的大规模供给是很难做到的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:45",
      "text": "所以在这个个性化这块其实也是非常难做的一个事情。对他需要可能对你个人有很深的理解。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:51",
      "text": "就是你请个一对一老师，那老师怎么了？又让孩子说先做这个题，叫诊断一下，就发现你什么地方掌握的不好，叫这个知识点掌握薄弱。然后你去跟你再布置更多的钱让你去练习，然后练会了他就会跳到下个试点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:04",
      "text": "其实AI做的就是同样的一个工作，但是AI相比真人老师比他优点在什么？首先他对知识点的掌握是非常全的，而他会做的更加的细化，而他永远不会遗忘，他可以记录每个孩子的学习，每个孩子他的学习画像记在计算机上，对吧？他他永远可以随时可以调取出来，这是他的一个优势。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:20",
      "text": "我们讲数学讲的蛮多了，然后可能是在作文助手，阅读助手这块，能不能帮我们稍微再提一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:26",
      "text": "好啊，现在我们学习上用的最多的这个工具，其实就是语文的作文批改和英语作文批改。像云的话，其实它写完之后，你拿我们学习机拍一下，他就跟你去做分析的批改。从字词的分析再到段落，再到全文，再到整个结构的立意，然后再到整个一线润色大于模型对这种语言的理解，包括其中很多所谓的是人类的感情的理解，他其实做了一些非常的出色。其实他这种情感识别做的非常的好。说白原理很简，他见过基本上见过所有的这样的表达方式他都记得住。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:56",
      "text": "那会不会有这种可能在统一标准化和创新性上面会有一个取舍。就比如说这个大模型创意出来是一样的，那孩子他的个性或者他的这个文风，或者他想要表达的东西其实是千姿百态的对，会不会给的这个反馈其实都是比较类似，不会激发大家的创新创造？",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:14",
      "text": "不会的，因为大模型大家知道它的输出是有概率采样的，它的每次输出是不一样的，对吧？它会有不同，而且你会你的输入的prom里面有不同的风格，它会出不同风格的这个批改说也一样。比如说如果你这个作文，希望他按照什么样的风格批改，它都能做得到。因为它本身就不是个固定一成不变的，而且你可以根据用户交互中不断的去调整。我觉得不会把孩子教成千篇一律的这种结果。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:35",
      "text": "我记得我应该上学的时候就是抄作文。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:38",
      "text": "然后抄范文。对，抄范文就我所有的范文，所以每次给你的范文都不一样的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:43",
      "text": "对，就是抄京剧，然后背京剧。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:45",
      "text": "然后是的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:50",
      "text": "我们来转向这个背后的具体的技术跟百度的合作这一块儿。因为我们刚刚听田老师用到了一个百舸异构的计算平台。这个异构是什么意思？谁能帮我们先科普一下？",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:02",
      "text": "所谓的异构其实是更多的是从以前所谓的同构来说的。简单的来说，可以说简单的认为就是用更多的像GPU这样来做加速的这样的芯片就叫做异构计算。如果说是以前经你常说的同构。",
      "speaker": "发言人3"
    },
    {
      "time": "00:21:14",
      "text": "就是CPU计算。明白。那这一次的合作为什么是咱们这样子的一个合作？就为什么选择了百度这一块？可能两方大家田老师何老师都可以说一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:25",
      "text": "选百度原因很简单，就是我们去年准备做这个事情的时候，国内只有百度推出的文心大模型，就只有他一家已经证明了自己可以迅速好的大模型。而百度云就是给百度文心提供这样的基础算和训练平台的。但自然我就说它既然可以迅速改善，那我就用它，当然最放心。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:41",
      "text": "我稍微引申一点多说一点，就是金融圈里面说的是金银天然不是货币，货币天然是金银，金银这种贵金属天然可以成为一种货币。所以GPU它本身虽然说最早是做图形加速的，但你可以看到它核心就是里面有大量的GPU上的小的那些核心，它是专门去做并行计算的。而且它GPU本身是对于这种浮点运算和这种不管是当年的图形去做渲染，还是说是现在的AI的这些计算，基本上都是一些矩阵运算。所以它天然GPU就是一个对于现在做数学运算也好，现在到了现在的AI的这种运算是一个非常天然的一个结合。因为它去掉了CPU这种非常复杂的一些做逻辑运算，它就是一些做这种高并发的这种数据运算。所以百度其实我们从09年开始就是中国互联网第一家。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:34",
      "text": "09年我们就开始用GPU做继续加速。一直因为百度在过去十几年一直在整个AI这方面投入很大，所以在整个白格，就是我们整个大的利用像GPU这一类的芯片去做整个的AI训练集群推理集群。所以我们从09年就开始用GPU来做加速了。所以在AI基础设施上其实一直积累了很多，不管是说是整个的大模型领域，实际上我们在21年就已经建设起来了差不多3000到4000卡的这样的单一任务的集群，这应该是国内最大的一个在当时的一个集群。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:08",
      "text": "当时这些算力主要用来是干啥的？",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:10",
      "text": "熏就熏文心大冒险。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:12",
      "text": "就是新闻，就是熏文心大模型。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:14",
      "text": "所以其实就是我们在过去的整个AI基础设施上，其实一直积累了其实很长的时间。不管是说是从单一任务的集群的规模的大，然后到整个的集群的对应的稳定性。GPU其实在过去几年更新换代特别快，它比CPU的迭代的速度要快很多。每一代的CPU出来大概性能提升10%，但是每一代的GPU出来至少是翻倍，所以它对于整个的功耗也在翻倍，所以GPU的故障率会比CPU要率要高很多。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:43",
      "text": "我们可以看到，因为前一段时间lama发表了一个差不多九十多页的llama 3的相当于技术手册一样的论文。其实里面专门谈到了他的一万多张的一个H100的集群里面的故障率大概是多少。所以它是大幅度的要比CPU集群要高。而整个的GPU的训练又是需要在整个集群统一来做一个单一任务的。所以它有关整个的故障率是一个故障。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:06",
      "text": "故障的发现，故障的修复，其实对于整个的集群的有效计算的时间来说，是一个非常重要的一个事情。所以百度我们记从开始做的就规模就比较大，同时也解决了规模很大的这样的稳定性也好，有效训练的也好的整个的这么一个问题。同时解决了这些问题，我们在这个基础之上也提升了整个的GPU的利用率，或者说CPU通常说叫利用率，CPU我们比如说叫MFU，我们把整个的这个数值其实拉的也很高，能够让我们整体的训练的所有的真正的有效的使用的效率也会变得很高。所以我们其实在训练的集群的规模上，在稳定性的层面上，在我们整个的使用的效率上，其实都做了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:49",
      "text": "其实内部已经有很多的测试和验证了，才拿来给这个好未来作为口头一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:54",
      "text": "这个是你会发现在infer上头投入，这其实只有大人才能做的这么细致。就是像我们这种中场是不可能投入我们经济做这个基础建设是建设的那就因为百度在文心上已经这样的时候，自己在硬盘这方面，刚才说的稳定性，训练的这种就是尽量不要被中断，中断就会立刻拉起来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:10",
      "text": "这是您最考虑的一个选择。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:12",
      "text": "因为这个事情这些方面我们是不打算投入做的那我们当然选一个关联最好的info厂商来做这个事情，就当然就选择了百度云。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:19",
      "text": "对，因为大家知道这个算力其实钱很多，我们之前简单的统计过一下，就是在过去在国外的除了一个拉玛3以外，还有一个不是整了一个10万卡的这个H100的这个集群。10万卡的H100从capex就是你的采购金额来说的话，差不多相当于北京到天津这个京津城际的高铁的投资额的两三。它的耗电量相当于一天的这个H100的10万张卡的耗电量，差不多相当于北京东城区居民一天的耗电量。对，所以它其实是一个超级大的一个工程。所以它在这个理念上，其实刚才我说花了这么多钱，如果你有10%的时间是消耗在修故障上，那意味着你有10%的投资其实是打水漂了。如果你要是有50%，那就50%投资打水漂。所以这其实是一个非常重要的一个指标。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:11",
      "text": "明白了有什么这个挑战吗？咱们在合作当会有一些什么问题是和我们经过这个配合磨合解决了的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:18",
      "text": "我不得不说就是我们是一家做基础设施的一个公司。百度智能云我们提供的是一个技术平台的服务。我们会对所有的客户其实都是提供同样的这样的服务。但是就是不同的客户在这个平台上能不能更好的使用到这个平台，依赖于两家公司更好的磨合。",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:35",
      "text": "在百度内部我们训了一个其实更大的一个通用大模型，就是文心大模型。我们解决的这种网卡层面上的故障率会越来越低，包括出现故障之后发现故障、定位故障，以及在这个故障之后恢复的时间越来越短。这些都是在百度内部，我们在内部环境都已经解决的。百度内部其实是一个内部的一个环境，我们和内部其实合作了很多年，然后也有内部统一的这样的技术站，内部有很多的碰不到的问题会在我们的客户层面上可能会遇到，这就是需要大家双方的去磨合。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:06",
      "text": "比如说如何去准备这些数据，事实上如何去训一个模型的一些基本上的方法，大概有哪些步骤其实是公开的，这不是一个秘密。如何能够把整个的基础上集群做的更好，这确实是一个很高难度的事儿。还有一些就是说把整个模型做好，还需要更高质量的数据。大家最近总是在提我们需要多大规模的数据，事实上更高质量的数据比更大规模还要重要。好在我们在教育领域上有好未来这样的有这么多高质量的数据。但这对这些数据的这些管理，你如何在训模型上去做数据的分布？为什么有的模型上训出来的可能语文会更好，有的会数学会更好？其实就是无非你用的这样的这种数据集在这个模型里面，当时训练时候的你所用的多少分布。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:52",
      "text": "这些都是有关系的。我稍微补充一下，其实站在客户视角来看，其实百度智能云是整体是一个基础设施。文心是它在公司内部的一个最大的客户，我们是他在外部的一个大客户，对吧？然后他毕竟百度云和百度文心它是一个公司里头，所以他很多比如说一些技术标准、技术站或者一些通用的组件都是一致的。但对我们来说可能还是会有一个需要磨合的地方。所以说很多还是要做一些适配的，或者根据我们的实际的需求做一些更多的一些一些个性化的一些调整。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:21",
      "text": "身上其实就是提效。刚才除了说是在集群稳定性上，在我们在做通信加速上，其实刚才一直我们提到的更多是稳定性。其实我们还有一个AI加速包加速工具集，专门去在这个里面去做一些专门针对它的模一些模型模型一些算子的这些优化或者是加速以及包括我们的叫beco的这样的结合通讯库去做模型训练时的这种高速的这种通讯。这些都是在我们做大规模的任务上的训练上所必不可少的。其实我们不只跟好未来，我们在我们帮助一些其他的领域上的，比如说在我们汽车领域上的一些客户，我们去帮他去调什么。当你用了像刚才说白歌这样的平台，你天然就会具备这样的能力。但是上面的这些训练的任务，那都是客户自己的，我们也帮助客户去做了任务的编排和调度，这样的话在我们有一个汽车的一个客户上，我们帮着他们去如何去优化你整个的这些任务的这些部署。就又帮助在这个基础之上，让我们的整个的利用率又提升了50%。这又或者说是你让你的钱又节省了百分之。五十这都是一个非常大的一个消耗。",
      "speaker": "发言人3"
    },
    {
      "time": "00:29:30",
      "text": "所以从去年8月度，咱们这个是发布了九张到现在最明显的迭代是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:37",
      "text": "其实每天都有不断优化，然后基本上每周或者每个月都有大的很多版本的发布。对对对，对你说特别大的，我觉得可能从最开始只是数学到或者知识全科，然后后来包括后来我们就是能把强化学习用的比较多，这都算个大的版本。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:53",
      "text": "因为我跟那个做视频的朋友在硅谷聊，他们就觉得其实这个夏天大家感觉是翻桌子型的这种在进步。对，可能我们看到去年年底的sora，还有collusions就不consistent的东西，到现在可能这个夏天就已经说是很多都已经进化了很快了。对，我不知道咱们是就是从用户那边的数据，然后我们再feedback再重新再再优化咱们的这个模型是不是也是一样的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:17",
      "text": "对，其实我觉得这点我想可能说点题外话，其实就大家看都是美国的一个模型发展很快，但其实中国更新也是很很迅速的。比如骚扰发布之后，其实坦诚到今天我们还用不了索软对吧？但是国内的其实无论是快手的可林。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:32",
      "text": "对，还有梦。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:34",
      "text": "其实国内这种跟进是非常快的。因为我觉得国内优势在于可能在数据上确实是有很多积累，包括可能在一些用场景上也有很多自己独特的一面。但是国外的美国的他们贡献在于说他们确实验证了这个路是可行的。验证可行的话是需要投入大量试错成本。这点的话，确实我觉得美国公司比中国会更加的愿意投入的去试错成本。然后如果这个路验证可行，中国跟进也是非常快的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:58",
      "text": "对我补一下，说到我刚才就是像首尔这样的多模态，除了大语言模型以外，就是多模态本身现在也变成了是一个特别大的一个热点和一个趋势。国内的一个初创企业叫牲畜科技，它的就是做一个，应该算是现在聚焦在多模态非常有名的一家创企。它的基础设施也都是在我们的这个白鸽上面。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:19",
      "text": "OK那何老师你刚才讲其实很多行业的应用，其实都在用百度在训练自己的大模型。是所有的行业它在如果想要AI化自己都需要训练一个自己的大模型吗？还是有一些公司他其实就不太需要。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:34",
      "text": "我觉得这个要看具体公司他自己的实力，还是钱多少的问题，有钱多少的问题，有很多的东西还是就是一个效率问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:45",
      "text": "是不是？",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:45",
      "text": "我觉得有很多东西其实是钱也买不到的，比如说像好利来这边的这些高质量的这些教育的这些的数据，你花钱你也是买不到的。还有一些其实特别是在中国，更多的其实是在做应用。如果你的核将来就是想做一款应用，做一款被AI所赋能和驱动的应用。但事实上你不需要真的自己去一个AW模型，现在去调这些通用的，比如像我们的文心大模型，我觉得其实就已经有非常好的这样的效果。特别是几家大模型厂商现在都在价格战，现在基本上是一个非常便宜的一个价格。如果你只用一些比较通用的能力，那我觉得现在直接调用应该是足够的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:32:28",
      "text": "另外的话，如果你不只做应用，那你也可以在一些现在的，比如说像我们的文心大模型上，在百度的千帆平台上去对，他用你自己的一些数据去对他做一定的再加工。比如说微调，或者说你也可以基于一些开模型，也可以去做一些微调或后训练等等的这些。当然如果确实我们是一个像比如说像我们好未来这样的客户，大量的自己所积累的这样的数据，同时又有自己的这样的非常强的这种算法团队。那OK你是完全可以去做一个属于你自己行业里的这样的一个更好这样的大模型。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:01",
      "text": "就一般这个小公司，他如果也有这样子做自己AI模型的，就可以使用掀翻。对，或者是还有很多开源的加。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:09",
      "text": "个对reg现在算是一种解决方案。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:13",
      "text": "对我觉得刚才回到你刚才问题，其实我觉得是不是所有的公司都需要训练自己的大模型，这是我觉得是确实depend他的这个经济实力和他想做的事情。对，因为就是我觉得像一些大厂，比如说大厂只有上万米上的研发的这样大厂就是像BBT这种，确实是需要自己从零开始训练基础模型。对，因为这样的话才能把自己的这个竞争力拉到最强。但是像这种小厂的话，可能就自己一共就几十个研发，或者上面研发的话，他确实也没有这样的实力。他自己去做一个做基于开源作战一些简单微调的话，他还不如直接调文心那种API来的更快。而且其实文心也那个千帆也支持你自己数据传出来，他帮你做微调。就是他百度做的肯定比你自己做的会更好。所以这种情况下你用它掀翻是更经济和效果，更判断出效果的一个选择。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:57",
      "text": "对，但确实像跑过来这种我们叫中产，就是几千个研发这样的公司，或者在某一个垂直领域是一个比较龙头的企业的。我也必须在这个领域下构建自己行业大模型的壁垒和实力。这种情况下，我觉得我们可能就依赖于百度云那种info在做事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:13",
      "text": "其实百度智能云我们更主要的是提供基础设施，提供平台。真正的企业的核心竞争力，企业带来的自己模型的这样的效果，还是要靠企业自己来来去做。我们来提供工具，我们来提用一个可能一个起点更高一点的，比如说文心大模型，你可以在这个基础之上去做。所以千帆其实就是这么一个平台。他对于一些小一点的企业，你就直接调用内置的我们的文心大模型就可以了。文心大模型其实有好也有几个版本，有效果更好的，也有推理上性能更好但也更便宜的，这其实都有。另外来说的话，基于千问大模型，你可以基于百度的文心，也可以基于一些开源大模型，也可以基于你自己的。因为它本身是一个工具平台，训练出来属于你自己的，你自己领一张自己的这个模型。",
      "speaker": "发言人3"
    },
    {
      "time": "00:35:00",
      "text": "同时千帆上会千帆我们有一个在千帆平台上有个产品叫做model builder。其实就是帮助我们的客户去训练出来属于自己的模型的，帮助他去建设属于他自己的数据飞轮。其实您刚才其实也问到田老师，就是我们的九张大模型有没有一直在迭代？事实上但凡是做AI模型的都是会一直在迭代。需要有更多新的一些数据作为数据飞轮，来让我们整个的这个模型变得更加的强大。我们坚定的认为数据飞轮百度会帮助我们的客户去做。而数据飞轮及对应的所做出来的这个模型是属于我们客户的，它不是属于百度的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:35:35",
      "text": "我们会帮助客户去打造出来在他自己领域里面的这些非常强大的这样的模型，这是我们千帆平台上能够提供的model builder的这个能力。当然了就说是通过bounder builder把这model做出来，你是要干嘛呢？更多还是要应用。所以我们现在也知道，特别是在中国，应用其实是非常繁荣的。我们有一个叫agent builder和一个a builder这样这么两个工具。我们可以帮助客户在自己的这个model的基础之上，你可以做出来自己的这个模型所加持的这种新的APP新的这种agent，能够更方便的发布出来你自己的这个应用。当然如果是更加需要更加底层的纯粹的infrastructure，那就是到我们白鸽的这个层面上了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:36:17",
      "text": "其实我们刚刚在最开始的时候，我们聊到整个有了AI之后，我们整个人类的学习的范式肯会完全的不一样。包括可能未来的大家又需要什么样的人才。我们将来人在满足了，比如说是所有的食物都是非常的丰盛，然后其实稀缺性已经不存在了之后我们的学习是什么样子的？我不知道这个好未来或者作为您来说的话，会有一个这样子的对未来一个畅想，或者是这样子的一个预期吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:45",
      "text": "对，这是个很好的话题，但是我也没有标准答案。坦率的说，因为这个问题有无数的朋友问我说，包括自己问自己说我们我们的孩子到底还要学哪些，不学哪些。但是我个人的观点，我现在我就说我希望他学好数学，英语和编程。需要数学的原因是因为数学是一切这种理科的基础，包括它逻辑思维，我觉得这是很重要的一个。学英语的话当然是要跟整个世界沟通，这是他要走向世界一个必备的技能。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:11",
      "text": "然后学好编程的话，因为其实很多人有争议的说为什么还要学编程？将来计算机都AI都会编程了。但我跟他说，你学编程的目标不是要成为跟爸爸一样成为一个程序员，而说你要是有编程的基本技能，你这样可能更好的对话。比如说我觉得你要懂一些编程原理的话，你写prom都也也会写得更好一些，对吧？而确实编程也会让默认的一些思维，所以我给孩子报了很多的这种班儿。最核心的说你要把数学、英语和编程学好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:39",
      "text": "比如说是现在十年二十年的这样子的一个未来的预期。就比如像纲田老师讲的英语还要不要学。因为我今年CES上我看了好多AI同声传译耳机，你带一个我带一个，这还学不学？然后比如说是可能编程curse对吧？大家都看到那视频了，那个八岁小女孩自然预言，然后直接就编出来了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:59",
      "text": "单的可能性。是比较简单的东西。未来学习的目的这到底是什么？我们不是为了吃饭了，我们也不是为了这个考学了，可能未来这个学校还存不存在我们都不知道了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:09",
      "text": "以前好未来的一个我不知道叫slog还是叫企业的一个价值观。他是怎么说？他原来是叫学习改变命运。因为这也是由我们创始人，他是80年的，包括我们都是80后。其实我们这一代确实是去改变命运。我们从一些三四线的城市，考大学考到北京来，然后在北京的这家公司里去去工作？更好的一个生活。其实现在我们的slog已经改成了叫助力终身成长，终身学习，终身成长。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:33",
      "text": "孩子要掌握能力，他是学习的能力，而不是学习的知识本身。因为知识是学不完的，或者也是不用学了，因为大模型记住所有的知识点，人类所有的知识已经被他学完了，现在已经没有知识可学了。但是人类还是要掌握学习知识的能力，因为将来不断新的事可以学。这对我来说，数学是种语言，编程是一种语言，然后运用是一种语言。它其实都是你和这个世界交互或者去沟通一种技能。这东西其实它你学编程并不是一条程序员你学你并没有成为翻译对吧？一些数学更不肯成为数学家。对他这个东西其实学习是让让你这个人更好的成长，然后掌握更多的一些必备的一些技能。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:09",
      "text": "然后再说一下，现在中国也在做那个新课标改革，他其实也是强调要跨学科的能力，和解决实际问题的能力。比如说你看现在新课标的数学题，首先是一个语文题，你要读懂它的含义，你的语文就不能太差，不然你的题都读不懂，就比如说做后面的题了。然后现在的数学题，也不是一个简单的把题目直接上来就做题，而是说它是把一个实际上生活中的一些例子给你，你要先把这个例子的原因理解之后，才用数学原理去解决它。我觉得这个新科改革也是说鼓励孩子更多是这种素养的教育，这种跨学科的能力，科学的sink能力，写问题的能力，我觉得这是一个教育的真实目的，是说将来这个学校包括了大学，这个是不是存在，这个确实是一个更长远的问题了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:52",
      "text": "是的，因为我自己在海外其实看到一些大家学校它主要的教学的材料，其实就不用实际的老师去讲了。他其实就是用一些这种开源的或者一些在线的这样的一种AI的老师在教。但是可能自己说AI老师欠，不知道是不是完全是AI，反正是在线的教育的材料。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:09",
      "text": "所以可能未来的学校的组织的这种范式，我也看到是在在变化的。你可能线下他就是大家组织到一块儿，有点像大学的。你比如说是可能NBA学校大家搞几个大家围在一块儿，然后大家一起在一个pad上面我们就开始学了。可能未来的这种组织形式也会发生这个改变。可能到时候我们其实一个是self driven，就是就自己的自驱力审美。就怎么样能够在未来的非常有富足的，然后你可能吃穿不愁，我们到底的人生意义在哪里？",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:38",
      "text": "田老师刚才说了一个终身成长，我觉得这是一个是特别好的一个观点。某种层面上我们可以看啊，就是我们现代社会每一个人都接受了一定层面的或一定程度的教育。至少国家现在有九年义务教育。我们现在的这种知识水平生活水平相比100年前、200年前都是属于大幅多的提高了。我们现在觉得好像目不识丁的一些人，觉得他没有什么知识，说不定到200年前都变成了一个特别博学的一个人，特别是说了解各种各样的自然知识。但是我们现在的这些人也仍然要学习，也仍然要去终身成长的去追求这个进步。你才能够去维持或者说我们整个这个社会现在的这样的一个平衡，和你在这个社会里所带有一个这么样的一个位置。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:25",
      "text": "也许学习的内容跟以前不太一样，学习的方法跟以前也不太一样。我们今天在这聊了很多的内容，其实聊的所谓的这个教育，更多是说是对于学生的教育，学生的学习。比如说到大学，事实上像我们像我跟田老师这样，比如说最近这几年AI发展的如此之快，那我们这早就不是我们当年上学时候讲的这些知识了。是的，那我们如果不学习。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:48",
      "text": "我们对还得看paper是吧？老马出来paper还得看你多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:51",
      "text": "我我我觉得我最近这一年多看的片比我上学时看的都多，而且根本看不完。是的，但你可能可以去用到一些工具来去帮你去辅助阅读。但是一些真正的经典，你还是要一个字一个字一段一段的自己要把它这东西要看透的。也有大量的网上的这样的视频，你要自己要需要去学习。我是觉得这个学习是一终身学习，终身成长的过程。教育其实也不只是在校园内的教育，也包含我们在当学生阶段的这种学校外的这种辅导，也包括你在工作以后，在职场上进一步的学习。我觉得这些管有没有AI有了AI会让大家学习的更快更容易，但maybe会让你学的东西会变得越来越多。",
      "speaker": "发言人3"
    },
    {
      "time": "00:42:35",
      "text": "今天无论从K12还是到大学，就他们这些学校存在例子。还是因为说现在企业在招聘员工的时候，还是要看你的学历。就是什么时候当企业不再看招聘员工的学历了，甚至可能将来公司这种形态就不存在了。大家都是在家里工作就好了，不用或者每个人都是一个小公司，不需要公司中大家的这种组织形态的时候，那时候可能就真的不需要把孩送到学校去上学了。在家里学或者你有任何想学的东西都可以直接AI学。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:59",
      "text": "对，而且我觉得未来可能确实也会说更多的。打个比方，比如说今天以前，比如说人的出行时刻要骑马，对吧？现在出去你说大家都是开车，你现在想骑马，对不起，你要去专门的马场去花很贵的价格去骑马。也许过了，比如说也许20年之后哈那时候你想开车，对不起，不能开。你所有五环内都是必须有自动驾驶的车才能上路，因为这人是一个不安全的因素。你想开车可以去赛车场，花很高的价格去体验一下手动开车的乐趣。将来也许教育也一样，就将来可能绝大数的教育都变成是你就是AI的这种更加的教学习。可能只有少量的人，有钱人才能去afford起这种真老师的一对一。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:38",
      "text": "的这种苏格拉底。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:40",
      "text": "对对对，但是其实可能那时候大部分AI教学也就够了。所以这种其实变成说将来教育可能就不再是说一个谋生的技能，或者是让大家去找工作的必备的一个条件。而更多是说你自己想学什么东西，你想成为上面的人。因为那时候整个社会足够富足，不需要去让你去根据自己兴趣而活。这个事情我觉得还是有点遥远的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:00",
      "text": "我觉得您觉得是多少年？我觉得50年、100年.",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:04",
      "text": "我觉得我们家娃能看到这一天就挺好的。对，我们估计是难了，看不见了。对，而且那个时候可能那个时候不光是叫整个社会形态，包括人类的形态可能都有。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:14",
      "text": "很大的一个变化。但我觉得现在特别好的是，我们好像又重新再思考这些问题了。有了AI出现之后。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:20",
      "text": "对，因为确实你会发现，如果你把AI看成一个人类的孩子的话，他学习知识的速度或者他能记住的知识确实已经远超人类了。所以人类好像说我们还是在创造力审美上是比他要强。但是也许将来这点也有可能。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:33",
      "text": "对我我今天早上跟我老公打电话，他还在硅谷，然后他就跟我讲，昨天他还挺不好意思跟我说，我挺不好意思，昨天晚上我跟这个AI聊了半天，因为他看了一个60年代的一个电影，就跟I就开始聊起来这个观影后感。然后他觉得好久没有聊得这么淋漓畅快了，AI对60年代这个电影非常的有丰富的认知，然后跟他聊的深度非常高。然后他就觉得好开心，跟人可能就没有这么强的一个沟通这种感觉他会觉得有开心，他觉得不好意思。但是我觉得未来可能不会是这样子的一个感觉了。你可能很很随随便便的很自然的就会说AI是我的老师，AI或者我的同伴，我们就聊起来了。所以刚您讲到其实有一个AI公平性的这一块，所以可能我们不谈到50年、100年，我们可能先谈到比如说是在近每笔十年、20年，他其实是对AI的这个AI对这个教育的公平性上面肯定会起到非常大的作用。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:29",
      "text": "的这是一定的。就是你会发现从原来传统的线下小班到线上大班以后，就会有很大的一个改变了。就是原来因为中国的师资力量还是很不均衡的，对吧？其实现在有了这种在线大班网课这种存在，使得一个可能五六线小城市的孩子也能享受到这种类似于清北这样高度的这种一些老师的优质资源。再进一步的话，如果AI能让这样的高质量和大规模再加上个性化，那就真正的变成教育公平。我觉得这也是AI对人类最大的意义。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:56",
      "text": "下一个问题问问侯老师，因为我们聊了很多。和教育方面的未来AGI您觉得是什么时候能够到来，或者是咱们能看到的可能一个飞跃式的一个AI对人类的影响会是什么样的一个途径？",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:10",
      "text": "首先AI不是最近的这一两年的概念。最近这一两年因为生成式的这个AI这个大模型，会让大家觉得通用的人工智能变得成为一种可能了。但真正的AI其实研究了很好几十年，所以现在我们可以看到就是几个趋势，确实发展的非常的快，就像科幻小说一样的。这样的AGI到底需要多少年，就现在还不好估计。",
      "speaker": "发言人3"
    },
    {
      "time": "00:46:35",
      "text": "但是现在我们可以看到在当下的一些技术的趋势上，确实整个AI的能力还会在大幅度的提高，有几个热点，现在比较热的，我们刚才其实也聊到，就是从语言模型到多模态，这其实是一个非常大的能够看得到的一个趋势。因为毕竟更多的这种内容，更好的一种的更丰富的这些信息，其实不只是语。而对于transformer来处理的整个这种信息流或token来说的话，它也不是只能处理语言。所有的这种序列性的这种信息，它其实都是可以处理的。所以就是多模态现在是一个比较大的一个趋势。",
      "speaker": "发言人3"
    },
    {
      "time": "00:47:13",
      "text": "第二点就是MO异化，就是多专家的这个模型现在也成为了一个趋势。因为真正你要训练一个非常稠密的这样的模型，其实是一个非常昂贵的一件事儿，不止训练要贵，然后推理力起来也比较贵。然后我们希望大模型能够更好的去将来能够得到第一更好的效果，也就更好的能到能够更好的应用，也就是更廉价，更可以支付得起的这样的成本去应用这些像MOE也算是一个当下比较大的一个趋势。",
      "speaker": "发言人3"
    },
    {
      "time": "00:47:42",
      "text": "当然还有一点就是最近OpenAI推出来的这个草莓，其实就是在后训练上面，其实我们可以看到就是整个你训一个模型去分几段来后训练，用强化学习这样的方式，现在也是一个非常大的一个热点。其实尽管我们之前大家都在等GPT5，但其实我们其实也很早就知道，他们其实在利用就是利用强化学习在训现在的这个草莓的这个项目。这其实都是现在一个比较大的一个趋势。某种层面我们还需要再再看一下，就是目前的这些生成式的这些AI基本上是基于transformer的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:15",
      "text": "Transformer是一个非常好的一个架构，但是它确实不算是一个特别高效。尽管它已经相对以前的RNN等等是一个非常高效的一个模型。所以现在你要想追求更好的效果，具有一个特别让人又爱又恨的的这么一个词儿叫scaling law。对，scaling law就是我对于我们这种做工程的来说，我们就喜欢当一个问题能够用一个scale up也好，scale out也好的这样的一个去大规模就能够去把这个问题解决的，我们会觉得很兴奋。但是现在现在的这个CK in law实在是太费钱了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:49",
      "text": "在transformer现在的这个sk in law的支持下，我们还是可以看到模型的效果还是会在持续的提升。而且因为模型效果还在持续的提升，所以不管对应的数据量大家还要准备更多。对应的去年的这万卡，今年要奔着10万卡的这样的集群，也会可能接下来会成为一个常态。",
      "speaker": "发言人3"
    },
    {
      "time": "00:49:09",
      "text": "所以就是skinning law还会再再继续相应的对于数据的准备，对于训练方法的准备，对于基础设施，我们前面其实聊到了很多。包括美国的一些都开始要建核电站去支持做训练的这个能源。所以这都是一系列的。但是是不是能够突破transformer，目前也有很多人在做这个研究。但目前来说的话，还没有一个可见的一个非常好的能够取代transformer这个网络架构的这样的一个方法。如果能有，那可能又维持一番新的一番天地。",
      "speaker": "发言人3"
    },
    {
      "time": "00:49:39",
      "text": "所以总体上来说的话，我觉得就是整个大模型在朝着通向AGI的这条路在走了。但是我们现在其实在相应的会带来了非常多问题，包括数据层面上的问题，包括储备能源的这样的问题，包括系统要去解决的这样的问题。然后另外一点，就是整个AI的可解释性的问题。现在的这个深度学习也好，其实通常为止都还算是在深度学习的这个框架下。其实都说他是在炼丹。",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:05",
      "text": "到底练成什么样东西出来？",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:08",
      "text": "你为什么是用这样的形式去炼丹？其实都是很多的经验主义。就是我们调你的数据结构，数据分布在这里面。但是它是不是一个真正可解释的，你只要它是一个可数学上可解释的，我们其实可以知道它将来一定能产生什么样的结果，或一定不产生出什么样的结果。但现在其实都需要一些更多经验去调。",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:29",
      "text": "但是另外说的更大一点的就是，我们可能需要去和人类的一些东西，思想学习能力去对齐，然后让他可以更好的自我去发展。我觉得这是一个更长远的后患。但是不管怎么样，我觉得现在都是在朝着去通向AGI的路了。但是通向AGI的这条路注定异常艰难。",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:48",
      "text": "因为其实我觉得现在好像大家很大的一个疑惑是scaling law是不是我们已经逐渐见顶了。对，因为现在投入像您刚刚讲就是又爱又恨。对大家其实是我们还是知道往AGI通向了这个路，我们还是得不断的去加大这个集群，然后去训练。然后其实还是你刚刚讲的，是看到了很大的效果的提升，但是这个路到底尽头在哪里？看不到。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:11",
      "text": "对，大家都觉得skin law是不是到顶？比如说第一个数据，所以现在有更多的这种机器生成数据的这种的这样的方法。当然说你机器人数据可能会闭环在这里面，所以有不同的模型去做交叉验证对吧？现在还要强化学习等等这样的这些方法。",
      "speaker": "发言人3"
    },
    {
      "time": "00:51:25",
      "text": "数据是一方面，还有一方面就是你训练出来的这个模型的参数规模越来越大之后，会不会带来应用成本越来越高。所以某种层面上MOE也是在解决类似这样的的这些问题。另外我刚才就说了，你真的堆到10万卡，你需要有这么大的这些能永远的去支持很多的一些小的国家，甚至都很难去挤出来这么多的电量，所以这些都是我们可能要去解决的这个问题。所以scaling一直在增长。但是我们看能不能用一个相对一些新的一些技术，能够让这个增长能够变得更加的平滑。",
      "speaker": "发言人3"
    },
    {
      "time": "00:52:00",
      "text": "其实你觉得现在很有意思，在说人工智能可能发展，它其实还是在模拟人类。就是人类觉得什么样的智能足够称之为通用人工智能。包括现在这个神经网络，它其实也是某种程度也是参考人类大脑来去仿制的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:13",
      "text": "知道现在最大的dance的这种模型，大约可能就是万亿参数，相当于1万亿个连接。然后现在人类大脑大概一般是说是几百个亿个神经元，但是他们只要连接大约可能就是据说是有大约是百万亿级别。就是现在人类大脑的里头那个连接数参数，可能比现在最大的模型还有大约是两个数量级的差异。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:32",
      "text": "但是你发现人类学习的话，你会人的大脑才耗电量才多少毫瓦多少。但是一个大模型训练可能是兆瓦或者是或者更高的瓦数。所以说人类学习还是更高效的。而且人类学习你看它只要很少的输入就能学到一些知识。而不要大模型也需要那么大的一个数据量去去学。所以我觉得在正常看，其实人类大脑比大模型还是有一些领先的一些地方的。但是这地方怎么能让大模型更低的功耗，更少的数据量学习，然后能达到人大脑这种地方还是需要研究的地方。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:01",
      "text": "然后另外就是这种所谓的通用人工智能，到底定义还是差别很大的对吧？其实大家知道像那个当然open ID是一个L一到L5的1个划分。说L一大约就是一个chatbot，l二大约是一个推理者。据说他觉得这个四边或者O一可以达到了这个L2的级别，但是真正到L5叫组织者。那时候是不是人工智能能组织所有的人类去做这个事情？我觉得这个事可能是一个伦理的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:25",
      "text": "所以我认为这种AGI的到来或者A加实现，首先取决于定什么叫AGI。如果是定义内容真的是就是到R5的HI，我自己觉得还有很长的路要走。没有我到我这个相对比较谨慎乐观，我觉得可能也许还得几十年或者更长的时间。就现在现在的这些方式，可能确实数据算力上可能都已经有些见顶的地方，或者人要绕开一些别的方式，去绕开现在的一些限制去做下路探索。所以这里头我觉得我们还是很幸运的见到一些时代的高速发展。但是AGI的到来，我们还是我个人还是坚持乐观的一个态度。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:56",
      "text": "其实过去几年，大家对AGI是不是需要他到来，或者是对他其实还是持保留很多保留态度的。像是马斯克就经常会批这个批判。对，但他自己开始在做XAI，然后做了很多机器人，买了很多卡。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:09",
      "text": "但是马斯克我觉得马克我觉得他是个很伟大的人我觉得他做的所有事情，无论是说去大模型机器人，这个电动汽车，包括他那个那个space x，最终他是他的梦想是要葬在火星上。我觉得其实我个人认我觉得人类下一步应是要变成一个冲突的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:25",
      "text": "multiplying多宇宙多星的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:28",
      "text": "是的，因为如果如果AGI所谓的AGI能帮助人类达成这个目标，我觉得它是好的。AGI的出现不是要会给人类去抢工作，或者是让人类每天就吃喝玩乐，就什么不用管了。他是让人能够。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:40",
      "text": "去更不能完成更伟大的任务。对，不要变成这个skyline，或者是这个天网，或者是那个soul的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:47",
      "text": "没错，是这样的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:49",
      "text": "我们不希望我们的AGI最后变成这个样子。好的，我觉得今天好像跟两位也聊的蛮多了。我们从这个好未来的产品，又聊到了这个百舸千帆平台，然后我们又畅想了一下未来大家对AGI和未来的教育。非常感谢两位今天的参加我们的今天节目。好，谢谢田老师，谢谢侯老师好，谢谢。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:13",
      "text": "这就是我们今天的whats next科技早知道。欢迎大家在评论区和我们留言互动，加入到科技和创新的下一步讨论中来。另外如果你想支持我们在播客内容上的探索和创新，欢迎大家加入我们的生动胡同会员计划。详细的加入方式和信息请查看本期节目的so no.",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:32",
      "text": "我们下期再见。",
      "speaker": "发言人3"
    }
  ],
  "lab_info": {
    "summary": "本次对话深入探讨了人工智能（AI）在教育领域的应用及其未来发展，特别关注了新模型“草莓”在数学解题上的突破，展示了AI如何通过个性化学习体验促进教育公平。讨论还涉及了教育大模型，如百度与好未来合作的九章模型，以及强化学习在提升模型性能中的作用。对话强调了在线教育和AI辅助教学在缩小教育资源差距方面的重要性，同时展望了AI教育的未来，包括通用人工智能（AGI）的可能性及其在支持创造性工作方面的作用。此外，讨论还触及了教育创新，如学习机、APP以及API SDK的定制化应用，以及AI在教育伦理方面的考量，如其对教师角色的影响和促进学生批判性思维与创新能力的潜力。整体而言，对话凸显了AI在教育个性化、公平性和创新方面的发展与潜力。",
    "qa_pairs": [
      {
        "question": "OpenAI最近发布的新产品是什么？今天我们邀请了哪两位嘉宾来讨论AI在教育领域的应用？",
        "answer": "OpenAI最近发布了一个名为“草莓”的新模型，以及基于该模型的两个新产品——o one preview和o one mini。其中，o one系列在推理能力上有了显著提升，尤其在处理多步骤复杂问题方面表现出色，并且通过了美国数学邀请赛，准确率达到了83%。我们邀请了好未来的CTO田蜜田老师和百度集团副总裁侯震宇老师。",
        "time": "00:00:20"
      },
      {
        "question": "百度和好未来在教育AI领域的合作起源是什么？",
        "answer": "合作起源于2022年10月底，当时GDP模型的出现引发行业焦虑，好未来决定自建教育大模型。在寻找技术与算力支持时，双方发现百度在大模型训练和推理优化方面有丰富的经验，因此主动寻求与百度云的合作，逐渐加深了双方的合作程度。",
        "time": "00:02:14"
      },
      {
        "question": "百度和好未来在教育领域的天然联系体现在哪里？",
        "answer": "百度与好未来在教育领域的天然联系在于，好未来在教育行业积累了大量专业知识，而百度在AI技术研发和应用上有着深厚积累，尤其是在基础算力层面能为好未来提供更多帮助。",
        "time": "00:03:12"
      },
      {
        "question": "AI大模型在教育产品中的具体应用和用户状况如何？",
        "answer": "目前AI大模型在教育行业的落地应用仍面临全球性难题，但好未来已将大模型成功应用于五个主要方面：解题、讲题、批改、英语口语对话练习及个性化推荐。其中，学习机产品深受市场欢迎，搭载了众多AI工具；独立APP虽然用户增长不错，但让用户为应用本身付费还需时日；同时，还将API SDK输出给其他厂商，如手机厂商、PC厂商和pad厂商等，以提供更多增值服务。",
        "time": "00:10:30"
      },
      {
        "question": "在教育领域，好未来作为一家拥有多年经验的公司，我们的护城河是什么？",
        "answer": "我们的护城河主要体现在三个方面。首先，我们在教育领域积累了21年的数据，拥有庞大的题库资源，包括几千万的教辅讲义、试卷，以及几百万的视频和学生反馈数据，这些构成了我们对大模型的核心优势。其次，我们在算力方面与百度云合作，借助其提供的异构算力来支持我们的业务需求。最后，我们在算法上利用开源模型并进行改进。",
        "time": "00:11:33"
      },
      {
        "question": "AI大模型在教育领域的应用存在争议，能否分享一下关于GPT相关研究论文的看法？",
        "answer": "该论文提到使用ChatGPT训练的学生在考试成绩上可能不如未使用的学生。但实际上，该研究基于去年秋天版本的ChatGPT，其准确率较低，存在较多错误。此外，实验过程和样本量也有限，因此不能据此断定AI无用武之地。AI工具本质上是一种提升学习效率的工具，不应完全禁止其在教育中的使用。",
        "time": "00:12:30"
      },
      {
        "question": "对于AI在教育中的应用，如何看待其作为工具的角色以及对未来人机互动范式的影响？",
        "answer": "AI首先是一个能大幅度提升人们能力的工具，尽管在某些情况下被教育界担忧会取代人类学习能力。但事实上，AI可以帮助教师和学生更高效地获取知识，不应该被视为完全禁止使用的工具。未来教育可能会基于资源丰富性和个性化需求，而不再是为考试层层选拔。",
        "time": "00:14:00"
      },
      {
        "question": "AI教育工具在批改作文和阅读理解方面有何优势？",
        "answer": "我们的AI作文批改和阅读理解工具能够从字词分析到全文结构立意，甚至进行润色优化，对语言的理解和情感识别表现出色。AI能够根据不同的作文风格进行多样化批改，并且每次输出都有所不同，不会千篇一律，还能根据用户交互中的反馈进行调整，激发学生的创新思维。",
        "time": "00:19:26"
      },
      {
        "question": "如何设计AI辅助学习流程，实现个性化教学？",
        "answer": "通过积累大量数据，我们可以分析如何更好地讲解题目，并根据不同老师和学生对同一题目的不同解法，形成针对性的教学方案。AI能根据学生当前的知识掌握情况，精准地补充薄弱环节，进行多轮对话交互式的教学，最终目的是让学生真正理解并掌握知识点，而非直接给出答案。",
        "time": "00:16:47"
      },
      {
        "question": "为什么选择与百度合作，特别是使用百度云的异构计算平台？",
        "answer": "选择百度是因为在当时，百度是唯一一家证明自己可以迅速构建优质大模型的公司，而百度云则为百度文心大模型提供了基础算力和训练平台。因此，我们选择了百度作为合作伙伴，以确保能够利用先进的技术支撑我们的业务发展。",
        "time": "00:21:25"
      },
      {
        "question": "金融圈里对金银和货币的关系是怎么说的？GPU最初的设计用途是什么？",
        "answer": "金融圈里常说金银天然不是货币，但货币天然是金银，意味着贵金属如金银由于其特性，天然适合用作货币。GPU最初是用来做图形加速的，其内部包含大量专门进行并行计算的小核心，尤其擅长浮点运算和矩阵运算，因此非常适合现在的AI和数学运算需求。",
        "time": "00:21:41"
      },
      {
        "question": "百度从何时开始使用GPU进行加速计算？当时GPU集群主要用来做什么？",
        "answer": "百度自2009年开始就利用GPU进行加速计算，并在AI基础设施上积累了丰富的经验，尤其是在大模型领域。当时这些算力主要用来训练文心大模型。",
        "time": "00:22:34"
      },
      {
        "question": "GPU集群与CPU集群相比，在故障率上有何不同？",
        "answer": "GPU集群的故障率相比CPU集群要高很多，尤其是大规模单一任务集群中，故障的发现、修复对集群有效计算时间至关重要。",
        "time": "00:23:43"
      },
      {
        "question": "百度如何解决大规模GPU集群的稳定性问题以及提升利用率？",
        "answer": "百度通过构建大规模、高稳定的GPU集群，并优化GPU利用率（如提高MFU值），有效解决了这些问题，同时通过内部测试和验证，提升了整个训练集群的效率。",
        "time": "00:24:06"
      },
      {
        "question": "百度智能云与好未来在合作过程中遇到了哪些挑战和磨合点？",
        "answer": "百度智能云作为基础设施服务提供商，会提供同样的服务给所有客户，但不同客户如何更好地利用这个平台则取决于双方更好的磨合。例如，在数据准备、模型训练方法、数据分布等方面，百度内部已经解决的问题，在与客户的合作中可能需要根据客户需求进行适配和个性化调整。",
        "time": "00:26:18"
      },
      {
        "question": "对于想要AI化自己的公司，是否都需要训练自己的大模型？",
        "answer": "这取决于公司自身实力和经济预算。对于小公司或没有大量自有数据和强大算法团队的公司，可以直接调用通用大模型如文心API；而对于拥有大量数据和算法实力的公司，则可以选择基于开源模型进行微调或训练自己的行业特定大模型。",
        "time": "00:32:28"
      },
      {
        "question": "对于中产阶级企业和垂直领域的龙头企业的研发公司，他们在构建行业大模型壁垒和实力时，百度智能云能提供什么样的支持？",
        "answer": "百度智能云主要提供基础设施和平台，帮助企业基于更高级的文心大模型进行创新和开发。对于小型企业，可以直接调用内置的文心大模型；而对于大型企业，可以利用平台上的工具训练出属于自己的模型，并通过model builder产品帮助客户训练自有模型和建设数据飞轮。同时，千帆平台还提供agent builder和app builder等工具，帮助客户在其模型基础上开发新的APP或agent。",
        "time": "00:34:13"
      },
      {
        "question": "数据飞轮及其对应的模型的所有权属于百度还是客户？",
        "answer": "数据飞轮及基于此构建的模型所有权归客户所有，百度致力于帮助客户打造他们在各自领域的强大模型，但模型成果归客户所有。",
        "time": "00:35:00"
      },
      {
        "question": "在未来人工智能高度发展的背景下，人类的学习范式、所需人才类型等是否会改变？您对未来有怎样的预期或畅想？",
        "answer": "这是一个很好的话题，但没有标准答案。个人认为，在未来，人们依然需要数学、英语和编程的基础技能，因为它们是逻辑思维的基础、全球沟通的必备以及提升对话和创作能力的关键。至于未来学校的存在形式、学习目的等，则可能随着科技发展而发生变化，人类更应掌握学习知识的能力而非具体知识本身，以适应不断出现的新事物和持续成长的需求。",
        "time": "00:38:33"
      },
      {
        "question": "随着AI技术的发展，未来学校教育的组织形式会发生怎样的变化？",
        "answer": "未来的学校教育组织形式可能会发生显著变化，例如采用在线教学材料或AI辅助教学，线下教学也可能会转变为更自主、自驱力导向的学习方式。未来学校可能更注重个体的终身学习和成长，不再以获取传统知识为主要目的，而是培养跨学科能力、解决问题的能力以及终身学习的习惯。",
        "time": "00:40:09"
      },
      {
        "question": "AI对教育公平性会带来怎样的影响？",
        "answer": "AI将对教育公平性起到重大作用。随着在线大班网课的发展，优质教育资源得以覆盖到五六线城市的孩子，实现了教育资源的均衡化。未来，AI还能实现高质量、大规模和个性化教育，真正实现教育公平。",
        "time": "00:45:29"
      },
      {
        "question": "您认为什么时候能看到通用人工智能（AGI）的重大突破，或者什么样的AI对人类影响会比较显著？",
        "answer": "近期生成式的AI大模型让通用人工智能变得可能，但准确预测AGI到来的时间尚不明确。当下可以看到的是AI能力在大幅度提高，例如语言模型向多模态的发展，以及MOE模型等技术趋势。同时，后训练方法如利用强化学习进行分段训练也是当前的研究热点。",
        "time": "00:46:10"
      },
      {
        "question": "AI的发展是否遵循着某种“scaling law”（规模法则）？",
        "answer": "是的，AI发展确实遵循着一种类似“scaling law”的规律，即随着数据量、算力的增长，模型效果也在持续提升，但同时也面临成本增加、数据准备、基础设施等问题。尽管如此，目前并没有明确的方法可以取代现有的网络架构，如transformer。",
        "time": "00:49:09"
      },
      {
        "question": "对于通向AGI的道路，是否已经接近某种上限？",
        "answer": "目前看来，虽然投入不断增大，包括数据量、训练参数规模以及能源消耗等方面，但AI仍然在朝着通向AGI的方向发展。然而，“scaling law”的增长是否见顶仍是一个疑问，且在如何实现更高效、低成本、可解释的人工智能方面仍需更多研究。",
        "time": "00:51:25"
      },
      {
        "question": "通用人工智能的具体定义及其实现程度如何评价？",
        "answer": "AGI的定义差异很大，从聊天机器人到能够组织所有人类行动的高级阶段（L5）。对于L5级别的实现，可能还需几十年甚至更长时间的努力。尽管当前技术和算力面临瓶颈，但人类大脑与AI之间的对比提示我们还需探索如何让大模型在更低功耗、更少数据量的情况下达到类似人脑的智能水平。总体而言，尽管对AGI的到来持保留态度，但仍保持乐观，认为它最终会帮助人类完成更伟大的任务，而不是取代人类。",
        "time": "00:53:01"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "AI在教育领域的创新应用与突破",
        "summary": "在本期节目中，讨论聚焦于AI在教育领域的最新应用与突破。特别提到了一个代号为草莓的AI模型，该模型在推理能力和处理多步骤复杂问题上表现出色，尤其在数学问题的解决上取得了显著进展，准确率达到了83%。节目中还邀请了好未来的CTO田蜜和百度集团副总裁侯震宇，他们分享了双方在教育AI领域的合作成果，并深入探讨了AI如何改变和优化教育方式。"
      },
      {
        "time": "00:01:36",
        "title": "好未来与百度合作开发教育大模型",
        "summary": "对话主要围绕好未来与百度在教育大模型开发上的合作展开。好未来在目睹GDP大模型带来的影响后，决定自建教育大模型，并选择了百度作为合作伙伴，因其在算力、模型训练和推理优化方面积累了丰富经验。双方的合作从2023年初开始加深，百度在算力和模型优化方面给予了大力支持。此外，双方都认为transformer模型因其强大的泛化能力和性能提升潜力，已经成为当前大模型的主流架构，重构了多个行业的技术范式。"
      },
      {
        "time": "00:04:28",
        "title": "教育大模型与O一在K12数学教育中的对比",
        "summary": "对话围绕O一在教育领域的应用展开，特别是针对K12阶段的数学教育。讨论者提到了O一发布后在朋友圈和业内引发的广泛关注，以及O一在AI辅导和解题能力上的展示，引发了对教育工作者未来角色的担忧。通过测试，发现O一在全场景的泛化性上表现优秀，但在特定的教育场景，尤其是K12数学解题帧率上，现有教育大模型并不逊色。讨论还提到了强化学习在提升AI教育产品解题能力中的应用，以及如何通过自我学习和数据标注来优化算法。"
      },
      {
        "time": "00:06:17",
        "title": "大语言模型在数学推理中的挑战与改进",
        "summary": "对话围绕大语言模型在数学领域的应用展开，特别强调了随着问题复杂度增加，模型在长逻辑推理方面的挑战。小学、初中到高中的数学题目解题率递减，主要原因是高中题目需要多步推理，每步出错概率累积导致整体错误率升高。为解决这一问题，模型采用类似人类深思熟虑的策略，通过慢思考和遍历所有可能路径来寻找最佳解。此外，模型采用多专家架构，分为语文、英语和理综三个主要部分，其中理综包括数学。模型在语言类科目表现优异，但在需要推理能力的数学领域相对较弱，因此团队致力于提升模型在推理方面的性能。"
      },
      {
        "time": "00:07:49",
        "title": "大模型在教育行业的五大应用能力",
        "summary": "大模型在教育领域的应用正成为全球难题，但已展现了解题、讲题、批改、英语口语对话练习和个性化推荐五大成熟能力。这些能力大大降低了题目的生产成本，提高了批改效率，提升了个性化推荐的准确性，从而有效辅助教育行业，特别是在节省教师时间和提升学生学习效率方面表现出色。"
      },
      {
        "time": "00:09:31",
        "title": "5G赋能教育硬件：从学习机到车载AI教育应用",
        "summary": "讨论了5G技术在教育领域的三个应用场景。首先，通过搭载大量AI工具的学习机在中国高端学习市场占据了超过50%的份额，验证了用户愿意为结合AI的硬件付费。其次，尽管独立的教育APP用户增长良好，但在中国的免费模式下，付费意愿仍有待提升。最后，通过API和SDK对外输出能力，不仅服务于内部业务，也与手机、PC、pad厂商以及一家新能源车厂合作，将AI教育功能融入其产品，特别是在车载场景中，满足家长希望孩子利用乘车时间学习的需求。"
      },
      {
        "time": "00:11:17",
        "title": "好未来在AI教育领域的核心优势",
        "summary": "好未来在教育领域积累了21年的经验，其核心优势在于庞大的数据资源，包括数千万的题库、教辅讲义、试卷以及数百万的视频和学生反馈数据。这些数据是其大模型训练的核心优势。在算力方面，好未来与百度云合作，获得各种异构算力的支持。算法上，公司借助开源模型并进行改进，以提升教育AI的效果。"
      },
      {
        "time": "00:12:04",
        "title": "AI大模型在教育领域的争议与应用",
        "summary": "对话围绕AI大模型在教育领域的应用及其引发的争议展开。一方面，部分大学担忧学生使用AI工具可能构成作弊，另一方面，有研究表明，使用GPT训练的学生在考试成绩上并未表现出明显优势，但该研究的准确性和实验设计受到质疑。对话者认为，AI作为工具，能够提升学习效率和能力，其在教育中的应用是不可逆的趋势。同时，他们强调AI不会取代人类的能力，而是应被善用以增强个人和团队的效能。以企业为例，内部已有30%以上的代码由AI自动生成，展示了AI在提升工作效率方面的潜力。"
      },
      {
        "time": "00:15:29",
        "title": "利用AI引导学习而非直接给出答案",
        "summary": "对话聚焦于如何利用AI技术，特别是多轮对话交互的chatbot，来引导学习而非直接给出答案。讨论指出，AI可以通过设问和分步骤讲解，根据学习者不同的理解和需求进行针对性的解释和补充，从而实现更有效的学习过程。这种方式的目标是让学生真正理解问题，而非仅仅获取答案，体现了教育模式从资源稀缺性向个性化、互动性转变的可能性。"
      },
      {
        "time": "00:16:41",
        "title": "AI教育：个性化教学的未来",
        "summary": "对话围绕AI教育的实施流程和优势展开。讨论指出，通过AI老师，可以实现高质量、大规模的个性化教育，这在传统教育中是难以实现的。AI老师能根据学生的学习画像，精准定位知识掌握的薄弱环节，进行针对性教学。此外，AI老师具有永不遗忘、全知识掌握和随时调取学习记录的能力，从而提供更细致、高效的学习体验。与真人老师相比，AI老师能够消除学习的心理压力，促进学生的自信心和批判性思维的发展。"
      },
      {
        "time": "00:19:20",
        "title": "大模型在语文作文批改中的应用及技术合作探讨",
        "summary": "讨论了数学之外，作文助手和阅读助手在学习中的应用，特别是云技术在作文批改中的作用，从字词分析到全文结构的深度批改。提及了大模型在情感识别和个性化反馈方面的优势，以及其通过概率采样和用户交互实现的风格多样性，避免了千篇一律的批改结果。同时，探讨了与百度合作中提到的“百舸异构计算平台”的概念，解释了“异构”的含义。"
      },
      {
        "time": "00:21:01",
        "title": "异构计算与百度合作探讨",
        "summary": "对话讨论了异构计算的概念，即使用GPU等加速芯片与传统CPU结合进行计算，以提升处理效率。双方探讨了选择百度作为合作方的原因，可能涉及百度在异构计算、AI技术或相关领域的优势和合作潜力。"
      },
      {
        "time": "00:21:24",
        "title": "选择百度云进行大模型训练的策略与原因",
        "summary": "对话中讨论了选择百度云作为大模型训练平台的原因，主要基于百度在AI基础设施上的长期积累，尤其是其文心大模型的成功案例。百度自2009年起便开始使用GPU进行计算加速，积累了丰富的经验，特别是在大规模集群的稳定性和高效利用方面。此外，GPU的高迭代速度和故障率也要求了高度的故障管理和集群稳定性，百度在这方面也进行了深入的探索和实践。最后，考虑到算力成本的高昂和故障修复对有效计算时间的影响，选择百度云可以有效避免在基础建设上的大量投入，确保训练的连续性和效率。"
      },
      {
        "time": "00:26:10",
        "title": "百度智能云与基础设施客户合作优化与挑战",
        "summary": "对话围绕百度智能云作为基础设施服务提供商与其客户在技术平台使用和优化过程中的合作与挑战展开。百度智能云通过内部开发的文心大模型，降低了网络层面上的故障率，并缩短了故障恢复时间，展示了其在内部环境下的技术优势。然而，面对外部客户时，双方需通过磨合解决数据准备、模型训练方法、数据分布等关键问题，以确保高质量的数据和模型效果。此外，百度智能云提供AI加速包和工具集，以优化模型算子和通信加速，帮助客户如教育领域的好未来及汽车领域的其他客户，实现任务编排、调度优化，从而提升资源利用率和降低成本。"
      },
      {
        "time": "00:29:30",
        "title": "大模型迭代与行业应用的发展趋势",
        "summary": "对话讨论了自去年8月以来，大模型的迭代与优化进展，特别是从专注于数学到全科知识，再到强化学习的广泛应用。参与者提到了国内外模型发展的速度与特点，强调了中国在数据积累和应用场景上的优势，以及美国在验证技术路径可行性上的投入。此外，还探讨了不同规模的公司是否需要训练自己的大模型，指出大型企业可能更倾向于自建模型以增强竞争力，而小型企业则可以通过调用现有大模型的API或利用开源模型进行微调，以更经济高效的方式实现AI化。"
      },
      {
        "time": "00:33:57",
        "title": "构建行业大模型：依托百度智能云与千帆平台",
        "summary": "讨论了在垂直领域构建行业大模型的策略，强调依赖百度智能云提供的基础设施和平台，企业需自行构建核心竞争力。百度的千帆平台提供不同版本的文心大模型供企业选择，同时通过Model Builder帮助客户训练专属模型，形成数据飞轮。此外，Agent Builder和A Builder工具助力企业基于模型开发新的应用，满足不同层次的需求，从应用到底层基础设施全方位支持。"
      },
      {
        "time": "00:36:16",
        "title": "AI时代下的未来学习范式与人才培养",
        "summary": "对话探讨了在AI普及后，人类学习范式的转变以及未来所需人才的特质。强调了数学、英语和编程作为基础技能的重要性，指出这些技能不仅是知识的掌握，更是与世界交互和沟通的工具。随着AI技术的发展，学习的目的已从获取知识转向培养终身学习的能力和解决实际问题的能力。此外，提到了教育体系的变革，如新课标改革，强调跨学科能力和素养教育，以及AI在教育中的应用前景。"
      },
      {
        "time": "00:40:09",
        "title": "未来教育的转变与终身学习的重要性",
        "summary": "对话探讨了未来教育可能发生的转变，包括组织形式的变化、AI在教育中的应用，以及终身学习的重要性。讨论指出，随着技术的发展，未来的教育形式可能会从线下转为线上，更依赖于AI的辅助教学。同时，强调了在社会日益富足的背景下，终身学习对于个人成长和社会平衡的重要性，认为教育不应仅限于谋生技能，而应更多关注个人兴趣和终身成长。此外，还预见了未来教育可能只有少数人才能享受真正的一对一教师教育，大部分人将依赖AI进行学习。最后，提到未来50年到100年，社会形态和人类形态可能都会发生巨大变化，而AI的出现正促使人们重新思考教育的本质和目的。"
      },
      {
        "time": "00:44:20",
        "title": "AI在教育公平中的潜力与影响",
        "summary": "对话探讨了AI在教育领域的应用及其对教育公平性的重大影响。AI以其快速学习和记忆能力，不仅能够提供高质量的教育资源，还能实现大规模的个性化教学，使偏远地区的孩子也能享受到优质教育。随着技术的发展，AI有望成为人类的老师和同伴，促进教育的深度交流与理解，从而真正实现教育的公平性。"
      },
      {
        "time": "00:45:56",
        "title": "通往AGI之路：AI技术的未来趋势与挑战",
        "summary": "讨论聚焦于人工智能（AI）尤其是通用人工智能（AGI）的发展前景与路径。当前，AI技术正经历快速进步，从语言模型向多模态模型的转变是显著趋势之一，这将促进AI处理更丰富信息的能力。同时，多专家模型（MOE）的兴起和后训练技术的强化学习应用，预示着AI模型将更加高效和应用广泛。尽管transformer架构在处理序列信息方面表现出色，但其效率和成本问题仍需解决，这可能需要突破性的网络架构创新。此外，AGI的发展还面临数据、能源、系统和可解释性等多重挑战，尤其是AI的可解释性和与人类学习能力的对齐，被认为是通往AGI之路上的重大障碍。总体而言，AI正朝着AGI的方向迈进，但这一过程充满挑战和不确定性。"
      },
      {
        "time": "00:50:48",
        "title": "探讨AI发展与AGI的未来路径",
        "summary": "对话探讨了AI的scaling law是否接近极限，以及在追求AGI（通用人工智能）过程中面临的挑战，包括数据生成、模型参数规模、应用成本、功耗和伦理问题。讨论还涉及了人类大脑与AI模型的效率对比，以及AGI定义的多样性。最后，对话者表达了对AGI未来发展的谨慎乐观态度，并认为AGI应助力人类完成更伟大的任务，而非替代人类。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "推理能力显著提升"
                },
                {
                  "children": [],
                  "content": "处理多步骤复杂问题能力强"
                },
                {
                  "children": [],
                  "content": "美国数学邀请赛准确率达83%"
                }
              ],
              "content": "OpenAI发布的“草莓”模型"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "强化学习应用"
                },
                {
                  "children": [],
                  "content": "自我博弈以发现新规律"
                },
                {
                  "children": [],
                  "content": "慢思考模式，深入探索多种可能性"
                }
              ],
              "content": "O one preview与O one mini"
            }
          ],
          "content": "AI大模型的最新进展与特性"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "全科覆盖，数学能力突出"
                },
                {
                  "children": [],
                  "content": "解题、讲题、批改、口语对话练习、个性化推荐等五大能力"
                }
              ],
              "content": "九章大模型（MathGPT）"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "GPT-3发布后的焦虑与应对策略"
                },
                {
                  "children": [],
                  "content": "百度与好未来合作，利用百度算力与训练经验"
                }
              ],
              "content": "合作起源"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "学习机：搭载AI工具，市场反响良好"
                },
                {
                  "children": [],
                  "content": "独立APP：免费提供，用户增长稳定"
                },
                {
                  "children": [],
                  "content": "API输出：内部业务与外部厂商应用"
                }
              ],
              "content": "应用场景"
            }
          ],
          "content": "教育行业AI应用现状"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "异构计算平台（GPU加速）"
                },
                {
                  "children": [],
                  "content": "高效的故障检测与恢复机制"
                },
                {
                  "children": [],
                  "content": "通信加速与模型优化工具"
                }
              ],
              "content": "百度的算力支持"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "数据质量与管理"
                },
                {
                  "children": [],
                  "content": "算力成本与效率"
                },
                {
                  "children": [],
                  "content": "模型训练的稳定性与效率"
                }
              ],
              "content": "数据与算力的挑战"
            }
          ],
          "content": "技术合作与挑战"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "提升教育资源的可获取性"
                },
                {
                  "children": [],
                  "content": "一对一定制化教学成为可能"
                }
              ],
              "content": "AI教育的公平性与个性化"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "终身学习与自我驱动"
                },
                {
                  "children": [],
                  "content": "学习目标从谋生转向兴趣与成长"
                }
              ],
              "content": "教育范式的转变"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "人类与AI在创造力上的竞争与合作"
                },
                {
                  "children": [],
                  "content": "AI在教育中的辅助角色，而非替代"
                }
              ],
              "content": "AI与创造力、审美"
            }
          ],
          "content": "AI教育的未来趋势与争议"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "从语言模型到多模态"
                },
                {
                  "children": [],
                  "content": "模型优化与成本控制"
                },
                {
                  "children": [],
                  "content": "强化学习与后训练"
                }
              ],
              "content": "当前AI技术的发展趋势"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "数据与算力的极限"
                },
                {
                  "children": [],
                  "content": "系统可解释性与伦理考量"
                },
                {
                  "children": [],
                  "content": "人类大脑与AI效率对比"
                }
              ],
              "content": "AGI实现的挑战与路径"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI在教育公平与个性化中的作用"
                },
                {
                  "children": [],
                  "content": "社会形态与工作模式的变革"
                },
                {
                  "children": [],
                  "content": "人类目标从物质追求转向精神与探索"
                }
              ],
              "content": "未来教育与社会形态"
            }
          ],
          "content": "AGI（通用人工智能）的探索与展望"
        }
      ],
      "content": "AI技术在教育领域的应用与未来展望"
    }
  }
}