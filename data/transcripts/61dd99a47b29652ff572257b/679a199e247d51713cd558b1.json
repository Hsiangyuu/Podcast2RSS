{
  "pid": "61dd99a47b29652ff572257b",
  "eid": "679a199e247d51713cd558b1",
  "title": "vol.114.AI行业的2025：技术的天花板、落地的方向和DeepSeek们的未来 | 对谈复旦张奇教授",
  "task_id": "ro84nrax28kzqkb3",
  "transcription": [
    {
      "time": "00:00:10",
      "text": "Hello, 大家好，欢迎来到我的播客节目起逐年宾客，我是大卫翁。这期节目是一月中旬我回上海的时候，和复旦大学的张琦教授录的一期关于AI行业的年度复盘。本来是准备春节之后再放出来的，因为春节期间大家可能也没什么时间听播客。没想到这两天deep sick突然出圈，再不放还不知道AI行业会出什么大事儿，所以就赶紧在大年初一把后期处理完，然后准备放出来了。不过实话实说，其实我在昨晚除夕夜还是很不好意思的打扰了张曦教授。问他deep c新版本出来之后，有没有觉得我们的录制内容有什么需要修改的？没想到他大手一挥说没觉得有什么问题。这当然一方面说明我们的讨论是经得起考验的，另一方面这一期的很多内容可能也会给现在有点上头的市场对于deep sick的这种热情泼点冷水。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:06",
      "text": "当然我也承认，deep sick非常令人震撼。这点其实我在用它的上一个版本的API接入沉浸式翻译插件进行体验的时候，就已经有所感觉了。我在节目里边也提到了，它的翻译效果甚至比公认的最适合翻译的DPL模型都好了很多。而到了这个新的版本，无论是普通人在使用中的体验感，还是模型本身训练量和算力要求的这种压缩，对于中国乃至世界AI行业来说，都绝对是具有里程碑式的这种意义。另外它其实也证明了我们在节目里面得出的几个结论。比如说agent会成为2025年行业最有潜力实现快速发展的这种应用方向。因为deep seek里面体现出的这种反思和学习的能力，就很像是把一个agent应该具备的能力，活灵活现的展现在我们的面前。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:58",
      "text": "不过我在这几天使用deep sick的过程中，依然会经常回想起张教授在节目里面提出的一些观点。比如说因为无论是哪个大模型，底层逻辑依然是微数据训练和应用统计机器学习的这种规律。所以这一轮生成式AI的技术天花板就在那里，我们是看得到的。甚至因为deep sick加入了这种深度思考的功能，让我们可以更加清楚的看到他的整个思考过程。反而能够更明显的感觉到它是一个人工训练出来的智能模型，而不是一个真正具有自我意识级别的所谓智能体。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:35",
      "text": "比如说张老师在节目里面提出好几次的strawberry有几个R的这个问题，deep sick就足足花了五十多秒去思考，翻来覆去的想了无数遍，当然好在最后还是犹犹豫豫的给了我一个正确答案。所以骄傲是绝对值得骄傲的。但是是否因此就应该觉得世界大不同，我们直接拥有了一个OpenAI级别的核弹，具有颠覆性的这种成果呢？我觉得听完这期你可能会有一个自己的答案。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:05",
      "text": "对了，说这么多，还没有介绍这次的嘉宾张琦教授的背景。他是复旦大学计算机科学技术学院的教授、博士生导师，上海市智能信息处理重点实验室副主任，也是复旦谋私大模型的负责人。对他也自己下场做了一个大模型。他在国际重要学术刊物和会议上发表了两百多篇论文，并有自然语言处理导论和大规模语言模型理论与实践两本著作。张老师其实还获奖无数，我在这里就不列举了，会放在show note里面。但对我来说，其实更重要的是它提供了一个目前中文博客圈相对少见的看待AI行业的这种视角，那就是在业界和投资界之外的学界的视角。作为一个研究了自然语言处理二十多年的学者，我觉得他对于这一轮生成式AI狂潮的很多总结和展望，至少对于我这样一个AI门外汉来说，是非常深入浅出又具有很强的启发意义的。好，7788说了这么多，那就让我们赶紧进入正题。祝大家在春节假期里收听愉快。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:12",
      "text": "今天特别高兴，能够邀请到复旦大学的张琪老师来做客其中联兵课。其实我跟张老师的认识也非常的凑巧，就是我们俩是一起拿了第一财经的一个奖，这个行业新锐。然后当时有幸跟张老师一起吃了一顿饭。当时就觉得您因为从事这个人工智能的研究已经二十多年了，对吧？对，其实一方面是非常的有经验，但是同时很多的表达其实我觉得很很深入浅出。另外因为现在虽然关于AI方面的播客节目挺多的了，但是绝大部分要么就是AI行业的从业人员，要么就是AI的媒体，还有一些可能是早期风险投资基金的一些投过AI项目的这些基金经理，也会出来聊一些关于AI行业的观察。至少在我的视野里面挺缺少学界的一个视角的。就是学术界的朋友们可能还是比较对博客这种形式不是很熟悉，所以我特别想借这次这个机会可以补上这么一个视角。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:17",
      "text": "是非常感谢您也有机会。然后我觉得因为学习可能对于这种新的媒体传播形式没有那么关注。但我觉得其实这个形式应该是非常的好。对平时的一个交通和运动的过程程当中。",
      "speaker": "发言人3"
    },
    {
      "time": "00:05:34",
      "text": "然后说起来非常的不好意思，就是我其实也是计算机专业毕业。然后工作之后，第一份工作是正儿八经的码农，做了两年的编程。但是做完之后，后来去读了研究生，就转入了金融行业。大概有接近20年没有碰过代码了。所以这次的AI这个热潮，说实话在一开始也是非常的懵懵懂懂，甚至是抱着很强的质疑的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:57",
      "text": "因为我在我金融行业的最后一份工作，这里面是做了一些关于自然语言处理的尝试。因为您可能也知道，就是现在的金融机构会发布很多的研究报告，对它有大量的这个内容，但是它都散布在几千几万篇研究报告。当时我在想能不能有一个方式去把这些报告里的内容抽出来。然后不同的机构他们在这个时间点关注的信息什么是最是重要？这个自然语言处理领域关于这方他们有很多的研究。但是后来发现打标签，就是相关的这个训练，我们找了一些外部的公司合作，非常不容易是吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:39",
      "text": "艰难。对，如果你是一个比较专业的语料库可能还好。但是因为你像金融机构的研究报告，它范围太广了。就是我们在聊几十个行业，在聊宏观的情况，各个国家宏观性。所以它的那种语句很难去把它给模型化，或者说就是怎么把这个非结构化。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:59",
      "text": "变成化过程。",
      "speaker": "发言人3"
    },
    {
      "time": "00:07:01",
      "text": "所以其实在那一波之后，我对于AI这个东西更多的解读，这是不是就是一个噱头，然后就是并没有什么实际的落地的东西。直到因为我这两年在日本生活，ChatGPT对，是我现在用的最多的一个AI的应用。其实我们在正式开始之前，其实想跟张老师来聊一聊我们现在自己在用的一些AI的应用。我非常不好意思，我其实用的最多的就是ChatGPT。然后我请他帮我做的最多的事情就是写一封日文的邮件或者回一个日文的信息。因为翻译这个事儿我觉得太牛了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:39",
      "text": "就是这一波生成式AI出来之后，比起之前我们常用的google translate或者这种方式，他的语言的表达自然了很多。而且你也不用一字一句的把内容告诉他，你就告诉他我大概想写一个什么内容，他就能很好的把它表达出来。是的，然后日文因为里面有大量的敬语，有一些特别的这种格式，那他就可以非常好的模拟你现在的这个。比如说我是给一个服务行业写的东西，跟我是给一个我的长辈写的东西，他所用的语言是非常不一样的。那我只要把我的这个角色告诉他就可以很好的写出来，而且他还有记忆功能。就是我这一次给他回了，我下一次就是告诉他，上次我回了一个什么邮件，我现在需要再给他一个回复。ChatGPT是完全可以记住你之前做了什么的，我觉得这个就特别的方便，它就真的成为了我在日常生活中非常必不可少的一个工具。是所以我不知道张老师您在这两年，特别是2024年有没有大量的使用什么那样应用，或者是看到比较有意思的应用，我们可以先聊一聊。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:42",
      "text": "对，其实我自己主要就是做自然语言处理，前面20年都是做自然语言处理。就像刚才您说的，核心点就是从非结构化文本到结构化的这样的一个工作。其实自然语言处理核心就是这个，没有大模型之前，其实自然语言处理是不能做生成的。就是你除了机器翻译之外，机器翻译也是有本可依的。就是你是有一个原来的语言，然后到一个新的语言。但是即便是这种情况下，它的翻译效果就像您说的，它其实翻译出来语言是很不自然。就是因为生成能力其实非常弱。所以在没有大模型之前，基本上自然语言处理的生成式的任务没有什么人敢碰，是非常难的一个工作。但是这次大模型出来之后，其实文本它的生成能力是可以做到非常的好。因为它建了大量的文本，所以从这一点上，它就是把我们整个自然语言处理的研究领域就有一个翻天覆地的变化。",
      "speaker": "发言人3"
    },
    {
      "time": "00:09:37",
      "text": "回到您刚才说的这个使用上，因为我自己其实主要做自然语言处理，然后日常的工作就是写论文、读论文，做点PPT，做点报告这样子。所以我自己主要就这样几个方面。第一个就是编程，编程的话可能之前是拆GPT或者是cloud。然后那现在肯定是交互式的curse会更方便一些，它的这个效果会更好。当然这个我觉得主要是因为我们经常会要切换一些不同的领域。比如说之前用python写这种神经网络的相关代码，在py toch上工作。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:10",
      "text": "但是可能你要做一个demo，就demo并不复杂。比如说我们要实现我们在做4O的这种demo，还需要一个流式的这样的一个交互。那这个东西对于我们做研究员来说可能就离得太远了，从来没有干过这事儿。但是你如果像过去你查文献等等等等，时间就会很长。那你让他帮你生成个初版可能会有错误。但是你在这个上面你就大概了解了整个的这样一个流程。那你其实可以非常快速在他这个版本上面做一些迭代。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:37",
      "text": "可能我觉得90%或者80的代码其实并不能够直接使用。但他给你的这个框架是非常好的。那你有编程的基础，你就可以快速的进行切换。",
      "speaker": "发言人3"
    },
    {
      "time": "00:10:48",
      "text": "然后第二个，比如说可能我们现在在用一些rust语言，然后你原来都是写CIG，写python的，你没有接触过rust，让你从零写一个你非常难受，这个学习成本很高。但是仅仅是一段代码的话，你其实语法基本上都是比较类似的。你根据它那个结果可以快速的进行一些调整。所以我觉得编程上面，其实对于这种就是你快速切换一个领域，换一个方向不是特别深入的那种编程，它其实可以降低你很大的这种工作量。",
      "speaker": "发言人3"
    },
    {
      "time": "00:11:18",
      "text": "关于AI编程这块儿，我能不能这样理解，就是他给你搭了一个架子，然后你再在里面再去精雕细琢一下，等于你用不同的语言。原来我们需要完整要学一套语言，那现在有了这样的一些AI的编程工具之后，相当于你就不用去学这门语言。它可以直接把相关的内容先生成出。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:37",
      "text": "你可以快速的入门。比如说我可能用rus仅仅是改一小段代码，我并不是要长期做rust的开发者。那这个时候其实你可以快速的进行一些入门型的这种工作。比如我不是做前端的那我可能就搭一个demo，那他就可以给你做出来一个样子，你不需要在上面特别的精雕细琢。但你不是做这种专业性的前端开发，它可以快速的帮你切换过去，这是一个方面，就是快速的切换不同语言前后端的这种开发，或者你不熟悉的一个框架，它可以帮你快速的去搭起来这个部分。",
      "speaker": "发言人3"
    },
    {
      "time": "00:12:10",
      "text": "第二个方面就是cursor是可以读你的project。所以那你再去写这个代码的时候，有很多其实不是一个脑力劳动，他其实是体力活。因为你要完成这个规范性，你要去写好这个comment，你需要把这些东西都填上。它可以根据你的这个project的历史这些文件，然后帮你快速的给它补全。那这个时候可能原来你需要打几十个字，现在一个tab键就过去了，那这个就会加速你的程序的写作。比如说可能也许20%的时间在整个这个流程里面。其实我觉得更多的时候，如果在你长期工作的这样的一个项目上，他大概就是帮你节省了20%左右，然后把这些不重要的体力活帮你给省掉了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:12:55",
      "text": "明白其实2024年curse r公众这个层面出圈，是因为诞生了几款APP。对，它是完全由AI小白或者说编程小白，对，等于完全没有编过程的。是的，只是有一个想法，那么把这个想法给了这样一个平台，他就生成了这么一个PP。当然我也问过一些我的真正的码农朋友们，他说好像也没有那么简单。也不是你就告诉，比如说你就要做一个淘宝这种根本就不行，没有希望。哪怕你说一个比较简单的要求，也不是科尔斯这个平台就可以全套都给你，还是要有一些这种怎么去把它打包，或者怎么样去把它部署等等的这样的工具在里面。但是不管怎么说，它还是帮助不懂编程的人能够完成从0到1的这么一个转化。这个跟之前的pilot这种，包括最早大家想用HGBTT去帮你改一些代码或者什么，好像是一个范式上的转变或者模式上的转变。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:49",
      "text": "或者是可以这么说，就是curse r它更聚焦于这样一个场景，就是代码。我把这一个场景按照不懂编程的人，懂编程的人再进行细致的切分。然后我根据这个部分做特定的训练，然后它就可以达到一个比ChatGPT更好的效果。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:07",
      "text": "所以这其实也是我觉得从24年开始，就我在各种报告里面都去强调的，其实AI核心是场景，并不是垂直。不是说一个行业是一个行业太大了，其实是场景。Cursor就是一个非常好的例子。可能比如说我觉得curse r也许未来还会再有一个编程，他可能就是纯纯的给小白，就完全不让你懂代码。然后那你在这种范式下面怎么能够构造出来一个简单的这种demo。还有一些可能就是纯纯的是为了我提升你整体编程效率，我给真正的码农去用。这两个场景我觉得还是很不一样。然后其实就可以再切分。",
      "speaker": "发言人3"
    },
    {
      "time": "00:14:47",
      "text": "就是特别专注于某一个场景的这种AI的辅助工具。对，反而可能会更好用一些就是太通用的东西，就ChatGPT或者这种的话，对它两个不同的发展方向可以这么解。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:00",
      "text": "对于AI我现在看到它的能力边界其实就是针对场景。即便这种模型O1O3出来，我依然觉得它其实实现不了通用化。它不是能力的提升，而是场景化的学习。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:16",
      "text": "您说的是这一轮生成式AI的这种大潮。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:19",
      "text": "或者是说我觉得就是现在的统计机器学习范式，用数据驱动它就达不到因果的一个逻辑，或者不能像人一样进行能力的提升。比如说我可以让他考研的数学做到130分，但是你依然竖不了strawberry里面有几个R因为这个对人来说是，如果我研究生考试数学考试我能考到130分，是非常高的一个分数。我其实做小学应用题，我觉得你就粗心错一两个，你得95分，应该是分分钟的事。如果你数strawberry里面有几个R这种事情你不可能做不对，除非就是你可能发烧感冒了。但是人是这样能力的提升。",
      "speaker": "发言人3"
    },
    {
      "time": "00:15:59",
      "text": "但是对于机器来说，这是两个完全不同的场景。就是考研是一个，甚至考研里面的题型都是，如果你这个题型没有见过，可能你就不会做。然后我微积分做得很好，我的初中数学题如果不给你训练，你也做不对。甚至我只给你训练上海的考题，你换到山东的考题，你可能就从100分降到了40分。因为它的训练数据不一样，它的偏重点不一样，老师的语言的表达风格不一样，那使得你就可能会有大幅度的下降。所以我觉得从这种角度上来看，我就觉得场景化越小的场景，整个AI发展其实都是场景化来驱动的。只不过现在大家看到ChatGPT好像一个模型能完成很多功能，但其实每一个都是一个一个场景堆起来。但这一个模型因为是生成式的架构，所以它可以融合到了一起。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:51",
      "text": "您说的这个蛮有意思的，本来我是想放在后面，就是关于底层这块儿我们再来聊。但既然反正聊到这个问题了，我觉得关于这一点可以再稍微深注意一点。因为站在一个小白的角度，或者说是一个普通人的角度，会觉得这一轮深深式AI跟之前最大的区别就是他好像变成万能型的了。对，就是我问他什么，他都能给我一个快速的回复，对吧？我打开一个对话框，国内可能是豆包或者是kimi海外是ChatGPT，就是我有任何问题你都可以扔给他。",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:19",
      "text": "但是就像您说的，如果用多了的人就会发现，第一它还是会有有一些幻觉，当然现在的幻觉比原来要好很多。第二就是他能完成的内容，就是你没有办法百分之百的依赖他。你经常会发现里面有一些莫名其妙的一些问题在里面。你如果问他一个日常的问题可能还可以，但越是简单的问题，甚至是比如说下一个星期日是几号，类似这样的一些问题，经常都会出现一些问题是所以您刚才说的这个场景化和这种通用化，它到底背后底层的原因会出现就是在一些专业问题上反而表现的很好。但是在一些很通用的，在人类看来是特别基础的常识类的问题反而会出错。它的底层的原因是什么？",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:04",
      "text": "底层的原因其实就是训练数据没有往里面放。比如说我们现在做了一个实验，就是我们前面大概一年的时间都在研究。一句话，在GPT4发布的时候，就是二三年5月份GPT4发布它有个technical report。它里面有一句话就是说我在模型训练之前，我就能知道我的某一个评测集合，它的准确率能达到多高。所以我们觉得其实open I不仅仅是盲目炼丹，他其实知道了一些底层的理论。就是我能够不在模型训练之前，因为GPT4大家通常认为是个1.75万亿的模型，那是一个训练一次的成本是非常高的，你可能大几千万美金。如果完全正确的情况下，所以他肯定不会盲目的一次次的做实验。这个资金成本跟计算资源都支撑不住，所以他一定有一些基础的公式来指导他。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:55",
      "text": "我想把这个能力提到90分，我应该在预训练阶段放什么数据？我在有监督微调阶段和强化学习阶段，我应该怎么做？它一定会有一个基础的这样一个理论在，所以它里面有专门写了一句话。然后我们研究这个事情干了一年多了，现在我们也基本上可以得到那个公式。",
      "speaker": "发言人3"
    },
    {
      "time": "00:19:13",
      "text": "在某些情况下，比如说我想让他去答题，首先这个模型有没有记住这样的一个事情。比如说复旦大学有几个校区，这个模型到底有没有学到这个知识点？你需要一种方式把它判定出来。",
      "speaker": "发言人3"
    },
    {
      "time": "00:19:26",
      "text": "然后如果这个模型我们判定它记住了这个知识点。让这个模型能够回答这类的问题。你猜我们知道多少条训练数据，这个模型就具备了这个能力。",
      "speaker": "发言人3"
    },
    {
      "time": "00:19:36",
      "text": "几万条，再猜几十万、几百万，六十条60条就可以了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:44",
      "text": "对而且如果比如说我们准备了这个训练数据，是这个模型没有记住的。他原来这个模型通过预训练，他没有把这个知识点记住。可能因为这个知识点出现次数太少了，他没有记住。那这个时候你在有监督微调这个阶段，你放大量的训练数据，你如果放2000条训练数据，还有可能会从60分降到20分，就是会把这个模型整体全部搞乱。所以其实这个模型它的知识来源就来源于预训练，就是你的所有的知识点全部是靠预训练数据来记住的。但是他有一些特定的规范，不是说你给他一条就能记得住，他有一定的要求，比如说他本身的出现次数要达到一定的数量。",
      "speaker": "发言人3"
    },
    {
      "time": "00:20:25",
      "text": "第二个是说它有一定的特异性。比如说中国第九长河，中国第一长河，这个第九和第一它之间就经常一起出现。那这个时候的模型就很难区分，但是第一长河出现的次数是远远高于第九长河的对所以如果这个时候我们去问一个模型，不是让他走AI search，仅仅是模型自己本身，你会发现可能700亿的模型也达不了地久长河是谁。甚至我们说现在的6000亿的deep seek v3，基本上我觉得也很难达到。我没测。但我估计从我们的计算上来看，基本上是答不对的。因为它根本记不住的，特异性不够高。所以这个模型它能够记住的知识其实来源于前面。",
      "speaker": "发言人3"
    },
    {
      "time": "00:21:06",
      "text": "而且这个模型的训练数据其实决定了他能记住什么知识，这仅仅是知识，这个地方还有别的任务。比如说strawberry有几个R他为什么数不对？就是因为这是一个数字的一个场景，那这个场景我就需要专门搞几十条训练数据放在这儿，这个场景太多了。对，如果按这个切下去的话，我可能有几百万个场景，每个场景我都需要特定的准备数据。这个事情我觉得是可以做的。但是问题是说你这样去做下去，它是个无底的。每个人都有自己不同的需求。我可能是说让你数几个大写的R，你如果没有准备这个训练数据，你只能数小写的，然后大写的你就数不对，那我可能再去给你稍微变形一下。任务的种类是无穷无尽的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:21:49",
      "text": "是的，这个其实就有点像自动驾驶。后来为什么到L4L5出现，大家觉得会有问题，就在于你在实际的驾驶中会出现的场景也是无穷无尽的。是的，而且那个可能会还涉及到生命安全，对吧？车辆的安全。对，所以大家就会觉得，但是这样的话我听下来，因为我理解，当然可能我理解太浅薄了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:11",
      "text": "就是生成式AI跟之前的最大的区别，不是说是你在已有的这种训练里面去找答案，而是他所谓的深沉。但如果你还是要用预训练的东西才能去得出一个答案的话，那跟这一波浪潮之前的AI岂不是还是挺像的。因为我最早聊到最早做这个自然语言处理，他就是要打标签。对，那就你要往里喂数据了。是的，那还是这样吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:37",
      "text": "那跟之前的区别是什么？我觉得基本的原理上面就是从他出来，我们发了moss之后，我们就开始做各种尝试，然后做真正的落地。所以我们其实一直都在思考它到底是什么。然后我觉得24年我们把这件事情想的就是我自己的感知，是应该从我们的角度上来看，它和过去的模型最底层的逻辑是没有变的，没有变。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:58",
      "text": "对，但是它变了什么呢？第一个就是长文本，就是原来我们做就是您在之前做自然语言处理那一波，我不知道是18年之前还是18年之后。18年之后，18年之后就有bert了，但是你能处理的单词数只有512个token，那就意味着大概就是六七百个汉字你不能再长了。所以你限制在这个长度下，你会发现像您刚才说的这个历史我就看不到。那这个单词在这个位置到底是人名地名我不确定。因为他要看更长的历史才能知道这个位置，所以这是一个长度限制。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:29",
      "text": "然后第二个限制是什么呢？语言的限制就是之前一个bert一个小模型只能处理一种语言，你不能去切换。第三个是任务的限制。比如说我这一个模型，我只能让他来识别人名、地名、机构名就完了。如果你想让他再去识别一个新东西，他不行，你就要再搞一个模型。那这个时候模型小模型一个一个的小模型。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:53",
      "text": "第四个是不能生成，你只能是抽取这里面有一个东西我抽出来，然后这时候就非常限制表达，就是我的很多的关系就是两个实体我可以抽出来，实体的种类还是受限的，就是人名、地名、机构名这种实体类型就这么多，我觉得是一个封闭集合。但是关系两个实体之间的关系，那就无穷无尽了，所以关系这边你就不好抽，不好抽，他就表达不出您要的那个语义。就把这个非结构化转成结构化就很难。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:23",
      "text": "所以这是过去我觉得其实大模型就有四个能力就完整可以确认的就是长文本，然后跨语言、多任务和生成。那为什么多任务很有意义呢？就像刚才我们看，我们让这个模型既能够做翻译，又能够去抽取里面的实体。原来我们需要很多个模型，现在我们只需要一个。因为它把它都转化成了生成式任务。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:46",
      "text": "原来我们要做bert必须要打标签，就是A这个位置它是一个实体的开头。但现在不是了，我直接用自然语言告诉你就是地址冒号一个名字。请帮我把下文当中的人名都找出来，对他就会给你人名冒号。然后什么什么就是所有的自然语言处理的任务都可以转换成一个语言的表达了。我其实就把所有的任务就都融合成了一个生成式的框架里面。但是并不意味着说你不需要训练数据了。也就是说你让他数store berry里面有几个R那大写小写长短短的你都得给他。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:22",
      "text": "就这个底层逻辑没有变没有变。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:24",
      "text": "这个没有变其实就使得是说AGI用这套框架，我觉得就遥不可及。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:31",
      "text": "对，就是我们等一下可能会聊到一些OpenAI的这些科学家或者什么，他们也就意识到这样的问题了，这个框架它是有一个极限在那里的。但是对于公众，对于我们来说就会感觉因为具有了您刚才说的这几个多任务，然后生成式的这种感觉，所以它整个表达会变得非常的自然。它似乎比原来像傻子一样的那些所谓的是的就聪明了很多。对，但是他的底层逻辑因为还是要为语料，还是要预训练，所以导致他如我发现自己没有被训练的时候，他可能会出现一些胡说八道，就是乱说。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:04",
      "text": "对他其实预训练这个阶段还好，但是预现阶段只让他见过大量的数据，然后做了很好的知识记忆，做了很好的表示学习。他其实最麻烦的是后面的后训练。就原来大家设想说我这个模型足够大我从1000亿涨到1万亿，甚至涨到10万亿，然后我给他喂无穷的数据，它有所谓的涌现。就是我这个能力没教给你，你自己就会了。对对对，但其实并不是。就说你其实如果我们再回头，因为我们自己做了很多预训练，就这个能力我在有监督微调阶段没给你，他为什么就会答了呢？",
      "speaker": "发言人3"
    },
    {
      "time": "00:26:37",
      "text": "其实我们可以反过去看预训练数据，你会发现其实他的能力来源全部来源于预训练数据，还是在里面。然后所谓的涌现，也仅仅是预训练数据里面在一些情况下让他去反映出来了。但是这个的准确率有的情况下只有10，有的任务好一点60%，所以它就达不到一个可用程度。如果你想让这个任务做得很准确，那你就一定要在后训练阶段放训练数据。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:04",
      "text": "这个训练数据是有监督的，而且是需要你精挑细选的。就像刚才跟您说的，这个60条训练数据就能做到很高，它并不是随便挑的。首先第一个是你得先探测这个模型记住了哪些知识点。然后第二个就是你针对他记住的知识点再来构造这60套训练数据。就是不是说你找专家把这个写出来就好了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:27:27",
      "text": "其实专家写的都是高质量的，但是如果专家的写的那些知识点，我这个模型都没有记忆住，那对不起，你这些数据进去我模型就崩溃了。所以他要跟模型紧密匹配的来构造一个这个，那这个其实就是模型的训练方法的不同。然后这个东西就需要花很多的钱，很长的时间来摸索。这个事情我们干了一年多，然后也仅仅是在问答这一件事情上相对比较准确的给出来的这样一个结论。还有很多任务，你翻译怎么做的，然后你的信息抽取怎么做的，这些都是需要单个挨个这样去摸索。所以这个时候我们看，其实后面的这些事情就有非常长的漫漫长路。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:07",
      "text": "但是我觉得这期节目一开始先定了一个相对比较，也不是说悲观。但是这一轮的生成恋爱肯定不是一个最终答案。我理解它是一个阶段性的东西，它比起之前的小模型或者之前的这种AI的阶段，肯定是往前走了一步。但因为它的底层逻辑没有变，所以它是有极限在那里的。而且极限可能现在都已经能够看到了，对吧？是的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:31",
      "text": "我觉得很多人看到了，所以对他的做法上就明显能够感知到不同。",
      "speaker": "发言人3"
    },
    {
      "time": "00:28:36",
      "text": "对，所以我看一些媒体报道像那个。OpenAI的联合创始人，前首席科学家对伊利亚，他不就在去年底应该是在一个机器学习的顶级会议上说这个技术迭代正在放缓。然后我们原来预计的ChatGPT的5就一直就没有推出来，他们反而走向了不同的这个路，这个OO什么的。对，他们其实在尝试不同的路径在走这件事情。但说回到我们最早在聊这个现在用的应用。对，但反过来就像我们引出这个话题的那个，原是您说现在的AI其实更适合用于场景。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:12",
      "text": "对这个事儿我是在最近听一期节目有一个更深的一个感受，就是在有一档中文播客叫做硅谷101。他其实采访了好几个在美国上大学跟读博士，包括做科研的一些华人在问你们现在在用什么样的AI那期节目的标题叫做没有AI我会难受到要死。就是AI新的应用的这个普及率，特别是我觉得在学生，因为他们更像是native AI的一代的，就跟我们可能用互联网是比较native的一代。是然后90后可能用移动互联网，那现在的00后就变成了AI对，他们用的AI的那个工具眼花缭乱。然后给我的一个感觉就是他们是在把他们像拼积木一样拼起来。就是我有一个什么同样的需求，我会用一个特定的AI工具。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:02",
      "text": "是的，比如说它里面有说这个叫GPT zero是用来检测这个AI内容，看它到底文本是由人类还是AI生成，它有一个比较好的辨别能力。对，然后有一个叫gramley，是专门做这个在线语法和写作的辅助工具，语法纠错。对，因为像我们这些不是AI native的这一代的话，我的习惯是啊我所有东西都去问GPT，我希望他给我所有的答案，我有什么任务都给他。对，但是好像我感觉这样做其实是不对的。你更合适或者说如果你想把你的这个任务用的更好，不是我们原来说的，你要学会怎么写prompt。只要你学会怎么写prompt了，对他就能很好的帮助。反过来是我们可以利用一些在垂类的这种AI工具，它在某一个场景已经打磨得很好了。然后你用它来做框架，你用它来改一下语法。然后你用它来做个什么，把它拼凑起来，能更好的辅助你现在的一工作。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:55",
      "text": "这就是场景化。刚才我们说到这个话题，就是因为cursor他其实写代码，对，然后他对这个部分单纯做优化，而它不仅仅是prompt的优化，其实prompt engineer其实你感觉24年是不是没人提这件事情，真的就因为其实没有意义，就是prompt二三年大家觉得好像我优化一下很好。对，其实就是因为你不知道人家怎么训练的。我训练的时候用了ABCD开头，就让他做信息抽取。那模型就按照我的要求，我再说ABCD的时候，他就开始给我做命名实体抽取。只是说我们训练的时候尽可能的满足大重，所以打1 worse的放进去。但如果你就是非不按我那个要求写，那你结果就差。所以其实和prompt没有关系。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:36",
      "text": "那你像curse他要单独针对代码的需求进行定制化的训练。然后像您说grama I那他就是改错，然后他为什么能做的比GPT好呢？他做了这么多年的改错，他有了大量的训练数据。然后他按照现有的这个方式，不管是在预训练阶段怎么做一些工作，还是在后训练阶段做一些什么工作，让它仅仅是针对这一个任务，他可以做得很好。比如说AI search，你用chat BT做AI search，他给你找出来的答案肯定没有你用的PP这个东西来做WX这个来做要好。或者是你们国内的这些部分，它其实就根据这个场景单纯训练来去完成。",
      "speaker": "发言人3"
    },
    {
      "time": "00:32:15",
      "text": "但你其实你觉得complexity可能还不能做deep search，我可能不能满足我日常代替google这个可能性。对，那是不是还有一个场景，有一个人专门做这样的一件事情，他可以做得更深入的一些部分。所以其实这种场景化，对于我个人来说，可能我查论文我可能会用google。就是如果深入型的查找，然后如果简单型的查找，我可能就是propac's ity去找。如果我去改错语法型的写作，我可能会用GPT帮我先生成个初稿，然后去改一改。那你确实离不开。因为原来你写一个论文，他的语言改错，我们其实是找美国的编辑帮我们改，要花钱的，就大概一篇论文改下来可能三四百美金。你现在肯定是拿ChatGPT给你改一遍，然后你还要反向修改。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:01",
      "text": "意思就是说他用了很多优美的词汇，你要把它改成那种简单词汇。因为这种词汇，特别是对于这种形容词、副词，中国人的理解没有那么深刻。对，所以你要把它改成简单词。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:13",
      "text": "就是我刚刚说的，否则看起来太像AI写的了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:16",
      "text": "对，太像AI写的。而且他用的那个形容词表达形式，你不一定确切的知道OK，所以要把它改成中国人习惯的那种简单的。所以这种部分你写论文的速度，我觉得比原来提高了非常多，就是只能减少50%的时间。然后我最近那本大模型的书在写第二版，我觉得60%的工作量都被省掉了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:33:37",
      "text": "因为你只要把你的思想表达好，你把这个段落组织起来，核心内容组织好，然后他会给你重组语言。然后这个语言重组完了之后，你再去把它去放进去。因为不是每段话里面全都是干货，它一定要有一个上下文的承接关系。对，要有一点这个肉在里面。这个肉其实就是一个可以让AR来做的事情。你把核心观点股价搞好，那这个时候原来可能60%的时间，甚至更多的时间都是在搞这个肉。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:07",
      "text": "你要想上下文怎么串接，这事儿太难了，尤其是对于我们这种理工科的人。写这种东西，你让我写论文骨架型的很容易写。你让我去把它变成一个书，然后要丰满起来太困难。那现在用GPT生成，然后你再去通读，再去把它按照你的这种表达形式再稍微做一些更改，那就能省大量的时间。所以你没有AI不可能了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:32",
      "text": "是的，其实张老师您因为是做学术研究，你就会说到其实你用它都是做学术这方面的这种丰满。那就像我最早讲的，我把它用在写日文邮件，其实它也是一种丰满。是的，因为他那些东西就您现在这样讲了，我就明白了。就是他其实预训练或者喂入了足够多的语料之后，比如说他对日文邮件他就知道这个场景应该是怎么写，用什么样的境遇对吧？他只不过再根据你的这个需求，然后把它给生成出来，用这样的一个东西。是的，您这么说，我确实现在想就是我真正在日常会用到的这种AI的工具都是非常垂类的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:09",
      "text": "除了chat BT之外，我会用一个叫做沉浸式翻译的一个插件，我今年给很多很多的朋友推过。对，就他在翻译这件事情上做到炉火纯青。对他当时他背后会再去接入OpenAI，接入DPL。然后你现在可以付费去把那个deep sick的这个API放进去。我最近在尝试，确实它的效果会比原来这个DPL的还要好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:32",
      "text": "虽然号称DPL是比较好的做翻译的模型，这个插件它的好处就是比如说你看一个网页，它会一段英文或者一段别的语言的文字，一段中文，就给你直接把这个网页对照，对，把它这样拼起来，或者PTF的时候也是给你左右变成左边是原文，右边是翻译文章。对，就是用起来就非常方便。就是我看起来就会特别的简单。你不是单纯的把一个网页全给我翻译成中文，是这样的话，我如果想看一眼原文是什么样子就到了。是的，然后整个生成的速度也很快，使用感也很好，那我就愿意他的订阅制。因为现在海外我觉得订阅制这个事情确实帮助很多的AI的这种垂直的工具，很好的在可能day one就可以得到比较好的一个盈亏平衡。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:14",
      "text": "是的，一个月69块人民币，就是说便宜，真的不便宜了。但是就像您刚说的，用了就离不开了。对我是能看懂英文没问题，但是我如果让他把它翻译成中文，我再来看，那速度是原来的五倍10倍。如果中间我发现有一些细节，我可能再去看一眼原文，对吧？对，但是大量的时间就被节省掉了。是的，当然这可能会带来一些负面的影响。我会非常的忧虑我的英文能力会不会退化。包括我不知道您现在有没有忧虑，我现在会有一些优点，就是我的写作能力可能会退化，肯定会退化对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:45",
      "text": "就是日文我到现在你让我真的从零开始写一个日文的邮件，我会发现我不知道该怎么排比。因为都是AI帮我把这个框架都生成好是的，这个当然是另外一个话题，然后另外一个我会用的，因为我做播客，那播客我会用一个海外的书创公司，他甚至是一个格鲁吉亚，还是拿一个很小的国家的一个创业者做的，他就是做播客的。后期处理这一件事情，把声音还原到类似像我们现在录的这个录音棚的这种声音。然后是非常简单的一键，就是你把那个音频导进去，然后一键。他就把里面的一些毛刺儿，然后把一些这种声音上的不平衡，白噪音、底层噪音全都给你去掉，非常方便。对，然后我为他一个月要付十几美元，类似这样的一个非常垂类的场景，好像我感觉现在AI确实是做的是非常好的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:34",
      "text": "其实AI就应该这样子，因为现在的不管是大模型，因为大模型其实还是基于深度学习。深度学习本质上也是统计机器学习，统计机器学习的核心逻辑就是针对一个场景，你给我足够多的数据，然后我来拟合，我学一个相关性，然后他就可以把这些地方你数据量越大就可以学的越好。只是说现在大模型训练逻辑上有一些变化，但是你的预训练数据还是非常大，那它的核心逻辑并没有变。那我在一个场景下，我其实可以打造的非常好。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:07",
      "text": "或者说就是这一轮的AI浪潮就应该这个样子，我们以后可能还会有新的，就总有一天应该我觉得会诞生出更加通用化或者它的底层的这个逻辑会变吗？还是您觉得这个东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:18",
      "text": "其实就我觉得这个事情您说会不会变？我觉得一定会变。但是是多少年呢？十年、20年、50年还是100年？因为他是需要一个类似于爱因斯坦这样的人，他把底层的机器学习，从统计机器学习这个架构转换成一个新的架构。这个事情其实非常难，主要的原因是没有数学工具的支撑。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:40",
      "text": "统计机器学习，您可以简单这么理解，就是我们把所有的不管什么东西都表示成空间当中的一个点，就像我们在一个平面上，然后属于A类的是圆圈，属于B类的是叉号。统计机器学习干什么呢？就是学一条分界线，把这个圆圈跟叉号让它分隔开，这就是统计机器学习的基本原理。所以如果你的训练数据足够量大，那我就能学出来一个很好的分界面，把你两个都分开了。然后我见到任何一个东西都可以这样去走，就可以判断你是属于A类还是B类，这就是基本原理。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:14",
      "text": "但这个基本原理里面有一个最大的问题，就是它学不到因果性。比如我们最简单在data里面经常举的一个例子，就是晚上美国的小超市这个尿布的销量跟啤酒的销量呈现正相关性。然后我们把啤酒如果往尿布那边放一放，它会销量更好。这个是沃尔玛或者任何小超时，现在都在做的这样data money的工作，大数据分析的工作。但是你给他再大的数据，你把美国几十年、几百年，把中国、日本的数据都给他他也得你为什么为什么？",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:47",
      "text": "其实这个背后的为什么，是因为美国晚上去买尿布，它一定是应急使用。对，然后肯定是男生去。然后男生去买尿布的时候，旁边有个啤酒，顺手拎一打，就是一个非常自然的动作。他当然会得到一个正相关的销售，但是这件事情你靠数据驱动，我觉得是永远学不出来的那他一定要回归到一个因果。其实我们人这个能力的提升，其实我们是建立了一个又一个的因果联系，最后串在一起得到的。所以我们的逻辑上你要有归纳能力，你要有使用归纳好的这个部分来做推理的能力。这个部分如果模型建立不起来，那我觉得他就没有办法像人一样按照能力进行提升。他就是一个小场景这样去做。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:36",
      "text": "所以您说它会不会实现？我觉得可能会实现，但是我觉得这个时间点会非常的遥远。因为它没有一个底层的数学的工具支撑了，因为因果这件事情在数学上都没有。我们现在的统计机器学习所依赖的都是概率学。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:53",
      "text": "相当于我们不能指望AI行业自己把这个东西给改革了或者颠覆了。我们需要自然科学，需要数学进一步的发展才有可能。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:02",
      "text": "或者是互相影响。也许搞AI的人，他原来数学背景很好，他发明了一套新的数学理论，新的数学框架，然后能够支撑。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:10",
      "text": "现在在学界或者是您看到在业界有这方面的尝试或者是努力吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:16",
      "text": "我觉得可能有尝试，我也没有看到。因为这种事情它真的是0到1，而且它不是一年、两年、三年，它是一个没有期限的，没有目标的。也许灵光一现明天就出现了，也许搞了几十年，一辈子都没有任何的产出，它就有就有没有就没有没有就没有。就像晨晨如果在没有就是ImageNet之前，他前面的20年非常悲惨，就连他创建的会议都不收他的稿件了。就是我们现在最好的机器学习会议。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:46",
      "text": "NIPS这个名字前面是neural，就是神经网络相关的会议。他有很多年他的论文是被拒稿的，他在做神经网络。因为从一九九几年开始神经网络消退，然后一直到03年左右，这个期间没有人相信神经网络能做什么事情，只有他在坚持。然后就是没有资金支持，没有国家的大钱的资金的支持，只有学校里那点小的资源，然后就这样干。",
      "speaker": "发言人3"
    },
    {
      "time": "00:42:12",
      "text": "然后他就赶上了几个优势。第一个是image NET，就李飞飞搞了一个大的标注集合。第二个是GPU的支持，GPU虽然没有扩大这样的部分，但是有一些通用化的编程。这样的一个结果出来了，有哭的出来可以来做一些通用编程，就没有排touch这样非常好的框架，但是至少有哭的。然后我定向性的开发一些部分，有具备了加速的可能性。在image NET在图像上大家看到了它的效果非常好，然后才一路起来。那你像hinton这样的，在现在这个时刻，可能我觉得除非极其牛的投资人还能在90年看到亨特，03年能够发展，我觉得这个很难非常难。因为做这样事情的人本来就非常少，然后他能不能做成也是一个巨大的风险。",
      "speaker": "发言人3"
    },
    {
      "time": "00:42:57",
      "text": "那说回到我们在过去这一年看到的变化，至少从2023年ChatGPT出现到去年在应用这个领域感觉百花齐放，或者大家都非常的兴奋，还有很多很多的事情可以做。我们且不去看遥远的那个极限的那个地方的话。那在您看来，除了我们刚才聊了AI编程对吧？聊了跟辅助的一些工具相关的事情，还有没有什么让你觉得很兴奋，或者说原来这个东西现在可以做到这个地步了的一些应用或者是服务呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:30",
      "text": "我觉得有几个。第一个其实是视频的生成。",
      "speaker": "发言人3"
    },
    {
      "time": "00:43:34",
      "text": "从最早的sora.",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:35",
      "text": "对，最早的sora就是在24年年初，反正过年也不让你。然后对我觉得其实就是视频的生成的不论是时长还是质量，包括图像，我觉得其实去年我觉得还是一个非常大的这样一个进步。因为这个也是你从原理上来看，它可能并不复杂，但是它的训练数据量级是非常大的。然后在没有ChatGPT的这种突破之前，我觉得大家应该没有人敢去投这么大的资源。就几个亿十几个亿的这样的一个成本，然后来训练这种模型。然后大家看到了在文本上面取得了这样大的成功之后，我觉得大家愿意投这种资源。然后当然在方法层面和训练层面，也是有很多艰苦的工作要去做的。但是你能看到它的效果确实提升了非常多。",
      "speaker": "发言人3"
    },
    {
      "time": "00:44:25",
      "text": "而且到年底的时候，大家好像已经觉得sora那个也不过如此，对吧？对，就是包括中国自己也诞生了一些非常好的。是的，就这一年在AI图像生成这块，确实感觉是翻天覆地的一个变化。对他还是很惊艳的这样的一种长进。这个变化之所以在中国会有这样的突破，是不是还是因为中国现在就预训练，相当于他的这个数据库足够的大了。因为我们看到很多是由抖音和快手他们诞生的这种产品。是的，那它背后是有大量的支持的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:56",
      "text": "对我觉得第一个是说大家对预训练大量的训练数据能够产生好的结果。这件事情在很多领域上是不需要质疑的，他一定会有信念。在图像生成上更是这样子，我都见过了。然后你给我一个图片去往后推理，它的训练模式非常明确。因为我有图像，我有这个视频一帧一帧的那我给了你前一帧，你给我推后一帧。只是说我需要花一些时间对这个图像和这个视频进行一些文字性的标注。因为你要用prompt进入，所以它需要一些资源。",
      "speaker": "发言人3"
    },
    {
      "time": "00:45:28",
      "text": "然后第二个是在训练方法上，就是经过了从20年开始，然后到了二三年相对稳定。其实模型的训练框架大家也已经都掌握了，然后你也有了足够多的卡那其实我觉得对于这种能够看得到的情况，对中国人来说这是最快的。只要你有demo，那前面的路径都是通的。所以搞工程肯定是搞不过我们，堆资源搞工程。对，有目标之后，堆资源搞工程，这绝对是中国人的最强项。可以非常快速的来超越，甚至还有很多图像的rag放进去，是吧？",
      "speaker": "发言人3"
    },
    {
      "time": "00:46:01",
      "text": "然后包括现在豆包生成的那个解决文字的那个情况。因为如果你直接让模型生成它文字都基本上会出错。对，都是乱码，都乱码一些。对，那现在我们其实可以靠reg，我字的生成其实可以跟图的生成分开，我可以先生成一个字的样式，然后再去给它再去走吧。",
      "speaker": "发言人3"
    },
    {
      "time": "00:46:19",
      "text": "但是他没有公开，我猜测是这个逻辑。如果解决字的生成，然后你看百度做的人的那个就是做一个人，你说一个prompt，然后一个人名，然后让他产生个图片，之前那个人他就经常出错，那现在他其实也是靠rec我先找到一个人脸的照。片作为一个reference，然后再生成，这个当然效果就好很多。所以像这种级别的创新其实在国内比较容易。所以你看到的这个效果上就会比，其实sora并没有在这个12天的发布里面没就引起什么浪潮。对，因为它效果确实也就那个样子。你想再去大幅度提升，然后去理解物理世界，那可能就是另外的话题了。但是在这个层面上我觉得是做的很不错的，然后国内国外其实还是很惊艳。",
      "speaker": "发言人3"
    },
    {
      "time": "00:47:03",
      "text": "然后第二个其实我觉得是O1O3的这种范式。就这种范式的改变看上去可能不大，它怎么实现的我们可能不知道，但是我觉得有几条路径。第一个就是我在推理的时候，我可能有一个模型在旁边监控它，然后它输出了错误的结果，我就让他去更改。你从表面上是有这么一个反思的一个过程。",
      "speaker": "发言人3"
    },
    {
      "time": "00:47:24",
      "text": "第二个就是我在推理的时候可能会有多个路径，这个改变看上去不是很大，但它其实对推理这件事情上来说是一个翻天覆地的变化。因为我们来看在GPT4OGPT4这样的一些部分上，它所有的推理都是一次性做对。但是这个难度其实很大的。就咱们自己做数学题也是这样子，你不可能一次性全都做对，你一定是这里做错了，然后回去再走。那这个时候其实你把这样的一个反思的路径加上去，其实就可以使得这样的一个推理的过程就会有了更大的容错的机会。所以它就可以使得我们的推理有一个大幅度提升。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:01",
      "text": "我们自己也做了一些相关的这种实验，就是max上面数学题上面你加不加，其实可能都会有20%的一个提升，量级是很大的。所以这个范式的训练，就这个东西的推出，我觉得是open I的一个非常大的一个贡献。别人至少没有从0到1给出来这样一个部分。其实这种简单这一个点我觉得也是花了好多钱，各种尝试是对，甚至我觉得这还是伊利亚的遗产，就是weak to strong的那套想法，在环境交互下去走，我觉得还是沿着他那条道路去走的。伊利亚肯定相信AGI，还是想去做AGI这个逻辑的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:48:37",
      "text": "但是O一这个部分，我觉得在学术界和在应用，特别在推理这条路径上，我觉得非常关键。你说就是强化学习这实现方法无所谓，只是说这种范式它不是要求模型一次性成功了，而是我可以在中间去改。但也有agent的思想在，对，就是agent你当然可以有外部的工具调用，然后memory等等。但是这个东西本身其实就带了反思，反思其实就是原有的大模型不具备的范式。它就是一种agent自己plan的这样的一个过程。所以我觉得这个思想对未来影响会很大，很多工具都会从这个角度上来进行更改。然后他未来把很多的之前我们一次性就能做对，但是你只能做到七八十分的东西，可能都会给你推到90分甚至更高。",
      "speaker": "发言人3"
    },
    {
      "time": "00:49:24",
      "text": "有一点就像最早聊的，加入了人类这个能力提升时候需要的一个阶段，就是反思反思。对，有一点人的这个样子是多年了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:49:33",
      "text": "就比如说咱们现在做rag，做知识问答，看上去很简单，但是一般只能做到一个七八十分。这里面其实有很多个点，比如说你搜索词可能就不对，那加入反思之后就不一样了。原来对照模型一次性把这个搜索词给出来，他如果不对，咱们人用搜索引擎也是这样子。我先输了一个query，你发现可能不对这个表达后面某一页看到了另外一个相关的词语，那我就改我的搜索词。所以这个过程其实就是一个反思的过程。",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:01",
      "text": "这个反思的过程如果引入reg系统，那马上就会使得reg结果又会大幅度提升。所以这个的引入，我觉得在很多很多地方，整个这样的一个部分都会有大的这种改变。但是怎么训练等等，大家还都在探讨，各种部分都在复现。然后我们也写了一篇综述搞它的路径，然后也在去做一些实际的工作去完成。",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:21",
      "text": "相当于OpenAI把这个东西发出来了。但他其实没有把底层的逻辑告诉大家。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:26",
      "text": "当然他应该是cloth AI，已经变成close AI了对吧？这么核心的东西他是不会说的，因为这个我觉得还是做了非常多的工作，各种尝试。我觉得这个0到1，其实人工智能很难。就是因为你看这么简单的一点，我觉得他可能两三个亿美金打不住。因为他试了各种条道路，然后真正事成了，然后你炒起来又很快。因为他只要给了你长相，那你反推起来就容易多了。而且你也敢试。",
      "speaker": "发言人3"
    },
    {
      "time": "00:50:53",
      "text": "反向工程又是中国人是比较擅长的东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:57",
      "text": "所以很麻烦。就是这个东西给出来之后，你的技术的领先性可能就是半年，也许快一点，慢1.3个月。你看它推出来O1O3之后，国内多少家都在推出，是效果上我们不谈，但是反正各种路径应该也就是在这个范围之内也跑不了。所以我觉得其实这个O1O3是一个大的这样的一个部分。",
      "speaker": "发言人3"
    },
    {
      "time": "00:51:17",
      "text": "虽然我们看好像本来以为会有JPPT5或者什么的，对，没有往那个方向发展。但它本身的推出的这两个东西证明了一些不同范式的存在。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:27",
      "text": "是的，我觉得其实是证明了什么呢？就是open I并不是一味的坚持skilling law，就是GPT5，我当时GPT4发完。我们对它的预估和预测就是把所有的模态都放进去，把理解和生成都放进去。所以基本上现在拿到的信息来看，GP5确实在走这条路。那4O就是把音频引进来了，但是没有把生成引进去。所以我们当时推测就是GPT5就是把所有的模态输出混合成一个。",
      "speaker": "发言人3"
    },
    {
      "time": "00:51:56",
      "text": "但是这个东西的训练真的太难了。你看sora自己本身训练都很难，然后如果把生成都合在一起，其实是非常困难。所以我觉得这是他在skilling上要走的一条道路，然后一直在坚持。应该是在训或者之前已经尝试过非常多次，但效果并不是很好。但是你会看到说他并不是盲从这个skill in law。对，然后他是在去探测不同的步骤。",
      "speaker": "发言人3"
    },
    {
      "time": "00:52:19",
      "text": "然后微软12月底发了一篇论文，然后他公开了GPT4O的参数量等等那个报道。我不知道您是不是有关注到，还没有？对，那个里面其实就能够看到。比如说GPT4是1.75万亿，然后GPT o one preview可能就是3000亿，然后GPT4O的mini只有80亿。我觉得它的值是大概率可信，因为微软跟欧巴还是有紧密联系的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:52:44",
      "text": "对对对，然后我觉得这个数据应该就是被这篇论文的实习生没有经过严格审核放出来了。所以您可以看到就是说就是他在完成不同的场景和任务的时候，他在测试各种各条的道路，在不停的推进这件事情。所以他的目标其实是明确的，要完成很多工作，他要解决的难题也是明确的。但他并不是说我就上1万亿模型，上2万亿模型不行，咱们上10万亿模型其实并不是我觉得他们一定看到了有一些基础的公式，他们一定看到了一些这个limitation，然后他也在不停的各种路径上面去探索。所以我觉得他们的技术功底和这种深厚度还是非常强。",
      "speaker": "发言人3"
    },
    {
      "time": "00:53:23",
      "text": "关于2024，其实还有一点想跟张老师探讨的。就是国内的这个公司里面有一个我不知道您关注没有，就是这个deep seek。对，因为它诞生于我们这个行业，就是说金融行业换方是因为换方也是，我其实很早就跟他们有一些交流，包括在他投资领域，他们其实做的非常的好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:43",
      "text": "量化领域。但是没有人想到他会突然在24年杀出来。在这样一个领域，当然有一些它底层的逻辑在。因为我现在看到一些报道，就是说deep sik最出众的地方就是他用比较小的这种训练量，对吧？用中国人能够接受的一个规模里面做出了相对比较惊艳的结果。但是他在包括底层范式或者在很多上面并没有特别多的突破。事实上是这样的吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:13",
      "text": "事实上是这样，我觉得第一个就是现在这种MOE架构，就是你看到的是一个六千多亿的模型，非常大。然后更惊艳的是说他用了500万美元然后来完成这一轮的训练。主要是因为之前的别人来做这种大规模的这种模型。其实没有MOE架构的情况下，它的训练速度是很慢的。然后他6000亿的模型，他用了256个expert，所以他其实每次激活只激活300亿模型。所以它的训练成本就基本上等同于一个300亿模型的训练成本，或者再高一倍，比300亿模型再高一倍，因为它占用显存还是比较高的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:54:51",
      "text": "然后第二个是从人员配置上来看，他们有很多是阿里的团队，过去在阿里工作过。所以阿里的特色是会把工程做到极致，所以他在训练上面一定会有极致性的一些办法来降低。比如说开源的牌touch每秒钟可能只能跑十个token，但是在他们这边可以给你优化到50甚至100，那这个时候它的训练成本会更进一步的降低。所以我觉得这个是没有问题的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:55:16",
      "text": "就是你追求极致化的工程，极致化的这个部分，然后去搞一个比较好的MOE的这种架构，然后来得到一个结果。但是预训练只是万里长征第一步，然后后面的后训练是非常困难的。而且预训练是有开源的，也有从20年开始的GP3也有训练数据。比如说可能90%的东西你都是知道的，不知道的可能就是那个模型的。最火的过程等等这些配比。但是基本上大家也都摸得差不多了，7788的。但是后训练是完全没有论文，比如说open I自己没有公开。那这个时候怎么搞？其实后面我觉得也是漫漫长路，就像刚才说的这个CBQA就是问答这个任务只需要60条训练数据，你有几百个任务每个任务都这么摸下去，你得花多少钱，多长时间你才能把每个任务都摸清楚，其实很困难。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:09",
      "text": "而且任务很难穷尽。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:11",
      "text": "对你即便是我只做高频的任务，对，就是几百个，那这么搞下去也很恐怖的。需要的时间成本，量的成本，我觉得也是可能范式上还会发生一些迭代和变化，而每一步都是需要大量的探测。在这个层面上来说，并不是说我们能力上的不行，我觉得是时间上跟成本上。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:32",
      "text": "我们可能知道GBG4O的不是它后面的后训练阶段在强化学习。我们看lala这篇论文，这是公开报道，我们不听小道消息，我们只看公开的公开报道。Lama 3在后面的强化学习阶段是标注了400万条训练数据。但是这仅仅是开源版本，那我相信open I可能会更多。",
      "speaker": "发言人3"
    },
    {
      "time": "00:56:53",
      "text": "这400万条标注数据看上去量很小，但是400万条标注数据是每条标注要花1个小时，也就是说他花了400万小时的成本，400万小时，而且这个标注它不是说随便找个人懂语言就可以了。比如说是儿科的问题，模型给了一个答案，你得找儿科医生对他进行判定。然后如果是个小学生的作文题目，你就得找小学语文老师来改卷，那这个成本就直线增长了。对，就是你可以认为大概在国内可能一条就是100到200块人民币，那400万条数据就八个亿干进去了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:33",
      "text": "而且这些标注还不能复用，就是我这个模型它是模型输出了两个答案。如果我把预训练改了，有监督微调改了，到强化学习之后，模型输出结果就不对了，又变了。变了之后你还得再去标注这成本是多大。那国内有多少的模型公司，六小龙公司能出得起十几个亿，在一个模型的一个阶段的迭代来完成，我觉得这是一个非常恐怖的数字。而如果你达不到这样的一个标注，达不到这样的一个质量，你模型的架构再一致再好也没有用。因为他根本没有见过。",
      "speaker": "发言人3"
    },
    {
      "time": "00:58:08",
      "text": "然后别人是这么多年从20年GPT3开始，然后发展到这个GPT4。其实它GPT4的架构21年可能就已经22年就给出来了。那你中间这段过程的摸索，其实如果我们再去翻看open I的历史，他在GPT2完成之后，做GPT3的时候就已经引入了刚才说的这种强化学习。然后甚至他都已经养活了一个小龙skill这个公司就做标注。他当时给他的要求是每周要标100万条数据。我的模型输出了两个结果，你找人给我标A好还是B好？然后延迟不能超过30分钟，每小时要达到5000条吞吐量，然后一周一百万条，标注多大的恐怖的量级。那这是多少钱砸进去才学到的这些经验。",
      "speaker": "发言人3"
    },
    {
      "time": "00:58:54",
      "text": "但是你复现它的时候，你什么错都不犯，你的成本可能都已经是二三十亿了。这个成本上我觉得在国内可能很难承担。但是你不投到这个情况，你的生成的能力如果别人是100分的话，那我们很容易的做到80。",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:09",
      "text": "提到90都很难，90再去覆盖到100那个钱就是乘以2上去，指数型指数继续往上涨非常恐怖。所以这个时候你80分花了1000万了，你要不要花十个亿去追那100分呢？所以这个时候其实很难权衡，我觉得这个难度上也非常大对。",
      "speaker": "发言人3"
    },
    {
      "time": "00:59:27",
      "text": "这个正好可以过渡到我们下一趴，就聊关于商业，关于公司这一块儿的。因为听起来确实深圳市这个事情是一个非常烧钱的生意。然后现在张老师您刚才提到了国内有所谓的六小虎，然后之前是四小龙，对四小龙说AI视觉已经基本上掉队掉的7788了。其实他们也是在某一个场景，对吧，在视觉安防这个场景深耕下去。但是你发现那个东西很难复用到其他的场景里面去就说到烧钱这个事儿，现在在国内我听下来是不是只有像字节这样的公司烧得起您刚才说的这样子规模的一个钱去做这么是不是只有他们在做这样的事情？",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:04",
      "text": "我觉得从烧钱这个角度，其实可能还有一个阿里。对，因为你看阿里在千问上面还是投了非常大的资源去做的，是开源版本上的发布。我们也能看到不仅仅是国内，其实国外千文的使用量级也非常高。因为这个预训练的成本还是非常大的。即便是模型一次性的训练，可能就是一两千万美金，这还是小钱。",
      "speaker": "发言人3"
    },
    {
      "time": "01:00:28",
      "text": "你前面准备预训练数据，18个T的token就意味着一个PB的接近一个180T的原始文本。180T咱们普通的笔记本是一个T的存储。对，180个笔记本的存储的文本文件纯文本，不是PDF，纯text的文件180个T然后这180个T的文件是从几个PB里的数据洗出来的。你需要多少的工程师，多少的算法研究员光洗这个数据，你还要调模型架构。也许就是没有准确数据，没有公开报道，那你大概估计也是几万张卡在跑。那这个成本量级其实是非常贵的那这样投下去，只有这样体量的公司，可能自己阿里才敢这么去烧。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:16",
      "text": "所以这个是一个非常耗钱的过程，这仅仅是预训练，咱们说的后面的这个有监督训练的时候，后训练阶段标这个数据，然后研究它的过程，那其实更花钱。因为你可能真正标注可能就标60条。但是我研究这哪60条数据，我三个博士生干了一年多。我们体量小，这个也是几十张卡陪着你跑，那仅仅是干这一件事情。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:41",
      "text": "所以在你看来这个六小虎或者说除了自己阿里这样的巨头之外的AI公司，他们可能的发展方向是什么呢？",
      "speaker": "发言人2"
    },
    {
      "time": "01:01:51",
      "text": "我觉得挺难的。因为第一个是融资已经融到这个规模了，是因为你基本上都是200亿到300亿了。对，就基本上都是这个逻辑了。其实我本来觉得他们手里拿到的现金，应该在26年可能才会有人不干了，因为这个钱数比较高。但是李老师01现在就把预训练团队卖掉，我觉得其实很好。因为他手里他现在能够卖的东西最值钱的是什么？是他手里这些人这做预训练的团队和他前面这些经验，那你把它卖掉其实是值钱的。可能再过两年这些人也不值钱了，因为这个技术都散播出去了，或者说大家觉得裕训练也不重要了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:30",
      "text": "那现在这个时刻把它早点卖掉止损，这挺好的，留下来团队做to b或者做to c的产品。其实我觉得01就已经选择了，我就不再做训练了，我就是做产品。至于做to b的产品还是做to c的产品，我觉得可能李老师就更有经验。这个方向上他不管to B2C to g之前各种公司都有布局。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:54",
      "text": "然后百川其实最早一上手就在说他要做医疗，因为之前小川可能一直都有做医疗的这样的一个梦想。从搜狗卖掉之后，就一直开始做这个医疗相关的部分。其实在搜狗里面也在做这种数字加一等等，都做得非常好。但是医疗这个场景下就要去考虑怎么变现，怎么能够支撑住一个200亿估值的公司，是这是一个大问题。",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:19",
      "text": "现在的医院也比较没有钱，整个医疗行业也比较累。",
      "speaker": "发言人2"
    },
    {
      "time": "01:03:24",
      "text": "其实医疗行业也很多，就是很多方向。比如说你是图医院，对，还是凸病人，还是凸家属，其实可能都不一样，或者是图医生。因为很多产品是给医生服务的，就像美国有一个公司做这种口语的病历的书写。因为美国人看病时间比较长，还有30分钟，前前后后的问他这个病例都要输进去的那他卖给医生说大概卖1万，有1万个医生用。他一年营收有1000万美元，然后他做私有化的这样一些部分，就是反正他有不同的方向。那我选择什么方向呢？我做一个产品给谁用呢？",
      "speaker": "发言人3"
    },
    {
      "time": "01:04:01",
      "text": "这个可能就是百川可能要去思考这些问题，但是估值在这里其实都不好做。是对，因为你现在融资是200亿，那你200亿估值这一轮如果再进投资人，他目标肯定希望你一千亿上市。那如果你是个400亿上市，他觉得可能都要赔钱了。那这个估值的情况下，你做什么业务能支撑住200亿、300亿的估值。那200亿300亿的估值我不管你赔多少钱，你一年给我拿十个亿的营收应该算是一个比较低的值了。或者是说按照正常的算法，可能你要拿20亿的营收。",
      "speaker": "发言人3"
    },
    {
      "time": "01:04:37",
      "text": "市销率10到20倍。其实对于这种所谓的心智生产力的公司是比较合适的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:04:43",
      "text": "可以接受。那你至少十个亿的营收，那这个时候其实难度是很大的。十个亿的营收我想在中国的上市公司里面也不多，对的比例也是很top的一个值了。所以那怎么能够支撑住，我觉得其实都是一个难题。",
      "speaker": "发言人3"
    },
    {
      "time": "01:04:59",
      "text": "所以反过来看，像海外这种订阅制已经深入人心的这种商业模式，可能还是更好的。就是你如果从to c端的话，对真的每个月的会员或者是每年的会员，大家愿意付这个钱。是的，就像我听我说硅谷101的节目，真的大家平均每个人会订阅3到5个A。的这种工具对吧？然后每个月你一个人可能就付出几十美元，三四十美元的。但如果你的基础量是一个几百万的人的话，这个营收就上来。是的，但中国的这个订阅的习惯始终没有培养。",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:35",
      "text": "对，是的。但是您看他们都不是做通用的公司，是因为做通用公司的话，你的投入就在这放着。就是OpenAI在ChatGPT出来之前烧了40亿美金，那我们把它前面犯错的成本全刨掉，只做ChatGPT，那你算一算可能也需要花个15亿美金。十亿美金这个量级可能你做到GPT4，可能没有10亿美金，很难烧出来和他一样的这样的一个部分。而这个钱就已经70亿人民币了，还不算后面的推广各个部分。所以我觉得钱是一个很大的问题，就一定要有很厚的资本量才能推着你往前去走。",
      "speaker": "发言人3"
    },
    {
      "time": "01:06:12",
      "text": "说回来就是我觉得这些巨头对于我们所谓的六小虎或者是这种公司来说，是一个巨大的降维打击。就有点像汽车行业对当华为跟小米进来的时候，有原来所的新势力会变得非常的艰难。因为你面对的是一个跟你不在一个维度上的竞争。然后那些巨头他有一些别的业务可以去真正他在这个上面去打这场仗，那让你原来只能在这个赛道上挣钱的公司就变得举步维艰，就有点这种感觉。过去这段时间您有看到什么相对更加小而美，或者是有自己的一些独到之处的AI方面的一些创业公司也好，或者是海内外都可以，有没有一些这种案例？",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:52",
      "text": "我觉得是这样，就我前面也仔细思考了一下，就是AI这个方向的创业跟他的公司的应用，其实我觉得是两个方面。第一个是现有的公司，现有的公司我一直是觉得最近这些的报告演讲，我其实都是有一个观点，就是25年是对现有的公司可能是一个巨大的机会。因为如果你的公司里面有一些业务可以非常好的使用AI并且能够带来一个体验感上的巨大提升的那这个时候就是一二三排序的这些公司，老大、老二、老三重新抢市场份额的一个机会。",
      "speaker": "发言人3"
    },
    {
      "time": "01:07:29",
      "text": "比如说我们说客服，客服之前的可能中国对于NA客户就那么几家，两三家大公司来进行服务，然后他想迁移其实很难。就是功能都差不多。但是AI出来之后，大模型出来之后，特别是语音出来之后，是完全不一样了。我可以外呼，原来是非常机械的，他现在是可以很自然的，然后接电话也可以很自然。这个时候他是对客服服务领域的一个巨大提升，并且我迁移成本很低。我做了A公司迁到B公司，其实我可以非常快，原来的那个迁移太累了。那基本上你给A公司做的70%的工作量要重干，再给B公司，他其实就是项目，根本就没办法做产品。对的，但是这次不一样，大模型可以在客服上比较好的做产品，可能只需要迁移10%的工作量就可以迁过去，就方法上可以支撑到，而且它在用户的使用体验感上非常好。对，就现在我接到了很多这个信用卡的分期的，就已经能够知道他是机器人打过来的。但是非常像，如果你不是做这个行业的，可能不注意听，听不出来。",
      "speaker": "发言人3"
    },
    {
      "time": "01:08:32",
      "text": "对，因为过去一年在社交媒体上最火的，比如说海外有很多把ChatGPT调教成跟自己聊天的这个对象。对，简直你听起来就是一个非常甜蜜的男朋友女朋友的声音，对吧？是的，然后您刚说到外，我就想起现在这个领域，现在游戏用上了。",
      "speaker": "发言人2"
    },
    {
      "time": "01:08:49",
      "text": "对，就是现在有一些这种恋爱游戏，会让这个游戏里的角色可以打电话给你。对，这个就是吸引了非常多的年轻人去利用这么个功能。现在确实虽然我接到这种一听就是机器人的电话，我会立刻把它给挂掉。但如果他能变得更加的自然，让你听起来真的就是一个人在给你打电话，很多时候你真的很难辨别。是的，咱就不说这个广告了，客服其实是很好的一个应用。是的，因为大家现在这个需求是非常大的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:16",
      "text": "对的，所以就是从客服这个行业来说，小公司是进不去的。因为它不仅仅是一个电话外呼这一个模型而已，它有前前后后各种部分，它要有管理端，然后转移端等等的，还有很多工程量。所以小公司是不用想做客服这件事情的，只有原来在客服领域的老大、老二、老三，谁先能做到最好的体验，那这个时刻就可以抢份额了。原来你老二只有43% 10，那现在如果老大没有做好，那你在这一年的时间之内，那就可能抢下来很多单子，那就占住了这个市场。",
      "speaker": "发言人3"
    },
    {
      "time": "01:09:49",
      "text": "相当于一些传统的这种行业。因为AI的加持，原有的行业格局会发生比较大的变化，这个变化很可能在2025年出现。",
      "speaker": "发言人2"
    },
    {
      "time": "01:09:59",
      "text": "我觉得是的。因为这个地方就要明确的是说，第一个是场景要适合它，不是随便去找一个就能完成。第二个是说这个场景它一定能带来非常大的体验感的不同，是不是简单的这种小的升级，它能让你惊艳的这种效果。",
      "speaker": "发言人3"
    },
    {
      "time": "01:10:15",
      "text": "然后这个时候我觉得就有可能性客服一定是像to海外的客服，其实也能看到，他们其实在去年卖得很好。就是因为你对一带一路销售，别人说印尼语，然后还有时差，你能从国内找到多少人说印尼语、马来语的客服，这成本也很高，你受不了。但是那你现在越来越下沉，你其实并不仅仅是原来是对他们的经销商，你现在可能就要直面他的客户。那这个时候现在做出海SARS平台的这些，他们面向的是小B然后我提供了一些工具，可以让你直接去发布你的产品，然后上架售卖等等这些。但是客服接进去，谁能抢到克服这个部分，那就使得你原有的产品的份额就会有大幅度的变化。因为大家上线下线都差不多，那分析工具也就这个样子。但如果我可以有一个很好的客服，那你没有，那我的销售份额就是老大、老二、老三之间有剧烈波动，那这些厂家25年一定是要紧盯这样的一个部分。但是这个市场就不是创业公司进的对，创业公司能进入的一定就是一个创新型的产品。",
      "speaker": "发言人3"
    },
    {
      "time": "01:11:24",
      "text": "这个产品之前是没有的，但是他要完整的利用大模型的四个能力，就是长文本、跨语言，然后多任务，还有一个生成。这四个能力如果你能利用的好，那它就一定是全新的这样一个部分。比如说AI测试其实是非常好，这个场景非常好，因为它完整的利用了大模型的能力。之前的小模型做不了，绝对做不了，效果很烂。但是有了这个东西之后，它就能做得非常好，而且是一个新的物种。",
      "speaker": "发言人3"
    },
    {
      "time": "01:11:54",
      "text": "但是AI社区为什么不是这些传统的搜索巨头能够去做到？",
      "speaker": "发言人2"
    },
    {
      "time": "01:12:00",
      "text": "对，您问这个问题特别好。我觉得大公司它有自己天生的惯性，那还是左右互搏的问题。左右互搏其实很严重的。你对于百度来说，你这边文心一言一上去，你百度搜索量级就会下来。那搜索排名的这个收入怎么办？",
      "speaker": "发言人3"
    },
    {
      "time": "01:12:16",
      "text": "对，你怎么办？然后你的曝光量一小，本来所有人都在做AI搜索，都在抢我搜索的份额，我自己再抢走一些。那我这边的搜索的本身怎么做没法弄。但是对于豆包为什么可以干？",
      "speaker": "发言人3"
    },
    {
      "time": "01:12:29",
      "text": "我一直都在做搜索，其实字节一直在做搜索，不管在抖音里面还是在头条里面去搜索，都是嵌入进去的，只是没有一个品牌独立出来。那我既然没有搜索的品牌，那我无所谓，我肯定大量的上。Google也是这种状态，我自己上到底怎么上呢？我原来也是有金卡排名的，你现在这边的Jimmy I还是没有一个收入的，然后我的收入逻辑现在还不清楚。如果我大量再去上，这个也是一个需要非常大的决心。",
      "speaker": "发言人3"
    },
    {
      "time": "01:12:58",
      "text": "而且从目前来看，还是有一些搜索的部分是解决不了的。就现有的AI测试解决不了搜索的一些问题，还是会回到google上去。那他这个部分也是可以继续承担，这个心理的冲击还是很大的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:13:13",
      "text": "就是自我革命始终是难的。好，其实最后一块儿我们就来聊一聊2025。刚才张老师其实已经涉及到一部分了，就是关于这个2025。其实对于很多商业的服务，传统的这种领域会有一个比较大的机会，是原有的行业格局可能会洗牌。因为这个AI的加持，除了商业这个领域之外，包括像底层的技术或者是其他的一些领域。您看到2025，我们可以期待什么样的一些AI方面的进展吗？",
      "speaker": "发言人2"
    },
    {
      "time": "01:13:43",
      "text": "我觉得2025就是明确的肯定是agent。因为从O1O3这套范式出来之后，就原来其实24年二三年大家谈的agent更多的是workflow，就是人写好的这样一个东西往下去跑。其实我觉得那不是agent，那东西就是RPA。过去传统的这个对，还是传统的RP没有什么特别的，只是说里面某些点上用大模型来实现。",
      "speaker": "发言人3"
    },
    {
      "time": "01:14:05",
      "text": "我觉得因为有了O1O3这套范式，真正的agent才会在25年开始出现。也就是说我自己会有反思的机制。我做了一个东西之后，我靠自我进行修正。我这样一个智能体它是做自我决策。其实O3其实就是这样子，它就是在做自我决策。",
      "speaker": "发言人3"
    },
    {
      "time": "01:14:23",
      "text": "这个时候我觉得它就会带来很多应用上的一些变化了。比如像荣耀手机agent这些部分。那你可能让他去选择某一个设置，它可能一步过不去，让这一步走错了，那我就需要反思再过去。然后这个过程其实就会变得更智能化，它可以帮你完成很多的一些事情，然后订机票、规划行程，反反复复多次才能搞好。",
      "speaker": "发言人3"
    },
    {
      "time": "01:14:48",
      "text": "就真正所谓的助手这个事儿。",
      "speaker": "发言人2"
    },
    {
      "time": "01:14:50",
      "text": "对对，所以我觉得25年应该是可以期待的对。",
      "speaker": "发言人3"
    },
    {
      "time": "01:14:53",
      "text": "因为这块儿咱们在录之前我也说过，昨天听那个十字路口也是一个AI方面的一个播客节目，他们就在聊到说2024年在海外诞生那个叫David的这么一个agent的平台或者说工具。很贵，一上来就要大量的付费。但是有做风险投资基金的人士就真的花500美金先买了，然后拿来用，就发现他确实至少可以抵几个实习生。而且因为他是可以做任务的，然后可以学习的，有反思的，所以他会越用越好。",
      "speaker": "发言人2"
    },
    {
      "time": "01:15:27",
      "text": "因为传统的AI工具最大的问题在于，他跟你招个实习生的区别在于，实习生可能上来笨笨的对，但是他慢慢的会知道这个公司里怎么对他会变得越来越好用。虽然这么说有点物化人，但是确实是这么一个感觉。是传统的AI的工具跟agent之间的差异，就是它缺少这样的一个过程。现在这个平台上来之后发现，确实有了一些这种能力，至少能看到可能性。对那在2025我们会看到这块儿有一个更快的一。",
      "speaker": "发言人2"
    },
    {
      "time": "01:15:56",
      "text": "我觉得会有。因为这种范式大家看到了，并且效果上无论从open I的自己，还是别的公司，还是学术界，从各种小的方面都做了一些这种证明。就是使用上的证明，或者是说研究上的一些复现。所以我觉得在应用上面大家一定会能够看到，这要看这个创业公司的场景怎么去选择，怎么去想了。对，然后就像您说的devin这种部分，他应该怎么去进化？但我觉得一定会有很多，所以这个上面应该是确定性的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:16:26",
      "text": "就类似2024年这个AI图像生成从年初做到年末有一个这样大的一个发展。可能2025是agent.",
      "speaker": "发言人2"
    },
    {
      "time": "01:16:32",
      "text": "这个我觉得会的，所以AI很难搞，这个太快了。等于年初和年尾的这种使用上的结果上，你看就会有非常大的变化，每个月都在变化。对，所以做AI很苦的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:16:44",
      "text": "但是从您看来，就是从事人工智能这个研究二十多年，他是一直变化这么快吗？还是最近这几年其实有一个突然的一个跳绳的这种变化的。",
      "speaker": "发言人2"
    },
    {
      "time": "01:16:56",
      "text": "原来也在加速，特别是在深度学习出来之后，是在不停的加速，但是也绝不到现在这个程度，这是加速的原因？其实主要就是使用范围变广了。原来的时候像自然语言处理只能用在极个别公司的极个别岗位。但是从bert出来之后，它已经用在绝大部分公司的里面了。可能也是小部分就隐藏在后面。但是绝大部分的公司其实都需要自然语言处理的人了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:17:25",
      "text": "这个时候这个研究的热点，公司的关注，使得这个技术就在不停的突飞猛进。然后到了拆GPT更不一样了，这就变成了一个全社会的焦点。大量的资金涌入，那一定会使得这个结果疯狂的往上涨。所以我觉得这个加速的速度实在是太快了，完全受不了。",
      "speaker": "发言人3"
    },
    {
      "time": "01:17:46",
      "text": "所以听您演讲说，最可能先下岗的是AI研究员。",
      "speaker": "发言人2"
    },
    {
      "time": "01:17:50",
      "text": "一定是25年，一定是因为你看它是多任务混合在一起。原来一个搜索引擎公司，搜索引擎公司里面上千个研究员算法，而且都是做自然语言处理的，他在干什么？其实就是一个用户的检索词进来，我先要识别里面有没有人名，有没有地名，有没有机构名，然后又没有医学名词。这些东西都是一个一个的小模型，每两个小模型你就得派一个研究员盯着。那一个搜索引擎背后可能有上千个模型，那我就得搞三五百个研究员盯着这一千多个模型，不停的升级改造。虽然可能每年进步很小，但是你得找人盯着他。这些人你可以想象，可能从300人1下降到30，这种一线大厂的高端的研究员的快速裁员很恐怖。",
      "speaker": "发言人3"
    },
    {
      "time": "01:18:37",
      "text": "所以我觉得可能在25年26年就会出现。因为他不像是工程架构的人，工程架构的人就像支付宝这种出现这种批评的事故，就是工程架构的人大家不太敢动的，因为你是有技术积累的。对我从一点点涨上来，这个东西哪里出错，我有经验的人一眼就知到。但是算法研究员是说你过去学的bot没有用了，然后我现在全换成大模型了。你不懂，你不懂我不如招一个刚毕业的学生，他懂他的工资还低，他一个人能顶你们十个人，那我干嘛不把你们十个干掉，作为老板一定会这样子。",
      "speaker": "发言人3"
    },
    {
      "time": "01:19:10",
      "text": "我突然想到跟这个相对应的，像现在因为大量的这些互联网公司都有所谓的审核团队这部分的是不是也可以比较，也可以快的用AI这个也可以去替代。",
      "speaker": "发言人2"
    },
    {
      "time": "01:19:22",
      "text": "但是他们成本不高。研究员成本多高？很明显能够看到就是大模型研究员的工资水平现在是涨得非常高。就是这种顶尖的研究员的工资水平就非常高，那一定意味着它能代替了之前很多的人。一下子就会有大量的这种部分。",
      "speaker": "发言人3"
    },
    {
      "time": "01:19:42",
      "text": "就是算法工程师本来是一个非常火热的职业，然后非常值钱的职业。对，结果可能一夜醒来变天了。",
      "speaker": "发言人2"
    },
    {
      "time": "01:19:50",
      "text": "是爷爷醒来两三年这个事就完成了，他不会那么快。但是我觉得2526年其实可能晚一点，26年快一点。激进一点的公司25年会开始搞了，因为他们不需要了，所以这个是挺恐怖的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:20:04",
      "text": "是所以本来我在来之前录这期节目之前，我会觉得作为一个AI方面的小白，我会觉得这样的速度因为在加速度的发展，所以会不会很快。我们就可以见到通用的，然后见到真正的AGI，见到可以涌现的这种AI的出现。但是今天张老师其实给我上的很重要的一课就是这个范式或者这个底层逻辑。其实大模型所谓的深圳市模型跟之前没有特别大的变化，导致了那个极限其实在那里。而这个极限如果想突破它的话，必须得在AI之外的地方，在数学或者是在自然科学这块有突破，或者是两者互相影响。对带来一个突破之后，才可能从现在的这个阶段走向下一个阶段。是的，而目前好像还没有看到这个迹象。",
      "speaker": "发言人2"
    },
    {
      "time": "01:20:53",
      "text": "对我觉得是我的个人观点。",
      "speaker": "发言人3"
    },
    {
      "time": "01:20:54",
      "text": "对我觉得确实。",
      "speaker": "发言人2"
    },
    {
      "time": "01:20:56",
      "text": "是这样的。您总结的非常到位，就是极限就在这儿，花板就是这四个能力。如果你想做推理也没问题，但它一定要限制在一个非常小的场景，而且这个场景里面你要有大量的训练数据。所以为什么大家愿意做数学？数学题目我可以搞到上亿道，然后我还可以生成一些，那它就可以把它做到一个90分、八十多分。但是别的这种领域的推理，你搞不到这么多训练数据，它的结果就很难提升。所以它的天花板就是放在这个位置了。突破的难度是我感觉很大。",
      "speaker": "发言人3"
    },
    {
      "time": "01:21:29",
      "text": "所以这个我觉得对于学术界的研究，甚至是业界研究，肯定是捧在心头的一个大石头。但是对于普罗大众，对于普通人来说，接下来几年可能会看到更加百花齐放的AI应用出来。其实这个事情很像互联网到移动互联网等等的这个过程，对吧？在你诞生iphone之前，对你就是没有办法有很多的移动的APP出来。是那么iphone的诞生又是因为了种种的原因，对吧？对很多的因素集合起来，然后互联网才开始向移动互联网这块切换。只是听下来AI的这个切换，接下来需要一个更加底层的一个范式的变化，或者说一个逻辑的突破。",
      "speaker": "发言人2"
    },
    {
      "time": "01:22:07",
      "text": "但是如果您从场景这个角度来看这个问题的话，他可能也会挺快的对。因为我们看这个人的公司其实是整个社会成本里最高的一个部分，或者比较高的一个部分。但是人工智能做什么？就是替代人。如果我把整个人的总量的20%的脑力劳动力的体力活都给你带掉，那这个部分是有可能的。而且大模型就有可能在这个边界上做到那是10%还是20可能不好说，也许是30。但是只要你是脑力劳动，你的体力活整理一下文件，然后填个报表，这些事情都可以给你干掉了。对，那干掉了就意味着AI具备这块的价值，然后他可以把这20%的代替了。20%那我就用10%的钱来代替，所以它的价值是非常大的。是的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:22:54",
      "text": "现在还没有到那个切换的地步。但是提升辅助如果用我很喜欢那个书，就是银河帝国的时代还没有到来。对，但是让AI来帮助我们做很多事情的这个时代其实已经到来已经到了。以及接下来这两年可能我们会看到在非常多的领域，就像张老师说的，在垂直场景上的一个深入。会是未来两年我会看到很多变化的地方。",
      "speaker": "发言人2"
    },
    {
      "time": "01:23:18",
      "text": "对我觉得会看到很多。",
      "speaker": "发言人3"
    },
    {
      "time": "01:23:19",
      "text": "好，今天特别感谢张老师的时间，然后我觉得我也学到了很多。没有，感谢您邀请大家。如果有任何的疑问或者是想要探讨的，其实我知道在听我这期节目的朋友也有很多这个行业的从业人员，或者是一些投资的人士，我们可以随时的交流。然后下次可能一年后有机会的话，再邀请张老师。我们来回头看一下2025年咱们说的这些事情有没有实现，或者是甚至有没有比现在想象的变化更大，可能也是会有的是的是的，因为毕竟现在是加速度。",
      "speaker": "发言人2"
    },
    {
      "time": "01:23:51",
      "text": "的一个过程中，速度加速太快了。是的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:23:54",
      "text": "好，谢谢大家，谢谢张老师的时间。",
      "speaker": "发言人2"
    },
    {
      "time": "01:23:57",
      "text": "我们下期再见，谢谢。",
      "speaker": "发言人3"
    },
    {
      "time": "01:24:00",
      "text": "Right show in .",
      "speaker": "发言人2"
    },
    {
      "time": "01:24:03",
      "text": "my life.",
      "speaker": "发言人3"
    },
    {
      "time": "01:24:05",
      "text": "I am still. Yeah, i'm still around.",
      "speaker": "发言人2"
    }
  ],
  "lab_info": {
    "summary": "本次对话深入探讨了人工智能（AI）在客户服务领域的革命性变化，强调了大模型在降低迁移成本、加速行业变革方面的关键作用。AI不仅使得原本对小公司开放的市场门槛提高，还促使特定岗位转型，同时在游戏、出海平台等领域展现出广泛的应用潜力。此外，讨论涉及了AI行业年度回顾，特别是深度学习模型在理解和生成方面的新进展，以及深度思考能力对市场的影响。赵琦教授和大卫翁指出，尽管ChatGPT等模型展示了生成式AI的潜力，但其底层逻辑仍基于统计机器学习，存在局限性，如无法进行因果推理或自我能力提升。他们还讨论了AI模型训练的挑战，包括巨大的计算资源需求和高质量训练数据的获取，以及推动AI发展的里程碑事件，如OpenAI的O1O3模型。最后，对话覆盖了AI在金融、医疗等行业的应用前景，以及阿里巴巴的“通义千问”和谷歌的“巴德”等公司在推动AI技术发展方面的努力，突出了AI技术的快速发展及其对未来的深远影响。",
    "qa_pairs": [
      {
        "question": "在大年初一这期节目中，我们讨论了AI行业的一个重要事件，是什么？节目中张琦教授对于AI行业有哪些深入见解？",
        "answer": "是的，我们讨论了Deep Sicky新版本的发布，它在AI行业具有里程碑式的意义，并且证明了节目中关于agent将成为2025年行业最有潜力实现快速发展的应用方向这一结论。张琦教授指出，本轮生成式AI的技术天花板是明确存在的，底层逻辑仍然是微数据训练和应用统计机器学习。尽管Deep Sicky展示了深度思考能力，但它仍是一个人工训练出的智能模型，而非真正具有自我意识级别的智能体。",
        "time": "00:01:06"
      },
      {
        "question": "Deep Sicky新版本的翻译效果如何？",
        "answer": "Deep Sicky新版本的翻译效果非常出色，甚至超越了公认的最适合翻译的DPL模型，无论是普通用户的体验感还是模型本身的训练量和算力要求的压缩，都展现了重大突破。",
        "time": "00:01:06"
      },
      {
        "question": "对于Deep Sicky的出现，您是否认为它代表了颠覆性的成果，带来了世界大不同？",
        "answer": "经过讨论，我们得出结论，虽然Deep Sicky令人震撼，但是否意味着世界因此发生了重大变革，我们不能盲目乐观，认为它达到了OpenAI级别核弹的程度，而需要理性看待这一成果。",
        "time": "00:02:35"
      },
      {
        "question": "张琦教授在AI行业研究领域的背景如何？",
        "answer": "张琦教授是复旦大学计算机科学技术学院的教授、博士生导师，上海市智能信息处理重点实验室副主任，同时也是复旦大学大模型的负责人，他在自然语言处理领域有深厚造诣，发表了两百多篇论文，并著有多本相关著作。",
        "time": "00:03:05"
      },
      {
        "question": "AI行业热潮中，为什么缺少学界视角的讨论？",
        "answer": "在众多讨论AI行业的播客节目中，往往缺乏来自学术界或学界对于这一轮生成式AI狂潮的深入分析和展望，因此希望通过这次机会引入并分享张琦教授的观点。",
        "time": "00:04:12"
      },
      {
        "question": "您自己在日常生活中如何使用AI技术，特别是ChatGPT？",
        "answer": "我日常生活中使用ChatGPT进行日文邮件写作和信息回复，它能根据不同的场景模拟出恰当的敬语和格式，并且具有记忆功能，极大地提高了工作效率，成为不可或缺的工具。",
        "time": "00:07:39"
      },
      {
        "question": "对于AI编程工具如何帮助科研工作，您有什么看法？",
        "answer": "AI编程工具能够快速搭建编程框架，尤其在快速切换不同编程语言和领域时，可以大大降低工作量，节省大量重复劳动时间，如补全代码、规范编写等，从而提高科研工作效率。",
        "time": "00:12:10"
      },
      {
        "question": "2024年curse r出圈是因为它帮助不懂编程的人生成了APP，这是如何实现的？",
        "answer": "curse r平台通过AI技术，即使用户没有编程基础，也能将想法转化为实际的APP。虽然真正的编程过程可能涉及打包、部署等复杂步骤，但curse r在一定程度上帮助不懂编程的人完成了从0到1的转化，类似于ChatGPT等工具，不过它更聚焦于代码场景，并针对特定场景做训练以达到更好的效果。",
        "time": "00:12:55"
      },
      {
        "question": "AI能力边界的核心是什么？",
        "answer": "AI的核心在于场景，并非垂直于某个行业，而是针对具体应用场景进行优化。例如，curse r就针对代码场景进行了深入训练，相较于通用型工具如ChatGPT，在特定场景下表现更优。",
        "time": "00:13:49"
      },
      {
        "question": "生成式AI大潮与之前AI技术的区别是什么？",
        "answer": "这一轮生成式AI大潮的一个重要区别在于其万能性，能够快速回复各种问题。但实际上，AI仍受限于训练数据，对于未见过的场景或常识类问题可能出错，底层原因是训练数据没有覆盖所有可能情况。",
        "time": "00:17:19"
      },
      {
        "question": "AI模型如何决定能记住哪些知识？",
        "answer": "AI模型的知识来源于预训练阶段的训练数据，模型会记住预训练过程中接触到的知识点，但对某些特定规范或特异性强的知识点，可能需要大量的有监督微调数据才能使其具备回答能力。",
        "time": "00:19:44"
      },
      {
        "question": "生成式AI与之前AI技术的根本区别是什么？",
        "answer": "尽管生成式AI能够处理长文本、跨语言、多任务和生成问题，但这四个能力并不是与前代技术的根本区别。真正区别在于，现在的AI可以将各种自然语言处理任务转化为生成式任务，融合在一个框架内，虽然仍然需要训练数据，但不再受限于传统的标签化过程和封闭集合，使得AGI（通用人工智能）的研究成为可能。",
        "time": "00:24:23"
      },
      {
        "question": "OpenAI的科学家是否意识到他们的框架存在极限？",
        "answer": "是的，OpenAI的科学家已经意识到框架存在一个极限，但公众可能由于多任务和生成式的特性感觉其表达很自然且聪明，但实际上底层逻辑仍依赖于预训练。",
        "time": "00:25:31"
      },
      {
        "question": "预训练阶段和后训练阶段的关系是什么？后训练阶段为何重要？",
        "answer": "预训练阶段让模型通过大量数据进行知识记忆和表示学习，而真正的问题出现在后训练阶段。尽管模型可能随着规模增大表现出一定的涌现能力，但在具体任务上，其准确率受限于预训练数据，并且需要针对模型已掌握的知识点精心构造有监督微调的训练数据。后训练阶段至关重要，因为即使模型很大，它所具备的能力本质上来源于预训练数据。要实现更准确的任务，必须在后训练阶段使用与模型紧密匹配的训练数据进行微调。",
        "time": "00:26:04"
      },
      {
        "question": "AI技术迭代的速度是否放缓？",
        "answer": "是的，OpenAI联合创始人伊利亚在一次会议上提到技术迭代正在放缓，并表示ChatGPT等产品的更新有所推迟，OpenAI开始尝试不同的技术路径。",
        "time": "00:28:36"
      },
      {
        "question": "AI工具在学生群体中的应用情况如何？是否所有AI工具都需要深度优化prompt？",
        "answer": "在学生群体中，尤其是被称为“AI原住民”的00后，他们广泛使用各种AI工具，并将其拼凑起来以满足不同需求。例如，GPT Zero用于检测AI生成内容，grammerly用于在线语法和写作辅助，而prompt engineering则是有效利用这些工具的关键。不一定，像curse这样的代码优化工具以及grammerly等改错工具，它们根据特定任务进行了定制化训练，能够直接针对某一场景完成高质量的任务，无需过多关注prompt的优化。",
        "time": "00:30:02"
      },
      {
        "question": "AI工具在场景化应用中的优势是什么？",
        "answer": "AI工具在场景化应用中具有显著优势，它们能够针对某一特定场景进行深度训练和优化，如论文写作、邮件翻译、播客后期处理等，极大地提高了工作效率，节省了大量时间，同时也保持了专业性和高质量的结果。",
        "time": "00:31:36"
      },
      {
        "question": "AI的核心逻辑是否会随着技术发展而变化，例如出现更加通用化的底层逻辑？",
        "answer": "一定会变，但具体时间难以预测，可能是十年、二十年、五十年甚至一百年。需要类似爱因斯坦这样的人才能将统计机器学习架构转换为新的架构，这需要数学工具的支撑，目前在数学上还没有找到因果性的相关数学工具。",
        "time": "00:38:18"
      },
      {
        "question": "统计机器学习的基本原理是什么？是否有科学家或研究团队尝试改革或颠覆统计机器学习？",
        "answer": "统计机器学习的基本原理是将所有事物表示为空间中的一个点，并通过学习一条分界线来区分不同类别。当数据量足够大时，可以拟合出很好的分界面，但对于因果性的学习，则是其一大难题。可能有尝试，但这种0到1的突破没有明确期限，且需要深厚的数学背景和长期努力。历史上如神经网络领域的发展也经历了数十年的低谷期。",
        "time": "00:38:40"
      },
      {
        "question": "AI能否实现类似人类的能力提升，即通过归纳和推理进行提升？",
        "answer": "如果模型无法建立因果关系和归纳能力，就无法像人一样按能力提升，而只能在小场景内运作。实现这一目标的时间点非常遥远，因为缺乏底层数学工具的支持。",
        "time": "00:39:47"
      },
      {
        "question": "在当前AI技术进步中，有哪些让您感到兴奋的应用或服务？",
        "answer": "视频生成是一个令人兴奋的领域，尤其是从2023年初开始，视频和图像生成技术在质量、时长和训练数据量上取得了显著进步，尤其是在中国，由于预训练模型的大规模训练和大量数据支持，相关应用得到了快速发展。",
        "time": "00:44:25"
      },
      {
        "question": "在引入reg系统后，对整个领域有哪些影响？",
        "answer": "引入reg系统后，该领域的技术成果会大幅度提升，但具体的训练方法和优化还在探索阶段。我们撰写了一篇综述文章，并在进行实际工作以完成相关任务。",
        "time": "00:50:01"
      },
      {
        "question": "OpenAI的某些技术为何没有公开底层逻辑？",
        "answer": "OpenAI不会完全公开底层逻辑，因为这涉及到大量的研发工作、尝试和创新，尤其是对于像O1O3这样的核心技术，保持一定的保密性有助于其技术和产品的领先地位。",
        "time": "00:50:26"
      },
      {
        "question": "OpenAI在GPT-4到GPT-4O的转变证明了什么？",
        "answer": "OpenAI并没有一味坚持GPT-5的发展路径，而是通过GPT-4引入音频模态但未整合生成能力，展示了他们在不同范式上的探索，并且在尝试多种路径来解决训练难题。",
        "time": "00:51:27"
      },
      {
        "question": "关于微软公开的GPT-4、GPT-4O和GPT-0 mini的参数量信息，您怎么看？",
        "answer": "这些数据来源于微软的一篇论文，可信度较高。它们展示了微软在不同场景下测试各种模型架构和训练成本的努力，以及其在预训练和后训练阶段的明确目标和技术深度。",
        "time": "00:52:44"
      },
      {
        "question": "对于国内公司DeepSeek在量化投资领域的表现，它是否真的突破了底层范式？",
        "answer": "DeepSeek在量化投资领域确实表现出色，其部分成果是使用较小的训练量实现了惊艳的结果，但这并不意味着在底层范式上有重大突破，主要是得益于MOE架构和极致工程优化降低了训练成本。",
        "time": "00:53:43"
      },
      {
        "question": "预训练之后的后训练阶段为何如此困难和耗资？",
        "answer": "后训练阶段涉及大量标注数据的成本，比如每条数据可能需要专业人员花费数小时进行标注，且这些数据无法复用。同时，随着模型架构改进，标注需求会不断变化，导致标注成本呈指数级增长，只有极少数大型公司能承受得起这样的投入。",
        "time": "00:56:53"
      },
      {
        "question": "对于国内除阿里外的AI公司，在当前环境下如何定位和发展？",
        "answer": "国内大部分AI公司在面临高昂的预训练成本时，可能面临困境。部分公司如李老师所在团队，选择将预训练团队出售止损，并转向to B或to C产品开发。至于具体方向，需要根据团队经验和市场需求来决定。",
        "time": "01:02:30"
      },
      {
        "question": "百川在做医疗方向时，面临的主要挑战是什么？",
        "answer": "百川在医疗领域的挑战是如何考虑如何变现以支撑住一个200亿估值的公司，尤其是在当前医院资金紧张且整个医疗行业面临困难的背景下。",
        "time": "01:02:54"
      },
      {
        "question": "医疗行业的产品可以针对哪些用户群体或方向来设计？",
        "answer": "医疗行业的产品可以面向医院、病人、家属或医生等不同群体，例如开发帮助医生记录病历的工具，在美国市场就有公司通过售卖此类产品获得成功。",
        "time": "01:03:24"
      },
      {
        "question": "面对200亿估值的压力，如何选择合适的业务模式来支撑这样的估值？",
        "answer": "在这种高估值情况下，需要思考如何通过业务模式实现至少10亿甚至20亿的年营收，市销率可能需要达到10到20倍。然而，要实现这样的营收目标难度很大，尤其是在中国市场。",
        "time": "01:04:37"
      },
      {
        "question": "是否存在更适合中国市场的商业模式？",
        "answer": "海外深入人心的订阅制商业模式可能更适合中国，如从C端收取月费或年费，但中国的订阅习惯尚未完全培养起来。",
        "time": "01:04:59"
      },
      {
        "question": "巨头进入对小而美的AI创业公司有何影响？",
        "answer": "巨头的进入就像汽车行业中新势力对传统汽车公司的降维打击，由于巨头拥有更多资源和资本，对于仅依靠单一赛道盈利的小型AI创业公司构成巨大压力。",
        "time": "01:06:12"
      },
      {
        "question": "AI技术对现有公司带来的机会是什么？为何像百度这样的大公司在推进AI搜索方面面临困难？",
        "answer": "2025年将是现有公司利用AI技术提升体验并重新争夺市场份额的重要机会，比如客服行业的AI加持可以显著提高服务体验并降低迁移成本，使得原有行业格局发生较大变化。大公司存在左右互搏的问题，以及对其搜索业务收入的影响，使得他们难以大量投入资源进行自我革命式的创新。",
        "time": "01:09:49"
      },
      {
        "question": "AI为何能在某些领域创造出全新的产品形态？",
        "answer": "AI通过利用大模型的四个核心能力（长文本、跨语言、多任务、生成）创造出全新的产品类型，例如AI测试等，这是传统小模型无法完成的任务。",
        "time": "01:11:24"
      },
      {
        "question": "对于2025年AI领域的展望是什么？",
        "answer": "2025年可以期待agent技术的发展，尤其是基于O1O3范式下的真正具有反思机制和自我决策能力的智能体，将会带来许多应用上的变化，比如更智能化的任务完成和生活助手功能。",
        "time": "01:14:05"
      },
      {
        "question": "传统AI工具和agent之间的主要差异是什么？",
        "answer": "传统AI工具与agent之间的关键差异在于，传统AI工具缺乏一个逐步适应和进化的过程，而agent则具备这样的能力，能够在使用中不断优化和升级。",
        "time": "01:15:27"
      },
      {
        "question": "对于AI发展的未来，您有什么看法？",
        "answer": "我认为2025年在AI领域会看到更快的发展，尤其是agent方面的进展。由于AI范式被广泛接受并取得显著效果，无论是从公司、学术界还是技术复现等方面都有所证明，所以未来在应用场景上大家一定能感受到其快速发展。",
        "time": "01:15:56"
      },
      {
        "question": "AI是否会在接下来几年内实现通用型AGI或涌现能力的AI？",
        "answer": "AI目前受限于底层逻辑和数学等领域的瓶颈，想要突破现有阶段需要在AI之外的领域取得重大进展。虽然短期内可能无法看到通用型AGI或真正涌现能力的AI出现，但在接下来几年，我们会看到AI在更多垂直场景上的深入应用和百花齐放的发展。",
        "time": "01:20:04"
      },
      {
        "question": "AI研究员是否有可能在接下来几年面临下岗风险？",
        "answer": "是的，根据目前AI技术突飞猛进的发展速度，特别是在大模型和多任务集成的应用中，研究单一任务的小模型的AI研究员可能会在2025年或之后被大量取代，因为企业更倾向于招聘能快速适应和改造现有大模型的新人。",
        "time": "01:17:50"
      },
      {
        "question": "AI能否替代互联网公司的审核团队？",
        "answer": "AI在成本上相比人工审核团队具有优势，随着顶尖AI研究员工资水平的提高，AI很可能会在一定程度上取代这部分人力，尤其是在需要大量模型维护和升级的场景中。",
        "time": "01:19:22"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "复旦大学张琦教授深度解析AI行业年度回顾与展望",
        "summary": "本期播客由大卫翁主持，邀请复旦大学计算机科学技术学院教授张琦共同回顾和展望AI行业。张琦教授在节目中深入讨论了AI行业的发展，特别是生成式AI的技术天花板以及DeepSeek模型带来的里程碑式意义。通过张教授的视角，探讨了AI模型的深度思考能力、技术局限以及未来的发展方向。同时，节目也反思了当前市场对AI技术的热情，提供了学界对于AI行业的独特见解和评估。"
      },
      {
        "time": "00:04:12",
        "title": "从ChatGPT到AI应用：对话张琪教授探讨AI在生活和研究中的实际应用",
        "summary": "本次对话邀请了复旦大学的张琪老师，讨论了AI在生活和研究中的实际应用。讨论者分享了他们对于AI行业的观察和体验，特别是ChatGPT在日常生活中的应用，例如处理日文邮件和信息，以及如何应对金融机构研究报告的自然语言处理挑战。此外，还探讨了学术界在AI研究和媒体传播方面的作用和缺失，以及如何通过新的媒体形式，如播客，来填补这一视角的空缺。"
      },
      {
        "time": "00:08:42",
        "title": "大模型对自然语言处理与编程的影响",
        "summary": "自然语言处理领域在大模型出现前，主要专注于从非结构化文本到结构化信息的转换，难以实现有效的文本生成。然而，随着大模型的出现，文本生成能力得到显著提升，对整个自然语言处理研究领域产生了翻天覆地的变化。大模型的引入特别在编程领域展现了强大的潜力，通过提供代码生成、快速切换不同编程语言、降低学习成本以及帮助项目文档的快速补全，极大地提升了编程效率。此外，大模型还使得编程小白能够通过AI平台完成从想法到初步应用的转化，尽管在实际应用中仍需结合一定的技术部署和打包工作。总体而言，大模型在编程和自然语言处理领域实现了从无到有的革新，为非专业人员提供了更便捷的入门路径。"
      },
      {
        "time": "00:14:07",
        "title": "AI能力边界：场景化与通用化的挑战",
        "summary": "对话围绕AI的核心是场景而非垂直行业展开，强调AI工具在特定场景下的高效应用。以Cursor为例，讨论了AI辅助工具如何针对不同场景，如为编程小白和专业码农设计，提供差异化服务。指出当前AI模型，包括生成式AI如ChatGPT，虽然看似万能，但其能力边界在于场景化学习，而非通用能力的提升。AI在专业问题上表现良好，但在人类看来的基础常识问题上常出错，这是因为AI缺乏像人类一样的因果逻辑和能力提升机制，其表现受训练数据和场景限制。"
      },
      {
        "time": "00:18:03",
        "title": "GPT4训练数据与模型知识来源研究",
        "summary": "对话围绕GPT4模型的训练数据和知识来源展开，探讨了模型在预训练阶段如何通过大量数据记住特定知识点。指出在有监督微调阶段，加入大量不相关数据可能反而会降低模型性能。此外，讨论了模型对于高特异性和高频率出现的知识点的识别能力，以及如何通过特定的训练数据量来提升模型的特定任务表现。"
      },
      {
        "time": "00:21:06",
        "title": "生成式AI与传统自然语言处理的区别及挑战",
        "summary": "对话讨论了生成式AI与传统自然语言处理模型的区别，强调了生成式AI在处理长文本、跨语言、多任务以及生成能力方面的突破。同时，也指出了生成式AI面临的挑战，包括需要针对各种具体场景准备大量训练数据、任务种类的无穷尽以及与实际应用需求之间的差距。此外，对话还提到了自动驾驶领域的类似挑战，即面对实际场景中无穷无尽的复杂情况。"
      },
      {
        "time": "00:24:23",
        "title": "大模型的多任务处理与训练挑战",
        "summary": "讨论集中于大模型的四种核心能力：长文本处理、跨语言、多任务和生成能力，特别是多任务处理的效率和意义。通过将不同任务转换为生成式任务，能够减少对多个特定模型的需求，使得模型在处理诸如翻译和实体抽取等任务时更加自然和统一。然而，尽管多任务和生成式框架提高了模型的灵活性和表现，模型的底层逻辑依然依赖于大规模预训练数据。这导致在预训练数据未能覆盖的领域，模型可能会出现错误或不准确的回答。此外，讨论还涉及了模型训练中的挑战，包括后训练阶段需要精心挑选和匹配的数据，以及对模型记忆知识点的探测，以确保训练数据的高效利用。这些挑战凸显了通向高级通用人工智能（AGI）的漫长道路，即使当前技术在特定任务上取得了显著进展。"
      },
      {
        "time": "00:28:06",
        "title": "AI技术迭代与应用的未来展望",
        "summary": "对话探讨了AI技术，特别是生成式AI的进展与局限性，认为当前的AI技术虽有进步，但因其底层逻辑未变，存在一定的极限。讨论提到了OpenAI的联合创始人对技术迭代放缓的观察，以及ChatGPT 5的未推出。此外，讨论还转向了AI在实际应用中的角色，特别是年轻一代如何将AI工具应用于各种场景，如语法纠错和内容检测，强调了将不同AI工具组合使用以提高效率的方法。"
      },
      {
        "time": "00:30:55",
        "title": "大模型在特定场景下的优化与应用",
        "summary": "对话围绕大模型在特定场景下的优化和应用展开，强调了场景化训练的重要性。通过定制化训练，模型能够在特定任务上表现更佳，如代码优化、语法纠错和信息检索等。讨论了使用AI如GPT辅助论文写作和语言改错的高效性，指出AI显著提升了工作效率，特别是在语言重组和上下文衔接方面，极大地节省了时间。此外，提到了AI在生成文本时的优缺点，以及如何结合AI生成的内容与个人表达进行修改，以适应不同的语言习惯和需求。"
      },
      {
        "time": "00:34:31",
        "title": "AI工具在学术研究和日常生活中的应用",
        "summary": "对话围绕AI工具在学术研究和日常生活中的应用展开，包括使用AI辅助撰写日文邮件、沉浸式翻译插件、以及播客后期处理软件。讨论了这些工具如何通过预训练和丰富的语料库，根据特定场景和需求生成高质量的内容。此外，还提及了使用AI工具可能带来的负面影响，如语言能力的退化，以及对订阅制商业模式的讨论。"
      },
      {
        "time": "00:37:34",
        "title": "AI技术的现状与未来发展",
        "summary": "讨论了当前AI技术，特别是基于深度学习的大模型，其核心逻辑和限制，以及未来AI可能的变革方向。指出当前AI技术基于统计机器学习，依赖大量数据来拟合和预测，但无法学习因果关系，这限制了其通用性和推理能力。未来AI的突破可能需要新的数学理论和框架，以及自然科学的发展。同时，讨论了AI行业近年来的显著进步，如ChatGPT的出现和其在应用领域的广泛影响，表达了对AI编程和辅助工具等领域的兴奋和期待。"
      },
      {
        "time": "00:43:30",
        "title": "2023年AI图像和视频生成技术的突破与进展",
        "summary": "对话围绕2023年AI图像和视频生成技术的显著进步展开，讨论了年初的sora项目作为早期尝试，以及后续在图像和视频生成领域的快速提升。讨论指出，虽然原理可能不复杂，但训练数据量巨大，且在ChatGPT等技术突破之前，投入如此大量资源训练模型是前所未见的。随着技术的进步，中国在AI图像生成领域取得了显著成就，这得益于大量预训练数据和对工程资源的有效利用。讨论还提到了文本生成的挑战以及如何通过技术手段提高生成质量，例如通过图像和文字的分开生成来避免乱码问题。此外，讨论还提到在理解物理世界方面的进一步探索，认为这是未来的一个重要话题。"
      },
      {
        "time": "00:47:03",
        "title": "O1O3范式对推理模型的革命性影响",
        "summary": "讨论集中于O1O3范式在推理模型中的应用及其带来的革命性变化。这种范式允许模型在推理过程中进行自我监控和修正，从而显著提升推理的准确性和容错率。通过引入反思机制，模型能够在推理路径中进行多次修正，类似于人类在解决问题时的迭代过程，这在数学题解答等任务中显示出20%的性能提升。此外，该范式借鉴了弱到强的学习路径，强调了agent在环境交互中的自我规划能力，这将对众多领域的工具和系统产生深远影响，尤其是在知识问答和搜索引擎优化方面。尽管OpenAI并未公开O1O3的具体训练逻辑，但其发布已激发了业界的广泛研究和复现尝试，显示出这一范式在推动人工智能技术进步上的潜力和重要性。"
      },
      {
        "time": "00:53:22",
        "title": "Deep Seek在金融量化领域的突破与挑战",
        "summary": "Deep Seek在金融量化领域取得了显著成绩，尤其是在利用相对较小的训练量实现高质量模型方面。其成功部分归因于采用MOE架构，有效降低了训练成本，并且团队在工程优化上有着阿里系的极致化特征。尽管如此，后训练阶段的挑战极为艰巨，涉及到大量的数据标注和成本投入。预训练虽有开源资源，但后训练阶段的强化学习需要大量高质量标注数据，这在中国环境下成本高昂且难以承受，对模型公司构成巨大挑战。因此，尽管模型架构和预训练取得进展，如何在成本和效果之间取得平衡，仍是一个亟待解决的问题。"
      },
      {
        "time": "00:59:27",
        "title": "大模型预训练的成本与AI公司的发展方向",
        "summary": "对话围绕大模型预训练的成本以及AI公司的发展方向展开。提到了深圳市的项目和国内所谓的“六小虎”及“四小龙”在AI视觉领域的状况，强调了这些公司在特定场景如视觉安防的深耕，但指出其难以将技术复用到其他场景。进一步讨论了预训练大模型的高昂成本，包括数据清洗、模型架构调整等，指出只有像字节跳动和阿里这样的大公司才能承担这样的费用。同时，探讨了AI公司在面临高估值和融资压力下的发展方向，包括to B和to C的产品策略，以及在医疗等特定领域的应用和变现挑战。最后，对比了海外订阅制商业模式的优势，以及中国AI公司在培养订阅习惯方面的不足，强调了资金雄厚对于推动AI技术发展的重要性。"
      },
      {
        "time": "01:06:11",
        "title": "AI技术对传统行业及创业公司的影响",
        "summary": "对话探讨了人工智能（AI）技术，尤其是大模型的出现，如何对传统行业，如客服行业，带来巨大变革，提升用户体验并改变市场份额的竞争格局。同时，讨论了AI技术对于创业公司的潜在影响，指出小公司难以进入客服等需要大量工程量的领域，而应专注于开发创新型产品，利用AI的长文本处理、跨语言、多任务和生成能力。此外，分析了大型科技公司如百度、字节跳动和Google在AI应用上的战略考量，包括他们面对的内部竞争和商业模型转变的挑战。"
      },
      {
        "time": "01:13:13",
        "title": "2025年AI领域的发展与期待",
        "summary": "对话讨论了到2025年AI领域可能的进展，特别是关于agent（智能体）的实现及其在商业和服务领域的应用。提到了AI的自我革命和自我决策能力的增强，以及这种能力如何改变行业格局和提升工作效率，如通过智能助手帮助完成任务、规划行程等。还提到了一个名为David的AI平台，其通过不断学习和反思，能够提供类似实习生不断进步的服务。预计2025年在AI agent技术上将有显著发展，类似于2024年AI图像生成技术的快速进步。"
      },
      {
        "time": "01:16:32",
        "title": "人工智能加速发展与未来展望",
        "summary": "讨论了人工智能领域，特别是深度学习和大模型技术的快速发展及其对社会的影响。强调了自BERT模型问世以来，自然语言处理技术的广泛应用和加速进步。讨论中提到了AI研究者可能面临的就业压力，以及大模型技术可能对审查团队等传统岗位的替代。此外，讨论还涉及了通用人工智能（AGI）的实现可能需要在数学或自然科学领域的突破，以及AI技术在替代部分脑力和体力劳动方面的潜力和价值。最后，表达了对AI技术未来几年将在各个领域产生更广泛影响的期待。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "Deep Seek新版本：体现了反思和学习能力，压缩模型训练量和算力要求，具有里程碑式意义。"
                },
                {
                  "children": [],
                  "content": "翻译效果提升：使用API接入沉浸式翻译插件，翻译效果显著优于DPL模型。"
                },
                {
                  "children": [],
                  "content": "技术天花板：本轮生成式AI的技术天花板可见，深度思考功能揭示其人工训练本质，非自我意识级别智能体。"
                }
              ],
              "content": "生成式AI的里程碑意义"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "Cursor：专注于代码生成，显著提升编程效率，尤其在快速切换语言和框架方面。"
                },
                {
                  "children": [],
                  "content": "场景化AI工具：如Graamly（语法纠错）、GPT Zero（AI内容检测），针对特定场景优化，提升工作效率。"
                }
              ],
              "content": "AI编程工具的革新"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI能力边界：基于场景化学习，而非通用化能力提升，受限于训练数据和特定场景需求。"
                },
                {
                  "children": [],
                  "content": "知识来源与局限：AI的知识来源于预训练数据，特定场景需专门训练数据，存在知识盲区和泛化局限。"
                }
              ],
              "content": "场景化与通用化的界限"
            }
          ],
          "content": "2024年AI行业回顾与进展"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "反思与学习能力：O1O3范式引入反思机制，提升推理能力，预示着真正意义上的agent将在2025年开始出现。"
                },
                {
                  "children": [],
                  "content": "智能体自我决策：agent将具备自我决策和修正能力，应用于复杂任务如行程规划、订票等，提升智能化水平。"
                }
              ],
              "content": "Agent成为关键应用方向"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "行业格局重塑：AI加持下，传统行业如客服、搜索等领域将迎来格局变化，老大、老二、老三的竞争将更加激烈。"
                },
                {
                  "children": [],
                  "content": "创业公司机遇：创新型产品，尤其是能充分利用大模型能力（长文本、跨语言、多任务、生成）的创业公司将迎来机会。"
                },
                {
                  "children": [],
                  "content": "AI研究员的未来：2025年可能面临大规模裁员，大模型的多任务处理能力将替代大量传统算法研究员的工作。"
                }
              ],
              "content": "商业与技术变革"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "底层逻辑与极限：当前AI技术基于统计机器学习，存在固有局限，突破需数学或自然科学的创新。"
                },
                {
                  "children": [],
                  "content": "场景化AI的繁荣：尽管通用AI受限，场景化的AI应用将迎来爆发，深度融入各行各业，提升效率和用户体验。"
                }
              ],
              "content": "技术与应用的双轨发展"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "脑力劳动替代：AI有望替代20%-30%的脑力劳动，包括文件整理、报表填写等，显著降低社会成本。"
                },
                {
                  "children": [],
                  "content": "职业转型与挑战：AI研究员、审核团队等职业面临转型压力，需适应新技术带来的职业变迁。"
                }
              ],
              "content": "社会与职业影响"
            }
          ],
          "content": "2025年AI行业预测与挑战"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "预期2025年将是AI技术与应用深度整合的关键年份，agent的兴起将引领新一轮的技术与商业模式创新。"
                }
              ],
              "content": "AI行业正处于加速发展阶段，未来两年将在垂直场景应用上实现深入发展，尽管通用AI的突破尚需时日，但AI辅助人类工作与生活的时代已经到来。"
            }
          ],
          "content": "结论与展望"
        }
      ],
      "content": "AI行业年度复盘与未来展望"
    }
  }
}