{
  "pid": "648b0b641c48983391a63f98",
  "eid": "64e040eb80c9ec4c5faf2868",
  "title": "这个男人帮 5 万个 AI 应用接上了大模型 | 对谈 Dify 创始人路宇",
  "task_id": "pev8qdo42rxxnkga",
  "transcription": [
    {
      "time": "00:00:02",
      "text": "上面你在。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:18",
      "text": "我们今天请到的嘉宾是defy创始人陆羽。陆羽是我们上半年合作的钻石客户项目，也算是合作伙伴。我上半年自己看到的AI里面最喜欢的项目之一，也是市场上很多人都非常喜欢，名气还蛮大的一个项目。我们定位其实叫LLM off。那你给大家大概解释一下这是什么电影。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:39",
      "text": "LM ops其实这个概念很显然是衍生自原来的devo s我原来就是做devo s产品的，我在开发者工具这块东西可能做了五六年的时间。传统的devo s它指的是软件的研发和运营一体化，是说你的运营过程是持续迭代的和开发之间是快速反馈的。到了现在大模型的背景下，自然我的背景会去想一个基于大模型的，我们说它是AI原生应用也好，或者什么应用也好，它背后需要哪些运营过程。我们认为这里LMOS和devo s它有一个最接近的一个地方，就是它都有一个需要持续的迭代改进的一个过程。也就是说你想基于AI去做一个应用。如果你不去接受市场的用户的快速的反馈，去纠正你原来无论是prompt也好，你的这个agent也好，模型也好，去改进它的话，它就没有办法去达到你想要预期的那个结果。所以它不是和传统软件研发一样，那种瀑布的，就是一次性干三个月，然后就上线了那种，所以这是区别。所以说define这个m offs，也就是说我们是一个基于大模型的应用开发的一套完整的技术栈。既包括了一个开发框架，也包括了一个运营工具。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:48",
      "text": "Defy我觉得很多人第一次听会误认为是那个web 3的那个defy，其实是DIFY.",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:54",
      "text": "其实我们就是do IT for you，而且这个名字是GPT帮我们起的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:58",
      "text": "对，所以其实就是develop加Operate，就是研发加运营。完了像你刚才讲传统的develop，它其实也有of运营那部分，对吧？那个的运营跟现在的这个大模型的运营的区别是什么？",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:11",
      "text": "在传统的devaux里，这里的运营其实翻译过来应该不叫运营，叫运维。他运维指的是偏基础设施的服务器监控可用性，它本质上更多的是看一个叫做应用的可用性，性能好不好。但是我们到了m ops的时候，我们去定位这个ops，我们把它定位是更偏向于运营。因为我们这里的运营指的是说很多非技术人员去参与到一个AI应用背后的塑造定义的过程中。因为我们相信AI应用绝对不是说像原来一样，少数几个工程师然后写完之后就上线，它就定型了。他实际上有大量的懂业务知识的业务人员、运营人员、销售人员，各种各样的人员，对吧？他们把他的经验去灌到大模型里面。所以说我们认为这个office是向更多人去开放的一个概念。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:01",
      "text": "现在你们应该算是这个领域的绝对第一名，就是几个指标，一个是现在的youtube star应该到快7000了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:09",
      "text": "对，我们差不多从五月中旬开园到现在有七天star。我们我们的那个安装数，我们在docker镜像拉取这个安装数也能看到，差不多有一万外面有一万多个安装的这个私有化部署的版本。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:21",
      "text": "Docker 1万安装数是什么意思？我今天会扮演听众的角色，所以有的问题我觉得大家不太理解，我会问一下。好的，其实是我也不太理解。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:31",
      "text": "简单来说，你可以理解为我们defied私有云的版本，被打包成了一个镜像或者说压缩包。你可以理解为压缩包，这个压缩包我们可以跟踪到下载的次数。它下载不是这种简单的浏览器下载，它是通过一个命令下载，它必然是会安装到它的服务器上的。OK那类似于一种下载调用的感觉，你可以理解为define在外面有接近一万多的私有化的安装数，以及说我们公有云的云服务版本，现在能看到4万多个应用。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:58",
      "text": "真的，大家用它做出来的大模型的应用。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:02",
      "text": "对，因为我们今年也看了很多AI产品，我们前面几周也在跟用户一直做直面会，或者各式各样的活动。我发现define受众开发者，它的质量是非常高的。第一是他们跟我们讨论非常严肃的问题。他们是想拿大模型的能力去做各种的应用开发投产，无论是面向市场的创业，还是说卖给甲方，还是说满足公司里的各种业务需求。哪怕仅仅是一些实验性的，都是非常严肃的情景和严肃的需求。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:34",
      "text": "其实是自从比赛开始，我们才比较关注github这个平台的。我们之前其实看开源干什么，这些不多，我其实自己特别喜欢github的。现在我觉得里面真的是有很多人在无私的奉献，而且他可以收到很多全球的正反馈，大型同性交友社区。对，我们现在也会经常每天去扒一下说哪些项目他得了多少stars，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:57",
      "text": "Defy当时我记得是我们聊的过程当中上点，然后几天就冲到了大概两三千还是34。对，我们是差不多一周充到3000。是，但你们其实也没做太多的运营动作，我们真的除了发twitter就几乎没有做运营。那你的twitter就我就几百粉丝还是多少粉丝，现在是有好几千，我说话都很小心。对对对，你说话一定要小心。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:23",
      "text": "但后来我们听说其实给hub上还也有基于star的SEO。我们之前其实有两年看消费品牌，不管是跨境还是什么也好，我发现有有就是刷单，刷空包。Github上现在其实很多投资人也会去看，对吧？去用sas来衡培养一个四大驱动开发。对对对，这个是事实，现在真的是有很多基于github的SEO去做啥。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:47",
      "text": "我就会收到很多邮件，老外的或者什么印度的哪里给我发什么，你给我多少钱，我们可以帮你刷到多少的，我确实收到过很多，我没有理他们而已，我也不知道做这个事儿太大了，我肯定不敢做这个事儿。Github现在的star是有水分的，因为今年本身AI就给他注水了，不同题材的项目也不能放到一块。比这种全自主agent的，它自然比我们这种什么IM ops的品类可能要回一个档次。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:13",
      "text": "它其实就跟文章是一样的，对吧？你是一个热点主题，自然人流量就是高的对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:19",
      "text": "但是有别的手段。比如说我们看一个项目可以看到别的数据跟它这种惯常性的在用的数据关联。比如说我们看我们的镜像被拉取的次数。如果是一个python项目，可以看到python包的被拉取的次数。什么NPM的也会有NPM前端的包的拉取次数。看这些数据会比单纯的看star要靠谱一点。你可以看一下google上搜索的趋势，几个数据要结合到一块儿去看你能更反映出这个数据的现实。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:48",
      "text": "因为github上有很多开发者用户是今天打开一个项目刷一遍，太牛逼了，点下心就跟浏览器里收藏一下，然后关掉了，这是很多人的行为模式。第二是github它本身有马太效应，它有日榜、周榜、月榜。强者越强，就是你上了榜之后，你会突然又又增量一部分，这都很正常。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:07",
      "text": "对那我们反正今年看了很多项目，所有人基本也都在问。说到底现在市场上真正能落地的AI项目有什么？我不知道在你看来，因为你上面有这么多，你说四万多个应用，对吧？里面到底有没有哪些规律或者什么是靠谱。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:22",
      "text": "的之类的，我们一层一层往下看啊。首先是模型层面，模型层面现在我们看到的是OpenAI明显是模型领域的领军者。它无论是在模型能力上，还是我们说API接口，也就是说它提供的功能上都会比其他模型要好出这么一大截，可能是一个八十多分的水平。第二名可能cloudy或者其他的，可能就是在六七十分的水平，离他有一定差距。然后我们还能看到很多拿开源模型的这种拉玛什么的，各种去折腾这些的都有。但是我们认为首先你想现在去做一个离生产离落地最近的，首选的是OpenAI的模型。当然咱们今后可以换掉。比如说你看到更好的国产的或者开源的模型，可以换掉这个模型层。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:04",
      "text": "你接入进去之后，你紧接着就会去定义你这个应用。我们现在从简到复杂，可以把这个应用的中间的服务层可以定义几个级别。最简单那是说我们叫prompt a service，它是由几个简单的prompt组成的。比如说你想去做一个文法的纠正，或者说评论的积极还是消极这种分类，这是大模型的基础能力，这是一种应用，这种显然它不能去作为独立的应用去做。它可能是你原来的应用的增强，或者说你可以把它封装成产品化的应用。比如说jasper人家听说过帮你大量做这种市场文案这样的应用，这是我们见到的最简单的第一类应用。然后再往上基于私有的数据。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:44",
      "text": "因为大家知道这个OpenAI这样的模型，大部分数据是截止到2021年的。我们就会给他去提供这个私有数据搞进去的这个方法。让大模型了解一个私有的数据有两种方式，一种是说微调这个模型本身，另外一个就是做模型的evidence。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:01",
      "text": "模型的emda就是一种把私有内容嵌入到prompt里的一种也叫prompt工程的一种方式。它基于大模型现有的能力，再加上一个大家理解为一个外脑去集成你各种的私有各种的知识库搞进去去，这是一种方式。这样的话你的能力大模型的回答的问题就不仅限于它现在有的东西，而带有了你自有的体验类的或者说一些知识。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:24",
      "text": "但emda这一步，私有的是什么时候去调用的呢？它跟prompt的区别具体是什么？",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:30",
      "text": "Emd ding你可以。理解为它是用户或者开发者调用大模型前的一个prompt的组装过程，我们叫event嵌入。其实嵌在prompt里的，比如说你现在拿GPT这样的接口，可能有8K对吧？8K的这么一个talk。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:46",
      "text": "比如说我们大模型说今年曲凯老师做了哪些项目，对吧？那大模型是不知道这个能力的。但是在回答这个问题之前，其实像defy这样的产品，我们就巧妙的把你的这个问题和我们已经有的向量数据库或者其他关系数据库里面的各种数据去组装成一个完整的问题。就是说可能组装成其他老师是谁，对吧？他今年我们搜索到今年在做的项目是可能有哪些，用户问了什么问题，这几个东西拼成一个更长的一个prompt给到大模型之后，大模型基于这些信息去做了一个文字的生成过程。这样的话他基于所有已知的信息来好好的回答你这个问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:24",
      "text": "调用的信息对于大模型来讲，它其实它就是prompt的内容。对他来说只是一个prompt，所以有可能对他讲，他觉得这个人发了一段超长的prompt.",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:35",
      "text": "你可以这么理解，没有问题。对，只不过说我们把它叫做prompt工程的原因是我刚才说的这过程很简单，但实际在做的时候会有很多工程细节，比如说一个8K的prompt，因为一共有8K，是你就得知道说我得命中什么词儿，命中什么样历史的私有数据塞进去在多少。比如说一个8K的这个上下文指的是用户提问占了一部分，然后你命中的信息占了一部分，一条也是五条也是十条也是多少。然后还要给他回答问题预留出prompt，就是总共的容量是8K那么这里字符或者说talking的分配就会有很多工程问题。明白，这里还没有涉及到向量数据库的部分，这里实际上用到了向量数据库。对，就是evidence其实会用到向量数据库。对，evidence本身不用，但是evidence搜索到的一些自有的数据是用到了向量数据库库的相似度匹配的一种功能。它有点类似于搜索引擎，但又不太一样。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:32",
      "text": "对它核心也是为了节省8K的token对吧？我可以这么理解对吧？是的，你再回到刚才你讲另外一条，就是三的微调对吧？但好像微调我觉得一开始的时候大家来讲的比较多。我们记得我们2 3月比较早期的时候聊相，大家都问说你们是不是fine too fine to find？后来好像越来越少人讲了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:50",
      "text": "坦率讲我们做理发这个项目，刚开始我甚至不叫define，我记得当时叫AI timer，AI驯兽师。当时我们最早定义项目的时候，其实我们就想做翻车。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:02",
      "text": "因为我们觉得这个名字还挺烂的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:04",
      "text": "特别烂。对但当然很早期很概念期，我们认为说想把大模型塑造成自己的样子。因为你想在2 3月那个比较早期的时候，每一个开发者看到大模型的时候都非常兴奋，想我是造物主，可以去做一个自己想要的这个AI一个形态出来。第一想到的就是我可以去调整模型，微调。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:23",
      "text": "但是微调这个事儿不太好操作。第一个是因为他要求的数据量蛮大，而且要求许多的QA形式的样本。比如说我想让大模型知道徐凯老师是谁，那么想让大模型知道这个数据，基本上要这个问题换着花样问问20遍，再换着花样回答20遍，再交给他，就灌进去，他可能才能达到这个效果。其实这个数据准备的过程中非常麻烦，因为你可能就没有这样的数据。你可能胡编乱造或者来自用户的回答，你得有这个数据。而且你让他学习更多东西，你就得有更多这样数据。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:00",
      "text": "还有一个点就是微调的时候，实际上是要把一个模型去加载到你的GPU显存里面的。就是它非常吃资源。所以说如果说你自己的开源模型，如果你要做微调，你可能需要运行那个模型，就是我们叫推理这个模型的机器配置的2到3倍。如果你是用OpenAI这种商业模型，他可能会给你一个微调的API。你把数据喂给他，那么可以微调。所以微调其实是一种不太划算的，只有在特别必要的前提下才需要用的一种能力。它对于大部分开发者来说还是门槛太高了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:33",
      "text": "所以其实刚才讲的那个场景，我觉得就是大家用embedding能够变相的去解决这个问题的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:13:38",
      "text": "对我当时我把大模型本身跟大模型本身能力的工程化，我当时写了三步放在我们blog上。第一步是放在工程本身，第二步是embedding，第三是微调。这基本上就是从易到难的三种选项。就是基于你的情景，你想怎么做，你可以选择一个划算的方式。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:56",
      "text": "比如说一个什么典型的情况，你觉得更适合使用finding，而不是用prom或者你bedding。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:02",
      "text": "比如说你希望一个大模型在没有很复杂的prom的情况下，它默认回答的风格。比如说你做了一个AI是用来写诗的，他你想他写的诗非常接近你想要的这种风格。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:16",
      "text": "就是他更普适的对这个大模型的性格进行了改变。对对对，是是是，OKOK明白。这里面还有个东西是few shot，是吧？Few shot是在哪一步的？",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:27",
      "text": "One shot full shot，它也是prom的工程的一种技巧。实际上是我看到论文是非常有用，它能对你的大模型回答的结果符合用户预期的这个概率能净提高百分之二三十。解释一下，就one shot few show实际上是在里面去给它一个小样本或者多样本学习。因为文本大模型它本质是一个文本股权机制，就说你告诉他一堆东西，他试图在你的后面去玩文字接龙，在后面拼。但是你只给他创的情况，其实是给他一个指令。比如说你说你让他写一首歌，他歌词应该是什么样的风格，那首先他要做的事是理解你说的这个东西。你说咱俩之间沟通，可能我跟你说一个你都不一定能理解。我可能都要举个例子，大模型更是这样。所以作为一个文本补全的这么一个原理的一个模型来讲，你给他一个或者三个五个例子时候，实际上是在对你的指令进行一个补充。让他去在他的参数里面去寻找更接近你想要的这个东西的一个结果。所以说我们如果说想控制大模型的回答这个准确度，那这个可能one shot few shot是必不可少的一个技巧。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:38",
      "text": "这个基本就是比较浅层的，所有的可能大家能用到的接触到的东西了，对吧？再往深就是推理，就是真的是从再去自己去模型之类的东西了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:48",
      "text": "这里就不得不说这个agent，我们前面说这个tom的工程，再说到embedding，再说到模型本身，都是在解决一个问题，就是模型在单次绘画的时候回答什么的问题。但是我们在考虑一个复杂的情境中，比如说我要一个AI的机器人帮我去订一张火车票机票这样竞争它。其实模型需要一个多轮对话或者说多步的推理过程。这个推理过程我们把一系列的能力封装进去，它就是所谓的agent的一个技术。Agent就是说意味着让大模型利用它的推理能力，利用它的上下文去反复的去推演和结合他手上可以用的这个工具。工具是打引号的，就是比如说搜索的工具，上网的工具，要API的能力等等。去完成一系列连续的动作，最终达到一个目标。所以这个就是agent。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:39",
      "text": "现在agent有3种，第一种是纯手工编排的。怎么讲？纯手工编排就是你第一步干嘛，第二步干嘛，并且调什么工具，那还叫一阵子吗？它不是一个编排的，就是颤，就是一个纯粹的是RPA也能实现吗？对，RPA第二种是完全自主的agent，但是这个自主agent非常的不可控。其实我们现在在探索一种中间形态，用了部分的编排的能力，在混合了他一些自主的能力去实现一个相对可控的状态。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:09",
      "text": "以及反过来，如果一个agent它表现比较好的时候，就完全达到预期手，我可以把他的动作和一些工具反过来预存成一个编排过的一帧的，相当于它完整的进行了一次推理，达到效果还不错。这个过程是可以重复的，我可以把它存下来。当AI有一系列动作表现好时候，你得激励他就反复去做这件事儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:28",
      "text": "跟养狗有点像，巴普洛夫的狗是吗？巴普洛夫的狗，但我其实一直没太理解，就是auto GPT出来以后，应该是最近几个月以来，好像sa最多的最火的跟大模型相关的一个概念了，对吧？但我其实从来说的一直没有特别理解，为什么他一出来引起这么大的轰动。因为在我的理解来看，我们自己在很早时候就提过说AI大模型发展的方向应该是从copilot到pilot是吧？其实本质上来讲就是人介入越来越少的这个过程的人介入到足够少的时候，它自然就是一个自动的系统了，对吧？它自然就是一个A智能的概念，我觉得这是一个点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:05",
      "text": "另外一点，听起来你刚才讲的那个auto GPT的本质上来讲就是给他一个嵌套的逻辑，对吧？我先问你一个问题说你怎么拆解这个问题，然后我再给你一个指令，那你按照拆解你自己做出来，我觉得是一个非常简单直接的一个概念。对我不知道为什么大家现在就不管是从早年的auto GPT还是到现在的agent概念这么火。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:24",
      "text": "为什么会这样？包括我们都是对agent这个概念非常兴奋的一群人我相信很多开发者都一样，因为我们现在已经明显看到了AI能提高人的效率。现在是叫什么？现在叫做。帮你更快的完成一件事儿，很快就会变成说帮你完成一件事儿。再往后就是帮你替代一个人。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:47",
      "text": "就是human的look的程度，从人工要强介入到人工不介入的一个两端。对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:53",
      "text": "因为agent它的这个推理过程实在是太接近人脑的过程了。我们总体上相信agent到了一定的成熟度之后，他就是一个员工。为什么大家对agent和开源模型这么热衷？是因为我觉得他就实现了一种这个时代的技术平权。一个工程师，一个技术人员，他们从来没有如此接近一个这么强大的武器。虽然它成熟度不高，但大家想到的是，当我有了这个东西，我可能可以以一敌百，我可以说和大公司去拼一拼，做各种我想要的事情，所以这个东西他们来说是实在是太有吸引力了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:28",
      "text": "是这个我肯定是同意的，这个vision肯定也是好的。我就说他我感觉agent它只是可拍照的概念一个自然的延续，我觉得它不是一个质变或者多大的一个跃升的感觉。对，anyway, 对，但agent我们现在看起来大家对他最大的诟病就是它的成本。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:47",
      "text": "有几个问题。一个是它的上下文窗口还不够。因为你要出做一个较为复杂的工作，你需要一个非常完备的一个上下文。也就是说比如说你想写一个软件项目，这个软件项目本身可能正常来说都是十万行代码以上。那么意味着说大模型在做这个事的时候，必须把这十万行的代码全部装载进去去做第一个上下文窗口。我们相信这个问题随着时间可以解决。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:10",
      "text": "第二是模型本身推理的质量。我们现在比如说看到GPT4，它的推理能力非常好啊，但是它偶尔也会出错，我们可以去试。比如说那个ChatGPT，它自带的那个代码解释器，它本身也就是一种编程agent的。你给他东西，他可能一般还要反复自己纠正几次达到效果。也就是说他自己承认他第一次推演的结果可能是错的，或者信息不完备的。就是说推理是这样心态不够，这个我们相信也能解决，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:35",
      "text": "第三个就是工具的质量，我们认为就是一个agent的技术栈，里面包括了大模型，也包括了我们本身的一些推理算法，推理逻辑以及prom的工程的一些技巧。还有工具解决一个情景，需要哪些高质量的工具，可以去满足各式各样的需求。比如说我之前我们做过一个内部的工具，让大模型去辅助软件工程师帮助他们完成API的自动化测试。这个自动化测试过程中，首先要去检查所有的API。我们发现市面上所有的这个API的定义的格式语言都很长，装到达摩心里就很慢，或者残缺的不够了，被裁剪了。我们实际上就自己发明了一个可能只有一半长度的这么一个语言来解决这个问题。所以说这里有很多工具层面的问题，也需要其他技术去适应这个大模型。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:20",
      "text": "明白，你刚才其实提到了这个大模型的局限的点对吧？一个是上下文关联长度的？然后这个其实类似于上下文下文记忆的问题，长文记忆的问题，还有就是成本的问题。对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:32",
      "text": "还有什么呢？还有比如说还有幻想，还有注意力不集中。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:37",
      "text": "注意力不集中指的是错记漏记。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:39",
      "text": "并不是因为我我前面提到大模型，它是一个文本补全机制。比如说你给他一个5000字的prompt，它会接近尾部的那些。对，越接近的它的权重越高。所以这个权重其实我比如说咱俩现在聊天，我给你吐了1000个字。其实你听我话讲完之后，你不管我可能说了很多废话口水话，你都能抓住我的重点。因为这里不仅是你作为人类的高超的理解力，你还能感受到我的这个情绪、停顿这样东西。但大模型基于文字想去获得这个信息是比较困难的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:10",
      "text": "对我其实跟我们同学也经常提这个点，就是抓重点这件事情人都很难做到。不同的人让他读一篇文章，每个人抓的重点都是不一样的。对，更别说大模型了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:20",
      "text": "也就是说在现在大模型眼里，因为现在还没有进入全面多模态的这个情况下，基于文本你给他5000个字，每个字对他来说权重是一样的。是啊，你这么理解这事儿就好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:30",
      "text": "对，但我听过有一种解决方案是在用另一个大模型帮助这个大模型，对吧？我先帮你把这5000字总结了，可能问这个大模型问题，你帮我把这5000字总结了？抓一些核心的重点，或者让他记一些核心的重点，然后两个模型配合着来用，我觉得这个是一种解决方案。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:46",
      "text": "我觉得这个还是需要一些人工的介入。完全自主化的情况下，其实并没有解决这个问题。因为你说的这个就是上面的优化，把一个长的做成短的。但是首先前提是他自主的完成这个从长到短的过程是OK的。而且你要给单位线下指令，不是说你文字短就能解决问题，你还是要测，还是要比如说one shot feel超烧的，你可能。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:08",
      "text": "少不了的是对，所以我觉得可能大多数项目它日常落地的时候，就是不断在做这些事情。感觉在一个既定的规则底下，他尽量的去不断的调优。",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:19",
      "text": "这个就是我始终想说的。现在我们看到好多软件团队，他们今年开始基于大模型的API，基于lang time，基于define这样的产品在做这个事儿。但是他们首先第一个需要迈过的坎就是prom的工程。其实这个恰恰是他们现在最难。我刚才说的三四种路径里面，prom工程首先是第一条最简单的。但实际上对他们来说实现难度恰恰是最难的。因为首先第一大家都没有经验，从来没有做过这个事儿，第二就是人和人之间默契都得配合，更不要说人和模型之间，你其实要不停的给他找感觉。我们自嘲我们的内部的是prompt，不叫工程师，叫prompt的艺术家找这种感觉，首先是他们要逾越这个事儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:59",
      "text": "所以我们你看为什么做defi？是因为你基于大模型的能力它很强。但你想它达到预期，这个过程有很多台阶要爬，它并不是一个高山，它就是一个台阶。你要爬，每一个团队都要一节一节的往上爬，爬去解决这个问题。Define可能就是解决了中间很多这样的问题。因为我们发现很多团队在做一模一样的事儿，就是在从第一步开始，第二步开始去搞这些问题。Embedding这个权重是多少，form的工程这个M应该怎么写，怎么测？就这些问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:26",
      "text": "但你后面打算怎么帮他们做prom的这件事情呢？如果按照你这个逻辑来讲，后面你应该是要做prom的社区的，或者说做做一些相关产品功能。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:35",
      "text": "首先我们得有好的prom工具，就是一层一层解决。第一层是prom的工具，就说我们传统写软件是不是有code的，这个IDE叫集成开发环境VS code什么的。首先基于prompt就得有prompt的ID你就是我快速的写一个prompt，然后可能有十种变种，在快速得到10种结果，在十个模型下的不同的结果，然后怎么去纠偏我预期的结果是什么样？现在写的这个point达到的结果和我预期结果是相比来说可能是多少分，就这么一个过程。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:05",
      "text": "首先你先得帮人在一个自然的没有辅助的情况下能高效做这件事儿。我觉得这是第一步，所以我们得有他们的工具，对，这个是真自然语言编程。对对对，是。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:17",
      "text": "然后第二步你得是有一些引导或者说一些模板。就是我们可能系统内部也内置了一些模板，就是解决哪类问题的时候，哪类范式是最好的。这个我们内置有一些模板，甚至比如说我们可能最近在接很多模型厂商，国产的什么呢？我们和模型厂商的合作会比其他的产品要更深入。比如说你和他朗善支持二三十种模型，什么都支持，但是它仅仅是简单的支持。我们在做模型的支持时候，我们会和模型厂商去合作。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:47",
      "text": "我跟他聊你这个模型的特征是什么样的？你能不能把你技术黑箱里面那些东西打开一些给我看一看。给你看吗？他会告诉我，因为他们有调试的报告。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:56",
      "text": "对，就是他会告诉我说解决哪类问题的，怎么写是最好的。这样模板给我过来之后，我们的模型给开发者拿去就是开箱即用的。首先他跟模型厂商沟通成本也很高点，我这是调过的。因为不同的模型它的调性都不太一样，甚至要换一套写法。那可能我有这个模板，就每个模型都调过了，你拿去用就好了。这就是很多很多细节帮开发者少走弯路的一个方式。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:20",
      "text": "第三种就是有点像接近你刚才举的那个例子，就是拿高级的大模型去辅助相对低的这个prompt编写的技巧，去帮他去做copilot，就是帮他去辅助去编写。你可能知道OpenAI官方有一篇论文，他指的就是说如果你拿GPT4去解释GPT3.5、GPT2，为什么这么回答，它是可以给你一个解释的。对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:40",
      "text": "好像之前也有人用，比如GPT4要生成那种问答，对，再放到其他的模型里面。对，是。所以你觉得整体而言，prompt这件事情是现在是被高估还是被低估？",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:52",
      "text": "你是说它的难度还是什么难度意义？我觉得它的潜力被低估了，它的难度也被低估了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:00",
      "text": "OK因为其实是OpenAI自己的人，之前写过一篇文章说大家不要好像是twitter还是什么的，大家不要过于滑稽，在prom这件事上，然后说他其实未来他可能是一个阶段态东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:14",
      "text": "prompt现在可能还必不可少。首先prompt确实可能是不可或缺的一个东西，但是写prompt的难度一定会越来越低。因为模型本身在改进，像我们这种工具可能也会提供很多研发的这种范式。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:29",
      "text": "是很多人是我写一段prompt，这段prompt作用就是帮助把你的话变成一个更好的prompt软件输入进去，反正这里就有很多嵌套的东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:38",
      "text": "我觉得还挺有意思的对对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:40",
      "text": "是倒回到刚才那个大模型的问题，大模型所以除了注意力什么的，还有什么别的你看到的问题吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:46",
      "text": "成本也是一个问题，特别纠结成本问题。在一些比较窄的领域，因为你最终做应用可能是映射到几个，比如说法律，教育这种垂直领域。但是一个通用大模型它有好处，它的通识非常多，推理能力非常强。但是它衍生的问题就是说它的性能会慢，它的成本也会高。因为这是它代价，它从0岁到18岁之间这个爬坡的代价。其实我们希望有垂直的模型，性能性价比又非常好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:16",
      "text": "我之前跟模型厂商也聊过，理论上其实不太容易存在这样的模型。比如说你们现在可以看到一些开源模型可能很小，什么6B13B然后又说可以简单的微调，能达到一个专业领域的。它实际上在文字的模拟，你就照猫画虎这种事情上，它确实能有很好的效果。就是你微调完了之后，他很懂法律，但是你但凡问他一些有推理的一些事儿就不行了，就是有逻辑的事儿他就不行了，他没有推理能力，因为他的模型参数不够，所以这个是目前一个主要的问题。所以我们可以总的来讲，可以说其实大模型的学习能力相比人来说还是挺笨的。因为你想他要吃掉几乎全网的数据，他差不多达到了一个可能成年本科生的这么一个水平。那人可能说今天一天两天在课堂上或者说网上看到一些东西，他学习理解速度也很快，就像我刚才说的那个few shot的问题，微调的问题，我跟你说一个问题，一下就明白了，那大卫星得说20遍是。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:12",
      "text": "但也有一种观点是说，其实是人类提问的能力太差了。因为理论来说所有的答案都在大模型里。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:19",
      "text": "对对对，这个问题确实比较难解决，但我们相信多模态能解决这个问题。在模型层面上的多模态训练可以解决这个问题。我经常举一个例子，就是说跟大模型问，你问他一个什么某一种木材，非洲枫木的一个木材做的吉他，他什么音色，他可能会跟你说什么温暖的、锐利的，其实他不明白他在说什么。你问他另外一种木材是什么音色，他可能也会这么回答。原因就是说这里没有对齐，他对这些词儿背后的那个意义没有概念，接受概念本身就是错的。因为人在描述这个音色的时候也不知道用什么，所以就用了几个接近的词可能说一下。所以就是人和人之间沟通都对这个事儿有信息的更好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:02",
      "text": "我明白了，我完全理解。我给你举个例子，就好像我期末考试突击了两天要去答卷，感觉我写的好像是正确的，但我其实也不知道我在写什么。对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:12",
      "text": "是就是说大模型的训练过程中就会有一些已经不太准确的信息。你再给他一个不太准确的问题，他还要去试图回答你。用户还会说你怎么回答的不对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:22",
      "text": "就鸡同鸭讲。对对对，你接触了这么多大模型，你们团队应该有自己一套评估大模型能力的体系，有吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:31",
      "text": "我们有自己的角度，市面上现在有很多评分的体系，国内的、海外的，我知道的评分榜单什么可能就20个以上了。首先我相信这些数据，因为我们再去做一个评估的手段，成本非常高。可能做的还没有他们专业，但也有很多大模型在刷题。对对对，但是你就取一个均值，你大概能知道它是什么水平。我们的评估标准是我们银河大模型是真的近距离接触。因为我们去拿它去调优惠的东西，以及说我们有用户的数据。比如说dey上现在有接近可能接近5万的应用，这5万的应用它在哪个模型上最终选择哪个模型，以及说哪个模型的效果可能更好，性能更好，有留存。我知道这些数据这个对我来说就够了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:16",
      "text": "是目前看起来各个大模型之间各有优劣吧？在某些领域里面，比如open I它可能推理能力更强，然后那个cloud什么上下文更长等等。你觉得未来大模型这块，大家会是混用的一个情况吗？还是怎么样？",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:30",
      "text": "会的，现在就已经有了。比如说文本生成的环节，特例的环节，embedding的环节，甚至还有这种声音转文字文字转声音的环节。很多环节现在在我们的这个工程里就已经开始混用了。那等接下来就是这种多模态出来之后，OCI的这种能力，各种能力增进了它一定是多个模型之间配合的过程，因为每一个模型都会有自己的擅长领域，以及说他们的成本也会不一样。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:53",
      "text": "所以这块其实是define能产生很大价值的地方，吧？也是相对这个系统会有复杂度的地方。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:00",
      "text": "我们想象两种情况，一种是说未来商业模型垄断了整个市场，对吧？在这种情况下，每一个模型会提供自己的一套解决方案。但是这个解决方案就是整个封闭在他的那个体系下。比如说OpenAI可能有自己一套，cloudy可能有自己一套，cohere有自己一套，这一套可能有他自己解决方案，但是你就可能就有一个环节不满意，你就想用另外一家的。这是一种情况下。另外一种是开源，开源的情况下，可能我们会看到像现在百模大战，一堆模型都出来之后，他们之间在各个领域会有自己的专长。对于def来说，可能开源模型如果说繁荣的话，对我们来说是更有吸引力的一件事。因为相当于说这里的工程可以做的事情就很多了，大家能想象的可能性就很多了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:43",
      "text": "如果是封闭的这种商业模型去去垄断市场的话，我们可能相信一共也就3到5家林家。这3到5家每家有自己一个派系。模型的多样性少了很多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:53",
      "text": "是你目前看起来你觉得更倾向于哪种会发生？",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:57",
      "text": "我现在从近一两年的角度来讲，我觉得还是商用模型为主，无论在效果上，成本优势上都好很多。开源模型现在来说还是比较早期，但是它仍然让人兴奋。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:11",
      "text": "但拉姆拉做得很快，然后国内GLM其实也效果还不错。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:15",
      "text": "对，我身边很多人我问他们一个问题，包括我们现在社群里面的，我问你们知道lama的运行成本是怎么样的吗？就比如说你想和达到GPT1样的，比如说就是100个并发跑起来，然后在服务器上你知道你需要多少显卡，大概是什么样的配置，能让它稳定运行吗？没有一个人能回答我这个问题，这是为什么让我们自己在研究说明，第一他们没有到这个阶段。第二是现在大家不在乎这件事，就大家享受这种做造主的乐趣，我就赶紧动手把这东西搞起来。或者说如果去做一个技术实验，大家还是在这个技术验证的角度考虑更多，而不是说放到投产角度更多。我刚才提的这个问题，推理成本就是一个很重要的一个问题，不然的话你的稳定性都保证不了。但是你可能说抓100个人，这里面可只有一个人知道这个事儿。OK interesting。所以我觉得开源模型可能离他真正投产还是有相当长的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:07",
      "text": "一个距离的。OK明白，但商业化模型应该也是那几个混用，对吧？商业模型。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:15",
      "text": "就是你你可以选一个OpenAI的，你可以选一个百度的，或者怎么样去各自分工去解决他们擅长的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:23",
      "text": "是对一堆投资人会问过你一样的问题。包括所有做中间层的人都会受到一样的问题。就是这个事儿是不是未来大模型自己会做掉，尤其是国内投资人会问这个问题问的最多。然后我一般的答案都是我觉得模型层就是像我们刚才讲，它会混合起来，它是多个模型同时存在的。只要是多个模型同时存在，那中间层就是有很大的价值的。我不知道你现在是怎么看这个问题的，如果今天再有个人问你说这个事儿，大模型是不是自己就做掉了？",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:51",
      "text": "大模型微软为代表，他们一定会去做自己蛮好的开发的工具包，甚至是中间件服务。我觉得这个都挺好的，因为他们离模型的这种技术细节也更近。但是他们有这么几个问题，第一个是他屁股不对，所有的事情就是围绕他自己的那个模型去做的。第二个我经常说的是说我云厂商做不好SaaS。看全球范围内云厂商几乎没有说自己在那个SARS产品上做的特别好。要么就是收购，因为他们的基因全部是导向到最终去卖资源。他们不对这个开发者体验，甚至我们说接下来饭的prom的工程师，或者说一些其他的IM offs人员去友好这件事也不是他们的基因之一。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:37",
      "text": "第三个就是他们做这个中间件本身，因为他不中立，所以他在开发者的角度来说，他们会保持距离，会比较谨慎。比如说现在的开发者，他们在选define或者说浪漫也行，选这样的产品的时候，他们其实就没有什么心理包袱。因为他知道你不是任何一家的，你后面的模型可以想换就换，我可以先拿这个OpenAI的能力去做一个最好的原型出来，然后再换到我想要的模型。这过程很自然，没有问题。但如果说你试图你拿到一个微软的开发工具包，只能接它的模型的时候，你就会有疑虑。万一说你模型下来跟不上市场的发展或者什么，那我的代码得重写吗？肯定不能这样。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:14",
      "text": "因为我们做中间件解决了一个很重要的一个问题，就是把prompt工程和它的原来的这种。程序代码做解耦就是分开，就代码跟代码，中间件为中间件。我们做有一个价值，就是做这个事儿，我好不容易把你分开了，然后你还要再把我连到一块，你不行。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:31",
      "text": "是是是，确实就是你从这个角度来讲，好像这个问题就很无厘头的。本来它的核心价值就是分开。然后你们现在观察了这么多个应用和大家在你平台上做的事情，你有没有得到一些跟市场不同的一些结论，一些观点什么的，或者一些有价值的思考和发现。通过实际的大家的应用。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:53",
      "text": "你们看的东西，不管是商业模型、开源模型，就是任何开发者、厂商、企业要去基于现在的模型做点事，肯定是有一个周期。不管是你打样原型，还是说产品调动，再到用户进来。对，和原来做软件一样，你至少得有个三个月的周期。三个月到更长的周期，每一个环节认认真真做这个心理准备的有没有那么快？",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:15",
      "text": "用了defi跟没用define到底能缩短多长时间？",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:18",
      "text": "我们观察比如说如果以浪漫为基准的话，大部分的这种典型应用可能能缩短1到2个月的开发时间吧。但这个不是重点，重点是我们说office，指的是后面需要各种人参与进来，这个反复运营的数据维护的时间。很多市面工具解决不了的，他不帮你解决，后面的问题他就算帮你解决了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:38",
      "text": "第一个阶段开发的问题，不帮你解决后面的问题。比如说数据集的维护，我们刚才提到私有数据，那私有数据你肯定不是录一次进去就好的。你image进行数据需要精细的分段，对吧？需要所有人都能掌握这个数据，需要给这些数据去增加权重或者降低权重。可能你在国内还需要什么维护一些敏感的东西。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:59",
      "text": "然后接下来A政策之后，你会有各种各样的工具。哪个工具效果好，你应该把它生权，哪一个工具不好，你应该把它替掉。有很多这样的事儿要人反复参与进行的一个事儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:09",
      "text": "对。而且你当时还讲了一个点，我印象很深。就是你说不可能这公司里面只有两个懂AI的人来做这些所有的事情，对吧？未来可能是大家所有人去围绕这个来做配合，所以你做的这件事情，你发做这件事情就是我完全不懂AI我就是一个真的运营的后台的人我也可以去做所有的AI相关的运营，然后并且持续的能真的改善产品的效果。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:31",
      "text": "因为我们相信如果做不到这样的话，那AI的可塑性的潜力就没有被最大的发挥出来。如果每一个人他没有能轻松的去塑造自己这个符合预期的AI的话，那么世界上的AI就仍然掌控在少数技术人员的手里，而他们对世界的理解也是片面的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:50",
      "text": "所以你其实也是在推动平权。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:53",
      "text": "那当然OK刚才。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:54",
      "text": "我们提到好几次lang ten对吧？这个lang趁其实是今年如果说有几个该相关的关键词，GPT long chain auto GPT等等，这agent这些应该是跑不掉的。所以long chain到底是一个什么东西，我觉得大家经常在讲。但可能这几个词里大家对long称的理解是最弱的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:12",
      "text": "你可以理解为它既是一个工具箱，也是一本教科书。我前面提到的说大家在探索tom的工程或者是更大模型怎么接入一系列的事情。当产从去年11月开始做了一件非常有价值的事情。人们在每个阶段有疑惑的时候，它正好是顺手可以取到的工具。它是一个library，就是开发者的库。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:35",
      "text": "就比如说你拿python或者现在叫JS去写代码接入大模型。然后比如说你从模型的驱动进入哪个模型，模型的模板，我这一个point的哪些词要替换掉。然后还有一个很重要的概念就是它的称就是链条一个掉模型之前你要干什么，调完模型之后你要干什么？这些抽象的概念它把它分装成了一个比较简单的形式的代码。你给他写代码的时候去用它这个概念。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:59",
      "text": "这就是老产所这事儿，它有点像一个API之类的那种感觉，它是一段一段的代码是吧？就是我要用的哪块的时候，我直接把它那一段复制粘贴下来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:40:08",
      "text": "是这么理解吗？我们编程叫方法，很多很多封装好的方式，你用说复制代码也没有问题。因为我们自己对浪费非常了解，对它的准确理解，它是一个cobo菜谱，各种你要用到的调味料这种东西都在里面，你可以拿它去用。但是它有一个问题，它其实是一个非常早期的产品。它在大家关心的模型的时候，把所有需要东西一股脑的放进去，油盐酱醋都在里面，你可以拿。但它其实因为太早了，没有经过很好的设计。当你做到比较深的工程的时候，你会发现它不够用，你必须改它。第二，它以一个成熟的产品的形式来说，它没有service化，它不是一个服务，它仍然是一个代码库，你需要去维护，它需要和你的代码去耦合，它并没有像我们这样去和代码去解耦。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:54",
      "text": "第但是他的那些分装的调味料、食谱，其实都非常的浅。因为的他们的团队的最大的能力是动员很多开发者加入他们社区，帮他去一块做。而且他早期对于开发者来说是最好的一个标的，大家都贡献代码。比如我刚才举的一个来说，他可能支持了20种模型，又支持了十种向量数据库，又支持了78种工具。其实你稍微把其中任何一个工具拿出来，你发现都很脆弱，仅仅就是能跑起来的程度。所以他对于有句话叫什么long chance开发者做大模型的新手村什么的，我觉得也差不多。你要把入门的东西都在里面，你可以拿来用。但是你稍微想拿这个东西接着做下去，你要么你用long time第一周写完东西，第二周接着写写到一个好的程度，你基本上就写完代码就得废了或者是魔改。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:43",
      "text": "所以他其实做的好地方就是他把一堆东西传到一起，然后他传的早。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:47",
      "text": "传的多。对，而且他有很多定义的范式，我们说量，agent这些抽象的概念。我跟你说代理你可能agent你可能不太了解，当然有一个代码放在那里，告诉你是这么写的。所以它是一个非常好的一个动态的教科书。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:01",
      "text": "明白，他把很多概念和大家基础认知去拉起。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:04",
      "text": "对你相当于是一个可以实践的，一边实践一边写的一个说明书一样的一个游乐场。你其实我觉得这么定义它是准确的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:13",
      "text": "但他最近好像也发现自己有这些问题，然后他出了一个long smith是吧？对，lang smith是一个什么东西？",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:19",
      "text": "Long smith其实是一个lunch的配套的服务，它是一个调试和跟踪的工具，在传统软件开发里面也会有。比如说你浏览器里面会提供一个控制台统计，你浏览一个网页里面又加载了图片、音频、文字，分别用了多少时间。它一样的。当时miss就是你用了LangChain的话，lang time代码里面可以有一个call back的开关把它打开。那你这个lang time的代码在运行过程中的所有的信息被跟踪，上传到long smith上，你可以去做可视化的调试。它是一个开发辅助的一个工具。因为本来你就黑盒，尤其是你用了链之后，你一个大模型的应用掉七八步，每一步输入是什么，输出什么，他用这个工具帮你统计出来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:58",
      "text": "所以LangChain跟long smith和define的关系是有什么关系？我觉得这个问题还挺难回答的。首先lunch对于define也是一个基础设施，我们就把它当工具箱就要用的用，不需要用就不用，后面可能完全不用浪，不是一个完全产品化的一个产品。Defy是一个完全产品化的IMM的一个应用技术站。它是一个既可以在云服务用的，也可以在开源，你拿回来自己部署的这么一个东西。因为我们是一站式的解决方案，所以long smith的那些调试的能力，包括我前面提到的这些我们的IDE这些能力，可能都会在define里面会有配套的工具。所以你可以理解为define一定是整体解决方案，即拆即用，可以满足百分之七八十的情景的。Lang可能会你得组上各种东西。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:43",
      "text": "然后放到一块儿才能去用。就是lunch它是一堆积木。对对对，然后define也用到了一些积木。然后未来可能还会自己重新造水泥。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:52",
      "text": "把这些积对对对对，我们现在有内部有个东西叫define canal，就是我们其实也在在做define的过程中，去想象一个更底层的一个库最好的形式是什么。未来可能这个东西做出来之后，我们可能会开源出来。那个东西就有点像迪拜自己的浪漫。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:08",
      "text": "对对对，是的，因为我们发现很多lang time的用户，我们也很了解lunch的用户，试图拿狼山做深度的应用时候，他们也把狼山丢掉，是我原来没有想到的。但是我最近和开发者接触，发现都是这样的，就是他做到了某个程度之后，狼山必须丢掉，因为已经帮他完成了新手做上路的过程之后。你也知道你那堆积木里面你要用哪个，你就把这几个积木拿出来重新造，剩下的不要了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:31",
      "text": "基本都是这么玩的。他就好像一个青铜剑，然后它不断的去打磨，打磨到最后的发现怎么打磨，还是就只能换成一个更高级材料的东西。是但迪拜会不会遇到类似的问题？我相信肯定有公司，比如他是一个AI的创业公司，他可能觉得自己技术很牛，那他不需要用到第三方一个很简便的工具，然后他就自己从零去去造的东西，他觉得是最好的。会不会有这样的场景的问题？",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:56",
      "text": "我们的使命当然是帮助更多的开发者把大模型的应用落地，解锁这个模型的潜力。但第一肯定不是所有的。第二还是我前面说的那个问题。也许在逮捕环节，你永远去自己写代码，不要用狼颤，甚至连paton都不要。你用C加加写好了是能达到最大的自由度的。但是你那些需要人反复去运营的这些工作，不是你的代码能解决的。这些基础设施是define能提供且非常好的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:28",
      "text": "我们现在其实也在做另外一件事儿，就define现在是一个整体的产品。我们会把几个非常好的零件，就大家觉得比如说我们的数据集的能力，我们现在上的那种agent的这种治疗的能力非常好。我们会把这些产品单独拆一个单品产品出来，它可以配合狼战或者你喜欢的其他东西一块用。你可以用我整体的方案，你也可以用我一个方向盘，轮胎没有问题。这样的话就可以用他自己的开发能力，再配合我们的一些做的比较好的工具。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:57",
      "text": "对我觉得你刚才那个解释也很好。他就是你你如果为了追求更大的简便性，你一定就是放弃了一些自由度，对吧？就不可能是兼得的。兼得的话一定是用你自己用29个字母从头去写。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:09",
      "text": "我们既然做define，我们就知道一个事。就是我们遇到的所有开发者，可能在拿大模型做应用的前三个月，遇到问题几乎都是一模一样的。这里会有一些细枝末节不一样，但几乎大体上问题是一样的。现在比如说很多在做偏自有的问答的知识库的，他们遇到问题几乎就会是同一类问题。你卖点怎么做，分段怎么做，掏空怎么分配？这问题是都是一模一样的，只是里面内容不一样。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:34",
      "text": "然后接下来就是agent a症的，就是说模型的驱动，怎么做模型的这个推理模板怎么做？模型的工具调用，调用哪些工具？这些工具的限制的轮次和成本怎么控制，他仍然会是一模一样的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:48",
      "text": "理解。然后我们刚才讲的所有的那些问题，包括大模型的问题，你觉得会在未来多长的时间内会得到怎样的解决？你有没有个大概的预期？",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:56",
      "text": "我比较乐观，我把defied开发者分为大以上两类。第一类是比较务实型的开发者，他们评估过大模型的能力，认为在现实的情况下，大模型应该可以做出什么样的事儿。我认为这类开发者，务实型的开发者，他们现在遇到的种种困难或者什么什么问题，在未来一年内都能得到解决。无论是通过在模型层面解决，还是通过我们这种中间件工程方面解决，我觉得能解决。",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:22",
      "text": "第二类开发者是比较愿景型的，就是他们希望大模型一次可以替代一个团队，或者能能做很多这样的事情。就是说想象中的大模型已经是一个非常强的一个东西，这种可能会比较难。这种我觉得有可能三五年内其中一部分需求能够得到满足，但另外一部分需求可能会被一些厂商做成比较深的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:44",
      "text": "比较垂直的产品。对我今天下午去跟妙鸭的负责人聊了一会儿。对，很多细节他是不能讲的。但我觉得他讲的有一个点，也是我最近跟你聊一个感想，就是大模型的能力肯定是有限的。但是在有限的前提之下，其实最考验的就是产品的能力。就是你怎么样把这个需求定义的足够清楚。如果你需求不清楚，其实你相当于说你要爬一座非常高的山。但你需求如果足够清楚，可能你就是要稍微让我进路，或者你可以开个隧道就可以过去了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:12",
      "text": "对，妙鸭就很好，他就解决特定问题，限定的问题。对你问题越限定，你想的越清楚，技术的解决的难度就越低。起泡沫也是这样的。是是是，那你们现在实际看到的最典型的一些应用场景，能不能给大家分享一下？",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:27",
      "text": "教育是最多的。比如说评估一个学生的水平，给他一些命题或者题目，这种是最多的。给作文打分这个事儿是不是完全是OK的？最近看到一些产品，你说打分这个事情太主观了，但是他哥告诉你说哪里对，哪里不对，这个事是很容易的对，比如说尤其是对于相对第一年龄段的，不管是编程也好，写作文也好，去做改进是非常好是是。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:57",
      "text": "对我为什么我提这个，我就觉得现在其实定量会遇到很多问题，就是他会遇到什么记忆问题，什么什么各种问题。但其实定性相对来讲对是OK的对，就是我觉得大家现在过多的去在意它定量的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:49:12",
      "text": "其实大模型给你的任何数字可能你都不要信，但他给你的方向很多时候都是好的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:17",
      "text": "所以我觉得大家可以多去从定性上去想这些东西，就比如说判断某段话的情绪等等，这种东西应该是会更好用一点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:49:26",
      "text": "对，教育行政市场行政是行政，就是我刚才给你举的例子，企业内各种内部的调度，市场营销，这其实是目前来说最成熟的。不管是写文案是图商品图什么的，然后就是客服？替代一些这种简单的客服情景也非常好。比如说现在已经能比较做到复杂的说用户买家进来去查你这个买家过去买过什么东西，订单是什么。他上来问一个问题，你大概就知道说我给他可能要解决哪些问题。他今天来的这个情绪是一个愤怒的还是一个积极的？我应该给他退款还是不退款，对吧？这样的问题我觉得大模型已经解决很好了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:04",
      "text": "所以你们实际看到的还是有很多比较乐观的例子，是大家持续在用，而且是很能很好的运用的对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:11",
      "text": "比如说我们团队内部，我们不会说所有的团队成员你们都把这个工作交给AI我们会把一部分的工作，比如说我们运营类的这个增长的工作，可能有二三十项工种。很多细活我会圈一下，哪些可能现在在大模型的成熟度下就很适合做。标出来我们就试图拿define或者拿各种技术手段帮他去做这个自动化的改进，去替换人，这个没有问题。你不要说我现在就要拿大模型去替换一个人，你要把一个人的所有的现在所有的这种工种能力列出来，去看一下哪些大模型的程度已经到了可以去做。也许你在这里能发现一个非常好的市场机会，做一些全世界都能用的一些非常好的产品。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:50",
      "text": "理解，我觉得我们前面所有的整体聊的有点像一个AI101的这个感觉。现在实际上你在日常的操作当中，你在想的一些更深的问题，你有没有什么事给大家分享？你能不能抛两个问题出来，是让大家觉得连问题都听不懂那种震一震。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:06",
      "text": "我们怎么说呢？我现在脑子里最困惑的是一个简单但是难以回答的问题。就是基于现在大模型的能力，未来会诞生出最多的新的增量的应用，我们可以叫他AI原生应用到底是什么样的？比如说我们知道移动支付在上一代互联网就激发了很多像o to这样的漫山遍野的这种产品出来。那么基于大模型可能会诞生什么样的一些应用，是非常大增量的这是我们最期待看到的机会。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:37",
      "text": "我现在看到的答案可能是说得多种模型的能力揉到一块儿的，甚至再加上一些硬件的这样的产品。它是一个非常封闭很好的一个解决方案。就得融入到你身边的一些物件里去，对吧？这个是一种我们能看到，因为我们并不相信说未来会有那么多chatbot。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:57",
      "text": "对你这个点我本来想问你的，像我们第一期其实他提到一个点，他说他的毕竟是未来每个人或者每个企业都有报道，对吧？然后未来可能就比如几十亿的人口，可能会有上千亿个报道。我知道你怎么看这个东西，因为现在实际上大家用题干做的东西本质上也是一种boat，对吧？就是对话，你可以定义成一种boat。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:16",
      "text": "Chatbot是一种我们交付给用户和开发者直观的显而易见的一种交付形式。因为这是大家现在最能理解的。Defi作为一个应用技术上，其实可以完全不做这件事儿。我们现在做这件事也是为了跟用户拉近距离，不意味着说我们相信未来都是chatbot。",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:35",
      "text": "就是我们总体上看，可能说可能手上有个ChatGPT。可能到今年9月10月之后，你的手机，你的windows，你的操作系统里面都会有一个，你的企业内部，你的公司里面可能有一个。其实你一个人有三拆的话，他已经就够受了。这一个你还得跟他磨一下性格什么的，三个你就够瘦了。你不可能需要那么多chatbot，大前端至少前端上不需要。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:00",
      "text": "对，因为你是觉得说像OpenAI，像微软，像苹果可能就把这事做掉了。我们今天入口我指的是入口。对，今天好像才看到新闻说苹果在招人做端上的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:10",
      "text": "对对对，我一定相信在操作系统级别也会有这个chatbot的入口，去解决调度和你看到的这种聊天体验的问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:19",
      "text": "对我之前跟聊个人助手这件事情的时候，其实你知道有很多创业者这一波肯定是想做个人助手的对，我们大家就聊说第一步是OpenAI这种做的怎么办，然后是微信做怎么办？Google这种操作系统做的怎么办？最后就是苹果自己从硬件端做怎么办？从逻辑上来讲几乎是必然的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:37",
      "text": "每个人都要做的。我们相信入口不会超过三个，肯定三个就够你受了。但是入口它可以是一个接线员，它放各种的agent接进去。因为我们相信一件事儿，就是每一个大模型它要做成一个完备的agent，其实他要组装很多东西进去。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:57",
      "text": "每一个A政策就跟每一个人一样，有自己的能力站必然是有不同的能力在里面。他不可能用一个AI模型去替代所有人的能力。因为这里面有我的特点，有自己的知识或者一些东西。那入口可以有一个，但是入口后面的这些AI的就你说的bot。是可以有无数个的，只不过中间有一个接线的过程，转接的过程。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:18",
      "text": "是啊路由的过程。对对对，你的这种路径其实比较符合大家在讲那种是大前端。可能前面就是一个OpenAI，还有一堆pluggin s plugins.",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:27",
      "text": "还不就是它现在是一个模型加pledging，它实现的还是一个意志，一个主体。但实际上我指的那种情况并不是我指的是有很多位置，他们有自己的工具，工具之间的权重和组合关系他们都设计好了。未来有很多很多这种虚拟的这种人的是代理人，类似于API的接口。对对对，是整体的，是一个完备的有自己意志的整体的这样东西。然后这样的东西会被一个入口去全集成进来，去接入进来。他可能会像你现在微信的通讯录，或者说你微信上的一个律师或者什么。反正在你需要的时候找到一个正确A的接进来。对，甚至说你搞三个A正在中间去讨论同一个问题，大家吵一个架什么的，这个都没有问题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:07",
      "text": "最近几个月其实跟大模型相关的新的热点，一些质变的东西，我觉得是明显的变少。你觉得未来还会有哪些方向是比较热的吗？比如说就像是从code到agent的这种概念，我们今天能不能创造一个概念，还有没有什么你觉得是未来的发展方向？",
      "speaker": "发言人2"
    },
    {
      "time": "00:55:27",
      "text": "我觉得光多模态的这个故事就已经够大了。现在你大模型的所有能力都是仅限于文字层面，他们对世界这种图形图像的理解还少。但你想是想在下一代的大模型，他们在训练的时候，如果能有人的五官的更多感知。比如说像我们这样聊天，要有视觉，有听觉，甚至有触觉温度这样的信息，结合文字再去一块去做一次训练的话，他的那个能力会远远大于现在。因为他现在接受的信息毕竟是单一的。我所以我相信说多模态这个方面，一方面是本身多模态的训练，哪怕还是文本模型，基于这种各种的感官数据重新训练一次，模型的能力会有质的飞跃。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:14",
      "text": "第二次是由于它有这个信息，让他输出的内容也是多模态的文字图片？3D的模型，声音等等。它的这个输出形式也丰富很多，它能真正的去做很多现在人类的知识工作者才能做的事儿。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:29",
      "text": "我觉得有点像我们邀请大模型看3D4D电影的感觉。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:33",
      "text": "对他现在还是看小说的阶段。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:36",
      "text": "对，我们要对他好一点，争取早上起来看4D电影。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:41",
      "text": "其实你会发现现在很多技术是有往一个方向走的趋势。比如说苹果新出的vision pro它本身就可以是一个训练数据的采集的那个东西，跟review结合起来就是完美的。对，你再看比如说马斯克在搞一些脑机结合的东西，等这个传感器这些方面都已经对其之后，那模型本身的能力就会超出我们现在想象很多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:03",
      "text": "你觉得还有什么是未来有可能会发生的，或者在divide的vision当中一些比较核心的点。",
      "speaker": "发言人2"
    },
    {
      "time": "00:57:10",
      "text": "还有吗？模型的小型化，模型的这个移动化小型化可能也是一个趋势。因为我前面跟你说的是模型现在参数量这么大，然后获得那么点智商，其实他还是冗余信息很多的。这个在算法面上和硬件层面上去做了调整之后，这个模型未来是可以就装到口袋里。这个我们也是相信的，又不需要去那么依赖去云云端。",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:32",
      "text": "对，至少是可以装在那个家里面，类似wifi一样的一个东西，对吧？然后不需要到云端了，然后它整个的成本、速度、效率什么都会比较。",
      "speaker": "发言人2"
    },
    {
      "time": "00:57:40",
      "text": "还有一件事儿就是我们define之前的一个原因。我们相信未来的所有的数据会向量化。就是你现在看到的所有的有知识产权的一些东西，电影、小说这种书籍，所有东西它现在是给人类阅读的。这些的材料都应该被向量化一遍，你让AI可以去快速的加载这些数据，就像U盘一样插到一个AI上。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:03",
      "text": "比如说你现在AI问他一个今年的一个什么什么知识，你看我们现在要用很多手段把它嵌入进去或者怎么着。这份数据可以由原来的这种内容的出版商或者直接提供的，我直接加载进去。完了这个我相信是一个很大的市场，相信所有的东西在这个情况下都要重新出版一遍，就是以一种AI的读的形式，而不是说现在像原来像人出版的这种形式。还是请他看4D电影。对对对，给他都准备好了，然后喂给他。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:30",
      "text": "对，因为现在本身大模型很多问题没解决。比如说你采集的数据的这个内容的来源，版权，这问题都没有解决。它其实也要一个很合规化的过程，比如说我会跟别人举一个例子，现在这个非常混乱的时代，define是一个开源项目。开源项目你知道是有许可证的，就是让你干什么，不让你干什么。如果像接下来GPT5，他们的能力足够强能加工很多代码。那我拿一个限制很严的开源项目给他读一遍，让他重写一遍，那不就是一个完全性的东西吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:00",
      "text": "对吧像我自己抄了一遍书，那这个书还是不是我的，就这样的问题有很多，这样版权的问题都都需要解决。有没有什么你现在最担心的问题，或者最焦虑的是什么事情？我最焦虑的问题，其实我焦虑的是模型的发展速度没有我刚才说的那么乐观。",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:15",
      "text": "我其实也是主要焦虑这个问题，所以要给尤其是国内的这些大模型创始人打call是吧？对，还是要加油。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:24",
      "text": "大模型厂商很多，最近也跟我聊了落地的问题，因为一个是define现在可以帮他们的一些用户做落地。一方面他们现在有一些模型厂商，他们已经卖出了一些蛮大的客户，客户的预期很高。即使现在拿出世界上最好的模型的的能力，其实还没有办法去满足。所以他们跟我一样，跟开发者一样，其实也处于在找情景，或者各种各样的尝试。",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:49",
      "text": "对他们的就像是技术材料提供商，就像是一个装修队，就还是要有人把这些东西真的装好，变成一个商品房。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:56",
      "text": "因为坦率讲，现在说今年国内大模型有一点计划经济的味道，对吧？他可能是这种需求端，可能是一股脑大家都去做。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:05",
      "text": "但这个我唯一有可能觉得他应该被计划的。因为大部分人这个事情确实很费成本。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:11",
      "text": "当然没有集中的资源调度，可能做的就赶不上人家。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:15",
      "text": "对，所以这个事儿我反而觉得说你计划一下。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:18",
      "text": "但你知道计划经济的带来的问题就是你需要拿着锤子找钉子。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:23",
      "text": "会有这么一个过程。是是是，拿着锤子找钉子，define是什么呢？Dey是锤子吗？也不是钉子。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:28",
      "text": "也不是锤子，不是，我们是介于锤子和钉子之间的东西。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:32",
      "text": "对对对对对你你是那个螺母。",
      "speaker": "发言人2"
    },
    {
      "time": "01:00:35",
      "text": "就现在锤子们都在相互模仿去造锤子。对。Define从第一天就是围绕钉子去做的东西。我们是基于一个开发者，甚至是小白的开发者反推如果要充分的利用大模型能力应该做些什么而做而诞生的一个产品。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:50",
      "text": "所以最后结我想讲的这就是我最看好define的地方。未来上游一堆大模型，下游是一堆应用开发者，中间一定是需要一个东西来串起来。",
      "speaker": "发言人2"
    },
    {
      "time": "01:01:00",
      "text": "我们最宝贵的那个东西不是我们现在是影视人，甚至已经连接到的这种几千个开发者，中间可能有上百个跟我们关系特别好。所有问题有需要落地什么，遇到什么样的技术难题，自己受到的这个成本限制或者什么什么。他们会把这些信息毫无保留的告诉我们，他们甚至不一定会告诉模型厂商，他会告诉我们。我们就知道说他在这个有限的命题作用下，可以做出什么样的东西，提法可以帮他什么。",
      "speaker": "发言人1"
    },
    {
      "time": "01:01:23",
      "text": "对我其实看了好几次你们的那个公号的文章，里面很多文章写的东西都非常的干货。而且他一看就是实打实的一线操作上遇到的各种问题和解答。所以我觉得大家有机会也可以去关注一下。你但你宗教就是divide这个四个字母，搜DIFY就能搜到，对吧？也欢迎大家github上搜一下，然后点一下star是吧？网站就是dividing AI就是现在已经可以用了。对，是对。最后还有什么想要跟大家讲的或者分享的吗？",
      "speaker": "发言人2"
    },
    {
      "time": "01:01:50",
      "text": "我们最近会和和很多的模型厂商合作，因为很多国产的模型或者说一些前轮大家还没有用到过，我们会跟他们合作，会给开发者送出很多很多的额度。",
      "speaker": "发言人1"
    },
    {
      "time": "01:02:03",
      "text": "这个听起来像是广告的有点对，但确实事实上是这样。对，这个就是底盘的家也是。对，目前是独家的。对对对，可以送很多很多token，挺好好，今天反正整体我觉得讲了AI相关的很多细节，我相信其实有很多人像我类似的，就是大家经常日常讲很多次。但其实对于这次背后到底实际的意义是什么，不一定有那么清楚。希望今天我们讲这些东西是也能给大家拉起一些共识，拉近一些基础的。好，以上就是我们这一期的节目，然后感谢陆宇。",
      "speaker": "发言人2"
    },
    {
      "time": "01:02:40",
      "text": "好的，谢谢大家好，拜拜。叮咚，下面是画外音环节。",
      "speaker": "发言人1"
    },
    {
      "time": "01:02:54",
      "text": "Hello大家好，我是一档播客的制作人c define是曲老师特别喜欢的一个创业项，也是他自己参与投资的一个项目。所以这期播客结尾我又拉他聊了聊他对陆宇老师，对中间层，对大模型应用的一些判断和思考。我们前两期聊了很多人本身，然后这期我们就单纯在辽AI在聊他做的事情。你能不能再展开讲讲你对陆伟老师人本身的认识？",
      "speaker": "发言人3"
    },
    {
      "time": "01:03:24",
      "text": "对，这期其实没有聊太多他个人相关的事情，你主要是因为我跟他还太熟了，然后陆羽是个很有意思的人，我们当时遇到他的时候，其实他大概我想是4 5月的时候。那个时候大家还都在看中间层到底有没有机会，大家都觉得说大模型会不会做，中国市场会不会跟海外不一样等等。但是陆羽跟我联系的时候，他们基本上已经把这一整套东西做出来了。所以说他其实是一个执行力非常强的团队。他也给我们授了他对海外市场的整体的研究，包括比如说蓝晨什么等等一些其他项目。他们已经把他们那些代码看了好多遍。我觉得就是执行力很强，然后人也很聪明，但是对于市场非常的理解。因为他做中间层其实是需要他对于开发者和大模型都有很多理解的。所以也是为什么我去找他来做这一期。",
      "speaker": "发言人4"
    },
    {
      "time": "01:04:16",
      "text": "我觉得他现在肯定是国内最了解大模型和整个生态的人，以及说他其实对这个方向有很多自己的想法。之前也做过很多在box，国内的这些应用开发的工具等等相关的市场。所以我觉得他其实特别适合做这件事情。",
      "speaker": "发言人4"
    },
    {
      "time": "01:04:35",
      "text": "你会格外喜欢什么样的创业者，就和市场上其他人相比的话，有没有什么不同的偏好？",
      "speaker": "发言人3"
    },
    {
      "time": "01:04:42",
      "text": "我们还真跟市场上大多数人可能不太一样。市场上有一派是喜欢很年轻的，就那种特别聪明，非常有潜力的那我们其实这种类型的项目接的并不多。现在市场更多的是需要经验，需要更多的有过组织花钱，知道这个事儿怎么落地，怎么从0到1的这些经验的人，这个是一方面。另外市场上还有一批人是非常喜欢特别背景善念的高管，但我们也不是特别喜欢这种。因为我觉得这种其实他有可能已经不是那么落地的能力不一定很强。",
      "speaker": "发言人4"
    },
    {
      "time": "01:05:16",
      "text": "我们认为一代人有一代人的机会。上一代的这些成功创业者，他已经在移动互联网里面，不管是赚到钱还是卖国公司也好，就已经有过成功的经验了。这一波我们更喜欢的是还是像之前提的那个所谓的underdog的这个概念。就是他怎么样能够在这个市场里面有足够的冲，然后又足够的hands on，能自己做很多dirty work，又学习能力很强。所以我们其实比较喜欢这类，就是有点像大厂的这种中间层，但是是大厂的核心力量。",
      "speaker": "发言人4"
    },
    {
      "time": "01:05:49",
      "text": "对，还有一点就是执行能力。我们刚才也提到了，我觉得现在其实整个市场拼的也是执行能力。这个事情我们也聊了很多团队，他其实很纠结，就是一直在看，一直在思考，那可能几个月时间就过去了，但像我刚才提的，像陆宇他们的团队，可能在大家还在想的时候，他已经把事做出来了。而且他不是说盲目的埋头去做，是想的很清楚前提之下把这事儿已经做出来了。这个也是我们非常喜欢define这个项目的核心原因之一。就当大家在差不多起跑线上的时候，那你每一步都能比别人快一点，那最后就能积累很大的优势。",
      "speaker": "发言人4"
    },
    {
      "time": "01:06:23",
      "text": "但执行力强的基础是什么呢？就做得更快的本质还是说他想的比别人清楚。",
      "speaker": "发言人3"
    },
    {
      "time": "01:06:30",
      "text": "想得清楚，这是最重要的一点。另外一点就是像我们刚才讲，他确实是做过类似的事情的。所以他知道这个事儿要落地，该怎么落怎么样，很快的就能跑通从0到1的这么一个过程，而不会像其他团队一样要重新再进来，再去踩坑，再去走弯路，再到他们现在这个阶段。",
      "speaker": "发言人4"
    },
    {
      "time": "01:06:49",
      "text": "所以在你看来执行力强等于想的清楚加有经验。",
      "speaker": "发言人3"
    },
    {
      "time": "01:06:54",
      "text": "是明白。",
      "speaker": "发言人4"
    },
    {
      "time": "01:06:56",
      "text": "所以你当时为什么自己也投了头发？除了刚刚提到的创始人的方面，主要看中他哪几点？",
      "speaker": "发言人3"
    },
    {
      "time": "01:07:03",
      "text": "我们在那个节点，其实在当大家都没有那么看好中间层的时候，我们就已经很看好。我觉得核心原因是因为大多数市场上的投资人是从大模型开始看起来的。所以大家都会觉得说，我投了大模型，然后大模型能力很强，或者说大模型把后面事情都会自己做。我们其实是从应用层看起来的。就我们先去看那些做应用的人，然后也聊了很多的公司，然后发现大家其实花费大量的时间在做一些基础设施上的东西。就比如说可能有团队花几个月时间就是为了追求一个可控性，或者追求一个可落地性。那这里面就有大量的时间和工作其实是浪费掉的，或者说是重复的dirty work。那他就很需要一个人在中间去把这些事情做掉，这个是一个点。",
      "speaker": "发言人4"
    },
    {
      "time": "01:07:45",
      "text": "另外一个点就是我们还是认为未来大模型会是一个分散的市场。就至少相当长的一段时间内，大家会选择各种各样的模型，或者甚至说会自己基于开模型去做些相关的训练等等这样的事情。所以如果我们认可说未来应用端会有海量的应用，大模型又是一个分散的市场。那其实中间层就会是一个很好的一个入口。反而中间层会把这两边集合起来，成为一个平台级的机会。",
      "speaker": "发言人4"
    },
    {
      "time": "01:08:13",
      "text": "就像美国市场，其实很多人在看现在数据库这个概念。但美国市场其实最近起来比较快的一个现代数据库叫chroma。那它为什么能起来呢？我们后来去看，就是因为LangChain它首选首推的是chroma这个相关数据库。其实应用开发者他可能不会那么care到底我用谁，或者说他不会花那么多的时间去研究各个环节。这里面他最能接触到的就是LMOS这一层。这一层就像迪拜这样的公司，后面他推荐谁，他把谁整合进来，后面这些东西就能起来。所以其实这个战略的定位，我们觉得是非常重要，非常有前景。",
      "speaker": "发言人4"
    },
    {
      "time": "01:08:48",
      "text": "的那你怎么看接下来中间层的创业和投资机会？",
      "speaker": "发言人3"
    },
    {
      "time": "01:08:54",
      "text": "我们把中间层其实分成两类，一类其实它更偏向于大模型层的，比如说现在很多做分类，做做训练，推理相关的这些公司。另外一类就像defy这样比较接近应用开发者的。我们觉得前一类会是比较困难的，就会遇到很多挑战。比如说这个东西它到底卖给谁，到底落的场景是怎么样的。像很多应用的公司，他可能不太会自己去考虑说我要怎么去做大模型。然后如果他的客户面向的是大模型层的，那大模型的很多公司确实会把这些东西自己做掉。如果他是核心的跟训练推理等等相关的东西，我觉得大模型不太可能把这个东西放给别人来做。所以我们觉得跟大模型越近，它的难度就越高。",
      "speaker": "发言人4"
    },
    {
      "time": "01:09:34",
      "text": "但跟应用开发者这边越近，它也有个问题，就是会不会to c的事情有很多人自己就做掉了。比如说现在有很多做bot社区，bot的应用开发平台等等这样的东西。它其实是比较偏向于to c的一个事情，就是大家进来以后就可以使用它。或者说未来可能它是要讲说我要做一个报的平台等等这样的事情。",
      "speaker": "发言人4"
    },
    {
      "time": "01:09:55",
      "text": "我们觉得两边其实你走的太近都会有问题。你跟大走太近容易被大模型吃掉，或者说没有市场空间。跟C端那边走太近，你就容易变成一个to c的平台。那未来的竞争又很激烈，然后很多做应用开发的事情也会觉得说你是不是竞品，或者你会不会他们就把这件事情做掉了。所以这里面是需要有一个团队的，非常有定力，非常有经验，就是把中间层做好。我觉得迪拜就是这么一个团队，所以我们是比较看好在中间的这么一个机会。",
      "speaker": "发言人4"
    },
    {
      "time": "01:10:25",
      "text": "这个思考怎么样有意思？如果再往上走，你对大模型怎么看，有没有什么unpopular opinions？",
      "speaker": "发言人3"
    },
    {
      "time": "01:10:33",
      "text": "其实我们在3 4月的时候就一直在提说，大家高估大模型的能力，低估了落地的难度。这个就是我刚才讲的，我们看了很多应用得出的结论。但目前越来越多的人其实是同意我们这个结论的，我们仍然是觉得说未来大模型能力是有限的，会是多模型共存的一个状态。所以说我们会比较看好中间层的一些机会，我觉得这个是一个非共识。",
      "speaker": "发言人4"
    },
    {
      "time": "01:10:57",
      "text": "以及说我们会觉得说大家既乐观又悲观。一开始的时候大家会很乐观，觉得大模型什么都能做。现在渐渐的就会变得比较悲观，觉得说大模型其实在能力上是有很多欠缺，很多局限的那我们始终是保持个中间态。我觉得大模型就好像每个人发的那一手牌一样，就是你不太可能一上台给你发个同花顺，但他其实也不会差到说是一手非常烂的小牌。那这里边就需要很多战略策略层的东西，你怎么样去把自己的手牌打好啊？比如说我是不是能够用大模型已有的能力去做这些东西出来。我们还是看到一些公司，比如像妙鸭会读这样的公司，它基于已有的能力能够去做更好的产品定位，然后能做出来一些跟之前不一样的产品，而且是大家能用应用的东西。",
      "speaker": "发言人4"
    },
    {
      "time": "01:11:46",
      "text": "明白，那除了你们之前说这种，不要试图用AI解决一个大问题，然后最好先找到一个小的精确的切口问题，越线就越容易出结果。你觉得现在创业者普遍暴露出来的问题还有什么？应用层的话。",
      "speaker": "发言人3"
    },
    {
      "time": "01:12:02",
      "text": "我觉得这个是核心的问题。就是作为一家应用的公司，现在有很多公司在讲自己怎么样去突破技术上的局限，或者说花了很多精力人力跟时间财力的成本在解决技术的问题上。我觉得这个不是应用层公司最好的选择。就做应用最好的选择是怎么样利用已有的技术去更好的定义用户需求，去解决用户的问题。而不是说我现在找到了一个需求，但是我需要更好的技术来解决这件事情。那我就要先投入很多精力在技术上，我觉得这个不是一个特别好的路径。",
      "speaker": "发言人4"
    },
    {
      "time": "01:12:35",
      "text": "然后最后总结一下，你聊完整体感受怎么样。",
      "speaker": "发言人3"
    },
    {
      "time": "01:12:40",
      "text": "你看像3 4月开始，我们其实讲很多所谓的fine tune on，所谓的什么embedding这样的事情。但至少从我个人的角度来讲，我其实也没有把这个事儿理得特别清楚。就到底在什么场景需要用番茄，什么场景需要用这个prop engineering，或者说到底这个背后意味着什么。我觉得这一期的节目主要是把这些问题相对的理清楚了，告诉大家说这个背后的意义是什么，在什么场景应该用什么东西。所以这件事儿我觉得是比较有价值的，以及说我们聊了很多跟大模型落地场景相关的东西。",
      "speaker": "发言人4"
    },
    {
      "time": "01:13:13",
      "text": "你看像迪拜，他讲他们现在平台上应该有五万多个实际的应用。就在大家都在质疑怀疑说到底哪些应用是好的，到底AI能不能落地的时候，他这边掌握了最一手的数据。所以他给我们分享的这些落地的场景和他看到的一些问题，应该是最实际的，是最好的视角。我觉得这些应该也能给大家一些参考。",
      "speaker": "发言人4"
    },
    {
      "time": "01:13:34",
      "text": "对我也觉得这是一期很完整的关于大模型落地的一站式讲解。就从开头的小白科普，然后到商业应用，到最后的未来展望。",
      "speaker": "发言人3"
    },
    {
      "time": "01:13:44",
      "text": "对这些可能不会有那么多的方法论什么相关的东西。但我觉得这些其实对于实际在做这个领域的人，或者关注这个领域的人来讲是价值很高的。",
      "speaker": "发言人4"
    },
    {
      "time": "01:13:56",
      "text": "好，我们这期就聊到这。",
      "speaker": "发言人3"
    },
    {
      "time": "01:13:58",
      "text": "好。",
      "speaker": "发言人4"
    },
    {
      "time": "01:13:59",
      "text": "拜拜。",
      "speaker": "发言人3"
    }
  ],
  "lab_info": {
    "summary": "在这次讨论中，强调了一位执行力强、对市场有深刻理解的创业者及其团队的成就，特别指出他们在大模型和应用生态方面具有独到见解。讨论者偏好具有实践经验、能将创意从概念转化为实际应用的创业者。对于大模型技术，市场预估存在偏差，未来将是多模型并存的格局，强调了中间层在连接大模型与应用开发中的关键作用。此外，讨论涉及基于大模型的应用开发平台Defy，强调持续迭代、快速市场反馈的重要性，以及多模态技术、模型小型化和移动化的未来趋势。",
    "qa_pairs": [
      {
        "question": "LM ops这个概念是什么，它与传统的devo s有何异同？",
        "answer": "LM ops是基于大模型的应用开发和运营一体化，强调持续迭代改进的过程。不同于传统的devo s中运维侧重于基础设施监控和应用可用性，LM ops更关注非技术人员参与AI应用的定义与塑造，让业务人员、运营人员等也能通过他们的经验影响大模型。而传统devo s是瀑布式开发，一次性完成任务后上线。",
        "time": "00:02:11"
      },
      {
        "question": "Defy项目目前的发展状况如何？",
        "answer": "Defy项目现在在GitHub上的star数接近7000，私有化部署的Docker镜像安装数超过1万次，公有云服务版本也拥有4万多个应用安装量。并且，受众开发者质量很高，他们认真讨论并利用大模型能力进行各类应用开发投产。",
        "time": "00:03:09"
      },
      {
        "question": "Docker 1万安装数意味着什么？",
        "answer": "Docker 1万安装数意味着Defy私有云版本被打包成镜像或压缩包进行下载和安装，这些安装都是通过命令行操作，并非简单的浏览器下载，表明有大量用户正在使用Defy私有化部署。",
        "time": "00:03:31"
      },
      {
        "question": "如何评估GitHub上的项目活跃度和真实性？",
        "answer": "除了关注star数，还可以结合镜像被拉取次数、语言包的下载次数以及Google搜索趋势等多方面数据来综合评判项目的活跃度和真实性，因为单纯看star数可能并不准确。",
        "time": "00:06:19"
      },
      {
        "question": "市场上真正能落地的AI项目有哪些？",
        "answer": "在Defy平台上，首选推荐使用OpenAI的模型，因其在模型能力和API接口上具有显著优势。对于实际落地项目，可以从简单的prompt service开始，例如文法纠正或情感分类，然后逐步过渡到基于私有数据的微调或prompt engineering，以增强模型能力并使其更符合特定需求。",
        "time": "00:08:04"
      },
      {
        "question": "微调一个大模型有哪些难点？微调在何种情况下会被使用？",
        "answer": "微调大模型的难点主要包括两个方面。首先，微调要求的数据量非常大，并且需要大量的QA形式的样本。例如，为了使模型了解“徐凯老师是谁”，可能需要同一问题和回答反复变换20种方式来训练模型。其次，微调过程对资源消耗极高，需要GPU显存充足的机器配置，甚至可能是推理模型所需机器配置的2到3倍。对于开源模型来说，如果要做微调，可能需要更强大的硬件支持。此外，对于大部分开发者来说，微调的门槛较高，不是常规操作。微调通常在特别必要时才采用，因为它涉及复杂的数据准备和资源消耗，并非适用于所有开发者。比如，在工程化大模型的过程中，可以根据具体需求选择合适的方法，从易到难包括使用embedding、fine-tuning等技术。",
        "time": "00:13:00"
      },
      {
        "question": "embedding如何帮助解决微调的问题？",
        "answer": "embedding可以作为一种变相替代微调的方式，通过将模型的输入映射到一个特定的空间中，让模型能更好地理解和生成与给定信息相关的内容。",
        "time": "00:14:02"
      },
      {
        "question": "Few Shot学习是在哪个阶段的应用？",
        "answer": "Few Shot学习是prompt engineering的一种技巧，在模型微调阶段中，通过给模型提供少量的例子（如一到五个样本），来帮助模型更好地理解和满足特定指令，从而提高回答符合用户预期的概率。",
        "time": "00:14:27"
      },
      {
        "question": "Agent技术如何应用于复杂情境中？为何Auto-GPT等agent概念备受关注？",
        "answer": "在解决复杂情境问题时，如机器人订票等，需要多轮对话和多步推理的过程，这时就需要使用agent技术。agent能够利用大模型的推理能力、上下文信息以及可用工具（如搜索、API等）进行连续的动作，最终实现目标。目前有纯手工编排、完全自主以及部分编排与自主结合的三种形态。Auto-GPT等agent概念受到关注是因为它们实现了从人工高度介入到逐渐减少人类干预，最终达到自动化完成任务的程度，体现了AI技术的平权性和高效性。同时，agent的设计理念与人类思考和解决问题的过程相似，具有很高的吸引力。然而，目前agent也面临上下文窗口限制、模型推理质量不稳定以及相关工具的质量等问题，这些问题正逐步通过技术进步得到解决。",
        "time": "00:15:48"
      },
      {
        "question": "所以你们做Defi的初衷是因为大模型能力很强，并且在解决问题过程中需要解决很多阶段性问题，Define在这方面做了什么贡献？",
        "answer": "是的，我们利用大模型的强大能力，解决了很多团队在开发过程中遇到的中间问题。比如团队在进行嵌入式权重计算、模型参数调整和效果测试等方面的具体工程问题时，我们可以帮助他们快速迭代和解决。",
        "time": "00:23:59"
      },
      {
        "question": "你们计划如何帮助团队完成prom相关的任务呢？",
        "answer": "首先，我们会开发出好的prompt工具，让开发者能在自然语言编程环境下高效地编写prompt。此外，我们会内置一些模板来解决特定问题，并且与模型厂商深度合作，获取模型的特性信息，为开发者提供开箱即用的模型支持，减少他们调试和走弯路的时间。",
        "time": "00:25:17"
      },
      {
        "question": "prompt这件事情现在是被高估还是低估了？",
        "answer": "prompt的难度和潜力都被低估了。虽然prompt目前不可或缺，但随着模型的改进和工具的帮助，写prompt的难度将会逐渐降低。",
        "time": "00:27:14"
      },
      {
        "question": "大模型除了注意力机制外，还有哪些问题值得关注？大模型在理解和回答问题时是否存在准确性问题？",
        "answer": "成本是一个重要问题。通用大模型虽然具有很强的通识性和推理能力，但在特定领域的性能和成本上存在问题。垂直领域的模型可能更高效，但目前技术上还难以实现既有高性价比又有强推理能力的模型。确实存在准确性问题，大模型在学习过程中可能会接触到一些不太准确的信息，导致其在回答某些问题时也可能给出不太准确的答案，这是因为它对某些词汇背后的真实概念理解有限。",
        "time": "00:27:46"
      },
      {
        "question": "在商业化模型和开源模型之间，您认为哪种可能性更大？",
        "answer": "近一两年内，商业化模型在效果和成本上更具优势，但开源模型也有其独特价值，随着技术进步，两者可能会共同存在并相互补充。",
        "time": "00:32:57"
      },
      {
        "question": "你们团队如何评估大模型的能力？",
        "answer": "我们有自己的评估体系，会参考市面上多种评分榜单，并结合我们调优和用户数据来判断模型性能。同时，我们与模型接触紧密，能通过实际应用和用户反馈获得第一手信息。",
        "time": "00:30:31"
      },
      {
        "question": "大模型之间是否存在优劣差异，未来是否会混用？",
        "answer": "目前来看，各个大模型在不同领域各有优劣，未来很可能会出现混用的情况，每个环节根据需求选用不同模型，随着多模态技术的发展，这种趋势将会更加明显。",
        "time": "00:31:16"
      },
      {
        "question": "在开发者选择中间件时，为何他们更倾向于选择非中立的产品？",
        "answer": "因为非中立的中间件产品如OpenAI，在开发者眼中没有特定公司的绑定，他们可以灵活地更换模型，先用OpenAI的能力快速构建原型，再切换至自己想要的模型，整个过程较为自然且无需担心代码重写的问题。而如果使用了微软等公司的开发工具包，由于其绑定特定模型，开发者在市场发展和技术更新时可能会产生疑虑，担心代码需要重新编写。",
        "time": "00:35:37"
      },
      {
        "question": "中间件的价值体现在何处？",
        "answer": "中间件的价值在于解耦prompt工程和原始程序代码，将两者分开处理，以避免因模型变化导致的代码重写问题。",
        "time": "00:36:14"
      },
      {
        "question": "开发者在基于现有模型进行应用开发时，通常需要多久的周期？",
        "answer": "大部分情况下，开发者从原型设计、产品调优到用户反馈等环节，完成一个典型应用可能需要3个月到更长的时间周期。",
        "time": "00:36:53"
      },
      {
        "question": "使用define（可能为产品名称）是否能显著缩短开发时间？",
        "answer": "观察结果显示，以浪漫为基准，大部分典型应用能通过使用define缩短1到2个月的开发时间，但真正的价值在于它解决了后续运营维护过程中的问题，如数据集维护、权重调整、敏感数据处理及政策变化带来的工具选择与维护等，这些是许多市面工具无法解决的问题。",
        "time": "00:37:18"
      },
      {
        "question": "define如何帮助不懂AI的人员参与AI相关运营工作？",
        "answer": "define的目标是让所有人都能围绕AI来做配合，即使是不懂AI的后台运营人员也能轻松进行AI相关的运营，并持续改善产品效果，从而实现AI的可塑性潜力最大化，推动AI领域的平权发展。",
        "time": "00:38:09"
      },
      {
        "question": "long chain是什么？",
        "answer": "long chain是一个类似工具箱和教科书结合的存在，为开发者提供接入大模型及构建相关应用所需的工具和抽象概念。它包含一系列封装好的代码片段，帮助开发者快速接入和使用大模型，但因其早期产品化程度不够，对于深度工程来说可能无法满足需求，需要开发者进行定制化修改。",
        "time": "00:39:35"
      },
      {
        "question": "long chain与define的关系是什么？",
        "answer": "long chain作为开发辅助工具，可以与define结合使用。define是一个完全产品化的综合解决方案，提供了包括调试、跟踪在内的全套工具和服务，其中部分功能可能借鉴或整合自long chain。开发者可以根据需求选择使用define的部分功能或将其与其他工具搭配使用。",
        "time": "00:42:58"
      },
      {
        "question": "你如何将开发者分为两类，并对这两类开发者有什么看法？对于大模型能力有限这一现实，我们应该如何应对？",
        "answer": "我将开发者分为务实型和愿景型两类。务实型开发者评估过大模型的实际能力，相信在未来一年内，通过模型或中间件工程层面的改进，大模型能解决当前遇到的问题；而愿景型开发者期望大模型能替代整个团队完成复杂任务，这类需求可能在三五年内部分得到满足，但也可能仅部分实现。尽管大模型的能力有限，但关键在于如何清晰定义需求。如果需求明确，解决特定问题就相对容易，比如妙鸭就专注于解决特定需求，且效果很好。泡沫现象也源于需求定义不清，而定性思考往往比定量更有效。",
        "time": "00:46:56"
      },
      {
        "question": "目前大模型的应用场景有哪些典型的例子？",
        "answer": "教育领域是大模型应用较多的场景，例如评估学生水平、批改作文等。此外，在教育行政、市场营销、客户服务等方面，大模型表现良好，如文案写作、商品图生成及初步的客服交互等。",
        "time": "00:49:26"
      },
      {
        "question": "在日常操作中，你有没有遇到一些更深层次的问题想要分享？",
        "answer": "目前最困惑的问题是基于现有大模型能力，未来会诞生何种类型的AI原生应用。类似于移动支付激发了大量创新产品，未来大模型可能会催生出大量新的增量应用。",
        "time": "00:51:06"
      },
      {
        "question": "对于Chatbot在未来的发展前景，你持何种观点？",
        "answer": "Chatbot是一种直观易懂的交付形式，但并不意味着未来都是Chatbot。大模型技术可以应用于多个场景，不一定局限于聊天交互。苹果等公司可能会在操作系统级别集成AI入口，提供调度和交互体验，而非仅限于Chatbot形式。",
        "time": "00:52:16"
      },
      {
        "question": "未来大模型发展的热点或质变方向有哪些？",
        "answer": "未来大模型发展的热点包括多模态训练和输出，即结合视觉、听觉等多元感官数据进行训练，以提升模型能力并丰富输出形式，使其能执行更多人类知识工作者的工作。此外，模型的小型化和移动化也是趋势，让大模型能够装进口袋，不再依赖云端，同时数据向量化也是一个重要方向，让AI能够快速加载和处理各种类型的数据。",
        "time": "00:55:27"
      },
      {
        "question": "国内大模型的发展现状是怎样的？",
        "answer": "国内大模型领域目前有点类似计划经济，大家都在争相投入，但缺乏集中资源调度，导致部分项目可能无法达到预期效果。同时，有很多模型厂商已经与一些大客户签约，但现有的顶级模型能力仍无法满足客户需求。",
        "time": "00:59:24"
      },
      {
        "question": "Define在其中扮演什么角色？Define如何与开发者合作并获取宝贵信息？",
        "answer": "Define像是介于技术材料提供商（如锤子）和实际应用场景（钉子）之间的“螺母”，围绕开发者需求来设计产品，帮助他们充分利用大模型能力进行落地应用。Define通过与上千名开发者建立紧密联系，包括几百名关系特别好的开发者，他们会毫无保留地分享自己在一线操作中遇到的问题和解决方案，这些信息对Define的产品迭代和市场理解至关重要。",
        "time": "01:00:35"
      },
      {
        "question": "为什么看好Define的发展前景？",
        "answer": "因为未来上游有很多大模型厂商，下游有很多应用开发者，中间需要一个像Define这样的产品来连接上下游，提供针对性的技术支持和解决方案。并且，Define团队拥有丰富的行业经验和强大的执行力，能够快速响应市场变化并解决问题。",
        "time": "01:00:50"
      },
      {
        "question": "Define近期有哪些合作和福利活动？",
        "answer": "近期会与许多模型厂商合作，为开发者提供大量额度支持，具体操作可以通过搜索DIFY或访问diving AI网站获取。",
        "time": "01:01:50"
      },
      {
        "question": "对陆宇老师个人的认识如何？为何青睐陆宇老师和Define项目？",
        "answer": "陆宇执行力强，对海外市场有深入研究，对大模型和生态有深刻理解，同时具备丰富的市场经验和从0到1的落地能力，是一个很适合做中间层项目的创业者。看重陆宇的执行力、市场理解和产品定位，以及团队的实战经验和学习能力强。Define项目从应用层出发，看到了中间层的巨大市场潜力，并且战略定位明确，具备成为平台级机会的潜力。",
        "time": "01:03:24"
      },
      {
        "question": "对于中间层创业和投资机会的看法是什么？",
        "answer": "中间层可以分为两类，一类偏向大模型层，另一类接近应用开发者。认为与大模型过近或与C端过近都会面临挑战。而Define这类找准定位、有定力、有经验做好中间层的团队，将有望抓住这一领域的创业和投资机会。",
        "time": "01:09:55"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "陆羽谈LLMOPS与AI应用开发",
        "summary": "LLMOPS概念源于DevoOps，强调AI应用的持续迭代和快速反馈，适用于基于大模型的AI原生应用开发。与传统软件研发不同，它注重市场用户反馈，以实现预期结果。Defy提供了一套完整的技术栈，包括开发框架和运营工具，支持基于大模型的应用开发。"
      },
      {
        "time": "00:01:48",
        "title": "DIFY：GPT协助创建的AI研发运营一体化平台",
        "summary": "DIFY，由GPT命名，代表“do IT for you”，是一个结合研发和运营的平台。在传统的开发模式中，运营主要指维护基础设施如服务器监控和应用性能的运维。进入MOPS阶段，运营的定义转向更多参与非技术人员，如业务人员和销售人员等，共同塑造和定义AI应用。这种模式强调了AI应用的开发不仅仅是少数工程师的工作，而是需要集合业务知识和经验于大模型之中，实现对更多人的开放和参与。"
      },
      {
        "time": "00:03:00",
        "title": "Defied私有云版本成功案例分享",
        "summary": "自五月中旬开园以来，Defied的YouTube频道已接近7000星，同时，其私有化部署的Docker镜像版本获得了超过1万次的安装。此外，公有云服务版本已有4万多个应用，显示出其在AI领域内受到的广泛欢迎和应用。通过与用户的直接互动，发现目标开发者群体对于利用大模型能力进行应用开发具有高度的严肃性和需求性，无论是面向市场的创业、销售给甲方还是满足公司内部业务需求，都显示出了对Defied技术的高度认可和积极的应用场景。"
      },
      {
        "time": "00:04:33",
        "title": "GitHub上的开源项目推广和影响力观察",
        "summary": "自从比赛开始，团队开始密切关注GitHub平台，发现了该平台上众多开发者无私奉献的价值和获得全球正反馈的潜力。尽管没有进行过多的运营活动，项目在GitHub上凭借自身质量获得了数千星标（stars），反映了GitHub社区的巨大影响力和马太效应。团队还注意到了GitHub上存在刷star等SEO行为，并认为通过查看项目拉取次数等其他数据比单纯看star数量更能反映项目的真实热度和影响力。"
      },
      {
        "time": "00:07:07",
        "title": "探讨AI模型应用及落地实践",
        "summary": "当前市场上真正能落地的AI项目备受关注。OpenAI因其在模型能力和API接口方面的显著优势，被视为模型领域的领军者，其模型被看作是离生产落地最近的首选。在应用层面，存在从简单到复杂的服务层定义，包括基于简单prompt的服务到基于私有数据的复杂应用。讨论还涉及了模型微调和prompt工程作为增强模型能力的方式，以及如何通过向量数据库和私有数据的整合，提升AI应用的实用性与个性化程度。"
      },
      {
        "time": "00:11:32",
        "title": "大模型微调的挑战与替代方案",
        "summary": "讨论重点在于大模型微调的复杂性和资源需求，以及提出的解决方案。微调大模型需要大量特定格式的数据，且对计算资源有较高要求，导致门槛较高。因此，提出了从易到难的三种解决方案：工程化应用、使用embedding、微调，旨在帮助开发者根据实际情况选择最合适的策略。"
      },
      {
        "time": "00:13:55",
        "title": "大模型的个性化调优与Agent技术解析",
        "summary": "对话重点讨论了如何利用大模型生成符合特定需求的输出，特别是通过finding而非prom或bedding来调整模型的默认回答风格，以及在不使用复杂提示的情况下，让模型输出如诗歌等特定风格的内容。此外，介绍了one shot和few shot技术作为提高模型回答准确度的手段，这些技术通过提供少量示例来增强模型对用户指令的理解。进一步，讨论了Agent技术，用于处理需要多轮对话和多步推理的复杂任务，如订票，展示了大模型在实际应用中的潜力和挑战。"
      },
      {
        "time": "00:16:38",
        "title": "探索Agent技术的发展与应用",
        "summary": "讨论集中在Agent技术的三种形态：纯手工编排、完全自主和混合形态。强调了混合形态Agent通过结合编排能力和自主能力，实现了相对可控的状态。此外，讨论还涉及了Auto GPT的影响力、AI大模型的发展方向、以及Agent技术对于提高个人与团队效率的潜力。特别提到了技术平权的概念，说明了开源模型和Agent如何使得技术人员能够以较少资源实现更大价值。然而，也指出了Agent技术目前面临的最大问题是成本。"
      },
      {
        "time": "00:19:47",
        "title": "大模型在软件开发中的挑战与解决方案",
        "summary": "讨论集中在大模型应用于软件开发时遇到的三大挑战：上下文窗口限制、推理质量的不稳定性以及工具质量。首先，大模型需处理的上下文信息量巨大，如一个软件项目可能包含十万行代码，要求模型具备庞大的上下文处理能力。其次，尽管GPT4等模型的推理能力强大，但仍存在出错情况，需要通过反复校正来提高准确性。最后，强调了工具质量的重要性，包括技术栈的完善、推理算法的优化及编程技巧的应用。特别提到了通过创新技术改进API自动化测试过程的实例，展示了针对大模型局限性的具体解决方案。"
      },
      {
        "time": "00:21:31",
        "title": "大模型的局限性与优化方案探讨",
        "summary": "讨论集中在大模型处理长文本时存在的问题，如注意力不集中和信息权重分配等。由于大模型对文本信息的处理无法像人类那样准确抓住重点，提出了使用另一个大模型辅助总结核心信息的解决方案，但同时指出这需要人工介入来优化，强调了在实际应用中不断调优的重要性。"
      },
      {
        "time": "00:23:19",
        "title": "软件团队面临的prom工程挑战与解决方案",
        "summary": "软件团队利用大模型API开发产品时遇到的第一个难题是prom工程，这一问题主要由缺乏经验、团队协作及人与模型配合的难题引起。解决这一挑战需要开发专门的prompt工具，创建有效的模板，并与模型厂商紧密合作，理解模型特征，以降低开发者的学习曲线。此外，利用高级模型辅助编写prompt，以减少开发过程中的错误和弯路，从而提高效率。"
      },
      {
        "time": "00:26:40",
        "title": "探讨语言模型的prompt作用与挑战",
        "summary": "对话涉及了prompt在当前人工智能模型中的重要性及挑战，以及对其未来发展的看法。一方面，prompt的潜力和难度被低估，虽然存在提升空间，但其在帮助模型理解用户意图方面仍不可或缺。另一方面，讨论也触及了大模型的成本问题、在特定领域的应用挑战，以及与人类相比学习能力的局限。此外，提到了多模态训练可能为解决模型理解和回答问题的准确性提供了一种可能的解决方案。整体上，虽然大模型在通用知识和推理能力上表现出色，但对于特定领域知识的精确应用和理解仍面临挑战。"
      },
      {
        "time": "00:30:21",
        "title": "大模型能力评估与未来发展趋势探讨",
        "summary": "在讨论中，提及了对大模型能力的评估方法，以及团队通过实际应用和用户数据来评估大模型的性能。同时，分析了市场上存在的多种评分体系，并指出直接进行评估的成本高昂。讨论还触及了大模型在不同领域的优劣，以及对未来大模型混用情况的预测。"
      },
      {
        "time": "00:31:30",
        "title": "多模态技术与模型发展趋势探讨",
        "summary": "在当前的技术发展中，文本生成、特例处理、embedding以及声音与文字的互转等多个环节已经开始在工程项目中混合使用。随着多模态技术的成熟，未来的发展将依赖于多个模型之间的合作，因为每个模型都有自己的擅长领域和成本结构。对于未来商业模型的走向，存在两种可能：一种是商业模型垄断市场，每家提供封闭的解决方案；另一种是开源模型的繁荣，提供更多工程灵活性和可能性。当前，商用模型在效果和成本上具有优势，但开源模型的快速发展也引起了人们的关注。对于模型的商业化运用，存在担忧大模型可能会自行解决所有问题，但目前看来，模型层的多元化将保持中间层的价值。尽管云服务商可能会提供自己的开发工具包，但其封闭性和非中立性可能限制其在开发者中的接受度。中间件的价值在于实现prompt工程与程序代码的解耦，提供灵活的模型更换方案。"
      },
      {
        "time": "00:36:31",
        "title": "探讨AI开发与应用的未来趋势",
        "summary": "对话中深入讨论了AI开发中的挑战与机遇，特别是关注如何通过不同模型缩短开发周期，以及如何使AI技术更加普及和平民化。指出了现有工具和模型在解决实际问题时的局限性，并强调了团队合作和跨领域知识共享的重要性。此外，还特别讨论了'Long Chain'的概念，认为它既是一个工具箱也是一本教科书，对于AI开发者来说是入门的起点，但同时也存在一定的局限性，需要开发者根据实际情况进行调整和优化。"
      },
      {
        "time": "00:42:13",
        "title": "Longsmith和Define在LangChain开发中的角色与应用",
        "summary": "Longsmith作为LangChain开发中的一个调试和跟踪工具，帮助开发者通过可视化调试解决代码运行中的问题。在讨论中，提出LangChain、Longsmith与Define之间的关系，强调了这些工具在支持开发者利用大模型应用时的重要性。Define被描述为一个一站式的解决方案，旨在满足大多数开发场景的需求，而Longsmith提供的调试能力对Define的开发辅助工具是不可或缺的一部分。此外，讨论还涉及了开发者在使用这些工具和技术栈时面临的挑战和选择，以及对未来大模型应用发展的乐观预期。"
      },
      {
        "time": "00:48:27",
        "title": "大模型在教育和企业应用中的潜力与挑战",
        "summary": "对话中讨论了大模型在教育领域，特别是评估学生水平和提供具体反馈方面的应用，指出尽管存在主观性，但定性分析对于改进教学方法非常有用。同时，强调了在追求定量分析时可能遇到的问题，提倡更多关注定性方面的应用。此外，还提到了大模型在企业中的成熟应用，包括市场营销、客服等领域，以及如何在不完全替代人类员工的情况下，通过自动化改进工作流程，提升效率。讨论还触及了探索大模型如何帮助企业识别市场机会，从而开发出全球适用的产品。"
      },
      {
        "time": "00:50:50",
        "title": "探讨AI原生应用的未来与挑战",
        "summary": "对话集中于未来基于大模型的AI原生应用的可能形态，以及它们如何与现有技术和用户交互方式融合。探讨了虽然目前尚不清楚这些应用的具体形式，但预计它们会深度融合到日常生活中，不仅限于chatbot形式，还可能整合多种模型能力和硬件，形成封闭而完整的解决方案。特别指出，尽管未来每个人或企业可能拥有数以亿计的个性化AI报告，但实际的AI交互入口不会超过三个，强调了AI技术的个性化和专属性。同时，讨论了在操作系统级别整合AI技术的可能性和挑战，以及这种技术如何通过不同的入口与用户进行高效、自然的交互。"
      },
      {
        "time": "00:55:07",
        "title": "大模型未来发展方向与挑战",
        "summary": "讨论集中在大模型未来发展的几个热点方向，包括多模态训练的深化，增强模型对图形图像的理解，以及通过结合多种感官数据进行训练，提升模型的能力。强调未来大模型的发展可能包括输出形式的多样化（如文字、图片、3D模型、声音等），以及模型的小型化和移动化，使得大模型能更加贴近人们的日常生活。特别提到了数据向量化的重要性，以及版权问题对未来大模型发展构成的挑战。"
      },
      {
        "time": "00:59:15",
        "title": "大模型应用落地挑战与解决方案探讨",
        "summary": "在当前AI大模型快速发展背景下，许多大模型厂商面临应用落地的挑战，即便拥有世界顶级的模型能力，也难以完全满足客户的高预期。讨论指出，市场需求呈现出一定程度的计划经济特征，资源的集中调度显得尤为重要。对于如何有效利用大模型的能力，提出需要有介于模型提供者和最终用户之间的平台或工具来搭建桥梁，明确指出“define”作为一个基于开发者需求反推而设计的产品，旨在帮助开发者更好地利用大模型能力。强调了在AI领域，中间环节的重要性，以及通过与模型厂商合作，为开发者提供支持和资源的重要性。"
      },
      {
        "time": "01:02:39",
        "title": "播客制作人谈论投资与AI创业项目",
        "summary": "播客制作人讨论了他对陆老师及其参与的AI创业项目c define的看法，强调了执行力、市场理解以及对大模型和生态系统的深刻见解的重要性。制作人表示，他们投资这个项目的原因在于陆老师的团队不仅执行力强，而且对于市场有清晰的理解和前瞻性，特别在中间层技术方面有独到的见解和实践。此外，制作人还分享了他们对于创业者类型的偏好，更倾向于有经验和能够亲手执行的创业者，而非仅仅有潜力或背景光鲜的人士。他们认为，执行力强的创业者能够在市场上积累明显的优势，而陆老师的团队正是这样的代表。"
      },
      {
        "time": "01:08:48",
        "title": "探讨中间层创业与投资机会及大模型的前景",
        "summary": "中间层的创业和投资机会被分成两类：一类更偏向大模型层，面临如何销售及应用场景的挑战；另一类接近应用开发者，可能因直接对消费者(to C)的特性而遇到自我发展或被视作竞争的风险。跟大模型太近可能无法保留市场空间，而过于接近C端又可能导致激烈竞争。因此，中间层需由有定力和经验的团队来把握，迪拜团队被看好。此外，对于大模型的未来和不受欢迎的观点也表达了兴趣。"
      },
      {
        "time": "01:10:32",
        "title": "大模型的局限与应用层创业挑战",
        "summary": "讨论重点在于大模型的能力被高估，而其落地的难度被低估。提出了未来将是多模型共存的状态，并看好中间层的机会。指出了创业者在应用层普遍面临的问题，强调利用现有技术更好地定义用户需求比投入大量资源解决技术问题更为重要。最后，讨论了大模型在实际应用中的意义和挑战，以及对创业者和关注该领域的人士提供了有价值的视角。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "基于大模型的应用开发技术栈"
                },
                {
                  "children": [],
                  "content": "包括开发框架和运营工具"
                }
              ],
              "content": "LLMOPS (LLM Operations)"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "大模型应用背后的运营过程"
                },
                {
                  "children": [],
                  "content": "非技术人员参与AI应用的塑造"
                }
              ],
              "content": "Agent"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "编写有效的prompt以引导大模型生成所需结果"
                }
              ],
              "content": "Prompt Engineering"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "将文本转换为数值向量，用于模型理解"
                }
              ],
              "content": "Embedding"
            }
          ],
          "content": "定义与概念"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "定位于帮助开发者高效利用大模型"
                },
                {
                  "children": [],
                  "content": "提供包括prompt工具和运营平台"
                }
              ],
              "content": "Defy项目"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "上下文记忆问题"
                },
                {
                  "children": [],
                  "content": "注意力不集中"
                },
                {
                  "children": [],
                  "content": "高成本"
                }
              ],
              "content": "大模型的局限性"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "教育"
                },
                {
                  "children": [],
                  "content": "客服"
                },
                {
                  "children": [],
                  "content": "市场营销"
                },
                {
                  "children": [],
                  "content": "企业内部调度"
                }
              ],
              "content": "用例与应用"
            }
          ],
          "content": "技术与应用"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "预期通过多种感官数据训练，提高模型能力"
                }
              ],
              "content": "多模态模型"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "将大模型能力集成到小型设备中"
                }
              ],
              "content": "模型小型化"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "将知识产权内容转化为AI可读格式"
                }
              ],
              "content": "数据向量化"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "促进开发者和模型之间的协作"
                }
              ],
              "content": "社区与开源"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "面向开发者与模型的连接桥梁"
                }
              ],
              "content": "中间层的机会"
            }
          ],
          "content": "未来展望"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "工具箱和教科书，帮助开发者快速启动大模型应用"
                }
              ],
              "content": "LangChain"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "调试和跟踪工具，辅助开发过程"
                }
              ],
              "content": "LongSmith"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "成为连接大模型与应用开发者的平台"
                },
                {
                  "children": [],
                  "content": "提供一站式解决方案，包括IDE、模板、工具等"
                }
              ],
              "content": "Defy的愿景"
            }
          ],
          "content": "产品与工具"
        },
        {
          "children": [
            {
              "children": [],
              "content": "大模型的成本和效率问题"
            },
            {
              "children": [],
              "content": "保持模型和应用的持续迭代和改进"
            },
            {
              "children": [],
              "content": "提升prompt工程的质量和效率"
            },
            {
              "children": [],
              "content": "多模型共存状态下的应用开发策略"
            }
          ],
          "content": "业界挑战与解决方案"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "需要明确市场定位，避免被大模型或C端应用取代"
                },
                {
                  "children": [],
                  "content": "执行力和战略定力是关键"
                }
              ],
              "content": "中间层的机会与挑战"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "高估大模型能力，低估落地难度"
                },
                {
                  "children": [],
                  "content": "应用层公司应更注重解决实际用户问题，而非技术难题"
                }
              ],
              "content": "大模型的局限与落地难度"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "执行力强"
                },
                {
                  "children": [],
                  "content": "清晰思考市场定位和用户需求"
                }
              ],
              "content": "创业者需要的品质"
            }
          ],
          "content": "投资视角"
        }
      ],
      "content": "大模型应用开发讨论脑图摘要"
    }
  }
}