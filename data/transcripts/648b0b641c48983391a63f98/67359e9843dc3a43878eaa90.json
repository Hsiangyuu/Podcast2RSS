{
  "pid": "648b0b641c48983391a63f98",
  "eid": "67359e9843dc3a43878eaa90",
  "title": "我在 Character.ai 做 Post Training｜对谈前 C.AI 模型应用算法专家 Ted",
  "task_id": "g2y8qe7ep38xnbeo",
  "transcription": [
    {
      "time": "00:00:02",
      "text": "Do something there.",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:15",
      "text": "我们今天很开心请到了一个老朋友，你们认识蛮久的了。然后认识太太的时候，太太是还在CAI，最近是自己刚出来。太太你可以给大家先简单介绍一下你的经历。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:28",
      "text": "好的，我最近也是刚离开CEI，在CEI差不多待了一年，主要做的就是大模型的post圈里也就微调这个部分。然后在那之前其实就一直是在硅谷的大厂robots meta、google、apple这样跳来跳去，做的也都是比较经典的全栈工程师，偏后端一些。但是在过去一年，在CAI有一个很奇妙的机会，让我可以加入到微调这边。和很多的研究员一起把一个不太会说人话的大模型调调，一直调到我走之前应该都算是业界最好的这样一个对话式大模型。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:06",
      "text": "哼大家都在讲CAI这款产品，它的用户群其实也是有点像rob blocks对吧？也是偏年轻的，然后二次元什么那些群体。但是大家就觉得它的商业化一直没做起来，这个的原因是什么呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:19",
      "text": "简单概括两点，一没有怎么做到目前为止就是一个简单的订阅。另外一个就是我觉得这个团队可能之前思考的也少。我在走之前团队是刚刚开始积极探索这个可能性。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:32",
      "text": "所以你觉得不是说用户人群什么的有问题，或者说现在还不知道有没有问题，就是现在最核心问题是公司层面就还没有去做很多的探索跟尝试是吧？对我在想这个原因到底是什么？因为你看国内的AI创业公司，这两年基本形成一个共识，就是商业化甚至于是最重要的一件事情了。当然跟国内的融投资环境什么的也有关系。但好像美国那边的产品，哪怕cii做了这么久，这么大的用户量，然后好像也没有强调要做商业化这件事儿。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:00",
      "text": "是吧？这个说起来有一点感觉像是开玩笑，但我是很认真的在说这句话。因为我们有的网以及会为了弄买账的大量投资人，导致商业化在很长期内都不是我们公司发展的一个重点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:14",
      "text": "就是因为你们相信AGI对吧？简单来讲是这样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:19",
      "text": "可以说很长一段时间内，我们所有的娱乐的属性都是我们narb为主的团队追求AGI路上的一个副产物。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:27",
      "text": "我记得你去CI的时候，他们大概有40个人左右是吧？对的，但大多数应该都是在做模型训练的人。",
      "speaker": "发言人2"
    },
    {
      "time": "00:02:34",
      "text": "当时是的，我加入的时候应该将近25人都是围绕着模型训练，就是postion这一堆。然后5个到7个左右是行政的，不到10人是前端后端还有一些运维。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:49",
      "text": "对然后再往后可能慢慢的才把产品什么的这些人开始招起来，是吧？因为国内其实我记得大概一年前左右，大家都在盛传一个事，就是CEI里面其实只有半个产品经理在做事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:04",
      "text": "对的，我加入的时候，其实全公司是没有一个真正title是产品经理的人。那半个是一个step chat的一个高管他等于说是兼职，是作为我们的顾问。但我觉得这老哥非常厉害。超级产品经理。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:18",
      "text": "你觉得美国的超级厉害的产品经理，尤其在to c端的他们和因为你也接触很多国内的公司，你觉得有什么很明显的差异吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:28",
      "text": "我接触的这种超级产品经理不多，所以说可能有点偏颇。但我在美国接触过的超级产品经理和我在国内看到的，比如说是张小龙这样或者类似的人。他们给我的一个感觉是国内可能更加重人文化。一就是他会总结出一些很好的方法论。但是在美国这边我接触到的人，他可能在数据分析上非常深入。他可能跟那种数据科学家有差不多同样那些比较复杂SQL的能力。并且他也很愿意亲身的去分析各种各样的数据，寻找里面的inside。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:59",
      "text": "对，这个我前段时间也发现了类似的一个点，就是突然我刷到了一个美国那边的产品经理的模拟面试。然后我就发现他整个模拟面试的过程非常像管理咨询的那个面试，就给你出个题说。最近用户行为发生了什么变化，他说怎么样了。然后被面试者就要解析说那可能我要看哪几个数据，然后他是不是怎么样了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:23",
      "text": "对，因为to c甚至说过去几年最热门的几个超级大的社交网络的兴起，其实背后都是比较严格的那种数据分析作为底子。所以无论是数据科学家也好，还是产品经理也好，技能的发展还有经验的积累都会。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:38",
      "text": "围绕这个是OK。所以讲回来就是CAI你觉得在你待的一年多的时间里面，你进去的时候他应该是非常向好的一个状态，对吧？然后你走的时候他就已经被拆开，然后一部分人回到那个大公司了。就在这过程当中，你都看到了他的哪些发展的问题，最后导致的这么一个结果。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:02",
      "text": "其实就像徐凯你之前写过的那篇文章，就是团队很长期里面就处在一个既要一个产品又要一个AGI这样的愿景。两件事都要做，最后的结果倒推看，就是你不能两边都抓，你必须得要放弃一遍。",
      "speaker": "发言人1"
    },
    {
      "time": "00:05:16",
      "text": "所以如果重来一遍，你觉得CI应该改变哪件事，可能会让它发展的更好？",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:23",
      "text": "我个人很偏颇的讲，我希望我们应该往AGI再赌一把。大的怎么去赌？可能我入职之前的很多决策都要为纯粹的AGI去服务。在这过程中我相信肯定会损失很多的用户增长。但是也有可能现在国外基本只剩下五家大lab的，里面也许能挤进去我们一家。",
      "speaker": "发言人1"
    },
    {
      "time": "00:05:42",
      "text": "对我觉得如果真的能在幻想中运营的话，可能当时把Carry点开前面那个产品直接卖给自己，或者卖给mini max对吧？然后后面就好好的做模型，也许是一条出路。当然这个可能政策上就不太能实现了。所以我正好提个点，这两天正好有个新闻是说toki的量超过了CI因为token的很多里面的人是从字节出来在做的。对，之前有人讲过说，如果把CI这家公司或者是那个产品交给字节系来做，可能是完全不一样。不管是从产品上还是从商业化上来讲，我不知道你怎么看这个问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:19",
      "text": "我觉得我会把这个事情更看像是说这个产品对于母公司来说算什么。Cat AI对于我们公司来说就是唯一的产品。但toki对于mini MAX来说，它是要证明他们这个模型有一个非常好的落地的可能性，以及它在海外有非常好的增长。Mini max自己有海螺，也有很丰富的产品矩阵，甚至还有API。所以从这个方面来说，talk I我觉得更像是mini max整个公司的战略的一部分。并不像是说整个mini MAX就全靠talk一个，然后必须就靠它去走出去。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:50",
      "text": "明白有一小撮人，大概在一两年前大家讨论过一个话题，就是你看一打开CEI产品的网站，一眼看过去就知道没有听过什么运营和雕琢的一个非常简陋的ugc平台的感觉。对，但toki你打开就发现它里面有非常重的这种推送推荐运营和一些其他的相关的东西。然后有人讲说CEI的建筑平台更容易让UGC的一些奇奇怪怪的原生内容长出来。也有人讲说toe这种的就是更重运营的话，可能一些用户的数据行为表现会更好。我不知道你们有没有讨论过类似这样的问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:29",
      "text": "我们在今年年初产品团队膨胀之前，我们做过一些推荐算法的调整。结果就当时比较有限的产品的资源能够做到的事情而言，我们发现就不太值得做。因为我们有非常大量的用户数据，我们的整个训练的这个管线又很健全。所以用户跟我们的机器人之间的交互，它能快速的回馈到整个模型，然后再进一步的回馈到全体的角色，跟用户这个反馈的体验。所以从这个角度来说，对我们而言回报最大的还是持续去迭代模型，持续优化在产品的细节上能够得到更多用户反馈的这些部分。而不是说通过运营，通过产品的思路去说，今天我怎么去做一些官方的角色，做一些更多推荐产品的调整。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:14",
      "text": "所以你们当时在内部没有一个时刻有个人突然说，toki最近涨得挺好的。我们来分析一下他的产品模式，然后看看哪些是能被用到CI产品里面的。我不知道包括CEI在内的美国公司很少会做这样的事儿吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:31",
      "text": "不会，我们正常做产品调研talk基本都是永远会在榜上的。因为安全的聊天对吧？就不是说无限制聊天的话，那其实你要看着外面的进没有几个，然后talking他本身又很主动的去做很多我们没有做的一些路线，所以看他这些路线做的怎么样，或者假设我们真的做效果会长成什么样，我们都可以把toki当做一个很好的参考对象。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:53",
      "text": "所以你们有总结出来他比如做的特别好的一两点东西吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:57",
      "text": "首先功能迭代的很快，这一点说实话他是让我们甚至觉得有点羡慕的。Talk I它能够快速的上各种多模态的新功能，或者在内购上面也做的很积极，然后做了很多市场，你可以自己制造卡。这些在我们看来都是很好的idea的这样一个输入。但是我觉得这里要澄清一点的就是我们看toki做这些功能的时候，既是认可另外一种也是一种警示。因为我们可以意识到，如果toki做了这么多丰富的功能，但是它本身的商业化也好，增长也好，依然没有说有一个特别大的突破的话，那可能这些功能本身是不太适合这个产品形态。所以我们更是带着这种中立的状态去看talk king的这些功能。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:35",
      "text": "明白，CEI现在这个结果其实对mini max来讲，我觉得他们也很尴尬对吧？因为他们是沿着这条路径做的最好的。但是突然发现最前面的标杆好像被大家认为不一定能行得通了。所以你现在你自己还相信CI这类的AI陪伴产品吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:57",
      "text": "我本身的话还是非常相信的。但是核心的问题就像徐凯你刚才提到的，商业化真的好做吗？商业化到底能走得多远？如果说这种重度使用的APP，它本身做订阅不好做的话，那是不是只能卖广告？那什么样的广告形式比较好呢？是说直接贴各种小广告放在里面，就先从流量上吃一波红利，还是说有没有更加原生态的，让机器人去给你推荐一些广告。我觉得这里面是有一些甚至技术上来说都还等待你去解锁的可能性在里面。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:26",
      "text": "但是它的这个可能的用户量，说实话我觉得是不能忽视的。官方的数据可以说，我们现在月活已经到达2000万了，然后日活也已经接近800万了，这跟去年的数字翻了差不多一倍。所以说按照这个速度，明年可能月活是能达到3000万，然后日活可能接近1000万。这样的一个用户群，无论在什么状态下，你其实都不能说可以忽视掉。所以从这个角度，我觉得mini max也不用特别慌，说明他们这个用户量的上限还是可以做到很夸张的。可能在将来随着这些用户慢慢长大，也会变成像是当年X一样。因为你像最开始robbo x作为一个教育软件，走进当时各种学生的家里的时候，其实也没会觉得它将来会变成一个月活4亿的大平台，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:10",
      "text": "到底现在是什么样的人群在使用类似CI的产品，我确实没想到它会有这么大的月活，或者说平均的用户时长什么的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:21",
      "text": "现在的应该是说年轻女性为主，相对偏二次元。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:25",
      "text": "你说的年轻大概是多年轻？",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:29",
      "text": "高中生的比例其实没有那么多，大学生和刚上班几年的这种。",
      "speaker": "发言人1"
    },
    {
      "time": "00:11:34",
      "text": "年轻人的比例还更高一点。OK, 我们上周正好跟Jason聊了一期，然后他他其实是觉得说类似CI这样的产品，更多的像是一个互动内容消费，或者说互动小说消费，而不是一个真正的AI陪伴的产品。你同意他这个观点吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:51",
      "text": "这一点我非常同意。很多人也会经常问我这个问题，CEI它到底提供的价值是什么呢？我此时就想说它是一个创造性的感情伴侣，它的创造性的部分是非常重的。用户的抽卡每一句文字其实都是一个抽卡的过程。用户输入很多东西，然后机器人说的话他还去筛选。有的时候说的话并不是特别完美的，他还得去替换。在这样一个重输入的过程中，用户的确获得了一些很新的体验。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:19",
      "text": "所以你回头看，你觉得CEI之所以在这个品类里面做的这么好，大家不管怎么样肯定都觉得他是老大。在这个赛道里面，至少目前为止，它核心的原因和他的优势到底是什么？",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:32",
      "text": "三点，从我技术出身的这个角度来分析的一点，就是我们有nm shazia，他厉害就厉害在他能带着一群其他的天才研究员，在去年这个时间点，把我们的整个的低成本压到可能外面同参数量的这个模型的1%以内。所以这一点导致我们可以轻松的hold得住上千万用户，不至于马上把银行里的钱给烧光。然后第二点，因为我们是自研模型，我们可以去控制它在运行里需要看过那几万亿的语料的比例。所以说我们可以说在初期就不是特别追求AGI的模型的那个情况下，先给大家看足够多的人类语料出来的模型，它自然就能跟人类开展各种各样极大广度的对话。然后第三点就是我们这样一个后训练或者说微调的管线，也是经过了多次迭代之后，它能够现在形成一个特别有效的把用户跟模型之间的反馈快速的进入到管线内部。然后再结合一些外部的数据标注，还甚至说一些用户会帮我们做一些额外的标注，让这些所有的数据能够高效的被模型在微调过程中吸收。就这三点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:36",
      "text": "我觉得你刚才提的其实蛮多的是前后端的一些结合。不管是数据上的还是产品上的。从理论上来讲，其实也是大家一直觉得说就是我数据对于模型的表现是最重要的。然后CEI的前端有这么多的用户，这么多的高质量的对话。那这些东西应该是能够反哺到它的模型也变得更好。如果能成为一环，其实这个事儿就成立了，对吧？那最后为什么变成说要把它拆开，或者说这个在模型上好像CI跟其他的那几个比起来也没有一个特别大的优势。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:11",
      "text": "这里面就有两个点，第一个点就是说肯定在现有的一些常见的一种感情陪伴场景里面，我们的模型的确是没有其他家好。但我刚才说了，我们这个厉害，他厉害的是广度，以及在这个巨大的广度之下，每一个的深度都不差。所以说很多用户在跟其他家聊完之后，发现他还是聊的内容比较窄。就是可能说情情爱爱对吧？或者说一些很经典的霸总的剧情的走向。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:35",
      "text": "但是你也不可能天天聊这些东西，对吧？你会希望有点变数。当他们习惯了其他家的变数不多的那些场景之后，他都会想起来来我们家试试看。然后发现在这些常见的场景之外，我们依然能跟他聊的有来有回，或者能给他一些启发式的回答。这可能就跟我们模型训练里面见过了太多的自然人类对话，它的这个广度是极其可怕的有关。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:56",
      "text": "OK. 好，然后我们来讲讲你在CI的这一年多时间，我觉得大家都会好奇说在类似CI这样的公司，你的每天都是怎么度过的，大概会做哪些事情，以及说你具体负责的一些业务是什么？",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:11",
      "text": "每天怎么度过？你要用一句话形容就是主动。996。因为这是我严格来说第一次加入一个初创公司，所以说我是真的是感觉到了我做的每一点事情，或者我看的每一点的额外的数据分析，如果能对公司有帮助那就好了，是真的很热情的去做这件事。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:27",
      "text": "这个是只有你还是几乎所有人？",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:30",
      "text": "大部分人就是说公司里并不是说主动强迫说大家都要加班。但是你会发现，比如说在网上看red上也有人在说，怎么CI又登不进去了的时候，我一般会去slack上面看一眼，有没有什么运维的朋友在，或者能不能我自己修。但往往我去看的时候都有十几个人在线。当时公司大概七八十个人，公司里也有对吧？正常就是说有老有小，可能也五十多岁经验非常丰富的那种老工程师。我觉得大家的合作是非常流畅的，没有说谁比谁真的就是主动加班，主动的去帮用户，去帮公司做更多的事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:01",
      "text": "你刚讲的里面有好几个点，我想再问一下。第一就是在美国，尤其是初创的AI公司里面，996是1个常态吗？你觉得。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:10",
      "text": "严格来说，996这个话有点夸张，周末可能也就刚才我说的那十几个人会主动的跳出来修点东西或者改点代码。平时其实正常上班时间也就九点到晚上五点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:21",
      "text": "中间还能吃个一小时的饭。所以还是像大家理解的，就是哪怕是硅谷那边也没有那么卷，对吧？大家还是比较chill的对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:29",
      "text": "亲友是一方面，但是刚才我说的那十几个，包括我的人在里面，就真是觉得使命感，或者说在跟很厉害的人做一些很有意思的事。那种个人驱使的996，我觉得比例是不小的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:40",
      "text": "明白。然后第二个问题，你刚提的一个点我觉得特别有意思。就是你说你们有一个五十多岁的程序员，这个在国内我觉得几乎是不可能发生的。在美国那边这个是常见的吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:16:52",
      "text": "我觉得这边还蛮常见的，就是我们公司甚至不只是一位五十多岁程序员，有好几位，而且其中一位还跟着去了google。我觉得这边对年并不是那么重要，对吧？更多还是看你本身能提供给公司的价值能到什么程度。然后很多这个年龄的程序员做了这么多年码农，对他来说最开心的事就是在这个年龄也不是去退休，那就得来这儿做些这种事情，就是一种很愉快的体验。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:15",
      "text": "OK好，那你继续讲，就是你自己会主动的996对吧？你的日常写作跟实际的工作当中是怎么样？",
      "speaker": "发言人2"
    },
    {
      "time": "00:17:22",
      "text": "因为我是在post圈里团队，我选的团队要回答的问题就是朱雀那边给我们一个很棒的大模型。然后我们现在已经有一套还不错的管线在那跑，能够把用户的反馈，能把一些额外的需要微调的数据给模型看一遍，然后出来一个理论上来说对话能力很强的大模型。但是我们要是每天去看discord，看ready，能看到用户还是在表达一些正常的愤怒的情况下，那怎么去让你的模型更为用户喜好呢？然后以及时不时改些东西，你这个AB测试它的流程，它的时长是会上升的那怎么去不停的去迭代模型呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:57",
      "text": "就是我工作的主要目要方式，其实就是看大量的数据，另外一方面是研究数据，那边就是分析最近的几次迭代的效果，怎么样去理解里面可能说模型是应该调数据还是调算法。然后在实际上工程那边就会思考我们现。这个管线里面是不是有些用户数据的使用方式还是不够优秀。或者比如说我们要做偏好对齐的话，DPU这个算法最近有没有什么业界的新的研究，发现它有一些缺陷可以去改善。当然少不了就大量的跟研究员去讨论，看看研究员那边对于最新的业绩的方法有没有什么新的见解。一般可能一天8个小时里面，我觉得真正的在写代码程序实现的里面，大概不会超过2个小时。6个小时基本都是在各种交流，还有分析各种数据。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:41",
      "text": "明白，然后你主要是负责post street，你这边有什么可以分享的一些best practice也好，know how也好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:49",
      "text": "我觉得最后能分享的东西就是说你怎么能最快的把用户反馈带着飞起来，对吧？就是上一代的AI模型，大家都会说有一个数据飞轮，我觉得这一代同样也有个数据飞轮，而且这一代的数据飞轮效应更加强烈。因为大模型本身就是个数据黑洞，就你喂他一堆数据，然后他吐出来一堆数据给你。而且这里面有很强的一个随机性，很大的不可控性。所以你可能在快速迭代的时候，你得不停的去改变这个数据配比。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:18",
      "text": "换了这个算法之后，我有一个新的模型OK我丢进生产里面AB测试一下，或者有一个简单的评估。但是它其实依然是一个非常不可控的过程。就很多你觉得在某个版本上好用的一些技巧，可能你带进来之后，你的AB测试就跑崩了，内部评估的分数就跑崩了。就属于里面有很多的你必须得在第一线去踩坑。在不同的场景下，不同的用户群，他的效果就很不一样。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:41",
      "text": "最终能够在我看来最有效帮助到这样一个过程，就是怎么样建立起一个尽可能高效的迭代过程。这个迭代过程可以说是管线非常的robust，所以我有大量的用户，或者我的用户量并不是很大。但是我用的AB测试的工具，能够快速的让我高效的收集到各种模型的小的变化对用户测的的影响。然后我能做一定的分析，积累性能好，或者有人说我在评估上特别努力，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:06",
      "text": "我内部做的这个评估集，它非常像真实的用户。我可能说内部圈了一个特殊的模型才能模拟。现在这个用户在说的话，他能用这个模型去跟这个新的模型去对话，然后来告诉你说这个模型是不是会被用户更加喜欢。也有人说我在数据的利用上，我做的特别的高效。只要你今天给我点个赞，可能明天这个模型在跟这个用户在聊的时候，它的效果就会更好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:28",
      "text": "我觉得这里面是非常开放式的，理想上来说每一个步骤都做得非常高效。你一点小变化可能隔天就能马上在生产里面，在评估里面都能体现出来他对于这个模型的变化。这样的话作为模型开发，你就少了很多不确定性。但现在的这个现状，大家依然是要面对大量的不确定性。每一个步骤其实它的效率都不是那么高。所以这其实要看你这个团队本身比较擅长的是什么。假设你有很多上一代的丰富的AB测试经验的人的话，那你可能要先想的是你怎么让这个上一代成熟的AB测试的best practice能够在大模型里面使用。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:03",
      "text": "如果你的团队里面有很多人特别懂数据平台怎么构建的话，那你在数据上面你能做很多很fancy的东西。比如说我不只是收集用户给我点赞点踩，我能收集用户跟机器人的互相的互动，多种方式收集到这样的反馈，然后把这些丰富的反馈丢给模型。我们甚至四条路线都做了很多的尝试，发现每一条路线都有不少滴水的果实。你做一做就能让这个模型的效果或者整个模型迭代的效率提高不少。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:30",
      "text": "明白杯子合理。你讲的就是说模型的不可控，要用更高频次的测试去迭代。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:37",
      "text": "对的，然后迭代的过程中，每个人会迭代不同的方向。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:40",
      "text": "但这里可能有个问题，就是你看我们经常听人讲说这个模型好，聊着聊着觉得变蠢了，或者聊聊怎么样。他可能是一个非常感性的一个感觉，也没有什么具体的指标，具体的一些问题。尤其是我觉得像CI之类的聊天的场景，我不知道你们遇到这类的问题，你该怎么去评估或者改进。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:01",
      "text": "这个属于如果有哪一家外卖公司说，我们解决这个问题，我也很想学习一下。我们只能保证绝大部分就是说我们会同时看平均值，并且看一些个例。比如说某个模型修改进去了，不论是评估级也好，还是说AB测试也好，平均的用户的对话次数上升了，这大概率是个优良的提升。但一般来说我们在平均值之外，我们会95的百分比看这些少数用户，尤其是那些其实时长下降的用户，他的这个使用画像大概是什么。我们每次在做这种迭代的时候，尤其是我们用户量比较大，对吧？我们都会去分析说对于这些用户来说，这个模型的退步到底是不是一个可以接受的trade off。因为有的时候你会发现在众多用户上面，它的时长下降了。哪怕他在大量的主流用户上他时长上升的话，你就会需要去做一个取舍。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:48",
      "text": "你可能说今天我这个模型的修改是让它尽可能再更加安全一点，对吧？一般来说一个更加安全的模型对于一部分用户，他就可能觉得没那么好玩了。但是一个很安全的模型，有的时候它会有另外一种特性展现出来。我觉得这算是一种EQ的涌现，它会开始拉扯，他会绕话。比如说你今天想跟他开展一些感情的对话，对吧？假设今天雷店长就说我爱你，你就你也说点我爱你的话，讨好我呗，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:15",
      "text": "但一个比较安全的模型，尤其是假设你跟模型说千万不要跟用户开展过于深入的感情交流。那模型它的理解方式可能说OK，我把这话绕起来，他可能会说你为什么觉得我爱你呢？他就开始问问题。然后问问题这个东西其实在外网很多用户都在吐槽，我们的微信特别喜欢说can I ask you a question？大家都已经把他们当成一个梗了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:37",
      "text": "但是当模型在问问题的时候，大部分情况下就是因为模型它感知到了他见过大量的对话数据之后，他意识到如果现在不问问题的话，直接回答用户的这个请求。接下来两三句话之后，用户可能聊的东西就会比较糟糕了。就是说不会是我们希望模型去跟用户去进行的这样交流。这个时候模型可以说我直接拒绝回答。但是如果我开始问问题的话，多问几轮，用户一来他会跟我产生更多的对话，对吧？二来可能用户被我问多了，他也忘记了自己本来想要什么。就很成功的以一个更委婉的方式绕开了这个本来可能有一定危险性的对话的方向。这就是我们观察到的某种意义上就是一种涌现。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:18",
      "text": "明白，我觉得你在CAI做post train基本就代表了全球post train最高水平了，对吧？包括你能接触到的数据、模型等等，都是很有代表性的。所以能不能给大家比较具体的讲一下，boost train它到底对模型起到什么作用呢？它整个流程是怎么样的？你日常都是怎么做这件事情？",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:40",
      "text": "可以，最基础的话post chain就是微调。微调就是指你拿到一个present好的模型，怎么让他去说真的人话。举一个比较极端的例子，一个刚见过几万文字的模型，你要是问他今天是星期几，他大概率接下来会回答你一个问号，对吧？因为他会说我见过的大部分的时候，这个问题后面最后是个问号。但他来跟人类对话肯定不能这样，所以你要给他看少一些量的数据，但这些数据都是正常的。问答不论后面是不是问号，当这个句式是今天是星期几，或者今天布拉听起来像是问句的时候，当模型意识到他该回答问题，而不是接后面这个问题。当然我知道就要快速的disco laim一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:17",
      "text": "现在有一些好的模型的，他在预训练完之后，他已经能学会这个能力了，对吧？这就是数据调整的结果。但方向来说就大差不差，就是你刚预训练完这个模型，它离真正的完成人类的很多正常的问答去做一些任务都是远远不够的。所以你要让他用更加高质量，但是规模更小的数据，让他以多个不同的方式。但其实现在主流的基本就是三种方式，一种是SFT supervise，翻译成理。这个的意思就是你给他看所谓的正确答案，对吧？各种在你这个领域，在你这个场景下的高质量数据让他去记住。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:49",
      "text": "还有两种就是指偏好对齐，就是他看过这些正确的案子，他说出来话依然可能不是被人类去喜欢你。怎么让人类的这种喜好交给大模型，有一种非常主流open I最先提出来，也是让大家觉得原来可以这么搞的方法就是RLHF。它就是用一个稍微比较复杂的管线去把人类的喜好就交给模型，同时也要做很多数据。但经过RHF之后，模型说出来的话，真的就是人类会期待机器人该说的话。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:16",
      "text": "同样ROHF它有一个简化版叫DPU。DPU的本质就是说如果ROH太复杂，我用一个简化的办法，也同样的把人类的喜好灌注到模型，基本我们在用的就是SVT加DPU，然后再加一点点的RHF。我认知里面你要的是能把基本就两步，一步就是SFT，一步就是偏好对齐。都数据调的很好，管线调的比较成熟的话，它是可以达到一个非常高的高度的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:42",
      "text": "对，能不能给大家再用人话解释一下，说在每一步里面你的输入是什么，做哪些东西，输出了个什么，然后再到下一步该做什么。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:50",
      "text": "就先说SFT，SFT它跟预训练阶段是一模一样的。因为预训练阶段就是让模型不停的去看大量的文字，可能先看第一个字再看第二个字。然后这个时候第一个字作为上下文，然后这样一直看到比如第100万个字的时候，前面我们都是有一个模型的记忆窗口。可能8000个token对吧？一个token可能说半个字这样。然后让模型不停的去看这样的一个类似文字接龙的过程。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:13",
      "text": "在这个看的过程中，我们模型本质是一个巨大的矩阵，矩阵里面有大量的数字。当你拥有了一个巨大的矩阵和一堆数字之后，你可以把你的输入变成一组数字，然后跟这个矩阵做一个乘法，然后它能乘出另外一组数字。这组数字就是告诉你接下来的一个词可能是长成什么样。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:31",
      "text": "通过预训练，你能把整个大矩阵里面每个初始化都是随机的数字变成一组新的数字。这组新的数字理论上来说给他任何的输入的这个矩阵的，它都能给你输出所对应到最有可能的下一个文字，就是所谓的最高效的文字接龙微调的时候，其实基本也是在调整这个矩阵里面可能全部数字，也可能调整部分的数字。这就看你能投入多少资源，以及你使用的微调的方法。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:55",
      "text": "SFT的过程其实跟预训练基本是差不多的，只是SFT我们用的数据质量会高得多得多。可能你在pressure的时候，你只是给他看。可能互联网上搜集了大量的，有的是正常的对话，有的是科学类的文章。但是在SFT的阶段，你会精心的挑选所谓的人类高质量的对话。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:13",
      "text": "这个对话是什么？就是A说了某句话，B说了某句话把这段对话全部拼成一句很长的话，然后让模型这样一个字一个字看过去。当你让模型把SFT所有的数据过了完这么一遍之后，它整个矩阵就变化了一遍，对吧？理论上说这个变化之后的结果的矩阵就可以预测。当A说完这句话的时候，逼的下一句话第一个字应该是长成这个样子的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:36",
      "text": "可能很多朋友就会马上有一个敏感的点，就说难道我跟机器人说的话他都拿来做训练了吗？这里我想就跟大家澄清一点，完全没有。因为你在训练的时候，你可以让他只去学B说的话，就A说的话只作为他的上下文。当模型扫到A说的那些话的时候，你可以让模型直接跳过，就说不要去学这些东西。从这个角度你就有很大的概率能够杜绝模型去学会这些用户。因为其实用户说的话有很多隐私问题，我们是不能让模型去学的。就SFD阶段差不多就是选最高质量的对话，或者符合你那个场景的对话，让模型去以类似预训练的方式去见一遍。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:12",
      "text": "这个讲的很清楚。然后再往后。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:14",
      "text": "对，再往后就是RHF或者DPU。我刚才说的不是所谓的正解，对吧？就高质量对话ABAB这样对话下来，但很多时候其实这个对话是没有太多的症解可言。就是说我今天假设ABAB我们一起聊了50句之后，你说了一句话，我对这句话的感觉就是还行，还挺有意思，觉得薛凯这人靠谱。我对这句话会有一个我自己的喜好的判断。而且你会发现其实在越是这种人类的对话或者比较开放式的领域，这种喜好的存在是远超于所谓的政界的存在。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:48",
      "text": "那怎么把这种喜好交给到模型？这其实就是open I一开始在提出来的LHF这个管线。LHF的管线的意思从尽可能通俗易懂的方式，就是假设上下文是这1000个字，然后有三四个不同的答案，第一个最好的答案是A然后是B然后是C然后是D你把这个数据去给模型去学，你能训出来一个模型叫奖励模型。这个奖励模型它要做的事情就是当下次看到类似的上下文，以及给他一个答案，他能判断这个答案有多大概率是会被人类喜欢的。因为他见过了很多人类对不同答案的偏好的排名。然后你有这个奖励模型之后，此处就是强化学习的领域。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:27",
      "text": "强化学习就是指你最好是让一个模型它能跟环境去进行一个交互。这个环境可能就是大量的语料，他能不停的去从环境拿到一些新的语料，自己生成下一句话。但是在强化学习里面最重要的点就是需要一个奖励模型，这个奖励模型就是不停的告诉这个被训的文字模型，你新的生成这句话好不好。这样的话其实你就形成了一个很自然的反馈的循环。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:50",
      "text": "奖励模型不停的告诉这个文字模型好不好。文字模型通过这个奖励去判断说OK这句话也许可能不是那么好。我来试试换一个方法。然后在这样一个过程中，你可以发现文字模型它就能不停的提升自己。这就是所谓的reinforce learning with human feedback，就是带有人类偏好的强化学习。人类偏好就是奖励模型。Reinforcement其实就是传统的reinforcement难点，可能就是说你怎么去设计一开始的数据来圈一个比较高效的奖励模型。其次其实都是很成熟的RL shift的关键。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:19",
      "text": "明白，相比之下DPO的方式就是告诉你，咱们也别整那么多，搞这么复杂的管线。假设你现在有的只是一堆用户点赞点踩的数据，把这些数据拼成一个偏好。对，就是说你能给模型同时看，这句话用户喜欢，那句话用户不喜欢。假设你有大量这样的偏好，的话，你能不能把这个作为一个简单的训练模式，让模型直接一遍过。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:41",
      "text": "就是DPU过程里面是要加载两个模型的，你要训练的模型和一个参考模型就加载完两个模型，然后把大量的偏好对让模型过一遍，让模型直接从这个里面学会该有的对偏好的信息。能不能呢？DPU就是告诉你，你可以做到非常不错，因为它简单快速。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:57",
      "text": "所以你是觉得说其实DPU是最好用且见效比较快的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:02",
      "text": "是吧？对，就它能快速的建立起一个反馈的这个循环。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:07",
      "text": "Reg和prompt在你们CI内部大概是一个什么情况跟位置？",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:12",
      "text": "我们很坦白的讲，没有做特别多reg那边的尝试。Prom的话，因为我们等于说是每个角色会有一个prom的对吧？其实跟GB store一样，就是说用户在角色上会给我们大量的prom。所以说我们也尝试过自己加一些额外的prom，发现这些往往会跟用户千奇百怪的problem产生一个冲突。所以做过一些小规模的实验之后，也没有在官方对这个模型做太多的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:36",
      "text": "所以你们其实还是非常强调模型本身能力。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:40",
      "text": "对，因为我们这个微调的管线还是蛮复杂的，就像我刚才提到？我们可能主要的是DPU再加上刚才SFT，这两个阶段对数据的要求是非常大的，或者说数据里面能够挖掘出来的天花板是非常高的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:53",
      "text": "明白，但这一整个流程我觉得现在大家好像都是共识了，都是说我要做post train，然后我的数据质量很重要？然后我要做DPO还是做什么东西的。比如说同样的事情tok肯定也在做，那他跟你们CAI做的区别是什么呢？不一定非要这两家，就是做的好的跟做的不好的区别是什么呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:15",
      "text": "我觉得这个可能就是有一点非共识，我是觉得你不论是SIT里面找来的高质量对话数据，还是偏好对齐里面找来的偏好数据，他真的是你现在能找到最高质量的偏好数据和对话数据吗？我们现在在CAI都觉得这上面还有很大的空间可以挖。所以说可能很多竞争对手，很多在这方面尝试会觉得，这已经是我能找到最高质量的了，我已经没法再提高。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:40",
      "text": "当你开始下这种结论的时候，我觉得你可以直接反问一下，真的没有办法让他再提高了吗？这就是你能找到最高质量的在你这个领域能用的数据吗？会不会说其中只有一半是所谓的真正高质量，其他一半你丢掉对模型来说，它的能力甚至能提升。又或者说其他一半你要是通过一些额外的大模型改写重写或者摘要，它质量也会提升的。这个数据本身它的质量其实有相当大的空间。我就会在这里给大家一个建议，就是我觉得SFT里面目前来说大有可为。就是大家会觉得SFT不就给他一堆正解，那我现在想办法找一堆高质量的人类数据是不是就行了呢？",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:17",
      "text": "但其实高质量的人类对话数据，它本身就是一个非常开放式的问题。我们在SFD阶段就是发现这样一个情况。因为我们SFT的时候，我们的人类对话数据它并不是说我们人工挑选出来的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:30",
      "text": "我们的挑选方式是说我们会拿用户反馈数据来辅助这个挑选过程，就是在做一个分类。这个分类器数据的来源就是用户给到你的反馈，就用户反馈在不断的提升，尤其用户反馈他可能在暑假的反馈跟在开学的反馈他是不太一样的。下一次SFT的时候，我们用最新的用户反馈数据来指导这个分类过程。这个分类过程在我们的观点来看，它就不停的在提升，他总能找到比上一次挑出来的这些人类对话质量会更高。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:00",
      "text": "其实我们的SFT是一个非常动态的过程。可能每一次的模型迭代，它的SFT的数据配比都会产生一定程度的变化。它这个变化的根源就是用户的反馈，用户的偏好。它是时刻在变，所以用户的偏好在变的时候，你这个所谓的高质量人类的数据其实也是应该去产生一定程度的变化。不然你这个产品可能迭代三个月。你一开始选的那段高质量的数据，对于你三个月之后进来的这些新的用户，他已经是非常的不匹配了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:27",
      "text": "在这里面你把DPU的简单的管线build好之后，你都能通过这里面快速的观察到用户的偏好具体是什么样。然后来指导你自己去做一个更好的SFT的过程。而且在这个过程里面，其实就属于抑制SFT一直爽，这里面其实有大量的潜力可以挖的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:43",
      "text": "另外一个在pressure那边很流行的观点就是大家总在说数据快用完了。但是其实互联网上现在在这个阶段，只是通过简单的过滤规则，被丢掉的数据依然有相当多。你先改写现有的这些质量不是那么高的数据，可能比从无到有生成一些新的数据效果要好得多。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:00",
      "text": "明白别的还有什么吗？",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:03",
      "text": "还有一个我可以跟大家分享一下，就是刚才说的EPU点赞点踩。但实际上在我们的这个对齐过程中，我们用的远远不止点赞点踩这么简单的偏好数据。你要想用户在跟你的APP在交流的过程中，他能做很多事情。比如说他可以说编辑，如果用户编辑的这句话，那是不是说他更喜欢编辑之后的这句话？刚才我DPU的时候不是说过，你需要有一个好一个坏才能给模型学会吗？那这样其实编辑后编辑前就是好和坏，对吧？同样的用户他可以说删除这句话，它本身也已经是一个偏好。所以你怎么在产品层面能够取巧的获得更多的用户的偏好的数据，把一部分可以丢进DPU。",
      "speaker": "发言人1"
    },
    {
      "time": "00:36:43",
      "text": "另外一部分刚才我不是说SFT里面大有可为。假设你收集了足够用户删除的数据，你就知道用户是真的不喜欢什么。我刚才分类器他可以说我只挑最好的，同时你可以叠加另外一个分类器。这个分类器要做的事情就是把用户可能不喜欢的东西挑出来，这个时候你就可以把用户删除这个动作转化成训练这个分类器所要使用的数据。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:04",
      "text": "所以从这个角度，在产品层面我们做的不算特别多。但sofa我们产品上能收集到的一些用户的行为，我们都能很高效的把它转化成对SFD阶段，DPU阶段能有帮助。甚至对一些其他比如说用户推荐非常有帮助的这样一个数据。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:23",
      "text": "我觉得我在观察其他的竞品，或者在跟其他无论是国内也好，国外也好，在做类似产品，类似场景的人在聊的时候，感觉很多人的一个思维定式就是说大模型这么棒，对吧？那我就想办法收集一个点赞点赞。但我是觉得你要是现在很严肃的想要在2024年下半年再做这个的话，你应该去想想看你在产品上能够怎么更丰富的收集到用户的这种反馈，收集到用户的这种互动。然后把它丢进你这个微调的管线里面。我相信是有大量的低垂的果实，我觉得这是非常重要的，能够产生一定差异化的点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:57",
      "text": "明白，所以你觉得核心还是在数据上？",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:00",
      "text": "对，就核心还是在数据它的清洗，它的收集里面，其实有很大的空间可以去做。而且我个人会觉得大家都做的不是很好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:07",
      "text": "这件事儿一般是谁来负责做呢？就是数据的时候进行清洗，以及说要定义？什么是好的数据，哪句要哪句不要，这就应该是更多偏产品运营还是技术还是谁。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:19",
      "text": "我觉得就POS圈里的NG要做。因为实际上是我们在用的这些数据是我们写的代码给模型去建，就像刚才说怎么让模型只看A不看B这都是要实际的代码写出来的。所以我们是最了解数据是怎么具体的被模型消化的人。同样的我们也知道数据长成什么样，它能对模型有最好的效果。但是具体的数据，就比如说我们现在是以女性为主的平台。我们在收集用户的数据的时候，是不是得做性别做一定的标准化，对吧？其实这个他就牵扯到产品了，产品你得先决定你调模型的方向是不是跟现在产品的方向有关，然后才能说那我们就怎么去收集。但我觉得主体还是微调组要去负责的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:56",
      "text": "哼刚才讲的是从数据上，然后从技术上，你觉得有什么在做的不一样的地方。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:01",
      "text": "可能还是多少是有个先发优势。毕竟我们以这个免费的状态持续了很久，吸引到了很多的用户。然后这些用户都有大量的在跟我们进行了交流。某种意义就是规模的暴利。比如说其他公司想做个AB测试，至少动辄了要一周才能拿到足够的数据，我们的规模可能一天就够了。然后在这样一个能够快速迭代的基础上，我们能够快速的实验。这样的话我们积累下来的这样一个know how，其实我们自己也不能完全解释，但是觉得这几个设定就恰恰能够去让用户喜欢。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:32",
      "text": "有什么是相对能解释的，可以分享的一些东西吗？我觉得现在大家比较流行在讲的几件事情，第一个就是评估，对吧？大家都觉得说要把模型或者说模型相关的产品做好，最重要的是说你要有一个很好的评估体系。这个事儿你们是怎么做的？",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:49",
      "text": "你要是写代码，程序跑一跑就评估了。但在人类对话这个场景下，我们就发现评估是非常难做的。就理想上情况就是你有一个模型，它能模拟用户偏好。如果这样的模型存在的话，那么你只要每次迭代一个新模型，你让这个模型去对可能预先选好的5000句话出一遍答案，然后这个模型打个分OK完了如果他分数上升，这个直接就生产，就不用想什么。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:12",
      "text": "然而实际上这里面就牵扯到模型能不能模拟人类，对吧？我们给他能够找到的人类的对话数据，让他去学习人类的可能的偏好，离真正需要的数据量缺口太大。所以从这个角度我们很难建立起一个能够模拟用户的具体偏好的模型。我们有些所谓的用户偏好模型，就是这种比较少的数据量训出来的。但这个用户偏好模型现在并不足以强大到能够直接说作为一个内部的评估集。所以我们的评估很多时候还是说，比如说你在SFT阶段不是要选很多所谓的高质量人类对话。那么你可以说把其中一部分预留出来，这部分对话就是用来做测试。你可以让模型去续写这一段，然后看它跟实际上高质量对话本身的内容之间的c cross entropy loss，就是说相似度有多少，这作为一个小的评估。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:57",
      "text": "然后刚才我说的这个不是那么的准确的，人类偏好的模型，它可以去辅助评估。但就现在而言，我不会说我们内部已经建立起来一套非常完善的评估体系。所以最终我们都是要在生产里面走一遍AB的。明白。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:10",
      "text": "然后另外一个最近总听的词就是意图识别这件事。刚才讲那个例子我觉得挺有意思的。就是我如果问一个问题，后面没带问号。理论来说，如果它是一个纯概率模型，它应该是回一个问号是概率最高的，就是你怎么样去更好的识别用户的意图，然后去针对性的回复。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:30",
      "text": "首先第一点，就是怎么让他不回答问号。这个就像我刚才说的，其实他的解答不是特别复杂。你在free的时候你都可以去调整数据，让他意识到不是问号，答案会更好。比如说lama的3.1和3.2，它的base版就已经基本不会回答问题了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:46",
      "text": "但是你想要更加深入的，基本就都是要postion才能把这个意图识别做得很好。比如直接我就说两个字，大选。如果是上一代模型做的不好的时候，OK我给你个维基百科对吧？大选是什么？或者我勉强给你摘抄几个新闻。但是一个意图识别好了，他会意识到如果你现在在晚上十点去搜这个新闻，你大概的是想看到现在两边的阵营最新的瓜，它会变成一个搜索行为。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:08",
      "text": "在文字模型，甚至说在我们cat AI上面，就大量的角色聊天情况下也会有类似这样的问题。比如说你去问一个超级马里奥，你去问他你给我写个hello word，那插件麻料就意识到等一下这小子是今天是在跟我开玩笑，还是说真的要去给他写个hello word出来。如果他想我写个hello word的，但其实里面也有一些看起来很搞笑的那种bug，他是不是写到这种东西，所以我觉得一个很贴近人类喜好的模型，它未必要做的很完美。但它基本上是需要能够理解到人类跟他说的这些话的潜在的意图，然后来判断说他是应该严格的去回答一个比较完美的答案，还是有一种比较随意的对话方式，还是说要触发一些外挂的一些工具来把这件事情做得更好。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:47",
      "text": "对，但就比如说刚才你说的一个例子，我只打大圈两个字，然后就是通过什么能把它的意图识别清楚的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:54",
      "text": "就是要用上下文。假设你现在在这个时间点你打了大型两个字，或许你就会意识到现在这个时间点是一个很特殊的时间点。可能在背后要调用一个搜索引擎的能力，确定一下这个时间点现在发生的跟大学有关的事情。然后把这里搜集来的信息作为一个上下文放给模型。模型会内部有一个用户看不到的这样一个输出的阶段去判。他说接下来用户希望得到的是一个新闻网页，还是一句回答，判断完之后再去做这个实际上的事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:21",
      "text": "明白了，然后正好接着我的下一个问题，就是抛开意图识别，就是在整个的它交互过程当中的成本和延迟是不是其实也是postion决定。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:32",
      "text": "如果你只是说单纯的文字接龙，延迟跟post圈的关系说实话不是很大，基本你就看你要输入多少字。模型并不会说因为你post炫酷之后，它整个的输入的速度就产生变化，除非你改变它整个模型的架构。成本的推理成本也不会变化，但是它这个训练成本就是你想做的更复杂的SFT管线，你就要收集更多的数据。你一部分得收集用户的偏好，这个成本就没有太多。但是一部分你可能需要一些专业的第三方的标记公司，给你提供一些额外的不同领域的标记数据。这种数据成本其实在portion里面不算是特别少的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:06",
      "text": "但我也知道有些公司就是它通过一些工程上的方法来哪怕说是trick，让大家觉得说这个东西的延迟没有那么高对吧？比如说他提前先发一段预制好的话，或者说他把某些话它分成几个模型分别去处理和发出来。我不知道这个是你们见过的比较常用的手段吗？或者有什么类似的例子可以跟大家分享。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:28",
      "text": "这个我稍微凡尔赛一下，大家不要骂我，我们有糯米写字A我们不需要去考虑这样的事儿。OK它能保证可以说在这个时间点，我们推理延迟依然可能是业界基本是第一这个档次的。所以在这之上我们就文字进去，让模型直接输出就好了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:44",
      "text": "但是我们在语音上面需要做一点类似的这样的去向，也就是语音模型基本是有三个模型你绕不开的。一个是ASR模型，你就是判断你说的这句话转成文字，以及判断你这句话有没有说完之后就语言模型，就是说你流量文字语言模型过一遍输出一个该说的话，然后最后你得把它还原成语音。所以你还有一个TTS模型，就text to speech，把文字转换成对话这样一个过程。转换完之后这个对话你为了能够让用户播放出来，你还得赶紧把它存到互联网上某个地方。这一步一步践行的过程，导致延迟是加起来的。可能说在去年最好的这样一套传统的架构，拼起来就一点几秒或者接近2秒的这样一个端到端的延迟，大家就是体验不好，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:25",
      "text": "但是如果能够自己去拥有这几个模型的时候，假设你说完第一个字之后，air模型直接把那第一个字丢给语言模型去做一个推理，语言模型直接把那第一个字推理出来，结果丢给后面的ttm模型生成第一个字对应的语音的文件。不停的持续去做这样的事情。我们因为都是自研这些模型，都用我们自己GPU，有很多办法去提高它的使用效率。所以当你真的说完最后一个字，这个时候ASR模型说你就说说完了好，说完这件事就是出发，然后开始下游所有相关，比如说前端的动画或者后端的额外的信息处理全部都开始跑起来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:59",
      "text": "这个时间点其实你该生成的文字和后面该生成的回答的语音都已经申请的差不多了。这也是因为我们都是全部托管在自己的云服务器上面，才能做到一个比较高效的预生成。然后就能把延迟可能说在美国地区这边差不多0.5秒之内就能马上回应过去。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:16",
      "text": "明白，有一个问题我觉得不一定是你们的CAI会接触到的。但是我看现在大家比较普遍的都在用多模型的混合。大家现在有的时候会用最高级的模型去判断一个意图，对吧？因为这可能是比较难的然再用一些其他的模型去做一些生成之类的。我不知道在美国那边，现在大家是怎么看这个问题。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:38",
      "text": "大家都不会在明面上说的，共识就是open I基本就是这么做的对吧？大概率你跟他家的GPT对话的时候，他背后其实是已经有多个版本特化的模型在后面去承接这个任务，对吧？就是模型的路由欧派肯定是这么做的，因为你会发现它在执行不同任务的时候，它不论是延迟还是这个内容质量是有一个明显大的区别。当然如果有我朋友的朋友说，我们其实就一个模型，那我觉得那太棒了。OK但是就这种路由的逻辑其实非常reasonable，就该路由。",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:07",
      "text": "对，所以你就说哪怕是同一个模型里面，其实它也是分了几个不同的模型的对吧？所以你觉得未来大家在类似场景里面多模型混用会是一个比较常规的操作。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:19",
      "text": "对，除非说哪天GPT6或者cloud 5说我们这一个模型比你们这两个模型做的都好，而且价格还更低，那我觉得何乐而不为，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:28",
      "text": "但长期来看，你觉得以你的视角，包括在硅谷的视角，大家对于模型未来的发展是会怎么看？",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:35",
      "text": "在o one出来后面这几个月的时间点里面，就整体还是很乐观的。O一这个证明说模型的迭代还有额外的路线可以走，可以继续对更多的推理式的算力去让它性能提升。然后好像训练的时候也有一些新的这种技巧，新的方法，可以再往里面研究一下。",
      "speaker": "发言人1"
    },
    {
      "time": "00:47:50",
      "text": "我这个时候其实我想讲的就o one延伸出来的一个我其实很积极的看待这件事情的角度。就欧派他自己在博文里的时候，他们欧冠做得很好的，就是有这种明确答案可以验证的过程，写代码、解数学题、解物理题。但是一旦放到写作，它其实跟40基本就是不相上下。你要是再扩展到其他领域，扩展到人类对话，扩展到很多这种没有明确答案的情况下，你要怎么去做？我觉得O一其实某种意义上它是证明了在computer time你可以做很多的优化。你不用天天就只看训练时间的这个computer，你可以在推理的时间computer来让模型产生一些新的能力。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:29",
      "text": "这里面其实最近在twitter上有一个很有意思的项目，叫做anthropic ENTROPIX。他在做的其实大家可以探索一下，他是github的一个rapper他们在推理的时候做了很多的额外的采样。就在推理的时候模型会生成几个答案，然后采样的时候我选哪个答案。这个过程他们做了很多的动态的数据调整。他说我选答案的时候，其实有大量丰富的信息来辅助我怎么选一个更好的答案。他做了很多的优化，最后做到结果是什么呢？他拉玛一个一逼的模型，能够很好的回答9.1和9.8哪个更大。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:02",
      "text": "很多人就觉得这是不是有点过拟合，或者是有点magical，是不是骗子。但其实有很多我很认可的推特大V也在很认真的看这个rapper的过程。现在大家把这个技术尝试运用到70B想说这个70B能不能因此有一个非常强大的采样的逻辑，来让他拥有类似思维链的这样思考过程。这是一个很有趣的过程。就open I的方向就是告诉你在推理的时候大有可为，它未必得是单纯的烧GPU。或许几百个答案，也许只是说这个GPU可以用在别的地方，这是一个方向。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:33",
      "text": "另外一个方向其实还是我刚才提到的，人类对话的思维链到底是什么？一个很简单的例子就是说你跟人打字？你会打了山可能会撤回。其实人类对话里面这种行为天天都在发生。大家都在想我这句话怎么说能让他觉得最有意思？他一直在前进后退，最后决定说这句话大概是比较有意思的那这种思维链有没有可能让模型学会呢？现在你在跟模型去产生这种陪伴对话，产生这种感情对话的时候，模型其实基本就是直树对吧？那有没有可能说让模型学会类似O一的这种，他内部也去想几十个回答，觉得这句对话可能会让该玩家友好度加5，另外一题的话可能会让玩家友好度减2，但是这句话之后的20句话可能好感度会增加100。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:19",
      "text": "我觉得这是一个非常开放式的问题。我自己现在在尝试做一些探索，探索的结果就是我会发现模型的确会产生一些很奇妙的感觉，这不像直接一次性能出现的回答。所以OpenAI至少他告诉你说这是一个方向，大家值得去研究一下，用RL去辅助模型，去获得更强的回答人类对话的能力，那么大家就去探索呗。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:45",
      "text": "当下硅谷那边有没有一些非共识或者共识的一些认知，或者特别火的一些产品公司之类的。你们日常在那边经常聊的都是啥？",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:56",
      "text": "尤其最近简单的一句话总结的话，偏产品的AI公司现在基本都在多模态方向，看怎么去赚钱。然后偏算法的公司基本就在想o one到底是怎么串出来的，或者类似的one方式我怎么复制，或者我要不要在推理的时候堆一些额外的技巧让它的效果更好。然后两边的公司有个潜在的共识，就是说类似就google宣布过的12月要发的那个java is对吧？这种交互式的agent可能会在接下一年里面有很大的可能性。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:28",
      "text": "非常的精炼且准确且有深度。我们捋一下你说的第一个有意思就是现在大家都要做多模态，而且在多模态的同时，你说的是他还是为了要赚钱，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:40",
      "text": "对当你不能再讲基础研究，或者说我在等基础研究这个趋势之后，投资人也好，你自己公司也好，你都在想我这个商业模式怎么能够快速的运转起来。哪怕不是说要赚大钱，但是你要证明这个商业。模式不再只是那种卖流量或者烧VC的钱，去让用户去体验一些东西。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:57",
      "text": "这个点我觉得跟资本市场的好外是相关的对吧？像国内这两年一直在强调这个点，就是因为国内的融资环境是很差的。但美国你觉得也是这样吗？美国你觉得这两年整体的资本市场对AI的热度，尤其是偏一级市场，你觉得是怎么变化的？",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:14",
      "text": "前两年VC会给你很多的信心，对吧？但是也是因为过去两年模型不断的能给人新的惊探。现在这个时间点我觉得这瓶维C还是整体来说信心很充足的。但同时他会希望你能更加脚踏实地，不用再讲特别虚的那种等这个技术等那个技术的缺口，而是希望说你这个模式的确是一开始就比较make .",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:34",
      "text": "sense的OK所以我能不能理解说那边的融资环境在过去的两年里面，也是在逐渐可能更务实也好，或者是变差也好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:43",
      "text": "对，肯定是这样。",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:45",
      "text": "OK另外就是你讲的第一条线，它的多模态。当你提到多模态的时候，你想的更多的是什么样？多模态是文字加语音，还是文字加视频，还是都混在一起。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:56",
      "text": "还是怎么样？我讲的是都混在一起，说简单的就是跟你现在产品的主要模态不一样的。另外一个模态，因为现有的模态下，无论是增长还是商业化好像都见顶了，故事也讲不起来，用户的增长也就停滞在这。所以都会想说我适当的选哪一个模态。可能有的模态就成熟点就图片的模态成熟。但是有的模态给人的想象力更强大，比如说视频模态或者说notebook LM那种。所以在这个时间点选哪一种模态会比较好，能够发挥这个产品。现在有的用户量已经有了这个momentum，然后能够快速切入到一些新的快速的能够获得一些利润的场景。我觉得AI产品现在很多都在考虑这个OK明白。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:32",
      "text": "所以第一种就是多模态的产品。然后第二种是算法，算法反正就是追赶最领先的模型，对吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:40",
      "text": "对，就研究能不能追，怎么追，然后数据要不要追，然后这条路线现在看起来还有一些可能的果实可以摘一下。明白。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:48",
      "text": "我知道之前一段时间你也聊了很多硅谷当地的各种初创公司，那你的感受是怎么样？",
      "speaker": "发言人2"
    },
    {
      "time": "00:53:54",
      "text": "就感觉业界现在越来意识到postion对于每一个产品线的重要性，以及postion人才他的技能树会点的很宽。它是左边是钢锤圈好出来的一个勉强能说人话的模型，右边是用户特别喜欢，然后他越喜欢用模型会变得越好的这样一个终极的形态。这中间可能全是POS圈的领域，各种各样的公司来下去发现。不论是模型的研究的也好，或者做一些企业服务这种agent的也好，又或者说还是偏陪伴、偏感情价值或者偏娱乐的也好，都会有对候选管线很大的需求。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:27",
      "text": "你面试的你最印象深刻的几个公司是什么？",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:31",
      "text": "肯定是科sir。我上来就说我可以用curse r吗？他说可以，那次面试我就很记忆深刻。他给了一个链接，下了一个文件，然后他说这个文件是他们实际上生产在用的相关的逻辑的一个实现。他也告诉我，他故意加了一个bug，导致这个程序运行起来很慢，然后让我去找bug。然后当时就说我试试看。问科。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:50",
      "text": "你在面试科sir的时候，然后问科sir能不能用科sir是吧？",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:54",
      "text": "对对对，就现在AI公司很多面试的流程就更加强调实战了。大家是真的很喜欢快速的coding，快速反应，快速的让你去使用一定的AI工具，能够短期的写很多代码，短期的分析代码。他甚至允许你直接问科室这个bug可能在哪。但是他会考验说你这个问题问的好不好。他不会给你很多的时间说你就反复去试错。你一开始上来问的第一个问题，就能证明你作为一个大模型从业员本身的素养。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:21",
      "text": "我觉得现在哪怕是说有一定算法成分在里面，面试对于正解这个过程的追求已经不是那么重要了。但这对于你这个解题的过程，这是你很难让AI去帮你去模拟出来，对吧？你得去表达，你得去分享你的思路，这些都是你的人性所在的部分。",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:38",
      "text": "就现在我要是碰到一个题目会觉得好难，可能三五年前我觉得完蛋了。今天这面试没搞错，我现在其实就挺自信的。我就说那行，那我就来硬着头皮上上看，我会把自己能想到的东西都分享给他。我甚至会说能不能用AI coding，能不能用编程助手。或者如果对方允许我用google搜索，我会直接把我搜索的思路，搜索的过程全部展现给他。我会告诉你这就是我加入你的公司之后我的工作方式。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:03",
      "text": "你觉得你在跟所有人聊的过程当中，不管是面试被面试，你觉得你听到的最好的几个问题是什么？",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:11",
      "text": "我想看因为我面的很多都是接近founder，所以被问的不多。但让我印象很深就是他会问我，你觉得我们这个idea有多不靠谱？OK, 我还蛮喜欢回答这个的，因为说实话我第一反应都是我是觉得不靠谱对吧？然后就会展开一系列的攻防问答。实际上在这个过程中，比如说我在to c那个领域，最后剩下的这一家，我甚至都觉得有点不礼貌了，天天质疑人家，没事就微信说我觉得你这个东西还是不靠谱。但我在这个过程中，我就越来越觉得，他们看到将来这个vision是真的，我能慢慢的理解，所以其实我很喜欢这一类的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:45",
      "text": "如果你是作为面试官去面试post training的人，你最主要会问他的几个。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:52",
      "text": "问题是什么？可能最想会问的是给他两篇paper，就会提前给他，让他跟我现场讲解一下这篇paper里面可能的问题是什么。我大概率会找两三篇，我们可能就内部试验过，知道这篇paper其实是有一些缺陷的。但我想看这个人有没有可能就只是通过读这篇paper能感觉到，我说哪怕擦到边，我觉得也可以。就是这种对于paper的美感，我身边遇到过的研究员对paper的美感的判断都非常好。他基本不用读特别多，或者说他读完之后一遍，他就能感觉到有哪些地方是不太对劲的，而且是那种直觉性的。然后你之后可能写个代码或者拿点数据。",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:26",
      "text": "才发现好像是真的对的OK。然后最后硅谷相关的一个问题，就是你觉得华人现在在那边到底是一个大概什么样的状况？就是华人做AI.",
      "speaker": "发言人2"
    },
    {
      "time": "00:57:38",
      "text": "我觉得这可能是过去很多年你们华人最好的机会。甚至是说在移动互联网之后，包括在内之内都可能说是华人最好的时机。因为从一些客观的事实来说，open a也好，很多这种大型的模型公司也好，或者很多AI的创业公司里面，你会发现华人比例是极其高的。我会相信既然有这么多的华人愿意去下场，甚至很多在大厂里面待了很多年，对吧？其实完全可以继续在那儿稳固的拿着极高的薪水，就慢慢的退休的人，现在也都下场，都觉得这是一个特别好的机会。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:09",
      "text": "在这个过程中，我是相信这样的一个趋势，能让更多的华人产生进到更有影响力的地方。比如说在B站做了一个技术分享的翁沥，之前是open I的安全的副总裁。我是相信像这样的华人？在这种核心的圈子，最前沿的地方去持续创业，或者作为企业的高管，能对接下来的华人的发展都会有一个特别大的帮助作用。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:32",
      "text": "现在很出风头的就在to c这边落地非常成功的AIGC的start up，它都是华人为主的核心。你就不会否认这个事实，就是华人在产品化上面就是有一个很强的能力，完全不输其他族裔的人。所以我是特别喜欢现在我们所处的这个气氛。",
      "speaker": "发言人1"
    },
    {
      "time": "00:58:47",
      "text": "对我在美国去meta的食堂吃饭，然后回头一看基本是百分百中国人，而且基本坐满了不是游客，就真的就是meter员工。那一瞬间我觉得好夸张，感觉回到大学食堂的感觉。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:00",
      "text": "对我觉得就是时代现在这个时代特别的match到我们华人在硅谷的各种各样的学术上的或者特别努力的这些优势。然后就一拍即合，就导致了大量的华人在这些公司里面都有很好的机会。而且我是相信对于两三年三五年之后，你像OpenAI，可以说每一次回购都有一小批的人就会财富自由。这些人就会慢慢分散到硅谷去创建自己的公司，或者培育新的团队。这些都是将来华人能够在硅谷有自己的立足之地，有更大的影响力非常必要的条件。",
      "speaker": "发言人1"
    },
    {
      "time": "00:59:32",
      "text": "可以这个低一下子就高上去了。OK我最后问一个问题，其实我们全程辽CI的时候，你经常说我们CAI我们C我感觉其实你还是很喜欢CEI这家公司，而且他过去这一年多肯定也带给你很多东西，对吧？对，所以你到底为什么要离开CI呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:50",
      "text": "我相信我在CI积累的东西，能够在一个不同的平台造福更多的人。虽然这话听起来有点大，有点假，但我是真心的觉得我能为全人类做更大更好的贡献。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "在这次讨论中，参与者深入剖析了人工智能行业的未来趋势，特别是对特定公司如CI和Tok-i的运营模式和产品开发挑战进行了探讨。强调了AI模型训练、优化和评估中的关键因素，如数据质量和用户反馈的重要性。同时，对话还展望了AI技术的发展方向，包括多模态技术的应用，并讨论了AI公司在商业上面临的挑战。讨论者分享了个人在AI领域职业发展的经验，表达了对技术进步带来的机遇和挑战的认识，以及对特定AI产品的偏好。此外，讨论还触及了美国硅谷的AI创新环境，特别是华人在AI领域的作用和未来展望。讨论者决定离开CI，目的是在新的平台上为更多人服务，体现了致力于AI技术最大化利用的积极态度。",
    "qa_pairs": [
      {
        "question": "太太，你能给大家简单介绍一下你的经历吗？",
        "answer": "当然可以。我最近刚离开CEI，在那里待了一年，主要负责大模型的微调部分。在此之前，我在硅谷的科技大厂如Robots Meta、Google、Apple等地工作，担任全栈工程师，偏后端开发。在CEI时，我有机会参与到微调一个不太会说人话的大模型，并成功将其调优至业界领先的对话式大模型。",
        "time": "00:00:28"
      },
      {
        "question": "CAI这款产品为何商业化一直没做起来？",
        "answer": "简单概括有两点原因。首先，商业化方面做得不够深入，至今为止主要还是简单的订阅制模式。其次，团队之前在这方面考虑较少，我在离职前团队才开始积极探索商业化可能性。",
        "time": "00:01:19"
      },
      {
        "question": "你觉得美国的超级厉害的产品经理，尤其在to c端的他们和国内产品经理有何明显差异吗？",
        "answer": "我接触过的美国超级产品经理和国内的顶尖产品经理（例如张小龙）有所不同。国内的产品经理可能更注重人性化，总结出很多有效的方法论；而美国的产品经理在数据分析上非常深入，拥有类似数据科学家的能力，他们愿意亲自分析各种数据以寻找洞察点。",
        "time": "00:03:28"
      },
      {
        "question": "在你待在CAI一年多的时间里，你认为它的发展问题主要是什么？",
        "answer": "主要问题在于团队长期处于既要打造产品又要追求AGI愿景的状态，最终导致无法在两者间做出取舍，必须放弃一方才能有更好的发展。",
        "time": "00:05:02"
      },
      {
        "question": "如果重来一遍，你会建议CAI做出哪些改变以实现更好的发展？",
        "answer": "我个人认为，如果重来，我会建议公司在纯粹的AGI方向上押注更多，牺牲一些用户增长，但有可能成为国外为数不多能在AGI领域崭露头角的企业之一。",
        "time": "00:05:23"
      },
      {
        "question": "对于将CAI产品交给字节系来运作的可能性，你怎么看？你们内部有没有借鉴过TikTok（Tok）的产品模式，并思考如何应用到CI产品中？",
        "answer": "我认为如果把CAI交给字节系这样的公司来运作，可能会从产品和商业化等方面带来显著变化，因为字节系拥有丰富的资源和成熟的运营体系，而对于CAI而言，其产品是公司唯一的核心业务，而字节系的产品矩阵更为丰富多元。在产品团队膨胀之前，我们确实针对推荐算法进行过调整，但发现基于大量用户数据和健全的训练管线，持续迭代模型和优化产品细节的反馈体验更具价值。不过，我们确实会参考像TikTok这样的成功案例，了解它们的功能迭代速度、市场活动等方面的做法，并从中吸取经验和教训。",
        "time": "00:05:42"
      },
      {
        "question": "在CI公司，你的日常工作是怎样的，具体负责哪些业务？",
        "answer": "我在CI公司的日常工作可以用“主动996”来形容，作为最早加入初创公司的成员之一，我积极参与到每一个可能对公司有帮助的事情中。虽然公司没有强制加班文化，但大家普遍表现出高度的热情和责任感，主动为用户解决问题，包括我在slack上看到问题时也会主动提供帮助。我的日常工作主要包括分析用户反馈、优化模型表现、迭代管线效率等，涉及大量数据分析、研究讨论以及工程实践。",
        "time": "00:15:11"
      },
      {
        "question": "在美国初创AI公司中，996工作制是一个常态吗？在美国的初创公司里，是否存在像在国内那样50多岁程序员的情况？",
        "answer": "在美国初创AI公司中，996工作制并不常见，正常情况下工作时间为九点到五点，中间还能休息一小时吃午饭。周末时，可能会有部分员工自愿加班修复问题或改进代码，但整体来说，工作环境相对轻松chill，更注重个人的工作效率和价值输出，而非强制加班。在美国的初创公司中，50多岁的程序员较为常见，甚至有50多岁的工程师成功加入Google等大公司。在这里，年龄并不是决定能否被接纳的关键因素，更重要的是个人能为公司带来的价值。许多经验丰富、年龄较大的程序员在年纪虽大但仍能通过自己的努力找到新的挑战和愉快的工作体验。",
        "time": "00:16:01"
      },
      {
        "question": "在实际工作中，你是如何运用数据和团队讨论来驱动模型迭代的？",
        "answer": "在工作中，我主要通过观察大量数据、研究数据变化以及分析模型迭代效果来决定是否调整数据配比或算法。每天大约6小时的时间都在交流、讨论和数据分析上，只有约2小时在编写代码实现。通过高效建立迭代过程和AB测试工具，快速收集并分析模型对用户行为的影响，以实现模型的持续优化和性能提升。",
        "time": "00:17:57"
      },
      {
        "question": "如何应对模型的不可控性，并进行更高效的迭代？",
        "answer": "面对模型的不可控性，我们通过高频次的测试和迭代来适应，每个团队成员负责不同的方向进行优化改进。同时，我们会关注平均值和个例，尤其是少数用户画像的变化，判断模型修改后对用户体验的影响是否可接受。在保证大部分用户满意度的同时，也需权衡不同版本模型间的 trade off，确保整体迭代效率的提高。",
        "time": "00:22:01"
      },
      {
        "question": "在模型交流中，为什么模型会在提问而不是直接回答问题？",
        "answer": "模型之所以选择提问，是因为在它感知大量对话数据后发现，如果不问问题直接回答，接下来的对话可能会变得不理想。通过先提问，可以引导用户产生更多有价值的对话，并且在用户被问多了之后，可能忘记了原本想要讨论的内容，从而成功地避免了潜在的危险对话方向。",
        "time": "00:23:37"
      },
      {
        "question": "post train对模型有何重要作用？能否具体说明其流程及日常操作方法？",
        "answer": "Post train微调是指在预训练模型的基础上，用更高质量但规模较小的数据进行进一步调优，使其更符合人类正常的问答习惯。具体流程通常包括SFT supervise（监督微调）、偏好对齐等方法。其中，SFT类似于预训练阶段，但使用高质量对话数据进行更精准的调整；而偏好对齐则通过类似RLHF的管线，将人类喜好融入模型训练中。DPU是简化版的偏好对齐方法，更容易实施。",
        "time": "00:25:17"
      },
      {
        "question": "每一步中输入、处理内容和输出是什么，以及如何进行下一步的操作？",
        "answer": "首先，SFT阶段与预训练相似，模型会读取大量高质量对话数据，逐字进行学习，调整模型内部矩阵以预测下一个词的可能性。这一过程只针对高质量对话数据进行微调，避免了用户隐私数据对模型的影响。接下来，通过RHF或DPU阶段，模型开始根据人类对答案的喜好反馈进行强化学习，形成反馈循环，进一步提升模型的表现。",
        "time": "00:30:50"
      },
      {
        "question": "在CAI内部，对于Reg和Prompt的使用情况是怎样的？",
        "answer": "在CAI内部，对于Reg的尝试并不多，因为没有找到特别高效的奖励模型设计方法。而Prompt方面，虽然有大量用户提供的Prompt，但由于担心与用户问题产生冲突，所以仅进行了小规模实验，并未在官方模型中大量应用。",
        "time": "00:32:12"
      },
      {
        "question": "大家公认的post train流程中，各家公司的区别主要体现在哪里？",
        "answer": "区别主要在于如何获取和利用最高质量的对话数据和偏好数据。目前，很多公司可能认为现有的数据已经是最高质量的，但实际上，仍有可能通过寻找更多高质量对话数据或通过大模型改写、重摘要现有数据来提升模型能力。例如，在SFT阶段，持续利用用户反馈数据来优化挑选过程，可以不断挖掘出更高质量的人类对话数据。",
        "time": "00:33:15"
      },
      {
        "question": "在SFT模型迭代过程中，为什么需要根据用户的反馈和偏好来调整数据配比？",
        "answer": "因为用户偏好是动态变化的，高质量人类数据如果不随用户偏好的变化进行相应调整，就可能导致产品迭代后无法满足新用户的需求。",
        "time": "00:35:00"
      },
      {
        "question": "DPU的简单管线如何帮助优化SFT过程？",
        "answer": "通过DPU管线，可以快速观察到用户的偏好变化，并据此指导SFT过程，挖掘更多潜力，同时通过改写现有低质量数据来提高效果。",
        "time": "00:35:27"
      },
      {
        "question": "如何更高效地利用现有数据并获取更多用户偏好数据？",
        "answer": "除了点赞点踩等基本偏好数据外，还可以利用诸如编辑、删除等用户行为作为训练数据，甚至从用户删除的行为中构建一个分类器以剔除用户可能不喜欢的内容。",
        "time": "00:36:03"
      },
      {
        "question": "数据清洗和收集阶段有哪些可以改进的空间？",
        "answer": "数据清洗和收集过程中有很大的空间可以做，比如根据产品方向进行标准化处理、高效转化用户行为等，并且认为大部分公司在这个环节做得不够好。",
        "time": "00:38:00"
      },
      {
        "question": "谁负责数据的清洗、定义好坏数据等工作？",
        "answer": "这部分工作主要由产品运营团队负责，因为他们是了解数据如何被模型消化以及如何对模型产生最佳效果的人，同时也会与产品方向相结合进行数据收集。",
        "time": "00:38:19"
      },
      {
        "question": "从技术和数据角度，有哪些与众不同的做法？",
        "answer": "技术上可能存在的优势包括先发优势和规模化效应，能够快速迭代和实验，积累下来的经验和know-how有助于提升模型效果。而在数据方面，则强调更丰富地收集用户反馈并将其转化为有益的训练数据。",
        "time": "00:39:01"
      },
      {
        "question": "如何建立和完善模型评估体系？",
        "answer": "目前难以建立完全模拟用户偏好的模型，评估主要依靠预留高质量对话数据做测试，计算模型续写这部分内容的相似度（如交叉熵损失）作为小评估。同时，也有利用用户偏好模型辅助评估的做法。",
        "time": "00:40:12"
      },
      {
        "question": "意图识别对于模型性能的影响有多大？",
        "answer": "意图识别对于模型至关重要，它能使模型根据用户的潜在意图做出更精准的回答，而非简单地根据表面文字信息。通过上下文理解用户的意图，并据此触发相应的工具或行为。",
        "time": "00:41:10"
      },
      {
        "question": "交互过程中的延迟和成本是否受Postponed（推迟）的影响？",
        "answer": "对于文字输入交互，延迟与Postponed关系不大；但涉及语音交互时，通过优化流程和自研模型可以降低延迟，例如提前生成部分语音内容，利用高效GPU资源实现近乎实时的响应。而对于成本方面，更复杂的SFT管线会导致更高成本，可能需要专业第三方标记公司提供的额外数据。",
        "time": "00:43:32"
      },
      {
        "question": "在美国，大家对于模型的使用和多模型混合的情况是如何看待的？",
        "answer": "在美国，业界普遍采用多模型混合策略。通常，会用最高级的模型去判断意图，并结合其他模型进行生成等任务。例如，在与GPT对话时，背后实际上有多个版本特化的模型在支撑任务，根据任务需求进行模型路由，以实现不同的延迟和内容质量。除非有更强大的单一模型出现，否则这种多模型混用会成为一种常规操作。",
        "time": "00:47:07"
      },
      {
        "question": "对于模型未来的发展，您们在硅谷是如何看的？",
        "answer": "在O一（可能是OpenAI的代号）发布后几个月，整体持乐观态度。O一证明了模型迭代还有新的路线，可以通过增加推理式算力提升性能，并且训练过程中还有新的技巧和方法可以探索。",
        "time": "00:47:35"
      },
      {
        "question": "O一在不同领域的表现和它的意义是什么？",
        "answer": "O一在写代码、解数学题、物理题等方面表现出色，但在写作和人类对话场景中表现一般。但其核心意义在于证明了在computer time可以通过优化推理时间来让模型产生新的能力，而不仅仅是依赖训练时间。",
        "time": "00:47:50"
      },
      {
        "question": "最近有哪些有趣的项目或动态？",
        "answer": "最近在Twitter上有一个名为anthropic ENTROPIX的项目，他们在推理过程中做了大量额外采样和动态数据调整，让模型在选择答案时能基于丰富信息进行优化，从而提高答案的质量。",
        "time": "00:48:29"
      },
      {
        "question": "硅谷目前对于多模态方向的看法如何？",
        "answer": "目前硅谷的产品公司大多关注多模态方向，包括文字、语音、视频等多种模态，目的是寻找新的商业模式以实现快速增长和商业化。同时，一些算法公司也在研究如何复制类似O一的成功模式，或者通过在推理时添加额外技巧提升效果。",
        "time": "00:50:56"
      },
      {
        "question": "对于硅谷当前的资本市场和AI热度，您有何看法？",
        "answer": "过去两年VC投资信心较强，但随着模型技术不断突破，现在投资人更希望看到商业模式的务实性和可持续性，而非单纯依赖新技术的前景。",
        "time": "00:52:14"
      },
      {
        "question": "面试过程中，您印象深刻的题目或问题是什么？",
        "answer": "面试过程中，印象深刻的包括被问及如何看待某个idea的不靠谱程度，并通过展开问答来评估候选人的思考和讨论能力；以及作为面试官时，要求候选人对预先提供的论文进行讲解，并识别其中的问题，考察其对学术文献的洞察力和直觉判断力。",
        "time": "00:56:11"
      },
      {
        "question": "您认为华人在美国AI领域的现状如何？",
        "answer": "目前，华人在美国AI领域拥有极高的参与度和影响力，尤其是在大型模型公司和创业公司中，华人比例显著增高。越来越多的华人抓住这一机遇，进入核心圈子并发挥重要作用，这将有助于华人社区在未来硅谷取得更大的影响力和成功。",
        "time": "00:57:38"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "大模型微调专家分享经验",
        "summary": "一位刚离开CEI的大模型微调专家分享了她的职业经历。她在CEI主要负责大模型的微调，之前在硅谷的几家大厂如meta、google、apple担任全栈工程师，偏向后端。在CAI工作期间，她有机会与研究员一起将一个表现欠佳的大模型调整为业界最好的对话式大模型。"
      },
      {
        "time": "00:01:05",
        "title": "探讨CAI产品商业化进展缓慢的原因",
        "summary": "对话中提到，尽管CAI产品在年轻及二次元群体中具有一定的用户基础，但其商业化进展缓慢。主要问题在于产品目前仅实行简单的订阅模式，缺乏多样化的商业模式探索，且团队前期对商业化思考不足。此外，对比国内外AI创业公司的商业化态度，国内公司普遍将商业化视为发展重点，而CAI似乎未将商业化作为优先级，这一态度在某种程度上受到融资环境的影响。"
      },
      {
        "time": "00:02:14",
        "title": "AGI追求路上的团队组成与挑战",
        "summary": "团队初期主要由模型训练人员组成，随着发展逐渐补充产品等相关人员。初期团队规模约25人，主要聚焦于技术开发，后期逐渐招入产品经理等角色以完善团队结构。"
      },
      {
        "time": "00:03:18",
        "title": "中美产品经理差异及数据分析重要性",
        "summary": "讨论中指出，中美两国在产品经理方面的显著差异，特别是在To C端。中国的超级产品经理倾向于重视人文文化，注重方法论的总结。而美国的产品经理在数据分析方面更为深入，他们具备复杂SQL技能，倾向于通过数据分析来寻找问题的解决方案。这一差异体现在美国产品经理的面试过程中，模拟面试更像管理咨询面试，侧重于数据分析和问题解决。此外，还讨论了一个案例，一个团队从成立到最终解散的过程，揭示了发展中遇到的问题，这些问题最终导致了团队的解散，成员回归大公司。"
      },
      {
        "time": "00:05:01",
        "title": "探讨CI公司战略调整与发展前景",
        "summary": "对话中提出，如果能够重来，CI公司应更加专注于AGI（通用人工智能）的研发，尽管这可能会牺牲一部分用户增长。建议CI可能将前期产品直接出售，以专注于模型研究，但这也存在政策上的挑战。同时，讨论了如果将CI的产品交由字节系公司运营可能会带来不同的结果，特别是在产品和商业化方面。进一步比较了CI与Mini Max公司的产品策略，指出Mini Max的Toki产品是公司战略的一部分，而不仅仅是单一的依靠。"
      },
      {
        "time": "00:06:50",
        "title": "产品团队对CEI和toki平台模式的比较分析",
        "summary": "在讨论中，CEI产品网站给人的初步印象被描述为简陋的UGC平台，而toki则因其重运营和推荐机制而有所不同。有人提出，CEI的平台更有利于UGC内容的自然生成，而toki的重运营模式可能对用户数据行为表现更佳。讨论还提到，尽管团队年初对推荐算法做了调整，但发现持续迭代模型和优化产品细节更能获得用户反馈。此外，尽管对toki快速的功能迭代和积极的市场活动表示羡慕，但也意识到即使引入丰富功能，如果没有实现商业化或增长上的突破，这些功能可能不适合产品形态。"
      },
      {
        "time": "00:09:35",
        "title": "探讨AI陪伴产品CEI的未来及商业化挑战",
        "summary": "对话中讨论了CEI作为AI陪伴产品面临的挑战，特别是商业化路径的不确定性。尽管对AI陪伴产品的未来持乐观态度，但对于如何有效实现商业化、特别是广告收入模式存在疑问。同时，指出CEI拥有庞大的用户基数，显示出其不可忽视的市场潜力。讨论还触及了类似产品主要用户群体的特征，以及这些产品更像互动内容消费而非纯粹的AI陪伴的观点。"
      },
      {
        "time": "00:12:18",
        "title": "CEI在AI对话模型领域的成功因素分析",
        "summary": "CEI在AI对话模型领域取得显著成就的原因包括：首先，具备强大的技术研发能力，能够显著降低模型成本，支持千万级用户规模；其次，自研模型允许精准控制语料库的使用，初期即能提供广泛的人类对话模型；最后，通过高效的数据反馈和微调管线，快速优化模型性能。尽管在某些常见情感陪伴场景中表现并非最优，但CEI模型的对话内容广度和深度给人留下深刻印象，吸引了用户寻求更多变数和启发式回答，从而巩固了其在该领域的领先地位。"
      },
      {
        "time": "00:14:56",
        "title": "初创公司CI的工作日常和文化",
        "summary": "CI公司的工作日常以主动、热情为主，尽管不是强制加班，但员工表现出强烈的主动性和责任感，愿意在必要时加班解决问题。这种文化不仅仅体现在年轻员工身上，连经验丰富的五十多岁程序员也积极参与，体现了公司对年龄的包容和对个人价值的重视。总体上，CI公司虽然在美国初创AI公司中可能不完全遵循996工作制，但员工普遍有使命感，愿意投入时间和精力完成有意义的工作。"
      },
      {
        "time": "00:17:15",
        "title": "优化大模型以提升用户满意度的策略与挑战",
        "summary": "团队在利用大模型处理用户反馈和需求时面临挑战，尽管已有有效的管线处理流程，用户在社交媒体上的反馈仍显示不满。为更好地调整模型以满足用户喜好，需要不断迭代和优化模型，这涉及到AB测试、数据研究和算法调整。日常工作中，大部分时间用于分析数据、与研究员讨论最新研究，实际编程时间占比不多。此外，探索DPU算法的缺陷和改善方法也是工作的一部分。"
      },
      {
        "time": "00:18:41",
        "title": "大模型迭代与用户反馈的有效整合",
        "summary": "在大模型开发中，快速迭代和高效利用用户反馈是提升模型性能的关键。面对模型固有的不可控性和随机性，开发者需通过高频次的测试和不断调整数据配比来优化模型。利用AB测试和精细的内部评估，可以实时评估模型微调对用户体验的影响，同时高效收集和分析用户与模型互动的数据，快速反馈到模型训练中，从而减少不确定性，提高迭代效率。不同团队根据自身特长，可以侧重于不同的优化方向，如测试策略或数据平台构建，以实现模型性能的持续提升。"
      },
      {
        "time": "00:21:40",
        "title": "评估和改进聊天模型的策略与挑战",
        "summary": "讨论集中在如何评估和改进聊天模型，特别是在CI等聊天场景下，面临的挑战是如何应对模型表现的波动。提出了一种评估方法，即不仅关注平均值，还要特别分析那些对话时长下降的用户群体。强调了在模型迭代过程中，必须对不同用户群体的反馈进行权衡，特别是当模型追求更高安全性时可能带来的交流质量下降。此外，探讨了模型在特定情况下的行为模式，如通过提问来避免潜在的不良对话。最后，提到了Post-Training（post train）的重要性及其在全球范围内的应用，请求进一步解释Post-Training如何具体实施以及其在提升模型性能中的作用。"
      },
      {
        "time": "00:24:40",
        "title": "微调模型以实现更自然的人机对话",
        "summary": "对话内容主要讨论了如何通过微调技术使机器学习模型能够产生更贴近人类正常交流的回答。首先，介绍了模型预训练后，通过少量高质量数据进行微调（SFT）的重要性，目的是让模型学会根据特定场景给出合适的回答，而非仅复制数据中的模式。其次，讨论了通过偏好对齐方法，如RLHF和其简化版DPU，进一步调整模型，以使其输出更加符合人类的期待和喜好。此外，还强调了在微调过程中，可以选择不包含用户隐私信息的高质量对话数据，以避免模型学习到不应有的信息。通过这些方法，可以显著提高模型在实际对话中的表现，使其更加符合人类的交流习惯。"
      },
      {
        "time": "00:29:12",
        "title": "强化学习与人类反馈在语言模型中的应用",
        "summary": "对话深入讨论了利用强化学习和人类反馈（RLHF）提升语言模型质量的策略，特别是通过奖励模型和数据偏好对齐（DPO）方法来优化模型的生成能力。强调了高质量对话数据的重要性以及如何利用用户反馈动态调整模型训练数据的配比，以更好地捕捉用户偏好。同时，指出了简单管线DPU的实用性及其快速见效的特点，以及在模型训练中挖掘和利用高质量数据的潜力。"
      },
      {
        "time": "00:35:59",
        "title": "利用用户行为数据优化模型对齐",
        "summary": "在提升模型对齐效果的过程中，除了点赞点踩等简单偏好数据，还应充分利用用户与APP交互时的多种行为数据，如编辑和删除操作，这些行为实际上反映了用户的偏好。通过收集和分析这些行为数据，可以更有效地对模型进行微调，从而提高模型性能和用户满意度。此外，数据的清洗和收集工作非常重要，需要明确好数据的标准，这一工作主要由微调组负责，同时需要产品团队和数据团队紧密合作，以确保收集的数据与产品方向一致，能够有效支持模型的优化。"
      },
      {
        "time": "00:38:55",
        "title": "利用大数据和AI技术优化用户交互体验",
        "summary": "讨论重点在于如何利用公司的数据和技术优势，特别是免费服务吸引的大量用户数据，来快速迭代和优化产品。通过与用户的大量交流，积累了对用户偏好的深入理解，但同时也面临评估用户偏好模型的挑战。虽然建立了基于模型评估的体系，但仍然需要通过AB测试来最终验证产品效果。此外，还探讨了意图识别的重要性，如何通过上下文和额外信息帮助模型更好地理解用户意图，从而提供更符合用户期待的回复。"
      },
      {
        "time": "00:43:21",
        "title": "优化交互式AI系统的延迟与成本",
        "summary": "在讨论中，重点探讨了提高交互式AI系统效率的策略，特别是如何减少延迟和控制成本。指出在不改变模型架构的情况下，文本交互的延迟和成本与输入的复杂度关系不大。然而，若要执行更复杂的任务，需要收集更多数据，增加训练成本。讨论还涉及通过技术手段优化用户体验，比如使用预制语句或分模型处理来降低感知延迟。在语音交互方面，提出了通过自研的ASR、语言模型和TTS模型紧密集成，实现实时响应的方案，以减少端到端延迟，提高系统效率。"
      },
      {
        "time": "00:46:15",
        "title": "多模型混合使用与AI未来发展探讨",
        "summary": "在当前AI技术发展背景下，普遍采用多模型混合方式来应对不同任务，特别是对于复杂意图识别和内容生成等任务。这种策略背后的逻辑在于利用不同模型的优势，以提高执行任务时的效率和质量。对话中提及了OpenAI的实践，暗示其通过多个特化模型来处理不同任务，以此提升模型的性能。未来，随着技术的进步，如GPT-6或Cloud 5等，可能会出现一个模型能超越多个模型的性能和成本效益的情况。同时，讨论也触及了AI在推理时间的优化潜力，以及通过动态数据调整和采样技术，使模型能在特定任务上展现出超越预期的能力。此外，还探讨了让模型学习人类对话中思维链的可能性，旨在让AI更加理解并模拟人类的思考过程，以期在对话互动中产生更自然、更有深度的交流。"
      },
      {
        "time": "00:50:44",
        "title": "硅谷AI行业的现状与趋势",
        "summary": "在硅谷，AI公司当前关注于通过多模态方向寻找商业变现的途径，以及如何在算法层面追赶最先进模型，提高效果。产品公司侧重于多模态整合以寻求盈利模式，而算法公司则专注于模型优化。双方对于交互式Agent的发展持乐观态度，预期其在未来一年内可能有重大突破。此外，融资环境趋向务实，投资者希望看到更为实际的商业模式而非仅基于技术的远景。"
      },
      {
        "time": "00:53:48",
        "title": "硅谷初创公司面试经历与感悟",
        "summary": "对话内容涉及了硅谷地区初创公司的近况，特别强调了岗位定位（postion）在产品线中的重要性，以及对岗位人才的广泛技能要求。讨论中提到了面试过程中的实战性增强，以及面试官如何通过问题来评估候选人的能力。特别记述了一次使用AI工具解决实际问题的面试经历，以及面试者对问题的深入思考和自我展示的方式。同时，也分享了作为面试官时，通过让候选人解读有缺陷的论文来测试其分析能力和直觉的策略。"
      },
      {
        "time": "00:57:26",
        "title": "华人工程师在硅谷AI领域的影响力",
        "summary": "目前硅谷地区，特别是AI行业中，华人工程师和创业者的比例极高，展示了华人在技术和创业上的强大能力。许多在大公司积累了多年经验的华人，选择投身创业，把握AI领域带来的机遇。这不仅为个人带来了财富自由的可能性，也为华人在硅谷的长期发展和影响力增加奠定了基础。此外，讨论还提及了一位在CI工作后选择离职的个人，表达了希望通过不同平台为社会做出更大贡献的愿望。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "在CEI工作一年，专注于大模型的post圈和微调"
                },
                {
                  "children": [],
                  "content": "之前在硅谷大厂（Meta、Google、Apple）担任全栈工程师"
                }
              ],
              "content": "最近刚离开CEI"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "与研究员合作，将大模型调优至业界最佳对话式大模型"
                }
              ],
              "content": "在CAI的奇妙机会"
            }
          ],
          "content": "个人经历与工作背景"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "用户群类似Roblox，年轻、二次元群体"
                },
                {
                  "children": [],
                  "content": "商业化进展缓慢，探索不足"
                }
              ],
              "content": "用户群和商业化挑战"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "强调AGI和创造性情感伴侣"
                },
                {
                  "children": [],
                  "content": "通过用户反馈快速迭代模型"
                }
              ],
              "content": "产品特点"
            }
          ],
          "content": "CAI公司及产品"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "改善模型输出，使其更符合人类对话"
                }
              ],
              "content": "微调（Post-Training）重要性"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "SFT（监督微调）、RLHF（人类反馈的强化学习）、DPU（直接策略更新）"
                }
              ],
              "content": "具体方法"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "数据质量对于模型表现至关重要"
                },
                {
                  "children": [],
                  "content": "用户反馈在微调中的作用"
                }
              ],
              "content": "数据质量与模型优化"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "评估模型性能的挑战"
                },
                {
                  "children": [],
                  "content": "利用用户点赞、编辑等行为作为反馈"
                }
              ],
              "content": "模型评估与用户偏好"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "大模型的推理优化"
                },
                {
                  "children": [],
                  "content": "多模态融合的应用"
                }
              ],
              "content": "技术实施细节"
            }
          ],
          "content": "对话技术与模型微调"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "企业追求多模态产品以突破商业化瓶颈"
                }
              ],
              "content": "多模态与商业化趋势"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "追赶最先进模型，探索推理时的优化"
                }
              ],
              "content": "算法研究与创新"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "华人在AI领域的机遇与挑战"
                },
                {
                  "children": [],
                  "content": "华人AI创业者的活跃"
                }
              ],
              "content": "华人参与情况"
            }
          ],
          "content": "硅谷AI行业动态"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "希望能为全人类做出更大贡献"
                }
              ],
              "content": "对CAI的贡献与离开原因"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "重视实验与快速迭代的价值"
                },
                {
                  "children": [],
                  "content": "对模型训练和应用的深入探索"
                }
              ],
              "content": "对AI行业未来的乐观态度"
            }
          ],
          "content": "个人看法与展望"
        }
      ],
      "content": "对话脑图摘要"
    }
  }
}