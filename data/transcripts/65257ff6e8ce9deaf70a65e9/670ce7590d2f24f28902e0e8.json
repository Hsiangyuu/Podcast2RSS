{
  "pid": "65257ff6e8ce9deaf70a65e9",
  "eid": "670ce7590d2f24f28902e0e8",
  "title": "从Notebook LM到ChatGPT：生成式AI这一年，我们多么痛的领悟！",
  "task_id": "g2y8qe7eokpbnbeo",
  "transcription": [
    {
      "time": "00:00:00",
      "text": "这个结论非常悲观。作为2个AI从业者，我们今天告诉大家，现阶段AI不适合拿来干太智能的事情。它更适合来做一些我们叫做用高科技干傻逼事，来干很傻逼的事情，而且是重复的，最好是越重复越好。如果你的输入是垃圾，你的输出也是垃圾。对，那你的中间这个AI这个战斗机也没办法在你这坨屎上面雕出花。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:29",
      "text": "对，叫做garbage out.",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:32",
      "text": "或者是说也不一定说你印的是garbage了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:35",
      "text": "有可能就是AI也有技术层面的问题，也有技术也有技术层面它理解力其实并没有大家想象的那么的好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:00:42",
      "text": "对，你就是你把这些知识红楼梦、三国演义都喂进去，它未必能够产生一个郭德纲，对不对？从实际生产当中，我觉得90%的中国企业没有资格去用AI，这个观点可能比较极端，但是意思是这么一个意思，AI1.0做的还是精确型的AI，它还是说不智能。对，但是生成的东西是精确的，这个图像识别是相对是精确的，但是它很少。对，那我们讲的现在讲的AI可能是2.0的AIGC。IGC所谓的智能就是说它不精确，就它能够胡编乱造，能够举一反三。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:24",
      "text": "对它能够用不同的话讲同一个意思的东西出来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:29",
      "text": "这是它的智能，让你觉得智能的恰恰是它不精确的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:32",
      "text": "从ChatGPT到现在，它其实更多你可以看得出来，它是给你展现一种可能性。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:38",
      "text": "可能性跟技术上面的探视。国外并没有这么狂热。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:42",
      "text": "它并没有那么狂。",
      "speaker": "发言人2"
    },
    {
      "time": "00:01:43",
      "text": "其实你说未来可能是一个多协作的这样一个很科幻的场景，我觉得还比较难的。这个难点并不是科学的限制，也并不是所谓的物理的限制，算法的限制。并不是这个东西是我们人类社会原本的这个社会基础的一个限制。我们整个人类社会的数据基础，组织形式关系等等的。这些还不够支撑起一个全AI自动化的社会。有可能AI会发展到一个高度，但是我们的基础还够不到。对你永远人类达不到所谓叫做生产极度发达，物质极度发达，精神极度发达。所以我们必将长期处于社会主义的初级阶段，就AI也是这样子的吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:40",
      "text": "就跟老肖聊一下这个no book l最近非常火的一个应用，看国内当下就蛮蛮多的人就开始跟进这个应用了。我做了一个中文版的这个no book LM，然后开始说什么AI播客出来了。然后这个卡帕奇也在那边鼓吹说这个是下一个GPT级别的应用。对，所以我想说今天我们就来录一期节目，专门来聊聊这个no book LM它是一个什么东西，它为什么会突然出圈？那它到底会不会是下一个GTP级别的应用？对，首先我们讲一下这个nobo LN，它是谷歌应该是去年推出来的一个这样一个应用。其实本质上应该最早是来做学术研究的对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:25",
      "text": "对，就是为了帮助学术研究的。它可以快速的帮你。它它的定位是一个AI也是AI assistant的，是一个帮你去整理快速总结，抽离那些论文信息的，是学术research相关的一个辅助的助手。对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:42",
      "text": "说白一点其实就有点像一个专门的一个agent的应用。但是它限定了一个范围。",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:48",
      "text": "就是垂直在这个做研究领域的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:50",
      "text": "这个就是你把文档喂给他，你的几个研究的文档素材材料，然后你能够针对你这个文档，这个专门的知识库进行学术上面的这种提问。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:02",
      "text": "尤其是它相当于背后我我我比较觉得比较好的比喻，可能有点像是量产车的那种感觉。就是他把你背后已经底盘调教好了，各种参数你的重要的发动机、变速箱这种都已经调好了。对，那你就是用，所以它就是专门为这个学术用的话，它就不会说幻觉比较小。他不会跟你像普通你真的用ChatGPT，有的讲到后面他其实会飘，聊的次数越多，它越容易出现幻觉，跟你说一个不存在的一个理论都被他推出来了。但是他他这边的话其实是有做了限制的，至少说是严格。",
      "speaker": "发言人2"
    },
    {
      "time": "00:04:42",
      "text": "根据你的文档。",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:43",
      "text": "对，不会那么容易出现问题了。当然说现在他也才做了一年，也还是会有bug的。但是总的来讲肯定比ChatGPT那个通用的是强很多。在在研究领域，就是你相当于要一个可靠的一个答案的时候，对他这个部分已经做的还不错。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:00",
      "text": "是的，对，其实我我理解就像你用define或者code这样搭一个自己的知识库，然后在有限范围里面进行问答。只是说它的产品化更好，然后他的体验可能做得更完整。",
      "speaker": "发言人1"
    },
    {
      "time": "00:05:14",
      "text": "对对对，他已经是一个他就是一个产品化的一个，你可以理解成是一个产品化的ChatGPT，专门用于论文写作。对，做的这个东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:23",
      "text": "但是过去一年就是不温不火，反正推出来了，可能会有有些用户，但可能有点像一个大厂里面实验性的或者探索性的这样一个产品。对，那突然就是今年最近，应该是最近突然就是因为加上了输出音频的这个能力，他突然就爆火了。后面我也去研究了一下，其实它还是在输出的层面，就是加了一个音频的一个对话生成的这样一个插件，应该叫illuminate这样一个东一个谷歌内部的一个东西。对，然后其实我觉得他的本意其实是希望去把这个问答做的更流畅，或者把这个知识学习通过这种收听的形式把它做出来。无意间做成了一个说被人发现它可以生成这种很高质量的对答的这样一个播客。就像我们今天两个人在这样讲一样，一下就出圈了。是，然后整个中文互联至少外网还好，但整个中文互联网就惊呆了，说天哪，这个AI都能生成播客了，AI又要替代你们这些主播了。对我我们很擅长制造这种焦虑。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:37",
      "text": "国内就是动不动就是惊天逆天什么什么一些东西替代人，这整天会讲这些。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:45",
      "text": "是是是，所以我们两个今天出来也是要证伪一下这个事情。因为首先我们是AI的从业者对吧？我们也其实坦白说我们过去一年也做了一个类似no book LN的应用。这个稍后我们可以跟大家分享，里面踩了哪些坑。然后第二个我们刚好又是播客的从业者，所以我们两个出来可以做一些辟谣。就是说老师你觉得AI会不会替代我们这样的主播，会不会能够替代播客？",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:14",
      "text": "其实播客我觉得有价值的博客一定是有深度的思维的碰撞的。那按照他现在的这种大模型的能力，其实肯定是替代不了。因为他是没有深度的思考的。尤其是其实讲到最后他还是会变成车轱辘的话，就是老师那几个套路就是像比如说以现在这个nobo alm的那个生成的音频来看，他如果我们中国人来理解也是很简单，就是多了一个捧哏。对，多了一个人在那边整天说爽h my god gunness，各种各样的那种语气，一直上就是搞得很夸张。然后这样就变成了你本来是一个平铺直竖的一个事情，变成了有一个人天天在一直捧你，但是这个事情你听多了，你就觉得这个套路实在是太，因为博客其实是一个看不到人的脸，其实信息全部靠听的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:09",
      "text": "这个时候对，其实听的时候你会更会在意他的情感一些和思考。他这次能出圈，我觉得首先是情感是做到位的。因为捧哏的那个情感真的到位了，听的就是感觉真的像是两个人在聊。问题是你多听了几个之后，你会发现的套路都是一样的。就是一个什么屁大的事情，他也给你asm一下，屁大的事情也amazing一下。这个其实你正常的一个你是真的是这个行业内容的人，你去听你会觉得这扯淡，那就这么点事情你也要搞那么夸张，真的变成了演绎的那种相声一样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:42",
      "text": "这个其实你还是失去了你的内核，就是你一个人讲漂亮话和语气很夸张。那那这个是如果是一个表演，那都OK。问题是其实大家听博客对大多数人是要听到内容的对，就是他要有一个情绪价值在那。对对对，那你这个是情绪的效果拉满，但是价值没有的话，节目效果拉满它还是一个空壳。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:06",
      "text": "就是从我们从业者的角度来讲，大家对AI要稍微下投一下，就要稍微有点趣味的这种精神。否则你就很容易被带入到这种焦虑里面。对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:09:18",
      "text": "是这样的那但是我觉得同时作为博客的，我们自己是主理人我是觉得看到这样的东西是很还是很开心的。首先与大家会看到说它产生的效果还不错。那大家会想到说，生成这个东西的感觉门槛像好像降低了，效率提升了。我可以更多的去生产我自己真正有价值那个内容，我可以少干一些脏活累活，这个事情是真的有用。",
      "speaker": "发言人2"
    },
    {
      "time": "00:09:46",
      "text": "是的，是，但其实从我的角度来看，还是输入的质量决定了你输出的质量。就AI的本质还是说你输入的质量怎么样，如果你输入的是这个垃圾，那出来的垃圾很正常的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:03",
      "text": "我们最近比如说跟海外的客户合作，他们其实会实际的碰到的就是这个输入其实没有你想象中的好。他们都会觉得说，我自己有自己的这个SOP standard Operation procedure，我有我自己的标准操作流程，也有文档我也写了excel我有啊，跑那个PPT我有，甚至一些项目的flow的一些东西全部都有。就觉得说这些东西可能给了AI就可以产生比较好的这个穴的知识库了。但其实实际的情况是你还是得自己去调。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:37",
      "text": "对，其实词对，他们自己到最后那步沟通的时候就会其实我经常会听到一句话，刚才说的叫做garbage in garbage out，是垃圾进垃圾出的。他们自己都会很明显的感受到这个事情，尤其是到了说，一些专家人员进来的时候，就有一些X本X而进来的话，专家其实他有他的特点，就是这个废话，就老师傅。对，就是没有废话。上来都很简单，就是问几个很刁钻的问题，然后看他情况怎么样，然后一下就发现不太行。是的，然后那那他们自己但是自己提问，其实很多专家也不具备一个很好的提问能力。他其实问的那些问题，有的时候也不是正常人会问的。那这样子的话变成说如果你在训练的时候，真的为一个很专家的人训练，对那有可能就只能照顾这个专家人群了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:31",
      "text": "那你非专家人群其实恰恰是很多企业他在做这个知识库的时候，其实他现在当至少现在这个阶段是想替代的是中层人员和初级人员，不是说想去替代老专家的。那结果训练的人员是老专家，当老专家训练出来的时候，能服务老专家，那这个事情就会问题就会比较大。那那其实所以到最后都会变成，如果说从我们从回到AI agent训练的这个角度来讲，相当关于你的数据清洗和准备这个环节，还是得靠自己弄好。这个门槛其实已经非常高，这个门槛还是在那个地方，就是我们碰到的不管是海外还是国内的，大家实际在做的情况其实都会在卡在这里。所以这个地方就是大家很很可能是容易。低估了它的难度，都觉得好像好像就是我平时做的事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:12:23",
      "text": "好比你写个作业，我觉得我这个作业一定会满分，老师一定给我全勾。但是其实你不知道你题目是做满分的，书面写字不工整，老师给你扣一分对吧？哪里那个那个图写太多了，老师给你扣一分，这个是你不知道的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:40",
      "text": "总有很多人跟AI的交互，其实还没有形成一定的默契跟习惯。没有的对，就是你刚才讲的就是我们其实也做过类似是这样的一个agent的一个产品，agent的apple builder这样一个产品。那我们有一些，当然我们是作为内部来使用，或者是说帮助我们一些合作伙伴来搭建他的这种AI的一些应用，但我们并没有把它推向市场。其实在过程中，就像你刚才讲的，就是垃圾进垃圾出。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:13",
      "text": "很多这样的人客户会觉得说，我这个内容已经准备的非常好了。你看我有这个标准那个标准，我有这个流程。对，但是可能我们不明白一点，就机在评判你的东西的时候，跟人评判你这个不一样的。对你今天说老板我有这个流程那个流程，我这个表那个表，老板说好有都有做很好。你是个好员工，但是AI来评判你的时候不是这样的。因为你的那些数据对AI来讲可能就是九牛一毛，就不够他学对他是一个胃口很大的一个机器。当你用很小的样本量去换取智能的时候，它的样本量不够的时候，他肯定会发散。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:56",
      "text": "除非你的样本质量特别高。对，你是为他专门设计的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:14:00",
      "text": "这个就讲回来就好了。这个讲回来说不要讲别的工业上面的应用。我们就想AI能不能生成一档高质量的有含金量有思想的博客。我觉得这个结论一定是不行，为什么不行？今天坐在镜头前的两个人，可能有三四十年的人生的阅历，有几十年二十年的工作经验？然后有多少坎坷的经历。对，有的亏了500万，有的亏了3000万等等。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:29",
      "text": "举个例子，这些是AI没有的对，那你未经AI的可能是你这个人生的知识里面的1‱。你怎么能够期待AI能够把你这1‱演绎成一个很精彩的一个对话呢？我觉得这是特别难的。对，就他只会根据你的东西去脑补他知道的东西。对，那这个时候就是两个没有灵魂的还在交流，你无非是用一个语音插件把它读出来而已，仅此而已。",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:02",
      "text": "一个专业的语音插件就是看起来专业，但是他就是专业在是的声音的合成上。是的，那这个东西里面还有隐藏，就是相当于AI它的编码还没有到那么多。因为我们刚才说其实至少在一个是有价值的信息。至少是首先信息本身有价值，它的内容是有价值。第二是情感上的一个多样性，其实人的情感还是蛮复杂的那这个东西只从我们说在声音的停顿也好，或者是声音的语气这些东西。虽然说他现在确实能模拟一些，但是我刚才讲的就是其实能模拟的相对比较好的，也就是刚才说的一些强烈的一些东西。因为它比较强很极致的一种。是的，我就强烈的喜欢，强烈的厌恶，或者是极度的平。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:50",
      "text": "这个是最常见的是平。其实我觉得我觉得应该怎么去定义它这个使用范围，就是说如果你真的想靠no book LM去生成一个所谓的有深度的博客，我觉得这是做不到的。但是你靠这个东西去做成一个有限范围的事情。我举个例子，讲故事，讲儿童故事、睡前故事，或者是啊念一些段子，做一些简单的播报，组合一些新闻，做一些简单的播报。你不要对他有太高的期待，那他反而能够把这个东西做的比你可能去做还好，就是重复的。然后脏活累活我觉得你交给AI来做，可能会做的比人会做的更好，这里面有非常多的因素在里面。",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:37",
      "text": "我觉得顺便要讲到一个观点，就是其实我们做了这么久，不管是做AI产品或者辽AI这么久，其实大家都觉得说我们要去追求一个更好的模型，对吧？或者是一个更先进的模型。几万亿的一个参数。其实我们作为行业从业者来讲，也做了这么多案例。不管自己做，帮合作伙伴做，或者是看别人做对，其实这个不是越先进越好的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:09",
      "text": "还是刚才那个观点，就是垃圾的内容进去，它只会输出垃圾的内容。那AI在中间只是一个生产内容的过程，我指的AI是AIGC对吧？如果你的输入是垃圾，你的输出也是垃圾。对，那你的这个中间是战斗机也没有用。因为你输入的是垃圾，而且是有限的垃圾。就算它是这个A还是一个战斗机，也没办法在你这坨屎上面雕出花。对他只能越叼越离谱，越雕越离谱。因为在他没有这个就是他他没有这个知识范围的能力里面，他只能去发散，他想去脑补对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:17:51",
      "text": "所以你就发现这个东西出来，反而已经离你想要的就会非常远的对对，当然其实今天讲这个是我们当然还有非常多例子，有一些能讲的，有些不能讲的。是因为我们其实也在行业里面做了蛮多这样的应用。特别是有一些合作伙伴，确实把这种agent或者多agent的这样一个交互已经是用的非常深了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:18",
      "text": "因为为什么会说no PLM？因为这个东西类似的这样一个agent的一个搭建的的一个工具，其实我们自己也也在做我们自己也在做这样一个东西。所以这东西一出来，我就跟老师说，这不就是一个agent然后输出的时候加了一个音频插件。我们本质上就是这样，但我们没只是我们没有去做这个音频的输出而已。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:43",
      "text": "对对对，因为我们觉得可能文本其实是更重要，你把文本玩清楚了，你最后输出的不管是图像，不管输出的是这个音频还是视频，只要这个文本你搞明白了，其实输出的就不会有太多的问题。对，因为整个AI还是围绕一个文本，围绕一个test，围绕这个token来进行这种演算的。是。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:07",
      "text": "对对对，所以我们当时就没有做音频的。对对对，所以那天我们问了一下我们社区的朋友说，那我们就我们也加个音频插件，我们也可以做一个note LM给你们玩一下，对不对？对，是，所以我们简单分享一下，我们在做这个agent builder的这个过程中，我们应该前前后后也经历了蛮多的项目，有自己的，有合作伙伴的。就是你觉得最大的坑是啥？",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:39",
      "text": "其实到最后还是那个数据的准备跟清洗会出现巨大的问题。完了以后这是第一个大坑，这个是很多人他不会这个问题的难。",
      "speaker": "发言人2"
    },
    {
      "time": "00:19:50",
      "text": "就是跟AI先不先进。",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:53",
      "text": "没有关系。而且是在于是说很多人他会不知道这个问题，他就是叫属于自己不知道有这个问题。他只有在做进去了以后才会发现有这个问题，那那就会出现明显的准备不足和和意外，还有就是很沮丧。因为他可能想象不到是这个原因，他一直觉得是自己的很多的文件也好，或者自己的人员是充足的，是够的，很正常。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:23",
      "text": "自己的就是都是够的。就举个例子，我们有很多听友，如果是打工人，你去问你老板，老板我要做个营销活动，可是我觉得我有这个困难那个困难。老板说你这有什困难的，我们有十万会员什么事情不能做。对对对，老板觉得我十万会员特别牛逼。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:42",
      "text": "对，十万会员好像随时叫过来干，叫他按着能干嘛就能干嘛。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:47",
      "text": "其实你把这十万会员放到市场上，你就会发现根本就不是那么回事。你只是有一张十万行的表。对对对，但他并不是真实的10万个消费者，对吧？离实际他能够变成业务还差的非常远。所以我就是举个例子来补充你的这个观点。就大概是这样一个意思，客户会觉得说我这个准备非常充足了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:10",
      "text": "对，就是高估了自己的这个数据的质量，很正常和准备。我觉得也很正常。对，很正常。其实他意意识不到那那这种问题的话是第一大坑。然后第二个坑就是可能很多人会觉得说是一个技术问题，我把这些数据准备好了，这个是不是往你们这个技术一放，这个技术就可以自己去识别，然后它的效果就很好了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:37",
      "text": "其实过于高估自己，也高估了你。",
      "speaker": "发言人1"
    },
    {
      "time": "00:21:40",
      "text": "也高估了技术，其实技术也没有那么牛。这个no book LM他从做第一版到现在，中间也大概叠加了。他可能两个月左右会叠叠一个版本，其实算比较快的，毕竟是谷歌大厂两个月出一个版本算比较快的。他差不多做到现在，价格还是蛮多的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:01",
      "text": "它的这个技术在背后其实是花了很多人去调的，就是看起来好像就这么几个事情上来传传文档，对，抓那个链接，抓视频，然后那个可以支持各种各样的文件，音频文件、视频文件看起来好像不复杂，但是其实它背后是大大的扩充了它的这个容量，然后还有拿进来以后怎么分段，怎么存储。怎么样去更高效的帮你提取出你要的信息。其实背后技术是挺多环节的那这些东西的话其实他也没有办法做到特别好。而且即使是谷歌，强如绝对是全球最top的开发者了，他们也只能做到这个程度。你拿给他的话，其实还是会有很多不足。",
      "speaker": "发言人2"
    },
    {
      "time": "00:22:45",
      "text": "的那就两端都有问题。对，就是很多的用户他以为他有标准，他有数据，他有SOP，对，其实他没有或者他没有能够给到AI的格式，或者说他给到的那个质量就是质量都不行，就是达不到。他又觉得说AI.",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:07",
      "text": "又很强大，他以为也很强。",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:09",
      "text": "但实际这两端都挺弱的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:11",
      "text": "都都不强。所以到了他最沮丧的就会出现说最后大家得去调试debug这个东西。很多脏活类最完善的时候会发现，前面的数据也没准备好，然后那个那个人员也没有到位，他很多东西得人工去标注，对，找不到人。",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:29",
      "text": "没有人愿意看这个标看看结果就是通过做一个AI项目，把自己公司所有做的不好的缺点都暴露出来了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:36",
      "text": "发现是会会更好看。",
      "speaker": "发言人2"
    },
    {
      "time": "00:23:38",
      "text": "这样这个是会就会更怀疑人生，对吧？",
      "speaker": "发言人1"
    },
    {
      "time": "00:23:43",
      "text": "技术你看我看各种技术都是说文件放上去就怎么样了。我先体验了几个也很好，为什么我放的越多好像没有那么更好了？对，这其实恰恰是有很多技术上的问题，就是你不是说我的那个就首先就刚才说的那个数据，它本身的质量是不是均分配的？",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:05",
      "text": "说实在还是可能就是那种夸大其词的自媒体的话听多了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:11",
      "text": "然后其实这里面你我们就说十个文档，十个文档是十个不同的人写的，他可能质量都一样，它看起来一样，实际上就是有差别的那你给AI这种，他是实际干活的一个生产力。他学习的的时候学习到garbage，学习到垃圾的部分，他就学进去了。对，那你到调试的时候，你得把这个部分得找出来找出来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:34",
      "text": "所以到这个时候为什么调试会难呢？很多时候就是大家可能会觉得，也许是训练一个靠谱的这个知识库出来，难的是数据。我们刚才讲的这是第一个难点。但是实际上综合的难点不还不是在数据，而是在于评估这些数据的结果是不是够好。其实你去评估一个东西好不好，其实也是挺难的。这个东西就是我我我如果说有很多听众可能做过一些管理，就只要你不是做只做自己，你不是一个自己就能完成所有工作的，你得跟别人去合作的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:07",
      "text": "到最后可能老板会来问你说，你觉得跟你合作那个张三他怎么样？你其实如果他就这么问你一下，你心里会想出来这个张三到底怎么样，这个东西怎么评估。这其实会每个人会有很多的没有标准的，然后每个公司也不一样，你做的活也不一样。那那其实这个大模型的情况比这个还更难。就是一个大模型本来里面的数据已经很多了，然后你为了它数据，你最后要评估他这个数据是不是比原来更好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:25:35",
      "text": "你现在评估也许是更好，但是我后面传了10个PDF以后，是不是比传之前更好呢？有可能更不好，有可能会更差，这个我们其实也经历过。有有小伙伴觉得说把这个历史的几年数据都传进来，肯定比我传三个月的数据好。结果传进来以后就更傻了。因为这历时三年里，有过去一些很傻的员工的一些操作也被学习了。那你这个时候还不好找，有的时候你可能有好多个员工的东西共一起贡献在你这个知识库里面。那你这时候要调整。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:07",
      "text": "其实还是数据清洗的问题。所谓叫清洗就是有很多脏数据或者你不需要用到的数据。对，比如说你这个一张表里面，你可能只是想问业绩，那你可能就不要把出勤时间类似这样的东西加进去。我讲的是最简单的场景实际的企业生产的这种表格里面有非常多这样的脏数据，有可能就是多到就是你要清洗的时候你要怀疑人生。",
      "speaker": "发言人1"
    },
    {
      "time": "00:26:34",
      "text": "是的，就是很脏很累的活。但是没办法，如果你想获得某种AI上面的智能，可能百分之七十八十的时间，根据我们的经验来讲，你是要做这些脏活累活的。对对对，因为这有个过程，就是人跟机器要交互，人跟机器要磨合。对，AI并不是一个垃圾桶，你把东西丢进去，他就可以给你变废为宝。他不是这样。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:00",
      "text": "这个东西甚至连垃圾分类它都不是太好的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:02",
      "text": "做好不要说变废为宝，对它并不是这样一个东西。它可能是我我觉得从我们的应用当中，他更适合那种就是我本来就知道我从A到B我要做什么，中间我有什么哪些地方我要靠AI帮我提高效率的这样的一些场景。而不是那种我要从A到B还是A到C我还没想清楚。但是我就是觉得我现在需要有人帮我提效，我觉得不是这样的那我觉得你更适合请个秘书，你不适合找A来做这样的事情。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:40",
      "text": "这投产品还是找人好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:27:41",
      "text": "对，而且很多企业其实它是在比较，我觉得就是至少是国内的企业，国外好一点点。国内企业很多还是在很粗放的阶段的。你不要说SOP了，有可能连数据都没有。你不要说这个数字化，可能他连信息化都还没做完，信息化都没，那这个是一个很糟糕的事情。你都没有这个信息化作为基础，你做的一些决定，你做一些业务判断，你们开的会都没办法拿出数据。你怎么一步过渡到AI，我觉得这个很难，我觉得这个特别难。是的，这几乎是一个不可能的任务。除非你老板就想像以前你一进我公司大堂，有一个巨大的那种屏幕，告诉你我全国的分店数字大屏，那以后可能进来就是我有这一群AI，你老板可能想达成这种炫耀的目的，否则我觉得从实际生产当中，我觉得90%的中国企业，还不到用AI，或者没有资格去用AI。",
      "speaker": "发言人1"
    },
    {
      "time": "00:28:50",
      "text": "我觉得是这样的对，这个观点可能比较极端，但是意思是这么一个意思。国外会好一点，因为我们也挺多国外的这种合作伙伴。国外好一点就是说他至少说他做的事情会切的相对细一点。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:08",
      "text": "他要理智的多，因为毕竟一个人工贵，人工贵。对，贵的贵。老师招过来对不对。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:15",
      "text": "老师招过来干活对吧？这个比在国内招个小叔贵多了。那你肯你还不能随便开他，对，那你肯定要把这个一张纸给老修，这是你今天要做的工作在这里面的我是付钱的哈那这个之外的什么东西，这个你自己考虑对吧？那就相当于说他有一个被主动或者被动的，他会有一个SOP，有一个标准，有一个工作手册在里面。是的，这是他们的整个一些大部分一些国外企业相对会好一点点。我说中小型企业，大型企业就不用讲了，中小型企业会相对好一点。但是还是会有老熊刚才讲的这些问题，就garbage in garage。对这样一个问题，就是我觉得这个问题的核心还是大部分人他不是做技术的，或者不是程序员出身，或者不是这个行业的，他很难用技术的语言去向AI提需求。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:11",
      "text": "我觉得这个是我自己之前我一个朋友也讲过，就是语言其实一个非常大的一个障碍是就我们今天沟通的语可能是中文，但是我们换成英文来沟通是另外一种思维方式。对，那我们换成代码来沟通，对，又是另一种思维方式。是啊中文本身它不是一个逻辑性特别强的语言。对，那语言。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:37",
      "text": "本身也会有很多的二意性和一些容易不容易，就是精确地做精确。",
      "speaker": "发言人2"
    },
    {
      "time": "00:30:43",
      "text": "的一个东西没错。那什么叫精确的语言？就是你你这个话里面不要有任何修饰的词语。对，然后最好每句话里面带数字，是当你。",
      "speaker": "发言人1"
    },
    {
      "time": "00:30:56",
      "text": "做到这个的时候，其实跟写代码的程序语言一定没有什么差别。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:00",
      "text": "那你想一下这种话你不管用中文、英文、葡萄牙语去说出来给到AI它是work的，它是能用的。但是你再想一想这个东西跟代码有没有区别。",
      "speaker": "发言人1"
    },
    {
      "time": "00:31:11",
      "text": "已经很接近了，基本上就叫我们叫做伪代码。它的伪代码其实已经是自然语言说的，但是说的就是刚才讲的，它是去掉了那些各种修饰。对，就是很简单的逻辑数据，数字逻辑。",
      "speaker": "发言人2"
    },
    {
      "time": "00:31:25",
      "text": "在这逻辑数据12三四分点，总分总三段式对吧？类似这样的语言结构，它已经无限的趋近于一个代码了。那这种情况下，这种是我觉得是所谓的AAI或者机器能读懂的语言。但是我打个包票，99.9%的人或者的企业他没办法做到这样。就包括我自己去做，我们自己做也做不了也很难。因为人去做事情总是会飘的。对，总是会就是语言还是会本质上语言还是会。有障碍的。对你不管在生成、写作、思考的过程中，你会加入很多人类的东西进去。那这个时候对机器来讲都叫脏数据。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:10",
      "text": "所以到最后的话，我们刚才说的第三个坑就是你得花大量的时间反复的去调试跟debug这个东西就是我们之前讲过的未来世界，大家是有讲，一个大神是有讲，就三步，听起来很简单，就human去describe，然后AI build，然后human descent类描述，对人类描述搭建，然后人类去bug去去调试，人类再来调试对讲起来很简单，想起来，但是这三步全是坑。就我们现在实际上你在企业去应用前面两个，刚才已经说了很难，前面两个就筛掉多少。对，然后到第三个是反复重复，前面两个没做好的事情一定要给他做好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:32:50",
      "text": "对，就像这个特别难，前面已经有两扇非常大的门槛。对你要先能突破过去，很多人死在第一道关。对，就是描述你的需求。对你能不能用计算机能够理解的语言把你的需求描述出来，这里可能挡死了90%的人。对再到第二道门的时候就是叫做AH build。这个可能有一部分部分决定决定于这个AI够不够智能。对，有一部分决定你描述够不够好是是当你两端都不太行的时候，大部分情况下真的是两端都不太。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:24",
      "text": "第一步就不太行，第二步也不太行。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:26",
      "text": "又挡住了90%的，好了，到了第三步，human debug这个事情我们做过的时候，我们是枯燥无比。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:36",
      "text": "而且其实要求也挺高的对，就是前面两步都做的不好的话，你其实基本上都得重新帮他做了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:33:41",
      "text": "好，那我们讲极端一点，就这三个砍，每个坎都挡住90%的人，那最后剩下的可能就是寥寥无几的对对能够跑出来的一个应用，那有可能这个应用还是个伪需求，完蛋了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:57",
      "text": "是是，所以这里面就是非常大的坑的。到最后得得回到说你得去解决一个需求，他不能有那么高的要求。就是这个需求大致它是容你就容错率比较高的是一个是需求。",
      "speaker": "发言人2"
    },
    {
      "time": "00:34:12",
      "text": "所以大家要注意这个结论非常悲观对，这个结论非常悲观。作为2个AI从业者，我们今天告诉大家，我们非常相信ai我们非常看好AI对，但是现阶段保修的这个观点其实跟我是一样的，现阶段AI不适合拿来干太智能的事情。对，很悲观的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:33",
      "text": "必须要告诉大家，对，千万不要对自己，也不要对AI有过高的期待。如果你自己连需求也描述不清楚，不知道自己要什么，你业务都还没做清楚，指望的加个AI能救你的命，或者能够提高你的这个洋气程度，我觉得这个大可不必。对现阶段不要对AI有太高的指望，它更适合来做一些我们叫做用高科技干傻逼事。我自己的总结来干很傻逼的事情，而且是重复的，最好是越重复越好。对对对，所以我觉得这个应该是我们聊到目前为止，或者是经历了这么多年对，就是做过来我们的一个总结，就是我们的一个经验。那可能未来会不会变得更好，我觉得不好说。对，但是从逻辑上面来看就是garbage in garbage out。",
      "speaker": "发言人1"
    },
    {
      "time": "00:35:35",
      "text": "对，未来我从事还是乐观他会好，但是他不会那么快的一下就一夜之间对就好了。就是老外很喜欢说的叫overnight。对，就是说他其实不太会overnight，对它是一个慢慢的一个过程，相当于是刚才说的三个环节。这个数你描述其实是一个数据准备的过程，你不然描述不了。对，完了AI build是一个技术的一个积累的过程。第bug是人要能把数据跟技术和你人人的一些东西。那那那个我们刚才说很多没有隐性的那些知识。对对对，就可能不是在数据层面。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:12",
      "text": "所以你不要说用AI来做个播客了，你就是你把这些知识红楼梦、三国演义都喂进去，他未必能够产生一个郭德纲，对不对？那没有办法，这个是很难做到的。另外我觉得大家会对说AI还会有惊奇的一个点，就是他竟然能够做到这样的一个惟妙惟肖的语气，但是他经不起你的推敲。其实我这么总结，就是说他更现在它更适合。比如说举个例子，还是说大家问的很多的AI能不能替代这个主播播客或能不能做内容。我的观点就是他可能更适合做那个粘合剂，把你有价值的观点用些车轱辘话串起来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:02",
      "text": "或者车车轱辘化和套路的语气，就把你这个串起来。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:06",
      "text": "你去评分。对，A点讲了，B点讲了，C点也讲了，或者我们今天聊的所有这些观点他都讲，但是他没有任何的态度。他也可能可能去照搬了一些很正确的话来讲，把它给串起来。是的，观点是都讲到了，但是可能没有太多灵魂。原因就是在于刚才老徐讲的这个就garbage in，garbage out. 对，会或者是说也不一定说你印的是garbage了，有可能就是AI.",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:38",
      "text": "也有技术层面的问题，也有技术层面。就是技术层面它理解力其实并没有大家想象的那么的好。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:44",
      "text": "对，因为其实AI1.0做的还是精确型的AI，他还是说不智能。对，但是生成的东西是精确的，这种图像识别是相对是精确的，但是他很傻。对，那我们讲的现在讲的AI可能就2.0的AIGC。那IGC所谓的智能就是用你的话讲，所谓的智能就是说它不精确，它能够胡编乱造，能够举一反三。",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:15",
      "text": "对他能够用不同的话讲同一个意思的东西出来，这是他的智能。",
      "speaker": "发言人2"
    },
    {
      "time": "00:38:20",
      "text": "让你觉得智能的恰恰是他不精确的部分。所以你怎么可能会要求他讲话又要政治正确，又要面面俱到，还要惟妙惟肖，又能够有幽默感。这个我觉得可能不太实际。更多的我觉得AI在这个阶段可能是满足了我们对于一个未来，或者是对于一个不确定的未来，或者是比较低迷的情绪的一个幻想。可能我觉得有点像是一个一个YY的一个对象，帮助大家在这个比较困难的阶段找到一个对对对对，找到一个这种叫做什么希望？",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:02",
      "text": "对，找到一点希望。因为因为这种体验，其实现在我们看这一年从ChatGPT到现在，chat PT是文字聊天，那你现在就好像有一个语音在聊天的感觉。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:14",
      "text": "对对对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:15",
      "text": "那这种感觉对人我觉得说是感官上冲击是很直接的。那做过程中还有生图生图就更直接了。大家看到的照片，生图生视频，是的，都会很那个。你看其实PNI这么久时间他是在领跑。他把文字、图片、视频，sora这个东西，它年初我们应该是我们春节的时候叫的，但到现在啥也没搞，但是国内的手法都做出来了，其实国外并没有这么狂热，他并没有那么狂。其实国他国外他其实更多你可以看得出来，他是给你展现一种可能性。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:48",
      "text": "跟技术上面的探视。",
      "speaker": "发言人1"
    },
    {
      "time": "00:39:51",
      "text": "也有他自己商业上的目的，最近ONI融了很多的钱，他把自己转成了一个商业化的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:39:57",
      "text": "他更多是一个叫做脱虚向虚的一个故事。就是，用AI展现的一个很前沿非常前沿的一个可能性。但是其实他不会像国内这么着急的去找应用。是其实其实还好，总体我觉得在国外的情绪是还好的。但是因为这个可能性展现了它的股价提升，它在资本市场上面的反应，更好的带动了整个链条的这种起飞。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:25",
      "text": "我觉得更多是这样一个在在脱虚向虚的一个盒子里面，我觉得是在空转的，本质上有点在空转那个意思。但是中国人又特别的务实，就希望说这个东西赶紧要找到场景，赶紧要落地，要心智生产力对吧？要数字化转型。但我觉得没那么快，对，没那么快。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:50",
      "text": "还是这个观点，就是我们也聊过非常多企业，包括我也做过非常多企业的顾问。在你信息化数字化都还没做好的时候，你去渴望智能化AI化，我觉得就是在一个这种叫做一拳打在海绵上了，我觉得是这样一种感觉，其实还是比较远的，国外可能会近一点，但是他们可能没有那么强那么迫切的这个动力。那那国内可能很迫切，但其实这个基础我觉得并不好。这个可能是需要时间的。我觉得可能从我的观点来看，可能未来五年或者十年。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:33",
      "text": "我自己的预测是AI可能是一个功能级别的东西，对它并不会是一个应用级别的东西。为什么会有这个观点？其实大家看特斯拉，我觉得是一个非常好的例子。",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:45",
      "text": "对，特斯拉本质上是一个AI公司。对，但是他的AI并不是说我那辆车就长得是一个AI的样子。对它是一个功能级别的叫FSD的这样一个东西，帮你开车。对，帮你开车。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:00",
      "text": "对，但是很多我们现在的过度的畅想，就AI它是一个应用级别产品级别的东西。我觉得这个可能是。太乐观了。就从我们从业者的角度来讲，我们觉得这个东西可能太乐观了。如果你把它放到一个功能级别，像你刚才讲的就是那种蛋白质的研究，做一个很具体的一个事情，去加速这个事情的推演计算产生研究。我觉得这个是对的。本质上它是一个还是一个功能级别提效的，它是加速，它重要是加速速度。对，或者是说像FSD这样的东西，它是改变了你的体验，或者提高了你的体验，就提效或者提高体验。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:43",
      "text": "我觉得这个是很就是从大的方向上面，我的我觉得AI是能够直接做到的做到。但是你说它是一个多么颠覆的，就是未来可能是一个多agent协作的这样一个很科幻的场景，我觉得还比较难。这个难点并不是科学的限制，也并不是所谓的物理的限制，算法的限制。并不是这个东西是我们人类社会原本的这个社会基础的一个限制。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:13",
      "text": "对，就像很多观点说，像之前讲人形机器人，为什么有一个争论说是要做有脚的还是没脚的？那有一派的观点就是说机器人他为什么要长成跟人一样？对，有一派的观点就是说我们人类所有的基础设施，它是基于这个双脚来设计的。对它不是基于轮子来设计的。对，那我人形机器人就应该是做铰的。那其实做做这个有角的这个成本其实是更高的。对，代价成本其实都更高。",
      "speaker": "发言人1"
    },
    {
      "time": "00:43:46",
      "text": "包括手也一样，手也是人的一个特殊。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:49",
      "text": "的以此类推，我没有对这个观点有这种对错的评判，就是以此类推，我们整个人类社会的数济基础，然后叫做组织形式，关系等等的这些基础。我觉得目前来讲还不够支撑起一个全AI自动化的社会。我觉得来讲目前是这个基础是相对是比较弱的，有可能AI会发展到一个高度，但是我们的基础还够不到。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:20",
      "text": "对，甚至现在为什么还有很多人会讲的说AI有可能就是说到下一个阶段是到必须得到什么阶段呢？得到AI。它能够帮助我们突破我们现在突破不了的人的基础的基建。他能帮我们想出来更好的基建来适合我们两边都能一起用的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:39",
      "text": "其实这个跟所谓的共产主义的理念特别像，就是在一个理想的社会里面，物质文明极度发达，生产效率极度提高，人类可以各取所需。对对对，理想来看是共产主义。",
      "speaker": "发言人1"
    },
    {
      "time": "00:44:56",
      "text": "的终极目标。对，大家就是直接按需分配了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:00",
      "text": "不用再劳动了。但是你很难或者你永远人类达不到所谓叫做生产极度发达，物质极度发达，精神极度发达，我觉得这个很难直接拉满。所以我们必将长期处于社会主义的初级阶段。AI也是这样子的，AI也是这样一个道理。",
      "speaker": "发言人1"
    },
    {
      "time": "00:45:23",
      "text": "对，就是我们知道了说OK就是未来它是这样一个阶段，有可能车是自动的，办公室里面的这个白领都变成了agent，然后那个工厂有这个机器人，码头是自动的。是的，万物互联的。对，然后这个城市也是智慧城市，自动的对，可是真的到有那一天的时候，你会发现跟我们憧憬的这个共产主义这个乌托邦特别像。对，就是那天是一个我们想要到的彼岸。但是我们人类会进步是因为我们一直在朝那天在努力，并不是说我们是可以从今天直接跳到那个争取。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:10",
      "text": "对我觉得这个过程可能是是更有意义的探究，就是AI的发展。然后把AI用到一个具体的事情。今天解决一个文本的生成，明天解决一个蛋白质？后天解决一个自动驾驶，我觉得这个可能是更有意义的对对，就是你我们所谓的万物互联，万物AI，它可能永远都不会达到。但是可能局部的一个功能级别的一个很好体验的一个AI，我觉得是很快的对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:46:41",
      "text": "是会有比较大的机会的这里面确实有已经开始，相当于这种基建已经开始说呈现出够用了。对，是够用了。那你关键是怎么把刚才这个人跟技术要做结合了。然后也是市场这里面包括这个东西的商业化，它其实整个环节融入，怎么融入这个社会，这件事情都是在。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:03",
      "text": "这基础设施蛮重要的那回过来讲，有人是说你们这种讲话是不是自我矛盾？刚才还在讲说AI只能干很傻逼的事情，傻逼又重复的是现在就开始讲说这个AI什么跟蛋白质自动驾驶有关，还是我觉得还是概念上没有讲清楚。对，我所谓说会AI会干更适合干这种复这种重复的傻逼的事情，特指的是AIGC r大语言模型。对，那实际上真的能够推动社会进步的一定不只有大禹模型，还有其他的更多的这种模型，视觉的各种各样的工业的一些模型。那就大语言本身可能是离我们普通人更近的一个AI了，或者说更近的一个AI的助理了吗？是的，那至少说从创业方向或者是说从提高效率角度，目前我个人会认为说大语言模型更适合做一些没有难度的重复性的工作。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:12",
      "text": "而且要尽量他能独立的完成。",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:14",
      "text": "基本独立的完。",
      "speaker": "发言人1"
    },
    {
      "time": "00:48:15",
      "text": "基本上能独立完成。",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:16",
      "text": "对你不要期待它的智能。对，我总结我举我们举几个例子。比如说你们公司总会有很多表哥表妹每天整的就是那三张表，对，那几十行数据，把这几张表整理成A老板喜欢的格式以及B老板喜欢的格式，然后再抄送给C老板，就干这样的事情。我觉得这样事情你就适合让AI去做。对对对，但他不适合说把你们公司最近一年的经营情况读出来，然后给你A老板一个经营决策。觉得这个事情你就不要想了，绝对千万别想。对我就别想了。对他可以给你进启发，就是他会有一些他这种发散的观点，突然间会给你一个启发，但是你不要期望他给你一个智能的决策。这个是我们作为从业者，我们觉得说AI目前AIGC目前的一个局限性。因为我们在聊这个nobo LM对会不会是啊下一个GPT，我觉得这个是个伪命题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:49:23",
      "text": "对我觉得是个伪命题，没有那么大的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:49:27",
      "text": "一个对颠覆的。就本身你从找场景来看，我觉得GPT也不能叫找到很好的场景，是他更多是找到了一个cheat的一个场景，我觉得已经算他成功了，在cheat之后就没了。对，那很多创业者就基于chat再去找别的场景，我觉得这个就很难的。对对对，因为就强如GPT，它背后它其实不是一个to c的公司，它是一个大模型公司，它也就只能找到一个to c的叫做chat的一个场景。我们何德何能对不对？我们何能能基于chat能找到更多的场景。对。所以我们从这么多的项目，或者聊了这么多的创业者，或者说这么多的经验，包括一些开发的经验下来，我们还是会觉得说，目前这个阶段可能AI干的事情还是会非常的初级。但我觉得也够了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:19",
      "text": "就挺好的。其实对，因为很越初级越好理解，你越能用得起来，就是这样。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:25",
      "text": "为什么最近我一直在夸豆包？而且最近豆包的访问量不是也一直在上涨值还是挺高的。就是我觉得他把这个AI干这种重复的初级的事情贯彻的非常彻底。对他没有什么特别强的智能在里面。我自己的应用就是我就是让他根据我的一段写的很烂的提示词，然后去帮我给孩子讲睡前故事，然后每天不重复。就这么几个主角发生在这么几个场地，用这么几个武器，对进行了几次正义的斗争。你每天给我讲三个不重复的这样的故事，他讲的非常好，讲得比我还好，绘声绘色。加上了豆包它的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:10",
      "text": "一个语音，那个语音包特别。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:12",
      "text": "做的还语音包又做得特别好。对我就觉得这个他是指我觉得豆包是一个很典型的一个我觉得就是AI干很傻逼的事情，能干的比人还好。对，就是这样一个东西。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:25",
      "text": "但是你说让他生成一个播客，我觉得这个难度太高了。对，至少说他生成的播客不是听播客的人会去听播客。是的，这个话有点绕。这就是他生成的播客，不是给人听的，你就这么理解好了。好，这期播客就到这里。好，谢谢大家的收听。",
      "speaker": "发言人1"
    },
    {
      "time": "00:51:47",
      "text": "好，谢谢大家，期待大家各种反馈和支持。好了，好，拜拜，那就这样拜拜。",
      "speaker": "发言人2"
    }
  ],
  "lab_info": {
    "summary": "两位AI从业者对当前技术的运用表达了悲观态度，认为AI多用于简单、重复任务，而非复杂智能工作，强调输出质量依赖于输入质量，垃圾输入必然导致垃圾输出。他们指出，AI理解力有限，无法进行深度思考与创造，存在技术局限性。在企业应用中，数据准备至关重要，技术局限与提高效率的挑战并存。尽管如此，AI在特定场景下能提升生产力，特别是在处理重复性工作方面。对AI的未来，他们持谨慎乐观态度，相信技术发展将逐步推进，但全面智能化社会的实现仍面临多重挑战。",
    "qa_pairs": [
      {
        "question": "AI技术实际理解力如何？",
        "answer": "AI技术的理解力并不像大家想象的那么好，例如将红楼梦、三国演义等喂入AI中，并不一定能产生类似郭德纲这样的创作人才。AI1.0阶段更多是精确型的应用，而现在的AIGC（AI生成内容）虽然不精确，但能胡编乱造、举一反三，展现智能的一面。",
        "time": "00:00:42"
      },
      {
        "question": "现阶段AI能用在较为智能的工作中吗？",
        "answer": "现阶段AI并不适合用于太智能的工作，更适合做重复性较强、输入输出较为简单的问题，比如垃圾处理。AI的效果很大程度上取决于输入的质量，如果输入是垃圾，输出也会是垃圾。",
        "time": "00:09:46"
      },
      {
        "question": "no book LM为何突然爆火？",
        "answer": "no book LM最近因为增加了音频对话生成能力，可以流畅地回答问题并形成高质量的播客形式，意外地受到了用户的热烈反响和关注，从而出圈。尽管它在学术研究中表现优秀，但在娱乐性和深度思考方面仍有局限性。",
        "time": "00:05:23"
      },
      {
        "question": "AI是否会在学术研究领域有所作为？",
        "answer": "谷歌推出的no book LM是一个专为学术研究设计的AI助手，能够快速整理和总结论文信息，尤其在学术研究领域表现出较好的效果，降低了研究者处理文献资料的难度，但仍然受限于特定领域，并非通用型产品。",
        "time": "00:03:25"
      },
      {
        "question": "AI是否会替代所有工作？",
        "answer": "目前来看，AI无法完全替代所有工作，特别是在需要深度思考和情感价值传递的工作领域，如播客行业。AI生成的内容可能具备吸引人的感情色彩，但缺乏真实深度的思维碰撞，长久听下来容易让人感到套路化，无法替代真正有价值的信息分享。",
        "time": "00:07:14"
      },
      {
        "question": "在AI agent训练过程中，数据清洗和准备环节是否存在较高的门槛，容易被低估其难度？",
        "answer": "是的，数据清洗和准备环节确实是高门槛，很多人在做知识库或AI应用时会碰到这个难题。即使在海外或国内的实际案例中，大家都会卡在这个环节上，因为这要求数据的质量和充足程度要足够高，才能让AI学习并产生有效的智能输出。如果样本量不足或者质量不高，AI可能会出现发散性的问题。",
        "time": "00:11:31"
      },
      {
        "question": "在AI agent搭建过程中，最大的坑是什么？",
        "answer": "最大的坑在于数据的准备和清洗阶段会出现巨大问题，这是很多人容易忽视的难点。客户往往会高估自身数据的质量和准备程度，以为只要拥有充足的数据就可以直接投入AI系统中，但实际上，这些数据可能并不足以支撑AI达到预期的效果。",
        "time": "00:19:39"
      },
      {
        "question": "AI在评判内容时的标准与人类评判有何不同？",
        "answer": "AI评判内容时的标准与人类评判不同，AI需要大量的样本去学习，而不仅仅是参考既有流程和标准。例如，如果用少量样本量去换取智能，当样本量不够时，AI会无法准确建模并可能出现发散情况。而人类评判则基于个人经验和知识积累，AI目前无法完全模拟人类复杂的情感和多样性表达。",
        "time": "00:13:13"
      },
      {
        "question": "AI能否生成高质量且有深度的博客内容？",
        "answer": "AI目前无法生成高质量且有深度的博客内容，因为高质量内容背后蕴含的人生阅历、工作经验等无法被AI所具备。AI只能根据现有数据进行脑补和模拟，无法真正理解和创造具有深度的思想对话。",
        "time": "00:14:00"
      },
      {
        "question": "AI模型的先进程度是否直接影响生成内容的质量？",
        "answer": "不是越先进越好的，关键在于输入的内容质量。如果输入的内容是垃圾，无论模型多么先进，输出的结果也只会是垃圾。AI在内容生成过程中只是一个工具，其输出的质量受限于输入数据的质量。",
        "time": "00:17:09"
      },
      {
        "question": "AI项目实施过程中，两端存在的主要问题是什么？",
        "answer": "主要问题是两端都可能过于高估自身和AI技术的能力。用户以为自己有标准、数据和SOP，但实际上可能没有提供给AI正确或高质量的格式数据；而谷歌等顶级开发者开发的AI产品也存在局限性，无法做到完美。",
        "time": "00:22:45"
      },
      {
        "question": "在AI项目中，为什么调试会变得非常困难？",
        "answer": "调试难不仅因为获取高质量的数据很困难，还在于评估数据结果好坏的标准不统一。每个公司、每个人对于数据质量的认知不同，而在AI中，即使是微小的垃圾数据也可能被机器学习进去，导致调试过程中需要找出并处理这些错误信息。",
        "time": "00:24:34"
      },
      {
        "question": "AI在实际应用中的表现为何并不总是令人满意？",
        "answer": "AI表现不理想的原因包括数据质量不均、数据清洗工作繁重以及人与机器交互过程中的磨合问题。AI并非能自动变废为宝，它需要干净、精准的数据输入才能发挥效能。",
        "time": "00:26:07"
      },
      {
        "question": "AI能否解决企业粗放管理下的数据缺乏和信息化不足的问题？",
        "answer": "对于许多中国企业来说，由于基础信息化建设和数据积累不足，直接过渡到AI应用非常困难。AI更适用于那些目标明确、只需提高工作效率的场景，而非帮助企业梳理混乱业务逻辑或填补信息空白。",
        "time": "00:27:41"
      },
      {
        "question": "语言差异是否也影响了企业向AI提需求的过程？",
        "answer": "是的，语言差异确实会造成障碍。无论是中文还是英文，日常沟通的语言往往不够精确和逻辑性强，而AI更理解的是类似代码的精确、逻辑性强的语言结构。大部分企业和个人难以做到用这种“伪代码”方式与AI交流，这也是语言障碍导致“脏数据”的一个重要来源。",
        "time": "00:30:11"
      },
      {
        "question": "在企业应用AI时，为什么有大量的人会卡在前两步，最终能成功应用AI的寥寥无几？",
        "answer": "这是因为前两步非常具有挑战性。第一步是将人类的需求用计算机能够理解的语言清晰描述出来，这一步就筛掉了约90%的人；第二步是AI根据这些描述去构建模型，如果两端都不够好，即需求描述不清和AI智能不足，那么大部分情况下都会导致失败。",
        "time": "00:32:50"
      },
      {
        "question": "那么第三个步骤——human debug（人工调试）的情况如何呢？",
        "answer": "第三个步骤极其枯燥且要求很高。如果前两步没有做好，往往需要重新来做。AI构建的模型即便较为智能，但如果人类调试过程中发现大量问题，仍需反复重复调试工作。",
        "time": "00:33:36"
      },
      {
        "question": "那么AI目前适合应用于什么样的场景？",
        "answer": "现阶段AI并不适合做太智能的事情，更适合用来解决一些重复性高、容错率较高、较为“傻瓜式”的任务。例如，可以利用AI将有价值的观点以某种固定、套路化的语气串联起来，但它难以实现像郭德纲那样的创作水平，也无法完全理解和创造深层次的隐性知识。",
        "time": "00:36:12"
      },
      {
        "question": "对于AI技术的未来发展，你们持什么样的看法？",
        "answer": "我们对AI的未来持乐观态度，但认为其不会迅速变得完美，而是一个逐步的过程，涉及数据准备、技术积累以及人类隐性知识的融入。AI目前阶段可能更适合作为一种工具或粘合剂，帮助整理和传达信息，但要达到理想中的智能程度还有很长的路要走。",
        "time": "00:42:00"
      },
      {
        "question": "为什么有人形机器人在设计上存在有脚和无脚的争论？",
        "answer": "这主要围绕一个观点，即机器人是否应模仿人类形态。一派认为，由于人类基础设施大多基于双脚设计，因此人形机器人应该配备双脚；而另一派则认为，从成本和实用性角度考虑，四足或有轮子的机器人设计可能更为合理和高效。",
        "time": "00:43:13"
      },
      {
        "question": "AI发展的现状如何，是否能迅速实现全面的自动化社会？",
        "answer": "目前AI还处于发展阶段，虽然局部功能级别的AI应用已经取得较大进展，但要实现万物互联、全AI自动化的社会还较远，更可能的是长期处于社会主义初级阶段，并通过不断努力逐步实现部分智能化场景。",
        "time": "00:45:00"
      },
      {
        "question": "AI能否帮助突破现有的基建难题并构建更好的社会结构？",
        "answer": "是的，有人提出AI发展到一定程度后，能够帮助我们设计出更适合人与AI共存的新基建，这与共产主义理念中的物质文明高度发达、生产效率极大提高的社会理想相似。",
        "time": "00:44:39"
      },
      {
        "question": "AI适合处理哪些类型的工作？",
        "answer": "大语言模型等AI技术更适合执行重复性、基础性的任务，如整理表格数据等，但不适合做需要深度思考和智能决策的复杂工作。例如，虽然AI可以提供经营情况的分析和启发，但它不能完全替代人类进行战略决策。",
        "time": "00:47:03"
      },
      {
        "question": "AI能取代人类进行某些初级工作吗？",
        "answer": "可以，有些AI项目能够很好地完成一些初级且重复的工作，并且由于其易于理解和使用，这样的AI工具对于提高效率和满足特定需求具有较大价值。例如，豆包AI通过简单的提示词生成不重复的睡前故事，就表现得相当出色，能在一定程度上替代人工劳动。",
        "time": "00:50:25"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "AI技术的现状与应用局限性",
        "summary": "现阶段AI技术不适合执行过于复杂的智能任务，更适合处理重复性高、内容简单的工作。AI的输出质量直接取决于输入质量，技术上仍存在理解力限制，导致即使输入大量知识，也难以产生预期的创造性成果。大多数中国企业目前可能不具备使用AI的条件。目前的AI技术主要集中在精确型AI和能够生成具有一定创造性内容的AIGC上，后者虽然能够展示出一定的智能，但往往不精确。AI技术的发展面临着人类社会数据基础、组织形式等多方面的限制，这导致了AI无法支撑起一个全自动化社会的想象。"
      },
      {
        "time": "00:02:31",
        "title": "探讨NoBook LM应用及其对播客行业的影响",
        "summary": "近期，NoBook LM应用因其能生成高质量的播客内容而引起广泛关注，被部分观点认为可能达到GPT级别的影响力。该应用最初由谷歌推出，旨在辅助学术研究，通过AI技术帮助用户快速总结和抽离论文信息。不同于通用的AI助手，NoBook LM专注于学术研究领域，能够基于用户提供的文档素材进行精准的学术提问回答，减少了信息幻觉的产生。应用加入输出音频功能后，其生成播客内容的能力意外受到追捧，引发对AI是否将替代人类播客制作的讨论。对话中，两位播客从业者兼AI领域的专家就NoBook LM的应用、其对播客行业的影响以及AI技术的未来发展进行了深入探讨，旨在为行业内外提供清晰的见解和理解。"
      },
      {
        "time": "00:07:14",
        "title": "播客与AI技术的局限性及内容质量探讨",
        "summary": "讨论强调了有价值的播客应包含深度思维的碰撞，而当前AI技术由于缺乏深度思考能力，无法完全替代人类创作。AI生成的内容虽然能提升生产效率，减少繁琐工作，但输入质量直接决定输出质量，存在“垃圾进垃圾出”的问题。特别是对于需要专业知识和高质量内容的领域，AI的应用效果有限，仍需人类的精心准备和调整。同时，也提到了在与AI交互时，人们可能低估了准备高质量数据的难度，以及AI对数据的要求远超人类的直观感受。"
      },
      {
        "time": "00:14:00",
        "title": "探讨AI生成高质量博客的局限性",
        "summary": "对话指出，尽管AI在模仿人类语言方面取得进展，但它难以生成具有深度和情感复杂性的内容，如高质量的博客。这是因为AI缺乏人类丰富的人生阅历和情感体验，导致其输出的内容可能在技术上专业，但在情感多样性和深刻见解方面存在局限。AI更适合执行如讲故事、播报新闻等重复性和特定范围的任务，而非创造有深刻思想的复杂内容。"
      },
      {
        "time": "00:16:37",
        "title": "AI模型的质量取决于输入数据的质量",
        "summary": "在讨论AI模型开发和应用的过程中，明确指出追求更先进的模型并非始终是最佳选择。强调了输入数据的质量对于AI输出结果的影响，即低质量的输入会导致低质量的输出，即使使用最先进的模型也无济于事。此外，讨论了在没有足够的知识范围能力下，AI尝试通过发散和脑补来产生内容，往往会导致输出结果与预期相差甚远。还提及了在开发agent builder工具时，团队选择了专注于文本处理而非音频输出，认为文本理解是产出高质量AI内容的基础。"
      },
      {
        "time": "00:19:37",
        "title": "AI项目中的数据准备与清洗挑战",
        "summary": "在执行AI项目时，人们常遇到的第一个重大挑战是数据的准备和清洗，这是一个很多人未意识到的问题，直到深入项目后才会发现。许多项目参与者高估了自己拥有的数据质量和数量，同时也高估了AI技术的能力。即便像谷歌这样的顶级开发者，其技术也无法完全满足需求，存在诸多不足。此外，许多用户误以为拥有标准的数据和操作程序，实际上却未能提供符合AI需求的格式或质量。这导致在项目后期需要进行大量调试和人工标注工作，暴露出公司内部的许多问题，让人感到沮丧和对项目的怀疑。"
      },
      {
        "time": "00:23:42",
        "title": "探讨AI应用的挑战与现实困境",
        "summary": "在探讨AI应用的过程中，存在三大挑战：人类如何准确描述需求、AI的构建能力、以及后续的调试与修正。这些步骤看似简单，实则充满困难，特别是对于企业应用而言，前两步就已经筛选掉大量不切实际的项目。即便到了调试阶段，如果前期工作不足，几乎需要从头开始。此外，高期望值可能导致最终应用仅为满足伪需求，因此，现阶段AI更适合处理重复性任务而非高度智能的活动。对未来AI的乐观态度需谨慎，其发展是一个渐进过程，目前的技术在理解力等方面仍有局限，难以达到人类的期待。尽管国外对AI的商业化应用持开放态度，但国内更倾向于寻找实际应用，表明了在AI发展和应用上存在文化与实践的差异。"
      },
      {
        "time": "00:41:33",
        "title": "探讨人工智能的现状与未来发展",
        "summary": "讨论者认为，人工智能(AI)目前更多地体现在功能级别而非应用级别，以特斯拉的FSD(自动辅助驾驶)为例，AI被看作是提升效率或体验的工具，而非颠覆性的产品。他们指出，将AI看作是解决具体问题的工具更为实际，如蛋白质研究加速和自动驾驶等，而全AI自动化社会目前仍受人类社会基础的限制。此外，他们也提到了AI在帮助突破人类基建限制的潜力以及对共产主义理想社会的类似展望，但强调了实现这一理想的过程比结果更有意义。最后，他们提到当前的AI发展已经呈现出在特定功能领域应用的可能，强调了AI技术与市场、社会融合的重要性。"
      },
      {
        "time": "00:47:03",
        "title": "探讨AI技术的应用及局限性",
        "summary": "对话主要围绕AI技术，特别是大语言模型的应用和局限性展开讨论。一方面，AI在处理重复性和低级任务方面展现出巨大潜力，如数据整理和格式调整，这些任务对AI来说较为简单且能有效提高效率。另一方面，尽管AI能够在某些领域提供启发性的观点，但不应期望它做出智能决策，特别是在需要深入理解复杂情况和做出综合判断的领域。讨论也触及了当前AI技术，如GPT，虽然在某些方面取得成功，但其应用范围和能力仍有限，特别是在内容生成方面，如播客内容的生成，对AI来说仍是一个挑战。此外，对话中还提到了一些具体的AI应用例子，如豆包，用于生成儿童故事，展现了AI在处理简单、重复性任务方面的优势。总体上，讨论认为虽然当前AI技术在很多方面仍处于初级阶段，但其在提升工作效率和执行简单任务方面具有明显的优势和价值。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "输入质量决定输出质量"
                },
                {
                  "children": [],
                  "content": "技术理解力有限"
                },
                {
                  "children": [],
                  "content": "“Garbage in, garbage out”问题"
                }
              ],
              "content": "限制与挑战"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "适合处理重复性任务"
                },
                {
                  "children": [],
                  "content": "在特定领域内辅助决策和内容生成"
                }
              ],
              "content": "应用领域"
            }
          ],
          "content": "AI技术现状"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "功能：学术研究辅助，论文信息整理与总结"
                },
                {
                  "children": [],
                  "content": "限制：不适用于复杂内容生成，如播客"
                }
              ],
              "content": "no book LM"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "挑战：无法生成具有深度思维碰撞的播客内容"
                },
                {
                  "children": [],
                  "content": "应用限制：适用于生成简单播报内容"
                }
              ],
              "content": "AI播客"
            }
          ],
          "content": "AI应用实例"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "AI作为功能级别辅助，而非完全替代人类决策"
                },
                {
                  "children": [],
                  "content": "社会基础设施与组织形式需要适应AI技术的发展"
                }
              ],
              "content": "长期视角"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "侧重于解决具体问题，如文本生成、蛋白质研究、自动驾驶等"
                },
                {
                  "children": [],
                  "content": "实际应用场景受限于技术理解和数据质量"
                }
              ],
              "content": "短期应用"
            }
          ],
          "content": "AI技术展望"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "数据质量直接影响AI模型的性能和应用效果"
                }
              ],
              "content": "数据清洗和准备"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "过高估计AI技术的能力和应用范围"
                },
                {
                  "children": [],
                  "content": "忽视了AI技术应用的实际限制和挑战"
                }
              ],
              "content": "技术理解的误区"
            }
          ],
          "content": "数据质量与技术理解"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "需要明确AI技术应用的范围和限制"
                },
                {
                  "children": [],
                  "content": "AI在企业中的应用需基于现有业务流程和技术基础"
                }
              ],
              "content": "企业应用"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "AI技术的应用受限于人类社会的基础设施和组织形式"
                },
                {
                  "children": [],
                  "content": "AI技术的普及和应用需要逐步适应社会基础的变化"
                }
              ],
              "content": "社会基础"
            }
          ],
          "content": "社会与企业应用"
        }
      ],
      "content": "AI技术及其应用讨论脑图摘要"
    }
  }
}