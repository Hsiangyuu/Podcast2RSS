{
  "pid": "60502e253c92d4f62c2a9577",
  "eid": "676d50f415a5fd520ed21e98",
  "title": "OpenAI 史无前例的发布会：连续 12 天发布内容全解析",
  "task_id": "p7g395y8mlxdqz65",
  "transcription": [
    {
      "time": "00:00:02",
      "text": "欢迎收听十字路口，我们关注新一代AI技术浪潮带来的行业新变化和创业新机会。十字路口是乔布斯对苹果公司的一个比喻，形容他站在科技与人文的十字路口，伟大的产品往往诞生在这里。AI正在给各行各业带来改变。我们寻找、访谈和凝聚AI时代的积极行动者，和他们一起探索和拥抱新变化、新的可能性。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:31",
      "text": "我是主播科技杨元成，联合创办了街旁新石像和唐岛。我相信科技尤其是AI会在未来十年彻底改变社会，赋能人类。欢迎大家找我聊天，碰撞想法，链接下一个可能性。我是主播戎慧，目前在一家专注科技投资的风险投资机构工作前在第一财经周刊担任驻硅谷记者。",
      "speaker": "发言人1"
    },
    {
      "time": "00:00:58",
      "text": "本周的十字路口，我们一起来回顾OpenAI连续12天的发布会，到底都发布了哪些新的东西。除了让全世界都惊叹的在最后一天发布的O3之外，还有哪些同样值得关注的新功能、新技术或者新看点。OpenAI和萨姆奥特曼堪称是营销天才，我印象中好像也是第一次有科技公司把发布会一开开个12天的这让我想起这个transformer的注意力机制。这12天的发布会也可以堪称是attention is all you need的一个绝妙实践。持续12天的发布会的轰炸，不仅垄断了科技媒体的头条，更让整个行业的目光都聚焦在他们的身上。所以这波营销可以说将注意力经济是玩到了极致。",
      "speaker": "发言人1"
    },
    {
      "time": "00:01:41",
      "text": "本周十字路口邀请到两位朋友，归藏藏师傅和大聪明与我们一起来回顾与讨论。这12天到底发布了一些什么好东西？归藏是AIGC weekly这一个news letter的主理人。这是全中文的互联网。我认为这个最最就有两个最最最值得订阅的AI资讯周刊。我追更了快两年，几乎是每个周末的必修课，获益良多。而大聪明的是赛博澶星公众号的主理人也是第二次来做客十字路口了。在我的朋友圈里面，他们二位都是持续12天一直在追更发布会。",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:18",
      "text": "我每天早上醒来第一件事就是看赛博财经的公众号和归藏藏师傅的极客。他们都是信息的速度和质量的双重保障。我们在本周播客的show note里面先整理了这12天OpenAI逐日发布的具体内容，方便大家一边听播客一边做参考。好，我们开场的第一个问题想问二位，你们认为在这12天的发布会里面最值得关注的一个重点是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:02:42",
      "text": "大家好，我是大聪明。这个问题就是我先来呗。这面最值得关注的一个重点，在我看来可能不是一个重点，可能是两个。第一个是毫无疑问O3的发布，它带来了一个完全的遥遥领先的模型，虽然它很贵，回答一个问题可能需要3500美金，这个值是我拿尺子量出来的。第二个的话是它在发布期间隐藏了一个细节。在第九天左右的时候提到了一个开发者的更新。这里面不更新既包括了是real time的API的更新，也包括了是对构语言的知识。但这里最核心的是它允许了在OE以及在real time的时候进行结构化输出。这对明年的AI的agent的爆发埋预埋下了无预埋下了伏笔。这里这两点是我认为非常重要的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:03:41",
      "text": "OK好，我们待会儿可以展开聊一聊这两点。O3的发布和在第九天针对开发者发的一系列的EPI。张师傅在你看来最值得关注的一个重点是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:03:53",
      "text": "我是规则，然后我觉得也是欧森这个是肯定是毫无疑问的。他因为他其实说实话，我们最近对大家对他的指望是他是一直在引领整个的行业的方向。虽然他有些地方不是做的最好的，但是他一定会把在行业达到困境的时候，给出一个新的路径。最近前段时间不是一直说预训练到头了吗？那可能在O3上我就看到的这个结果，就OE还没有那么明显，就没有那么让人坚信这个推理的进化的方向。但是在O3上我们看到了很明显的一个进步和进展。我觉得对整个行业的信心和整个比如说投资或者一些其他的东西的信心的提振是非常大的对这个还是挺重要的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:04:45",
      "text": "可不可以用什么样的方式让大家感受一下O3到底有多强？",
      "speaker": "发言人1"
    },
    {
      "time": "00:04:49",
      "text": "一个最直接的一个说法就是有一个程序员的一个大神榜。在那个叫做code forces，它是一个比例更硬核的一个编程的，算是技能展示或者是竞技平台。很多的非常优秀的程序员都会在里面玩一玩。比如是OpenAI现任的首席科学家，他在这个court forces里面，它的得分是2655分。而这一次的O3它的编程得分是2727分，就是超过OPPO I的手机科学家一大截。如果放在现行的榜单里面，能够排到人类的第175名，这还是非常离谱的一件事情。",
      "speaker": "发言人2"
    },
    {
      "time": "00:05:38",
      "text": "这个O三还有一个惊人的数字是啊他每做一个单任务大概就需要3500美金，等于是2万人民币。然后我看到大聪明也有写公众号说你去问O31个问题，9.09和9.11到底谁是更大的数字？那这个问题下去，2万人民币就没了。对这是不是也背后说明这里面还是可以在大力继续出奇迹的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:06:01",
      "text": "这里其实有一个小的细节，O3在比照O1的时候，O3它有两个版本，一个叫做低低算力版本，它计算一次的任务量大概需要20美金，可能未来我们用的可能是这个版本。它还有一个高计算量版本，其实也是更详细的模式。它的计算量是低计算量的，大概是170多倍，然后算下来的话，就是3500美金，大概是有1000倍的一个增幅，大概3.5.5 3.5美金到3500美金，1000倍的一个增幅。",
      "speaker": "发言人2"
    },
    {
      "time": "00:06:44",
      "text": "所以其实他那个低计算量模式的话，我看他那个arc测试集，他那个低计算量模式75%点几的结果的话，它是20美金。其实这样算的话就还好。",
      "speaker": "发言人3"
    },
    {
      "time": "00:06:58",
      "text": "我看到那个up的表单，这时候你会发一个很有趣的事情。正确率的百分比和消耗算力的指数是呈线性关系的。我们可以拉出一条直线，近乎的直线就是我计算量每就是翻每增加十倍，我们的这一个准确度可能会增加个百分之多少？",
      "speaker": "发言人2"
    },
    {
      "time": "00:07:26",
      "text": "20% 10%到20之间。",
      "speaker": "发言人1"
    },
    {
      "time": "00:07:29",
      "text": "这件事情就预示着假如说我们要到达100%，在这个表单里面到达100%，我们的这个算力成本是天价的，这还不算完，在他的一个新的表单里面，我们现在看到的是O3的高计算量模式，能够达到88%的计算率。但是在第二版的阿克榜单里面，它的正确率就只有30%了，还会再被压缩。如果我们即便是按照up的这一个测试集，实现up版本的AGI，我们当前的计算成本可能都是在百万美金以上了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:08:10",
      "text": "我也看到张师傅有在即刻上发一条很长的内容，就是在讲说O三带给你的一些感受。然后你还提到一个非常强的说法，你说可能在未来几年，我们会像记住ChatGPT的发布时间一样，记住昨天晚上的这个O3发布的时刻。是什么原因让你对O3的发布这么的兴奋，认为它是里程碑一样的事件。",
      "speaker": "发言人1"
    },
    {
      "time": "00:08:33",
      "text": "其实这些是整理的一些大佬们的说法，就是说陶哲轩说这个技术人本来是能顶住单元模型可能好几年的，但现在一下给他拉到了25%的成功率，包括刚才说的那些程序员竞技的榜单，对吧？那这个其实代表了非常令人憧憬的一个未来。O1到O3只用了三个月，他就达到这样一个进步。如果说这个缩放定律继续的话，明年上半年我们会不会有O4O5？如果OSO放出来的时候，在我们就不说其他领域，就只说在数据和代码这两个领域，人类是不是就彻底无法追上他了？说代码其实是我们构建整个软件世界的一个基石，所以这个其实它会带来非常大的变化。",
      "speaker": "发言人3"
    },
    {
      "time": "00:09:18",
      "text": "我补充一个信息，关于AGI的就是上一次参加open的线下活动，当时的mark的一个分享。就是这一次我们O3发布的时候，就是开局的时候就是mark和山姆奥特曼一块分享的。Mark当时说了一个有趣的观点是我们什么时候到达A加，取决于对于我们对AGI的定义。然后很快的话我们会到达我们所定的AGI，而那时候我们会对AGI再有一个新的定义，然后不断的追赶OpenAI。他选取了up作为AGI的这么一个评测的合作伙伴，up提到了一个主流的关于A加的表述，能把大部分有价值的经济工作进行自动化的系统。我们看到如果以这个为标准，我们可以认为O三已经近乎的达到了AGI。但很快随着我们把这个事情达到了AGI，我们会有更高更新的标准。",
      "speaker": "发言人2"
    },
    {
      "time": "00:10:18",
      "text": "这个很有趣，就是去定义AGI到底是一个什么样的定义，对吧？之前其实大家一直没有达成过共识。那在arc的定义里面就是说真正的智能是在现在是做有经济价值的工作。也依旧意味着他去安慰你的情感，或者他去共情你的这种感受，这不再是AI的定义里面。",
      "speaker": "发言人1"
    },
    {
      "time": "00:10:39",
      "text": "然后于是的话就给出了一个新的一个定义，就是需要说一个AGI它并不是指的你有多少技能，因为技能是可以通过训练而获得的，而是你有多会学习。一个婴儿我们天生的认为他是AGI，如果是按照我们最朴实的想法，但是他什么技能都不会，他既不会编程，更不用说是编程。到达了人类的175名。但是他很会学习，他可以从零的掌握语言，他可以去用筷子，他可以去给你哇哇大哭，他很会学习。那么我们对于A加的定义是不是要从有多少技能变成他能够在之后自主的学会多少东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:11:26",
      "text": "我们聊了最值得关注的O3之后，我们来过一下，就这12天到底发布了什么。我们先快速的过一过，然后我们再来每一天稍微展开一下，和大家聊一聊。第一天是满血版的O一上线。这一天同时还有一个当时大家都争议非常大的，就ChatGPT发了一个pro的会员。这个会员要卖200到1年，就有一个很大胆的定价。然后同时在第一天还发了OM pro，到第二天是发了一个强化微调RFT，然后第三天是正式版的sora终于发了。然后第四天是发了一个campus的功能，这个对标的是cloud的artifacts，这个更是一个交互上的变化。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:08",
      "text": "然后到了第五天，第五天很水，他几乎是一个给苹果站台的PR，只是在宣布苹果全系接入了GPT。到第六天就是临近圣诞节，发了4O的实时视频通话和视频理解。可以理解这个实时的视频流，也可以理解你分享过去的屏幕。同时根据视频流和屏幕的内容来去实时的问答。然后同时因为圣诞节快到了，你可以给圣诞老人打电话。然后到了第七天发布了一个叫项目的功能，这个其实也是cloud早就有的projects的功能。",
      "speaker": "发言人1"
    },
    {
      "time": "00:12:43",
      "text": "然后第八天是ChatGPT的搜索全量的开放，甚至开放给了免费的用户。这里面也做了很多的细节体验的优化。比如说可以在浏览器的地址栏里面直接搜，也可以搜出视频。然后同时也把这个FO的实时语音接入了搜索。然后到了第九天，是发了o one的API，然后这里面是一系列给开发者用的API。然后待会儿我们邀请大聪明给大家展开讲讲，因为这是他认为和O3同1样同等值得关注的主要发布。然后到第十天是一个也有点小的一个有一点水的一个发布。就是你可以物理意义给HIGP打电话，而且他还做了一个WhatsApp的一个聊天机器人，你可以在WhatsApp上和他聊天。",
      "speaker": "发言人1"
    },
    {
      "time": "00:13:30",
      "text": "然后到第11天，其实是他们之前就发布的东西，然后再拿出来讲了一遍，就是ChatGPT的桌面版，就是它的桌面客户端的版本，可以读到别的应用上的内容。这样你就不用老去比如说给正在写的代码截个图，然后丢给ChatGPT。而是可以直接让它就看看我的屏幕上在干嘛，然后直接提问，直接回答。然后这里是可以支持掉OY模型，也可以支持用FO的实时语音功能来对话。然后12天就是我们刚才聊到的这个王炸，他发了一个O3，这个是让全行业震惊的一个发布。我们现在再回来，从第一天开始，我们还记得第一天发布的时候，其实很多人是很期待的。我相信张师傅和大聪明，你们当时应该也熬夜看了发布会。然后可不可以讲一讲当时看到o one pro和这个x GPT pro 200刀的会员的时候。",
      "speaker": "发言人1"
    },
    {
      "time": "00:14:23",
      "text": "你们有哪些感受？我最大的感受一他疯了吗？二百刀这已经远超出大家的正常的支付习惯了，真的会有大冤种去买吗？我买了，然后的话用了这么一个OE pro，然后发现真香。我经常会和那个AI或者说ChatGPT1块儿去思考一些东西。比如说是项目怎么做，事情怎么规划，然后我再和4O说的时候，基本上他就是一个我给他说一个东西，他就会顺着我的话把我东西补全，有时候补还乱七八糟的，我要给他纠正很多次。但是我是用的这个O1 pro的时候，他能他经常在一次对话中把我所需要做的事儿拆分的非常清楚。这样的话就能够省了我一小时的反复的给他修订时间，这个时间让我觉得太香了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:15:22",
      "text": "太值了。我看到还有一个说法就是200到这个pro会员之所以值，是因为它有点像是一个无线和你可以对话的，7乘24小时随时在线的her就之前那个科幻电影，因为你可以实时的开始无限的和FO的实时语音对话了。然后张师傅当时看到第一天的发布会之后，有去试用吗？有一些什么样的感受？",
      "speaker": "发言人1"
    },
    {
      "time": "00:15:46",
      "text": "第一天其实我没有买这样买的。会对，当时我觉得确实是苑孔才会买。然后那个OE pro当时看他们那个测试，因为他们用的是很多推理的方式，那可能我或者是普通用户，这我觉得这也是他们宣发的一个问题，就是他们用的一些案例。当然你要去测试智能，你用推理，你去做数学、做物理是可以的。但是你需要穿插一些说可能真正的普通用户会用到的一些案例，就是来体验他有多强。他们缺失了这个功能，导致我的感知是好，你的物理和数学很强。好，对我没有用，因为我并不知道他对于真正的开放域的智能，他到底有多少提升。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:26",
      "text": "对，但是后来是因为编种骚扰我是因为骚扰那是我这是专业正苑种，我用sorry开的，开了以后去用了一下图。我发现他对于开放域的一些问题，就刚才大聪明说的，我去讨论一些问题的时候，会给出很全面而且很新颖的观点和很具结构性的一个问题回答。所以这个确实是挺值。",
      "speaker": "发言人3"
    },
    {
      "time": "00:16:48",
      "text": "可以讲一个具体的例子吗？就是你用O1 pro做了什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:16:52",
      "text": "我昨天第一次试，我就想突然写想写一个我跟AI的一个一年的总结。因为我我想说的事情特别多，然后我就想让他给出一个大纲，或者给出一些我可以写的方向。他给出了很值得参考的方向，就是我们知道我们写东西的时候会有个问题，就是你去找搜或者cloud。他会就是刚才大聪明说的，他说一些你说过的事情，或者是很显而易见的事情，或者跟你本身的职业，或者跟你的路径完全无关的事情。但是O1 pro不会，O1 pro真的给出了非常有建设性的意见，就是你完全可以按照它这个大纲去一步把它写完。对，这个很厉害。但这个是很感性的一个结果，是你不能通过这样去描述它真的很厉害。你只能通过你自己看到他的时候，你就觉得这个是你要的东西。",
      "speaker": "发言人3"
    },
    {
      "time": "00:17:40",
      "text": "这里我再补充一个信息，刚才提到了如果你是他的pro会员，你是可以无限的使用它的高级语音模式的。然后高级语音模式如果你用API的第二种方式，平均每小时的消耗是50美金。假如说你特别喜欢和AI聊天，你只要跟他聊够了4个小时，这两百刀你就赚回来了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:18:04",
      "text": "说实话我真的和FO聊会有一种和真人聊的感觉。",
      "speaker": "发言人1"
    },
    {
      "time": "00:18:09",
      "text": "所问的问题我觉得就是一个是它响应确实还是不够快，而且就是贵。然后我手机一开的时候，我手机就会巨烫，可能是他这个实现方式有问题。这个就说回来谷歌那个Jimmy的面的那个，我就完全没有这个负担，就是我我跟我跟风流的时候会有负担，一个它很贵，一个是他看起来很做的很重。但是我跟这边聊的时候就没有这个负担。虽然这个人现在只会说英语，但是我就很很随便的聊，而且他那个响应比比我们还要快很多。对，可能是模型小。对，这个也是我用用那个我我用我们真的觉得我他很强的一个地方。",
      "speaker": "发言人3"
    },
    {
      "time": "00:18:49",
      "text": "其实这一次就在这12天期间杰班长也发了2.0，然后他受到的PR的关注肯定是不如OpenAI，但是我感觉他的口碑是非常好的。我们其实待会儿也会和大家再讲一讲我们几个人用GM的2.0的一些体验。好，那我们到第二天，第二天发布的是基于o one的一个强化微调，叫RFT。这个可不可以请你们来给大家介绍一下，RFT是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "00:19:17",
      "text": "一个AI比如说是GPT4O你希望他每次说话的时候非常的简明精炼，但他自己不行吗？你就要对他进行一个微调，是给他非常多的一个样本，让他在之前的基础上进行学习。OE其实它本身并不能够完全的归入我们传统的大模型范畴，它其实是一个大模型结合agent的一个聚合物。只不过他把agent这一块做到大模型里面，他会自主的反思。那么对于传统意义上的这个微调就不再支持了。如果我希望这个OE它的生产，它的输出有一定倾向性，无论是思考的方式还是输出的样式，一定的倾向性就需要再进对它进行微调。于是就有一了一个对于o one的一个微调方式RFT。它其实就是原来的FT的一个变种，一个微调的变种。它是什么目标对象？从原来的大模型变成了O一这一周agent形式的大模型。",
      "speaker": "发言人2"
    },
    {
      "time": "00:20:28",
      "text": "明白，所以这一个发布其实当天也是没有引起特别多的关注。是因为其实它带给这个C端用户的体验不是那么直接。",
      "speaker": "发言人1"
    },
    {
      "time": "00:20:39",
      "text": "不仅是对C端用户不直接，哪怕是对B端或者是开发者端。因为O01太贵了，就是正常情况下不会把它放到模型成本打过来是而微调的成本还是会比直接使用OY还要再加上一层。所以说做项目的时候暂时还是不会去考虑的，对于绝大多数的这一个项目来说，但另外一个层面我们知道模型会不断的降价，然后如果它的成本降到一个比较亲民的时候，同时你还有类似的需求，我相信有不少的开发者也会对他进行维好的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:21:21",
      "text": "OK, 这是第二天。然后到了第三天，第三天是在发布会开前面的倒数12个小时，就已经开始有谣言满天飞，说今天晚上要正式的发sora。所以那天也是蛮多人熬夜在看的，然后sora是发了，但是发出来之后，就好像毁誉参半，甚至慢慢的对他的吐槽还越来越多。然后可不可以请张师傅专门说一下，因为你刚才有提到一开始发这个o one的时候，就满血版o one和o one pro的时候，你是没有充200到会员的。但是sora让你充了会员，可不可以讲一讲你充会员之后用它的一些体验。",
      "speaker": "发言人1"
    },
    {
      "time": "00:22:00",
      "text": "它是这样的，它如果你是plus 20美元用户的话，你只能生成最高720P的视频。而且的话你只能生成十几个，就是十几个就结束了。如果你要拿它做片子，你必须要充200美元，所以就买了。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:15",
      "text": "买了以后，试了一下它的它有两方面的，一个是它的功能还是挺精细的。比如说在故事版，这个就是它的故事版就是你可以去连续的输多个视频，然后他会用一些转场做，可能是首尾帧，可能其他方式做，把这个视频连起来做成帮你做成一个一整段完整的视频。这个其实是在交互上和在功能性上其实做的非常好的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:22:41",
      "text": "对接下来我们要说的模型，模型本身的话，我们就说看一个模型的底子。你是看那个纹身视频，我们是视频的话，它的整个的质量好的会很好，但是好的很有限。它可能比现在最好的视频模型好个零点几这个程度。对，就是他他达到了一流水准。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:01",
      "text": "然后视频模型训练和单元模型的训练其实一样的，它也是需要先有个纹身视频的模型，然后再基于图去做图像视频的微调。那么在图片视频上你发现它的微调是完全不足的，它可能是一个很仓促的结果。对，就是他但凡说好好训了，他就不会成那样。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:21",
      "text": "就是图片视频起码我们要的要求是你可以动，对吧？我不管你动的好还是动的坏，你可以动。但是骚二图像视频90%，你伸进去一张图，输出的就是一张图。对你花了可能是几块钱的积分，把它从一张图等了几分钟变成另一半，变成了一张图。对，这个是很恼火的。我觉得这个是非常恶劣的一种商业行为。",
      "speaker": "发言人3"
    },
    {
      "time": "00:23:49",
      "text": "对，就是他是诈骗。对他不是说你服务的好不好或者模型的好坏，这是诈骗。就这功能你宣传的完全不可用。对，然后你卖的又那么贵。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:00",
      "text": "这是一个非常严重的批评。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:02",
      "text": "对，这是一个诚信问题。就是你你用这个诱导我去开发一个1500人民币的一个月的会员，然后这个功能其实是完全不可用的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:24:12",
      "text": "大聪明，你有什么想要补充的吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:15",
      "text": "我因为我本身不是专业的视频作者，但这个里面对我来讲这个无限循环以及这个故事版功能对我来讲还是蛮惊喜的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:24:26",
      "text": "说到sora这一次发布，我觉得还有一个值得注意的细节，就是前几天我们和Monica的方的小红录播课的时候，他提到这一次sora是没有发API的这是OpenAI历史上少有的一个情况。这其实背后有说明，就是在今年做应用，对OpenAI来讲也变得好像更重要了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:24:46",
      "text": "对我觉得核心还是要拿数据。一个是拿数据，一个其中一个是占住这个人们的认知。所以这对于我本来或者其他公司来说，作为应用一直是最重要的，因为我们都都知道这个东西，就你发API你卖token是没有壁垒或者是没有无法规模效应的。你一定要做成产品。所以用一些功能把用户留在这儿去，把扩大用户规模，让他离不开你这个产品才行。",
      "speaker": "发言人3"
    },
    {
      "time": "00:25:15",
      "text": "说到我们的这个大模型的厂商需要去做应用，做一些功能，然后来提高用户的粘性。那正好就说到第四天的发布了，因为第四天发布的就是一个这样的功能，是叫canvas。当然这个也不行，cloud在半年前就已经有了artifact，然后当时artifact发布的时候还是得到了大量的好评，确实对生产效率的提升也很有帮助。来请二位介绍一下canvas是什么，以及如果可以的话，再介绍一下它和artifex的区别。",
      "speaker": "发言人1"
    },
    {
      "time": "00:25:45",
      "text": "我来说一下，其实如果先说artifact，这个东西的话，你可以理解为当大模型生产出一个比如说HTML，或者是再加点JS这样的一个内容之后，它是一前端页面，在cloud里面可以把这个页面直接渲染出来，你可以看它的页面好不好。然后同时的话，如果它生产是一个markdown，我也可以拿浏览器把它渲染出来，也可以实时的去看，然后看最终的效果。这是一个非常有利于我看这个前端代码的一个东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:19",
      "text": "而ChatGPT它的这一个canvas其实最早应该是脱胎于它有一个叫做代码编译器的功能。就是你让他你给我写一个鸡兔同笼算法，他可能会把这个代码还有代码框展示给你，还可以把这个代码运算给你。它后面是跑了一个相当于一个python的服务器。那在之后除了能够跑代码之外，它还可以在上面给你展示各种各样的文字，你可以对这个文字进行一些修改。",
      "speaker": "发言人2"
    },
    {
      "time": "00:26:53",
      "text": "其实我有看到一个网上很有趣的用法，就是有一个人他请加GPT给他写了一篇论文去做批注，然后他还请对方模仿一个哲学系教授的风格来去批注，最后在commas里面展现出来的，就很像是一个在word里面看到那样的批注。首先有一篇是他原来的文章，然后批注又是在侧边栏再单独出来的，然后还会指向到底批注的是文章中的哪个部分。这个我看到之后也觉得还蛮惊喜的。这个和原来直接请大模型帮我改写我的文章，感觉又进步了，又升级了。从交互层面。",
      "speaker": "发言人1"
    },
    {
      "time": "00:27:32",
      "text": "其实这段时间OPPO I私底下是发了好多的货，但是他没有开发布会，也没有用任何的新闻方式去露出，这点其实蛮有趣的。你包括你刚才说的这个功能，我一篇文章放进去，然后让他对我进行批注展示出来。这个功能是来自于OpenAI前一段时间，上个月，他偷偷的放出来的一个叫做predicted API或者叫做predicted的一个模式，叫预测性输出。就什么呢？我把一篇内容给他，我告诉他怎么改，他就可以快速的把这篇文章要改的地方，或者是需要批量去订正的地方给它标志出来，并且修改出来。这是一个它上线了但一直没有发布的功能。那我相信在这个cmos里面它使用的我觉得猜的应该就是这个功能。",
      "speaker": "发言人2"
    },
    {
      "time": "00:28:36",
      "text": "对，这个其实还真的是挺有用的，我之前一直在用notion AI，就是会在notion里面请他直接帮我改东西。但他也就是直接改了就改了。他不会是像比如说你原来请一个同事或请一位律师帮你改一个文件的时候，他会保留那个修订记录。然后你自己去决定我要不要接受这一点，我拒绝下一点。对，但是现在其实OpenAI也可以。",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:00",
      "text": "做到这一点了。然后这里面它还有一个很有趣的点，就是因为它只是修订，它并不是重写，他可以快速的去处理一长篇的内容，并且保持你的主体结构不变。这个事儿除在修订文章之外，在修改代码上面也是非常的有用。很多时候你在让他修改一个代码时候，因为你你的代码会和其他的老代码做交互。一旦你动了结构，有时候会非常的麻烦。如果它只是修改前部分参数，并且是这个参数之间如果有关联，它会把这个关联一块修改掉，就会非常的实用。这一块也是预测性输出的一个用法。",
      "speaker": "发言人2"
    },
    {
      "time": "00:29:42",
      "text": "藏师傅有没有什么要补充的？",
      "speaker": "发言人1"
    },
    {
      "time": "00:29:43",
      "text": "他的做负责开发的那个功能的一个人，在今年10月4号发的时候，是他写过一些内容，就是说他怎么思考这个功能的对class的核心区别和add fix有两个点elements的。就是他的一个目标，就是尽量不让你去想什么时候该触发，什么时候不该触发，什么时候该用什么不该用。他会让AI决定去给你。它是一个展示性的方案，就是说我用一个更友好的方式去展示一些不好在对话中展示的内容，这个是核心。就比如说文案也是，长文本也是，然后那个外部渲染也是。",
      "speaker": "发言人3"
    },
    {
      "time": "00:30:23",
      "text": "但是canvas那个作者他的想法是他想要打造AGI的一个终极界面。他想象中的AGI终极界面是一个空白画布，就是你怎么样去调整它都行。然后他核心的话是想作为一个创作伙伴去帮你去创作或者给你指导。这个就解释了为什么刚才说的那个批注那个功能，这个就完美的符合一个创作伙伴应该做的事情。",
      "speaker": "发言人3"
    },
    {
      "time": "00:30:49",
      "text": "我们想象就是刚才袁晨说过，就是我们想象中的同事去在工作的时候是跟你怎么协作的，他就是会评论你的东西。好，你可以给你建议，你可以选择改，也可以选择不改。然后在代码里也是，就是在代码review的时候也会我会去给你这个东西去做一些标注，或者做一些注释，你可以选择改，也可以选择不改。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:15",
      "text": "对他是一个以创作伙伴的形式去做的一个功能，所以他俩本质上其实是不太一样的，所以他就衍生出来这么多不一样的功能。就比如说开发的其实很重，对吧？它有很多功能其实就是在模拟一个创作伙伴该对你的内容做的一些事情。Airfix其实就是一个很简单的愿景，就是说把对话内容里。不好展示的内容拥有一个更好更适合对吧？比如说长文本之类的展示形式给你展示出来。对我觉得这个是核心的。两个根本性不一样，导致他俩的这个功能设计上不太一样的东西地方。",
      "speaker": "发言人3"
    },
    {
      "time": "00:31:48",
      "text": "我觉得这个其实还是产品哲学的不同。然后说到这里，其实我会感觉2025年非常值得期待的一个点就是在chatbot的这种传统交互之外，会大家发现有什么新的交互。这在很多地方都已经开始在萌芽了不只是在这个AI coding，像curse，然后也不只是David带来的a agent这样的模式，然后也包括看到的canvas，甚至还包括we craft的纹身图和图生图，也包括像we craft的这个无线白板这样的去做图片编辑的模式。我觉得这很多，这个感觉都有点数不过来，就各种各样的这种产品创新在大量的发生。这个还蛮值得期待的，也是上一周和莫妮卡的小红在录播客的时候，他有提到在2024年有点boring。因为感觉还是是ChatGPT3.0发布的chatbot这样的和AI交互形式的线性外推。但是到2025年尤其值得期待的一个特别大的原因，就是各种各样和AI交互的这种用户体验交互方式已经在雨后春笋的发生了。",
      "speaker": "发言人1"
    },
    {
      "time": "00:32:54",
      "text": "然后到第五天，第五天就是给苹果站台，这感觉像一个公关发布会一样。就是发现了念了一篇PR文章，告诉大家你们可以在苹果里面用到ChatGPT了。这个没什么特别好讲的那我们就到第六天，第六天是for o的这个实时视频通话和视频理解，然后包括和圣诞老人的通话。这个其实是在社交媒体上有一点小水花的，因为很多博主就会用ChatGPT去和圣诞老人聊天开玩笑。你们在第六天看到这样的发布之后，有一些什么样当时的感受或者想法吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:33:30",
      "text": "高级实时语音，这个是一个很极致的一个最让人感觉到这个东西存在智能的一个方式。对，就是可能你说O1或者O3，普通用户根本不理解这个东西有什么意义，对吧？不就是分，而且我也用不着吧？但是对于实时语音通话来说，普通用户会觉得这个东西真的好厉害。因为他他就是模拟了一个科幻电影中存在的一个场景。对，所以就看到你只要在比如说你在小红书或者在抖音上发，你用这个实时语音做的一些事情。就比如说很多人我们看有些研究生拿他去让他认识这个化学药制剂，让他去指导自己怎么去配那个实验。然后或者说做这种跟GPT谈恋爱这种对，其实就是很很戳人，很容易引起普通用户的共鸣。",
      "speaker": "发言人3"
    },
    {
      "time": "00:34:19",
      "text": "对，包括练口语，然后包括练习模拟面试，都变得很有用。然后我自己也试了一下，因为同期还有界面的2.0也在发一样的东西，就可以打开摄像头，你直接举一个东西问他这是啥，这个识别率还是蛮准的。我甚至指着我墙上的一张海报问他，这是一个电影节的海报？你告诉我这是哪一年在什么电影节的海报？对他这个也都可以给出他的猜测。",
      "speaker": "发言人1"
    },
    {
      "time": "00:34:45",
      "text": "我补充点信息，在这一天的发布中，他的两个主要的卖点，一个是可以视频通话了，一个是可以共享屏幕了。但其实他话说到这儿很久没说一，我们先说一下视频通话。如果我们去翻OpenAI，在过去年中它的一个无论是对外投资还是对外合作，你会发现这家公司去涉及了很多线下和硬件相关的场景。如果ChatGPT能够很丝滑的，比如说教你干什么，教你去煮咖啡，教你去做化学实验。那么这个功能也可以迁移到他接下来或者之前投资的那些硬件产品当中。那这个就变成一个相对来讲会王炸很多的东西了。而我们会发现这个里面它的技能点也好，它们的技术路线也好，是一模一样的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:35:45",
      "text": "我们看到这个化学实验，你拿摄像头去兑的一个化学设备。那么如果这个摄像头这个插值BT是内置在这个化学仪器里面的？如果这个东西再和一些机械臂结合的，那这个东西就可能会变成自动化的。就是关于这个实时语音的这一块，视频电话这一块。",
      "speaker": "发言人2"
    },
    {
      "time": "00:36:04",
      "text": "第二个的话是共享屏幕。大家可能会记得在今去年，微软是发布了一个叫做copilot的品牌。其中一个很有趣的点是你可以你和你的电脑可以相互的对话，然后你的电脑可以自主的去干一些活。在这里面就有一个很有趣的事儿，你需要把这个信息，把页面上的信息去传给你的这个助手。这个是这一个功能，据传可能是被放弃或者搁浅了。但是你会看到在ChatGPT的这一个发布里面，它可以去监控其他的应用的一些信息。我并不知道它的监控信息到达了一个怎样的一个程度，但有可能这就是和苹果的一个合作，可以拿到很深层的信息。那么在移动设备上，这个东西就变成了一个额外的一个外挂。比如说我是炉石玩家，那我可能边打炉石我就边问他，那这以后这张牌怎么出？",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:08",
      "text": "我们其实待会儿也会聊到，他在后面还有发一个客户端的一个功能，大概是第11天的时候也是类似的。就他可以这个读屏可以理解你屏幕上不管是编程，还是是你在玩什么游戏，甚至是你在和别人聊天，他也可以给你一些如何回复的指导，理论上都是可以实现。",
      "speaker": "发言人1"
    },
    {
      "time": "00:37:27",
      "text": "的这一个做法其实说白了是绝了很多的copilot的产品的路了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:37:34",
      "text": "这就是让大家想到这个经典的AI创业的困境，就是你做的东西会因为OpenAI这样的大模型公司的发布会而感到开心兴奋，而还是你会感到担心和绝望。OK好，那我们再看第七天，第七天是发布了这个项目的功能，就是你可以把一个项目里面的各种各样的文件全不丢到一个文件夹里面，然后再去和这个文件夹进行对话。这样这个模型就可以有一个知识库，有一个上下文，可以更好的来给你一些回复。这个其实也是cloud在半年前就有的功能，OpenAI现在才加上。然后这个做出来之后，二位有看到一些有趣的用法吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:38:16",
      "text": "具体的预训练或者说模型训练的细节我可能不太知道。但是其实这个功能和刚才我说的刚才说的artifact的功能就有一个特点。就是说我们在推理的过程中，或者说我们在模型训练的过程中，你要对语料进行分析和归类。然后你要去识别哪些是高质量的语料，然后再把拿拿再把这些合成数据拿去再训练。那么规律就有个核心的问题，就是很多内容都是开放性的，你其实不太好去验证的。语言模型输出的内容的对话的价值，你要想他拿想拿去再训练的话，可能会有一些问题。",
      "speaker": "发言人3"
    },
    {
      "time": "00:38:50",
      "text": "这两个功能就从某种程度上解决了一个问题。比如说project，我放在project里的所有文件以及我跟他的所有对话，基本上应该都是一个主题的。如果对话人数多的话，我们通过一些其他的数据筛选方式其实能筛出来。这就解决了一个问题，就是优质的对话的一个归类。同时还附带有一些现实的可能非合成数据的一些语料，这个其实对模型训练或者对数据收集是很有帮助的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:39:19",
      "text": "Affect也是一样，就是说那个cloth的affect其实在分享的。我只需要去分析一下分享的数量，就分享的能点击的数量，我就能判断一个大元模型生成代码的基本上它是正相关的。它的代码质量或者说对话的质量是正相关的。那么在代码这一层面或者说长文本这一层面，我就能去把它筛出来，去作为一个语料，这样就减少了一个筛选的成本，对于模型训练本身或者是数据本身收集是有非常好的正向的作用的。就是可能我们会在很多其他的优秀的AI项目中以后都会看到越来越多这种设计。我看到这个官刚。",
      "speaker": "发言人3"
    },
    {
      "time": "00:40:00",
      "text": "其实有一个不错的例子，就是把一个求职者的他的各种各样的简历，他过去他的这社交媒体的所有的链接等等，都放到了一个项目里面。这样就可以让模型更好的了解你是谁，同时应该就可以请OpenAI来给你一些职业上的建议，或者和你做一些模拟的面试。",
      "speaker": "发言人1"
    },
    {
      "time": "00:40:21",
      "text": "我想讲一个去年差不多这时候的事儿。在去年年底的时候，open是更改了一版他的隐私协议。在这版隐私协议里面他提到了作为ChatGPT的用户，你的任何时候和open s的信息的交互。无论是在ChatGPT里面，还是和ChatGPT的社交媒体的交互，这些数据都可以被open I拿走当成训练语料。当时的话随之发布的是GPT s其实当时我们说的open and那个agent，在这个里面的话，就像刚才张师张师傅所说的，一方面你是更可以更方便的去使用ChatGPT了。另外一方面的话，你也为了这一个便捷性帮OpenAI做了数据标注。这是一个非常聪明且不会太过于让大家反感的事儿。",
      "speaker": "发言人2"
    },
    {
      "time": "00:41:18",
      "text": "对我觉得这里面其实也是大家都在追求数据飞轮，对吧？在一个工具应用没有壁垒的情况下，它也形成不了社交飞轮的情况下，怎么能够增加用户的粘性？好，我们进到第八天，第八天是ChatGPT的搜索全量开放，然后搜索的界面和搜索的体验都有了各种的优化。然后这个二位有体验下来什么样的感受？",
      "speaker": "发言人1"
    },
    {
      "time": "00:41:38",
      "text": "我对他没有什么感知。就是它的整个的搜索质量和这个结果质量，在移动AI搜索产品里但凡有的用，我都不会用它去搜。我哪怕我自己用谷歌。",
      "speaker": "发言人3"
    },
    {
      "time": "00:41:52",
      "text": "那我们就跳过第八天，进到第九天第九天是发了开发者用的各种API。然后这个也是大聪明在一开始回答第一个问题，就这12天有哪些值得关注的重点发布里面特别提到的一点。直接请大聪明来给我们介绍一下第九天发布了一些什么，以及你为什么认为他那么重要。",
      "speaker": "发言人1"
    },
    {
      "time": "00:42:11",
      "text": "总的来讲的话，是从官方说明里面，他发布了OA的正式版的API，之前的是预览版。它的real time的API就是我们的高级的语言交互的API，是调价了，并且是有SDK。之前的话你必须得自己去写这个兼容，现在你有直接的那接口可以去调用了。第三个的话是它新增了一种新的微调方式，非常有趣，叫做偏好微调。",
      "speaker": "发言人2"
    },
    {
      "time": "00:42:43",
      "text": "稍微再细讲，我们来说下这事儿为什么重要。我们都说2023年我们当时是有了agent然后今年彭博这生产面前A症的需要爆发，我们会有慢慢的会让感知，也包括是扣子的成长。在这些agent成长的背后有一个非常重要的技术的革新，这个革新叫做结构化输出。什么叫结构化输出呢？比如说我希望让我家灯把它调一半的亮度，我跟灯说实话这个灯不会理我的他只能接受一什么信息呢？就比如说像Jason这种指定某某灯，是第19号亮度50%这么一个结构化信息，那么AI可以充当这个翻译器。",
      "speaker": "发言人2"
    },
    {
      "time": "00:43:34",
      "text": "在去年时候，在我们GPT4那个版本里面，叫做0613那版本里面。那时候官方还没有一个比较标准的一个结构化输出的方法，他们有一个叫做方程号，不过也不是很稳定。如果他只通过我们所有的泡沫技巧的话，我完成这一个结构化输出。而当你给我从78%到60%，它的成功率是35.9%。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:04",
      "text": "很多时候就发现他好像也work了，那只不过是AI在后面多试了几次，你总是能试对了，一次不成再试一次。而直到今年4月份的时候，这一个成功率变成了75.3%。而到了今年的这一个五月份的时候，这一个成功率变成了86.4%。",
      "speaker": "发言人2"
    },
    {
      "time": "00:44:30",
      "text": "而在最近的这个版本里面，也就是8月6号更新的时候，它带来了一个叫做结构化输出的这么一个标准接口。在严格模式下，这个接口的输出质量能够达到100%，就是100%成功，这个事情就很牛逼了。所以说我们看到8月6号之后，我们的很多的agent的工具。比如说是可的age版本，或者乱七八糟的版本，它才从雨后春笋一样的出现，因为它的成功率提高了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:45:05",
      "text": "我们再回到我们上面所说的这几个东西。第一是O1OE，它是一个非常强大且牛逼的思考工具。如果我们只拿它去写文章，那无所谓。如果你希望让O一的这一个生产出来的内容能够作用于你的日常的工作。无论是你的机械控制，你的IOT的控制，你一定需要一个结构化输出。在这一次发布之前，在第九天发布之前，OE是不存在结构化输出的。或者说你需要自己再通过一些奇怪的方面技巧让它结化输出，但这是不稳定的。而第九天的时候它支持了标准的减宽输出，它支持了这个方向靠他就可以百分之百的将这一个高质量的思考用于你的日常设备的这么一个控制。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:00",
      "text": "同时的在real time API里面，它是新货的调价。而这里面有一个没说的是real time API它也支持了结构化输出。这个事情意味着什么呢？OE他需要思考很久，思考半分钟，但很多时候我并不需要你思考这么久，我要关个灯，思考这么久干嘛？我希望我这边说了，你那边就关灯了。那么real time API我们实测的话，它的延迟是低于300毫秒的。也就是说我和AI说了这件事儿，0.3秒以内我的灯就关了，它里面也支持了这个结构化输出，这是第一点变化。",
      "speaker": "发言人2"
    },
    {
      "time": "00:46:36",
      "text": "第二点变化的话，是u time API每每小时的消耗是50美金。50美金意味着什么呢？如果要把产品化的话，我必须要找到一个每小时能帮我赚200百美金以上的场景。我的天哪，每小时赚200美金以上的一个线上场景，而且只能通过语音聊天，反正我是不太能想到这个场景在哪。而这个里面的话，在u tape API里面，它新的去蒸馏出来了一个mini的模型，它的成本在每小时5美金。虽然每小时二十美金场，每小时200美金的产品我找不到，但每小时20美金的场景是有的。比如说给海外的这些学生去辅导功课，去接到他们的这个电话的一个安靠。也就是因为此，real time的API具备了可商业实践的可能性。",
      "speaker": "发言人2"
    },
    {
      "time": "00:47:34",
      "text": "第三的话，它发布了这么一个SDK。其实并不是所有的同学都很擅长去玩语音的那一套模型的。而且尤其是在这一套模型里面，它是用的那个web socket，是很多人很熟的那在新的发布SDK之后，你可以直接的去调它的这么一个模型了。并且这里面也支持了可能很多人熟悉的这个web RTC的这么一套，这使得real time的API能够被很多人去商用了。",
      "speaker": "发言人2"
    },
    {
      "time": "00:48:09",
      "text": "但这个里面隐藏着一件事儿，他没说以前我们叫做端到端的模型，就语音到语音，中间不过文字。而这一次的更新，它带来了一个叫做多端到多端的模型，怎么理解呢？它的输入包括你的文件信息、文字信息、语音信息、视频的这个多模态的信息，你可以同时输入给它。而同时输出的包括文字，包括放声号，包括语音。并且这里有一个很好玩的事儿，它输出的文字和它输出的语音是有关联，但不一定一样的。我再重复一遍，它输出的这一个信息，它的文字信息和它的语音信息是非常的有关联性，但不一定一样的。也就是说它并不是一个顺序的一个构建，而是同步的构建。而这里面的话还可以同时的去输出它的这个方程号的信息。",
      "speaker": "发言人2"
    },
    {
      "time": "00:49:15",
      "text": "这使得在一些教学场景，比如说我现在问这一个AI一个问题，你给我讲一下为什么哪三个和尚没水喝？它可以同时输出三件事。第一，他可以把三个和尚没水喝的这个动画画出来。然后有一个鼠标指着某和尚跟我说，这是大和尚，他不想挑水，想让小和尚挑。再去把鼠标移到小和尚去，说这是小和尚，他不想挑水，想让大和尚挑。然后下面同时的去说这个故事的背景，使得这样的一种程序构建成为可能。而在第九天之前，这一套东你是不可能出现的。这些东西的话其实他并没有在发布上说。但是你如果你去仔细的去读他的文档的话，你会发现这才是第九天发布的核心。",
      "speaker": "发言人2"
    },
    {
      "time": "00:50:10",
      "text": "我们回顾这12天的内容的时候，也有一个提醒，就是大家知道OpenAI很会做营销，所以这12天的内容很多是为营销而发布的。它不一定代表着最主要的技术进步和最关键的实力。然后另一方面，就是OpenAI也在一个激烈竞争的环境里面，所以它的发布有一些可能也不是他最牛逼的东西，他会做一些隐藏。他甚至通过这12天的发布，来去影响竞争对手的一些思考和节奏。所以大家除了看这12天的发布内容本身之外，也可以多去看一看他们背后的一些没有发布的东西，说不定也能挖掘出一些有价值的一些洞察出来。",
      "speaker": "发言人1"
    },
    {
      "time": "00:50:51",
      "text": "而另外的一个发布的话，叫做偏好微调。什么叫偏好微调呢？就是我可以让AI去输出什么，我喜欢师傅买家让让他去写。第二种还是对于ODE的这个强化不说了，而偏好微调是也是可以一个更进阶的。我不仅可以告诉ai我喜欢什么，也可以告诉AI我不喜欢什么。对，他是有点像是黑名单和白名单，我就不需要去给他挨个的在提示词里面去说，你不能这样，你不能罗里吧嗦的，你不能够去说各种冗余的话，你不能够使用怎样的语言，我直接把它微调进去就行了。这样话使它的稳定性能够获得提升。然后这几个事情同时作用下来，它其实奠定了接下来一年我们认为的那一套agent的爆发的可能性。",
      "speaker": "发言人2"
    },
    {
      "time": "00:51:42",
      "text": "所以其实在2025年我觉得还是蛮值得期待的。在各行各业应该都能看到各种agent可以更好的落地了。之前很多落不了地，还是最后实现出来的就是效果不够好，取代不了足够多的人工。现在第九天虽然是一个低调发布，但是被大聪明这么一解读，发现它的对整个应用生态的价值是很巨大的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:52:07",
      "text": "这里还有一个好玩的事儿，就是之前如果在没有这个叫做优化输出之前，在点之前我们所有的和AI的交互，我们虽然我们看到所有的agent都是一个chatbot，我们看到真的都是chatbot。那你可能说他干了很多事儿，但最终还是一个聊天方式给到你。但是如果他有了防尘套，再结合你的各种各样的IOT，或者是各种各样的其他的东西。它使得和线下设备，使得和我们的商业世界可以非常紧密的关联。",
      "speaker": "发言人2"
    },
    {
      "time": "00:52:38",
      "text": "第九天其实是非常硬核的一天，我们聊完第九天就到了第十天。第十天又变成了非常好玩的一天。你可以给ChatGPT正在打电话了，然后他发布了一个800的电话，你可以和ChatGPT通话。但是他又指这个抠搜搜的给了15分钟的时间，就感觉你稍微聊一聊，感受一下，感受一下未来是什么样子，但是时间有限，我们跳到第11天。第11天其实发布的是一个已经上线有段时间的功能，并不是新功能。就是ChatGPT的桌面版，可以读到别的应用的屏幕，然后根据他读到的屏幕的内容来给用户一些交互。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:16",
      "text": "这个我还没用，因为由于大陆用户用这个车的具体的问题，所以客户端一直尽量避免使用。对，但其实能看到说他因为我有个疑问，就是我我没用，我不知道他是读的平还是读的内容。就比如说如果说你选择的是一个，比如说x code或者是VS code，他读到的是这个AVS code窗口里的所有内容，还是说只是我划到的屏幕这块内容。就这两个意义我觉得是不一样大的。",
      "speaker": "发言人3"
    },
    {
      "time": "00:53:49",
      "text": "我理解他应该是可以读到内容的。",
      "speaker": "发言人1"
    },
    {
      "time": "00:53:51",
      "text": "他读的信息有三层。第一的话是截屏，他肯定能读到的。第二的话是它能够读到这个软件里面的内容，可以直接读。第三个的话，在读这个过程中，它会额外的强调你划线或者是鼠标选中的地方。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:09",
      "text": "以及它有上下文了。就你选中的这个部分的上下文，它全部都知道了。对。",
      "speaker": "发言人1"
    },
    {
      "time": "00:54:13",
      "text": "然后你把鼠标悬浮在ChatGPT的mac版的客户端的横幅上，在这个过程中你可以看到你选发送给ChatGPT是哪些东西。那就比如说我现在在写一个代码，然后同时我选中一部分。你他在思考过程中，你把鼠标宣布过去，你会看到他发送了s code的里面的某一个文件的信息。同时他也会重点的去标注哪些信息需要你去更用心的去读。在去查这个访问请求的时候是可以查到的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:54:50",
      "text": "最后就到了第12天，12天也是我们开篇聊的第一部分，就O3的这个震撼发布。然后刚才已经聊过了。好，我们12天的内容全部过完之后，最值得期待的看上去有两个，一个是O3的发布，而O3现在其实大家还只能内测，可以去申请，但申请的概率应该不是很高。然后应该还有一个预测是明年1月份，maybe大家可以用到一个缩水版的O3的mini。然后这是第一个重点值得关注的。第二个重点值得关注的就是发布的一系列针对开发者的API，这个对于应用，对于agent的繁荣，有可能大家想象不到的重大意义。然后各种工程师、创业者可以特别去关注一下这里面带来的新的机会。好，然后我们现在聊了12天下来之后，还想再问一下二位，在这次发布会上还有哪些值得一提的，或者说都没有被多数人注意到的一些小细节，你们能想到一些吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:55:52",
      "text": "有两个挺好玩的事儿，第一个是他每一次发布会的时候，比如说第一天他桌子上会摆桌子上后面的架子上会摆一个玩偶，第二天会摆两个，然后最后一天会摆12个，就是挺有趣的一个恶习玩。第二的话是他每一次发布的时候，他都会额外的去link你一些信息。那就比如说是多少天之后AGI来临，但这些信息我觉得更像是留给你一个悬念，让你猜你。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:23",
      "text": "好像是给这个媒体留一些标题。",
      "speaker": "发言人1"
    },
    {
      "time": "00:56:27",
      "text": "对，也就是说是open a在这种去通过link的方式去搞传播热点还是蛮有趣的。我就额外给你点信息，我也不知道你这是什么，你自己去猜。我故意给你留出一点好像是内部文件的东西。",
      "speaker": "发言人2"
    },
    {
      "time": "00:56:43",
      "text": "我其实觉得有一个值得关注的小细节，就是华人在OpenAI内部的这种重要性。然后包括O3发布的时候，其实有一位新出场的一位华人叫任宏宇，之前是北大的校友。之前传闻说o one mini，这里面有三位主要的华人在负责，除了任宏宇，还有Kevin和佳慧。张师傅你有什么注意到的一些细节的补充吗？",
      "speaker": "发言人1"
    },
    {
      "time": "00:57:06",
      "text": "华人这个事情确实是这12天整个的我觉得华人的比例甚至反倒比白人或者其他主意的人的比例都要加起来都要高。这个确实是open I现在一个非常大的变化。然后另外的话，昨天看到有一个人问了个问题，就是为什么印度人在这里边在AI领域没有那么。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:27",
      "text": "多好有趣的洞察？",
      "speaker": "发言人2"
    },
    {
      "time": "00:57:29",
      "text": "为什么没有印度人？就是说不是说多少的是没有。",
      "speaker": "发言人3"
    },
    {
      "time": "00:57:33",
      "text": "在前段时间我在新加坡那边参加open I的活线下活动。然后现场的也是见了发布会上的那一个mark，然后见了很多的offer的新老朋友。在这里面的话我和一些人聊就提到一个问题，就是提到谁可能会是OpenAI的这么一个有力的竞争者。我本来以为是cloud，大家都家都说cloud击败了OpenAI，然后我得到了一个不太是我这个答案的一个答案，我说什么呢？",
      "speaker": "发言人2"
    },
    {
      "time": "00:58:08",
      "text": "是谷歌，但这也不代表是open a的观点，是谷歌，为什么呢？其实每首先两天两点。第一，每一个模型都有它的生命周期，你能不能在模型的这个生命周期半年到一年之内，把这个训练模型的成本收回来，这是一个非常大的问题。收回来成本什么呢？有足够大量的客户来买单。我们看到了谷歌它有自己的办公的一个全家桶，有自己的非常集成到位的这么一个生态环境，它是不愁卖的。而cloud它目前是绑定的亚马逊云，但亚马逊云它更多的是基于云的这个服务，而并不能够很快的去铺开。所以说cloud并不不一定，如果是真的更快起来，并不一定能够及时的收回成本。谷歌是可以的。",
      "speaker": "发言人2"
    },
    {
      "time": "00:59:05",
      "text": "open I应该也是可以的。其实这里让我想到确实不同的观点在这个时候会碰撞。就广利在最近一次被问到说七家巨头最看好谁的时候，他提到的是亚马逊。因为他认为这个anthy c和亚马逊之间的合作是非常健康的。而在亚马逊的财报里面也能够看到这个AI带过去的收入是百分之百的增长。基于author c再加上AWS的云服务，它形成了一个协同作用。所以在未来亚马逊的实力也是非常可期的。因为我觉得整个聊下来，感觉还是2025年会有挺多风云变幻的，会有很多让人感到兴奋的事情会发生的。因为我们这一期是今年可能是最后一期了。然后也特别想问二位，在2024的年底再回顾这一年，你们印象最深刻的AI领域的一个技术突破或者产品突破是什么？可不可以先请张师傅来回答这个问题。",
      "speaker": "发言人1"
    },
    {
      "time": "01:00:05",
      "text": "我觉得最重要的两个就是，第一个是cloud 3.5的代码能力突破，尤其是前端代码。第二个是server的发布和多模态输入输出一起的这样的一个操作。感谢open I当时在sora发布的时候，放了那么多比较详细的再细节出来，让我们看到路径，才促成了后面一系列的不管是图片模型，我们有flex对吧？或者说我们有更多的这种海螺王位可林这些视频模型，更好的视频模型让我们可以用。另外的话就是多模态输出的这个东西，让整个的视频音频或者更多模态内容生产在H的层面变成了一个可能。就这两个事情结合起来，我们明年能看到更多的自动化的内容生成AI产品一直都受限于工具这个属性，无法构建壁垒，无法构建，让更多的普通人用上。在明年可能这个东西会带来一个比较大的变化。就是说我们在内容生产上会让更多的普通人能感受到，享受到更多蓝牙生产的针对他自己的内容。",
      "speaker": "发言人3"
    },
    {
      "time": "01:01:10",
      "text": "对cloud的话就是另外一个代第二个代码能力。代码能力的话，尤其是采用代码能力的话，它是一个突破性的进展。就是比如说我们刚才说的curse或者说David，为什么它十月份之后OK了那一个就是刚才大聪明说的agent就是结构化输出这些能力。另外的话就是cloud 3.5，它的代码能力在比如说在SSSWE这种指标上真正变得可用了，才会变得OK对，然后我一个感触是，我的朋友他是一个设计师，就是完全不懂开发的设计师。我那天给他展示了一个boat点6这个工具，他以前根本不敢碰这些开发这些东西，他觉得不可能学不会。但是那天我第二天我给他展示之后，我再找他的时候，他给我展示了一个应用。他在学粤语，粤语他用boss写了一个普通话转粤语的工具。那工具做的很好，就是他把想到的一些都写上去了，然后他是完全真的完全没有开发机，他他都怕这个东西，就是这个东西带来的带给普通人或者带给有创造力的人的的的变化是非常大的。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:15",
      "text": "每一年我们会看到更多的这种案例。比如今年我们有小猫补光灯，有华生？还有一些其他的，你比如说赵春祥，可能明年会看到更多这个案例，他完全解放了一个人的创意。",
      "speaker": "发言人3"
    },
    {
      "time": "01:02:28",
      "text": "很棒。其实2024年即将过去，就是看过去一年是有的人觉得AI进步是惊人的，自己的日常工作有一半以上都可以让AI自动化帮着处理。但也有一些人觉得，好像没有啥特别的进展，用来用去都还是聊天界面，还是那一套。对，但我是认为两种看法或许都有道理。但是如果你只用月，只用kimi只用豆包，只用ChatGPT和cloud的网页版，可能会真的觉得AI的进展不大。但是如果用过了cursor devin或者we craft等等的工具，我相信大家是能够感受到AI在过去一年的巨大的进步的那在十字路口，其实我们一直有一个关键词叫做AI时代的积极行动者。这个积极行动有一个很重要的行动的指标，就是去积极的使用各种新的工具。所以真的在这里还蛮推荐大家去花点时间试一试这些新的工具，感受一下扑面而来的这种进步。",
      "speaker": "发言人1"
    },
    {
      "time": "01:03:25",
      "text": "然后说到2024年让人印象深刻的AI突破，其实我自己是认为是年底用到的。David然后他让我看到了一个说了很久的agent到底应该长成什么样子。第一次觉得AI变成了一个真正的像同事一样的一个agent，而且是一个智商、情商向上，管理能力、项目规划能力方方面面都很强的agent。所以我自己也很期待在明年看到不止在AI coding编程领域agent的不断的进步。也希望看到类似的的交互范式可以泛化到各种各样的领域。然后其实大聪明也有提到，就是在agent的进步的背后是function code成功率的提高。然后也想问大聪明，2024年最让你印象深刻的AI的突破是什么？",
      "speaker": "发言人1"
    },
    {
      "time": "01:04:17",
      "text": "我个人的视角可能是更偏向于项目方，所以说每当拿到一个新的AI的产品之后，无论是cosa还是保佑之类的，我都会想这个里面是调用了哪些API，然后是怎样的串行或者并行的去调用的。然后把这个东西给解构出来，最终再套上了一个怎样的壳。其实我们看到各种各样的非常3 cy的AI应用，都可以把它拆解成几个OpenAI API的组合方式，这是一定的。这个时候，当我们去看到我们明年或者接下来几个月会有哪些新的玩法的时候，有一个非常tRicky的做法是每个星期去过一下OpenAI API的变化和里面的变更。就比如说是刚刚提到的方程号从30%的成功率变成了100%的成功率。那在这一个机遇下，它能够带来哪些的变化？我这个人有习惯，就像刚才提到的，我每个星期都会通刷一遍文档。",
      "speaker": "发言人2"
    },
    {
      "time": "01:05:28",
      "text": "这个过程中我自己也总结一下，就是今年基本上OpenAI的各种的API的变化，或者是产生的应用，都是围绕着一个词儿结构化输出。怎么这么说呢？是在去年年初的时候，三月份的时候，他open I是发布了第一版的结构化输出的方案。还并不是以API的方式给到的，而是以一个内测的方式，你给open a一个压尾文件，在某些调用的情况下，它可以给你一个结构化的一个Jason。然后直到去年6月份的时候，open I发现了agent这么一个可落地的场景。去找了很多做A镇的开发的朋友，然后同时也表示会进一步的去迭代这个结构化输出的方案。",
      "speaker": "发言人2"
    },
    {
      "time": "01:06:20",
      "text": "在去年11月6号的时候，OpenAI悄悄的啊不要悄悄的，是低调的发布了一个模式，叫做Jason mode。这个时候预示着结构化输出成为一个主流的一个重头戏。而在今年的时候我们会发现，无论是实时交互的API都不思考的API和等等等等的这么一个API，它其中都会去围绕着结构化输出的成长。而每一个产品最终落地的时候，都预示着都是对应着这一版结构化输出到达了一个新的规范。而在现在的的一个新的一个范式里面，就是结构化输出将同时的从你给我一个信息，我给你一个遮挡文件，变成你给我一堆信息，我同时给你一堆的这份文件，让你同时有多个手去操作不同的事情。而每一件事情的操作的成功率都从30%变成了100%，使得AI可以去handle一个足够大足够复杂的交互。在我看来，于是2024年最令我印象深刻的突破就是结构化输出。从一个tRicky的玩具变成了一个真实的，能够影响现实世界的，能够影响我们的开发者生态的项目生态的一个非常核心的因素，但这个因素是隐藏在背后的，并不为大家所见。",
      "speaker": "发言人2"
    },
    {
      "time": "01:07:52",
      "text": "我们聊完了OpenAI这12天的发布会，然后也不得不提的就是在这12天期间，google也放了大招，发了GM的2.0，然后我自己用下来是感到挺震撼的。不管是他的这个flash thinking的这一个版本的模型的这种回馈的质量，然后包括他把他整个思考的过程也暴露出来，就思考的过程暴露出来的文本甚至超过了他吐出来的这个答案的文本量，你可以看到它是多么聪明的一个智能体，在认真的对待和认真的拆解你的每一个问题，一步一步的思考给答案。而且这个速度很快的，就是差不多也是几秒内就可以给到答案，这个比o one当时发的时候可快多了。然后同时还有他的多模态也感受这个很丝滑很流畅。然后想问一下二位，我们在看到界面的2.0的时候，当时用下来有些什么样的感受，或者有没有一些可以和大家分享的一些信息资讯等等我核心。",
      "speaker": "发言人1"
    },
    {
      "time": "01:08:52",
      "text": "的感受就是它的多模态输入输出。刚才其实大概说了open I也有，但是我就是其实没有一个地方可以让用户感受到他这个结果。但真正的那个视频理解真的是独一份的强视频理解。他如果我那天试了一个给他一个20分钟视频，那个视频是没有那个字幕的，让他去转录这个视频，然后根据视频的内容去给我整成整理成一个文章，他整个模型一下就给我把整个的这个整理出来了，而且和润色结果直接一步输出，这个很厉害。",
      "speaker": "发言人3"
    },
    {
      "time": "01:09:24",
      "text": "另外比如说我之前参考海信做了一个拆解，就是说给他一个一分钟的一个AI做的一个视频，就是多段AI做视频。其实是AI创作者做的视频，它有多个分镜，你的一分钟可能有十几个分镜。然后他给我输出每一个分镜的开始时间、结束时间，然后给我说出每一个视频，是分析视频的具体内容。那这个时候我可以快速的把那个视频复刻出来，就是基于我们刚才说的很成熟的这个DIT视频模型。就是他俩一结合的话，我几乎可以复刻任何一个视频。对，就是一步到位给他视频点击确定，把这次的是扔到视频生成模型里，直接自动剪辑，自动输出。对，配音如果他有原声的音，他有原声的语音，语音模型也可以用它直接出，这个是很厉害的对，这个是代表一个在内容生产或者在内容是视频内容生产上一个飞跃的效率进步。",
      "speaker": "发言人3"
    },
    {
      "time": "01:10:22",
      "text": "其实今天这一期聊到这里，我还蛮开心的，就觉得对2025的期待值是蹭蹭蹭的往上涨。感觉得到了非常多积极的信念感，相信2025会发生很多了不起的新的事情。然后也感谢二位。今天我们先聊到这，我觉得你们输出了非常多很独特的洞察。我看到了我们只看新闻发布会的这个新闻通稿本身，看不到的背后的一些细节和观点和对未来的影响。然后谢谢二位，我们一起期待2025，也欢迎2025你们再多来做客几次十字路口。如果你认为有朋友也会喜欢本期十字路口的内容，请转发微信推荐给他们。最后欢迎你加入十字路口的会员群，我们会在群里每天放送AI全球新闻，并且鼓励大家在群里聊天互动、交朋友，寻找未来的同路人。",
      "speaker": "发言人1"
    }
  ],
  "lab_info": {
    "summary": "本期《十字路口》节目探讨了人工智能（AI）技术的浪潮及其对各行业的深远影响，强调了科技创新与人文关怀交汇点诞生伟大产品的理念。节目中重点回顾了OpenAI发布的O3，这一在AI模型领域领先的突破性成果，尽管成本高昂，但通过长时间发布会成功吸引了全球关注，展现了极致的注意力经济运用。同时，对比了OpenAI与Google在AI领域的竞争态势，指出了结构化输出技术的发展对AI未来应用的重要性。节目末尾，主持人与嘉宾展望了2025年AI领域将迎来更多突破与变革，鼓励听众保持对新兴技术的好奇心与探索精神。",
    "qa_pairs": [
      {
        "question": "在OpenAI连续12天的发布会上，最值得关注的重点是什么？张师傅认为在这12天的发布会上最值得关注的重点是什么？",
        "answer": "最值得关注的重点包括O3的发布，它带来了遥遥领先的模型，并且在发布期间隐藏了一个细节，即第九天针对开发者的一系列更新，特别是允许在OE和real time时进行结构化输出，这为明年AI agent的爆发埋下了伏笔。张师傅认为最值得关注的重点也是O3的发布，因为它再次引领了整个行业的发展方向，尤其是在预训练模型的发展上取得了明显进步，提振了整个行业对未来发展及投资的信心。",
        "time": "00:02:42"
      },
      {
        "question": "如何让大家感受一下O3的强大之处？",
        "answer": "O3在codeforces编程竞技平台上的得分超过了OpenAI首席科学家，达到2727分，排名人类第175名，展现了其强大的计算能力和学习能力。",
        "time": "00:04:49"
      },
      {
        "question": "O3发布的单任务成本为何如此高昂？",
        "answer": "O3有两种版本，低计算量版本任务完成成本约为20美金，而高计算量版本的成本则达到了3500美金，相差约1000倍。这意味着用户在追求更高准确度时需要付出巨大的经济代价。",
        "time": "00:06:01"
      },
      {
        "question": "为什么对O3的发布感到如此兴奋，认为它是里程碑式的事件？",
        "answer": "因为O3在短时间内取得了显著的技术突破，达到了令人憧憬的未来水平，如果保持当前的发展速度，未来可能会出现无法被人类追上的AGI，并对数据和代码等领域产生深远影响。",
        "time": "00:08:33"
      },
      {
        "question": "关于AGI的定义，O3是否已经接近实现？",
        "answer": "根据目前AGI评测标准（如能进行经济价值工作的自动化系统），O3已近乎达到AGI水平，但随着技术进步，人们对AGI的定义也将不断更新和提高。",
        "time": "00:09:18"
      },
      {
        "question": "对于200美元的Pro会员，大家的感受如何？",
        "answer": "刚开始时，大家普遍觉得价格过高，怀疑是否有用户会购买。但实际上，有人购买并体验了OE pro后表示非常值得，因为它能高效地帮我完成项目规划和构思，节省了大量反复修订的时间。",
        "time": "00:14:23"
      },
      {
        "question": "OE pro有哪些具体优势？",
        "answer": "在使用OE pro时，它能将复杂的任务拆分得非常清晰，提供精准且具有建设性的意见，甚至在开放域的问题讨论中能给出全面而新颖的观点和结构化的解答。",
        "time": "00:16:26"
      },
      {
        "question": "你能分享一个使用OE pro的实际例子吗？",
        "answer": "我曾要求OE pro为我提供一年来与AI互动的总结大纲，它给出的方向很有价值，避免了重复信息和无关内容，让我可以按照这个大纲直接进行写作，这个功能很强大。",
        "time": "00:16:52"
      },
      {
        "question": "作为Pro会员，你能无限使用高级语音模式，这与API调用的成本相比有何优势？",
        "answer": "如果你是Pro会员，可以无限制地使用高级语音模式。如果通过API调用，平均每小时消耗50美金，那么只要与AI聊天达到4个小时，你购买的200美元就赚回来了。而且在使用过程中，感觉就像在和真人聊天一样自然。",
        "time": "00:17:40"
      },
      {
        "question": "RFT是什么？",
        "answer": "RFT是对OE（即O1）模型进行微调的一种方式，它的目标对象是从原来的大模型范畴转变为针对O1这一周agent形式的大模型微调。",
        "time": "00:19:17"
      },
      {
        "question": "Sora发布后用户反馈如何？",
        "answer": "Sora发布后口碑参半，有人认为其定价过高，且部分功能不如预期。例如，用户需要付费才能生成高质量的视频内容，而该功能在宣传中似乎并未明确指出其限制条件。",
        "time": "00:25:15"
      },
      {
        "question": "Canvas这一新功能有何特点，以及它与Artifex有何区别？",
        "answer": "Canvas是一个类似于云开发环境的功能，允许用户实时查看大模型生成的前端页面或代码效果。相较于Artifex专注于前端页面的渲染和交互，Canvas可能在功能展示和用户粘性提升方面有所创新。",
        "time": "00:25:45"
      },
      {
        "question": "OpenAI最近有一个叫做“预测性输出”的功能，能否介绍一下这个功能以及它在OPPO I中的应用情况？OpenAI的“批注”功能与Notion AI有何不同？",
        "answer": "这个“预测性输出”功能是OpenAI上个月低调推出的，它能够根据用户给出的修改建议快速标记出文章中需要改动的地方，并进行相应的修订。这个功能在OPPO I中可能被用于自动批注和内容修订，而且特别有用的一点是，它能够保持原文主体结构不变，不仅适用于文章修改，在代码编辑上也非常实用，能够避免因结构调整带来的复杂性。OpenAI的批注功能与Notion AI相比更为精细，不仅能够修改内容，还能保留修订记录，让用户自己决定是否接受每一点修改，更加符合人类编辑文本时的需求。",
        "time": "00:29:00"
      },
      {
        "question": "对于“预测性输出”功能的核心设计理念是什么？",
        "answer": "“预测性输出”功能的设计初衷是打造一个无需用户频繁思考何时触发或如何操作的智能工具，其核心目标是成为一个友好的创作伙伴，展示一些原本难以在对话中展示的内容，比如长文本、文案等，并通过展示性方案帮助用户更好地理解和利用这些内容。",
        "time": "00:29:43"
      },
      {
        "question": "ChatGPT在苹果站台后的实时视频通话和视频理解功能引发了怎样的反响？",
        "answer": "实时语音通话功能因其科幻电影般的体验而受到普通用户的高度关注和赞赏，许多用户通过实时语音进行各种实用操作，如学习化学知识、模拟面试、练习口语等，这极大地提高了用户体验，并且预示着智能交互方式的巨大潜力和发展空间。",
        "time": "00:33:30"
      },
      {
        "question": "关于ChatGPT发布的共享屏幕功能，它可能带来的应用场景有哪些？",
        "answer": "共享屏幕功能可能让ChatGPT能够获取并监控其他应用的信息，在移动设备上作为一个外挂工具，比如炉石玩家可以通过语音指令让ChatGPT提供游戏策略建议。此外，该功能也可能为ChatGPT提供更深层的应用信息，有助于提升模型训练的质量和效果。",
        "time": "00:36:04"
      },
      {
        "question": "关于项目文件归档与对话结合的功能，它对模型训练有何积极影响？",
        "answer": "这个功能允许用户将项目中的所有文件整合在一个文件夹中并与之对话，形成一个具有上下文的知识库，有助于ChatGPT更好地理解用户意图并提供回复。这有助于解决模型训练过程中语料筛选和优质对话归类的问题，同时通过分析分享数据也能为模型训练提供高质量的合成数据，减少筛选成本，提升模型性能。",
        "time": "00:38:50"
      },
      {
        "question": "在移动AI搜索产品中，你为何不会使用他们的搜索功能，即使在第九天的API发布后？",
        "answer": "我对他们的搜索质量和结果质量不满意，即便有改进，我仍习惯于使用如谷歌这样的其他搜索引擎。",
        "time": "00:41:38"
      },
      {
        "question": "第九天发布的重点内容有哪些，以及为何认为它是重要的？第九天发布的SDK和其他隐藏细节有哪些值得关注的地方？",
        "answer": "第九天主要发布了OA正式版API（之前是预览版）、实时API调价和新增了偏好微调方法。其中，结构化输出技术的革新尤为关键，它提高了AI处理指令的成功率，并且在8月6日更新后，官方提供了标准的结构化输出接口，使得在严格模式下输出质量可达100%，这一进步对agent工具的成功应用至关重要。发布的SDK使得开发者无需深入了解语音模型细节即可调用相关模型，同时引入的多端到多端模型可以同时处理多种信息模态并输出相关联但不一定相同的文字和语音信息，这对于教学场景和其他需要丰富交互的领域具有重大意义。此外，发布会上的一些未明确指出但隐藏的价值点，如优化输出和偏好微调功能，也对构建更强大的agent生态具有深远影响。",
        "time": "00:42:11"
      },
      {
        "question": "结构化输出在2023年的AI发展中的作用是什么？",
        "answer": "结构化输出技术在2023年随着agent的爆发而变得至关重要，它允许AI以更精确和高效的方式理解和执行用户指令，特别是在控制IoT设备等场景中，确保了高质量思考能被转化为实际操作。",
        "time": "00:45:05"
      },
      {
        "question": "real time API在此次发布中的变化和重要性是什么？",
        "answer": "real time API不仅支持了结构化输出，降低了延迟并提高了每小时消耗的成本效益（从50美金降至5美金），还具备了多模态输入输出能力，能够同时处理文件信息、文字、语音、视频等多种信息类型，并能同步构建输出内容，这为许多线上服务提供了更灵活、高效的交互方式，降低了使用门槛，也预示着商业实践的可能性。",
        "time": "00:48:09"
      },
      {
        "question": "对于接下来一年AI发展的展望是什么？",
        "answer": "预计在2025年，基于本次发布的技术和功能改进，各行各业将看到更多更好的agent落地应用，取代人工的可能性将进一步提高。同时，第九天的低调发布对于整个应用生态的价值巨大，对未来的发展具有重大影响。",
        "time": "00:51:42"
      },
      {
        "question": "在OpenAI内部，华人的重要性如何？比如在O3发布时，有哪些华人参与其中？",
        "answer": "在OpenAI内部，华人的重要性确实很高。例如，在O3发布时，新出场的华人任宏宇是北大校友，另外还有传闻中在o one mini项目中有三位主要华人负责，除了任宏宇外，还有Kevin和佳慧。",
        "time": "00:56:43"
      },
      {
        "question": "为什么在AI领域中没有看到印度人较多参与？",
        "answer": "目前还没有明确回答，但提到的是一个有趣的现象，并没有给出具体的解释。",
        "time": "00:57:33"
      },
      {
        "question": "在最近的一次讨论中，大家认为OpenAI的最大竞争者可能是谁？",
        "answer": "大家原本以为是cloud，但得到的一个不太一样的答案是谷歌，因为谷歌拥有自己的办公全家桶和集成度很高的生态环境，能够较快收回训练模型的成本；而cloud虽然绑定亚马逊云，但云服务特性可能不利于快速铺开。",
        "time": "00:58:08"
      },
      {
        "question": "对于2024年底回顾这一年，张师傅印象最深刻的AI领域技术或产品突破是什么？",
        "answer": "最重要的两个突破是：1）cloud 3.5的前端代码能力突破；2）server发布及多模态输入输出的操作。这两个突破将推动自动化内容生成AI产品的发展，使得普通人也能使用并享受到更多AI创作的内容。",
        "time": "01:00:05"
      },
      {
        "question": "对于2024年AI突破，大聪明有何看法？关于2024年AI突破，项目方角度有何见解？",
        "answer": "大聪明认为最深刻的突破是看到了类似David的agent能够像同事一样智商情商俱佳，管理能力强，项目规划能力强，并且在agent进步背后的功能代码成功率显著提高。从项目方角度看，2024年最深刻的AI突破是结构化输出的成功率从30%提升至100%，它成为影响现实世界和开发者生态的核心因素，并体现在各种实时交互API和思考型API的设计中。",
        "time": "01:03:25"
      },
      {
        "question": "对于Google GM 2.0的感受如何？",
        "answer": "Google GM 2.0的多模态输入输出令人震撼，尤其是其对视频的理解能力独树一帜，能够快速转录无字幕视频并生成高质量的文章，以及结合DIT视频模型实现视频内容复刻和自动剪辑输出，代表了内容生产效率的巨大飞跃。",
        "time": "01:09:24"
      }
    ],
    "chapters": [
      {
        "time": "00:00:00",
        "title": "探索OpenAI连续12天发布会的新功能与技术",
        "summary": "本期节目聚焦于OpenAI近期连续12天举办的发布会，探讨了除最后一天发布的O3外，还有哪些值得关注的新功能、新技术或看点。OpenAI的这一系列发布会不仅吸引了全球科技媒体的广泛关注，也使得整个行业聚焦于其身上，展示了营销策略的成功。节目邀请了归藏和大聪明，共同回顾了发布会期间的重要发布，探讨了这些新技术可能带来的行业变化和创业机会。"
      },
      {
        "time": "00:02:17",
        "title": "OpenAI新发布解析：O3模型与开发者更新重点",
        "summary": "OpenAI近期的发布会引起了广泛关注，其中O3模型的推出被视为一大突破，尽管其使用成本较高。同时，对开发者友好的API更新和对编程语言知识的补充，特别是在实时API更新和结构化输出方面的进步，预示着AI领域即将迎来新的发展。这些更新不仅为AI行业的未来设定了新的方向，也极大地提振了行业信心。"
      },
      {
        "time": "00:04:44",
        "title": "O3编程技能展示及其成本分析",
        "summary": "在code forces这一硬核编程竞技平台上，O3以2727分的编程得分，超越了一位知名科学家，位列人类选手中的第175名，展示了其惊人的编程能力。同时，O3的使用成本惊人，单任务成本达3500美金，即便是询问一个简单数学问题也需支付等额费用。O3有两个版本，低算力版本单次任务成本约为20美金，而高算力版本的准确率虽高，但成本也随之大幅上升。此外，正确率与消耗算力之间呈线性关系，意味着达到极高准确度将需要极高的计算成本。"
      },
      {
        "time": "00:08:10",
        "title": "O3发布对未来技术发展的重大意义",
        "summary": "讨论集中在O3技术发布被视为里程碑事件的原因，以及它对未来技术，特别是人工智能（AI）领域的潜在影响。O3的发布不仅在技术社区内引起广泛关注，而且被认为可能对程序员竞技榜单产生重大影响，并且预示着数据和代码领域人类可能无法追赶AI技术的进步。此外，讨论也涉及了AGI（通用人工智能）的定义及其对未来技术发展的意义，强调了学习能力作为AGI的关键指标，而不是仅仅拥有的技能数量。随着技术的进步，对于AGI的定义也在不断演变，预示着未来技术发展中对于智能的定义将更加注重其学习和适应能力。"
      },
      {
        "time": "00:11:26",
        "title": "回顾O3发布及12天的重要更新",
        "summary": "在过去的12天里，一系列的技术更新和产品发布引起了广泛关注。首先，满血版O一的上线和ChatGPT Pro会员的发布标志着一系列创新的开始，其中ChatGPT Pro会员以其大胆的定价策略引发了争议。随后的几天里，发布了包括OM Pro、强化微调RFT、正式版Sora和Campus功能在内的多项更新，这些更新不仅拓展了产品的功能边界，也提升了用户体验。特别地，对苹果全系接入GPT的支持、实时视频通话和视频理解能力的引入、搜索全量的开放、o one的API发布、以及支持在WhatsApp上与HIGP聊天等功能，展示了技术发展的快速步伐和广泛应用的潜力。其中，O3的发布被认为是行业内的一次重大突破，而O1 Pro的实际应用体验让人印象深刻，被认为是物超所值的。这些发布和更新不仅展示了技术公司的创新能力和对未来的展望，也为用户带来了更多便利和可能性。"
      },
      {
        "time": "00:16:48",
        "title": "O1 Pro的高级功能与应用体验分享",
        "summary": "用户分享了使用O1 Pro编写年度总结的经历，强调了O1 Pro相较于其他AI工具的优势，如提供建设性意见、高级语音模式以及对模型的微调（RFT）等。用户体会到与O1 Pro交流类似真人聊天的体验，尽管存在响应速度、成本和设备过热等问题，但总体上对其功能表示满意。此外，也提到了O1 Pro的成本对于开发者来说可能偏高，但预期未来随着价格调整，将吸引更多开发者使用。"
      },
      {
        "time": "00:21:21",
        "title": "Sora发布及用户反馈总结",
        "summary": "在发布会前的倒数12个小时，关于Sora的谣言开始流传，引起许多人的关注。Sora发布后，评价毁誉参半，逐渐转向更多负面反馈。特别地，提到Sora的服务要求用户付费200美元成为会员才能使用更多功能，比如生成高清视频。虽然在故事板功能和视频连接上有所创新，但视频模型的性能有限，质量提高不多。特别批评了图片视频功能，指出大部分情况下输出结果与输入无异，认为这是商业欺诈行为，对服务的宣传与实际可用性不符，是严重的诚信问题。"
      },
      {
        "time": "00:24:12",
        "title": "探讨sora发布及Canvas与Artifact功能区别",
        "summary": "对话者讨论了sora发布的新功能，特别提到了无限循环和故事版功能让他们感到惊喜。此外，他们注意到OpenAI这次没有发布API，强调了应用对于获取用户数据和认知的重要性。进一步讨论了Canvas功能及其与之前Artifact功能的区别，表明对提高生产效率和用户粘性的关注。"
      },
      {
        "time": "00:25:44",
        "title": "大模型产出内容的实时渲染与批注功能探讨",
        "summary": "讨论集中在如何利用大模型生成的内容，如HTML、JS代码或Markdown，实现实时渲染以方便前端页面的预览。特别提到了ChatGPT的代码编译功能，能运行Python服务器以执行代码，并展示其结果。此外，还探讨了一个创新用法，即使用ChatGPT进行论文批注，模仿特定风格提供侧边栏式的详细批注，增强了交互体验。提及OPPO私下发布的产品特性，强调了OpenAI预测性输出功能的实用性，该功能能够快速标识并修正文章或代码的特定部分，保持原结构不变，对于内容修订非常有用。"
      },
      {
        "time": "00:29:41",
        "title": "探讨AI功能开发与未来交互模式",
        "summary": "在10月4号，一位负责开发特定功能的个人分享了他对该功能的思考，强调了不需用户过多考虑触发时机和方式，而是通过AI自动决定，以展示性方案友好地呈现难以对话表达的内容，如长文本和外部渲染。此外，还提及了一个将AGI视为终极界面的构想，意在成为用户的创作伙伴，通过提供类似代码review的标注和建议来辅助创作。这一讨论揭示了产品哲学的不同以及对2025年AI交互模式创新的期待，包括AI coding、图片编辑等各种形式的产品创新正在大量发生。"
      },
      {
        "time": "00:32:54",
        "title": "ChatGPT功能更新及用户反馈",
        "summary": "在苹果平台的应用、实时视频通话和视频理解功能引起关注，特别是与圣诞老人的通话在社交媒体上引发讨论。这些更新被看作是朝着科幻电影中场景的现实化迈进，引起了普通用户的共鸣，并在实际应用中展现出巨大潜力，如化学实验指导、口语练习、模拟面试等。此外，ChatGPT的摄像头识别功能和共享屏幕功能的发布，进一步拓展了其应用范围，可能预示着与硬件产品的深度整合，以及对其他智能助手产品的挑战。"
      },
      {
        "time": "00:37:33",
        "title": "应对大模型挑战与利用AI提升项目管理",
        "summary": "对话集中在如何在OpenAI等大模型公司发布新功能后，AI创业公司应采取的策略。讨论了一个项目管理工具的功能，该工具允许将项目文件统一存储并进行对话，以便模型能更好地理解上下文并提供有针对性的回复。此外，还探讨了如何利用AI来分析和归类高质量的语料，以及这些功能对于模型训练和数据收集的积极作用。提到了一个实例，利用该工具帮助求职者通过整合简历和社会媒体信息，获得职业建议和模拟面试的机会。还提及了OpenAI隐私协议的更新，讨论了用户在享受便捷服务的同时，也为OpenAI提供了数据标注的劳动。"
      },
      {
        "time": "00:41:17",
        "title": "OpenAI发布详解与技术革新",
        "summary": "OpenAI在过去一段时间内进行了多项重要发布，包括ChatGPT搜索功能的全量开放和搜索体验的优化，以及针对开发者的API更新。特别地，发布了正式版的API，支持实时API和SDK，新增了偏好微调功能，以及引入了结构化输出的标准接口，极大提升了AI的实用性和交互效率。此外，还介绍了实时API的成本调整和SDK的发布，以及多模态输入输出模型的革新，这些技术革新为AI应用提供了新的可能性。"
      },
      {
        "time": "00:50:50",
        "title": "偏好微调及AI未来发展展望",
        "summary": "偏好微调使AI能够根据用户的喜好输出内容，允许用户指定喜欢和不喜欢的内容，类似于黑名单和白名单，提升了AI输出的稳定性。此外，讨论了对AI未来一年爆发的期待，特别是在各行各业的落地应用。还提到了ChatGPT的新功能，包括与用户的电话通话功能和桌面版的屏幕阅读功能，后者能根据屏幕内容提供交互。"
      },
      {
        "time": "00:54:50",
        "title": "OpenAI发布会重点回顾及细节揭秘",
        "summary": "在OpenAI的发布会中，O3的发布成为最受关注的亮点之一，目前仅限内测，预计明年1月将推出缩水版的O3 mini。另一个重点是针对开发者的API发布，这可能对应用和agent的发展产生重大影响。此外，还有一些有趣的细节被提及，如发布会中玩偶的数量变化和提供的一些悬念性链接，增加了发布会的趣味性。特别值得注意的是，OpenAI内部华人员工的重要性，以及在AI领域，谷歌可能是OpenAI的一个有力竞争者，这与谷歌拥有的生态优势相关。"
      },
      {
        "time": "00:59:04",
        "title": "2024年AI技术突破与展望",
        "summary": "2024年见证了人工智能领域的显著进展，特别是Cloud 3.5的代码能力突破和多模态输入输出技术的发布，这两大突破极大地推动了自动化内容生成的发展。此外，AI工具的运用，如David和Cursor Devin，展示了AI技术在提高工作效率、促进创造力释放方面的巨大潜力。展望未来，AI agent的进步及其在各种领域的泛化应用，预示着AI将成为更加智能、能辅助人类完成复杂任务的同事。这一年中，AI不仅在技术上取得了显著进步，而且在实际应用中展现出其为普通人带来便利和创新的能力。"
      },
      {
        "time": "01:04:16",
        "title": "结构化输出在AI应用中的突破与影响",
        "summary": "对话内容主要探讨了个人对于AI产品开发的视角，特别是如何通过分析和解构使用OpenAI API的AI应用，来理解其内部机制和创新点。强调了结构化输出作为AI技术发展的一个重要趋势，从最初的内测版本到后来的Jason模式发布，显示了结构化输出从一个实验性的技术转变为影响开发者生态和项目生态的关键因素。此过程中，结构化输出的不断迭代使得AI能够处理更复杂、更大规模的交互，显著提高了操作的成功率，从而对现实世界产生了实际影响。"
      },
      {
        "time": "01:07:52",
        "title": "探讨Google 2.0发布与未来AI展望",
        "summary": "对话中讨论了Google在12天内发布的GM 2.0版本，特别强调了其在速度、多模态输入输出以及视频理解方面的显著提升。参与者分享了使用体验，包括模型的快速响应能力、视频内容转录与分析的强大功能，以及对未来AI技术的乐观预期，特别是在内容生产领域的革命性进步。此次讨论还涉及了OpenAI的比较，并对2025年的技术发展表达了期待。"
      }
    ],
    "mindmap": {
      "children": [
        {
          "children": [
            {
              "children": [],
              "content": "持续12天，涵盖多项技术更新和新功能发布"
            },
            {
              "children": [],
              "content": "目的：展示AI技术在各行各业的潜在应用，激发行业新变化和创业机会"
            },
            {
              "children": [],
              "content": "主题：科技与人文的交叉点，探索AI时代的新可能性"
            }
          ],
          "content": "发布会概况"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "特点：遥遥领先的技术，高效回答复杂问题"
                },
                {
                  "children": [],
                  "content": "成本：高昂，每单任务约3500美金"
                },
                {
                  "children": [],
                  "content": "应用：高端研究和开发场景"
                }
              ],
              "content": "O3模型"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "强调实时API和结构化输出的重要性"
                },
                {
                  "children": [],
                  "content": "对AI agent的发展具有重大意义"
                }
              ],
              "content": "开发者API更新"
            },
            {
              "children": [
                {
                  "children": [],
                  "content": "sora：视频内容生成工具，受到一定争议"
                },
                {
                  "children": [],
                  "content": "canvas：提高生产效率的工具，与cloud的artifacts类似"
                },
                {
                  "children": [],
                  "content": "高级实时语音：改善交互体验，提供更人性化的服务"
                },
                {
                  "children": [],
                  "content": "project功能：改善团队协作和项目管理"
                }
              ],
              "content": "其他重要发布"
            }
          ],
          "content": "重点发布内容"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "多模态输入输出：提高了AI的实用性和交互性"
                },
                {
                  "children": [],
                  "content": "高级语音模型：改善实时交互的质量"
                }
              ],
              "content": "结构化输出：使得AI的应用更加灵活和高效"
            }
          ],
          "content": "技术细节和创新"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "预见AI技术将进一步融合进人们的日常工作和生活中"
                },
                {
                  "children": [],
                  "content": "开发者和创业者需关注结构化输出等技术，探索新的应用可能性"
                }
              ],
              "content": "期待更多基于AI的创新应用，尤其是在内容生成、代码编写和日常助手等领域"
            }
          ],
          "content": "对未来AI发展的展望"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "高级AI技术的商业化应用将带来新的商业机会和挑战"
                },
                {
                  "children": [],
                  "content": "需要关注AI伦理、隐私和数据安全问题，确保技术的健康发展"
                }
              ],
              "content": "OpenAI发布会展示的技术更新将促进AI行业的发展"
            }
          ],
          "content": "行业影响和展望"
        },
        {
          "children": [
            {
              "children": [
                {
                  "children": [],
                  "content": "鼓励大家积极体验和使用最新的AI工具，探索未来可能性"
                },
                {
                  "children": [],
                  "content": "建议关注OpenAI以及其他AI公司的动态，共同探索AI时代的未来"
                }
              ],
              "content": "2025年AI技术将带来重大变革，期待更多创新和应用"
            }
          ],
          "content": "结语"
        }
      ],
      "content": "OpenAI发布会总结"
    }
  }
}